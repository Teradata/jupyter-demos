{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f51cd2f7-a4c4-4edf-848a-b46e3cdd651b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Unstructured Text Analysis With BYO-LLM and NVIDIA GPU Acceleration\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a701f80-07b2-47ad-b2fd-2dcc597b97b2",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px;font-family:Arial\"><b>Introduction:</b></p>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "This notebook is designed for developers, data scientists, and AI practitioners who want to bring open-source Language Models (LMs) and Large Language Models (LLMs) closer to their data ‚Äî quickly, securely, and at scale. As organizations race to deploy AI applications, developers face key challenges: selecting the right model, minimizing data movement, ensuring security, and controlling costs.  Teradata‚Äôs Bring Your Own LLM (BYO-LLM) capability addresses these challenges by allowing you to deploy open-source <b>Hugging Face</b> models directly inside VantageCloud ‚Äî where your data already lives.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:18px;font-family:Arial\"><b>What is BYO-LLM?</b></p>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "<b>BYO-LLM</b> (Bring Your Own Large Language Model) is one of the VantageCloud Open Analytic Framework (OAF) key capabilities you‚Äôll use in this notebook which gives developers complete control over AI deployment in VantageCloud:\n",
    "</p>\n",
    "\n",
    "<ul style=\"font-size:16px;font-family:Arial\">\n",
    "    <li>Seamlessly integrate open-source models from Hugging Face</li>\n",
    "    <li>Eliminate the need to move data ‚Äî reducing cost and compliance risk</li>\n",
    "    <li>Leverage GPU acceleration for inference speeds up to 200x faster than CPU</li>\n",
    "    <li>Experiment freely without vendor lock-in, while keeping your data secure and your operations scalable</li>\n",
    "</ul>\n",
    "\n",
    "<img src=\"./images/BYOLLM_Flow.png\" alt=\"Architecture for BYOLLM\" style=\"width: 90%; border: 4px solid #404040; border-radius: 10px;\"/>\n",
    "<p style=\"font-size:18px;font-family:Arial;\"><b>Business Impact of Open Source Language Models (LMs) for NLP tasks such as Unstructured Text Analysis?</b></p>\n",
    "\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Language Models (LMs) are the foundation for solving Natural Language Processing (NLP) tasks such as unstructured text analysis ‚Äî enabling machines to understand, interpret, and generate human language. Language Models enable businesses to:\n",
    "</p>\n",
    "\n",
    "<ul style=\"font-size:16px;font-family:Arial\">\n",
    "    <li>Extract key information from documents, contracts, and research papers</li>\n",
    "    <li>Analyze customer feedback from emails, reviews, and social media</li>\n",
    "    <li>Power chatbots and virtual assistants for real-time support</li>\n",
    "    <li>Personalize marketing and customer experiences based on user interactions</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Through unstructured text analysis and open source LMs, businesses can:\n",
    "</p>\n",
    "<ul style=\"font-size:16px;font-family:Arial\">\n",
    "    <li>Improve operational efficiency through automation</li>\n",
    "    <li>Gain real-time insights into customer sentiment and behavior</li>\n",
    "    <li>Respond proactively to customer concerns</li>\n",
    "    <li>Stay competitive by adapting to market and customer trends</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"font-size:18px;font-family:Arial;\"><b>How to Get Access to Run This Demo in VantageCloud</b></p>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Gain free access to Teradata‚Äôs <b>Open Analytics Framework</b>, which includes support for <b>BYO-LLM capabilities</b> and <b>GPU compute clusters</b>. This enables you to run open-source Hugging Face models directly within your VantageCloud environment</p>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "To request access and be able to execute this demo, send an email to <a href=\"mailto:Support.ClearScapeAnalytics@Teradata.com\">Support.ClearScapeAnalytics@Teradata.com</a>. Our team will provision your environment with the required permissions for BYO-LLM and GPU-accelerated inference.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329b1b1e-8041-4462-899a-04b52fabbed2",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none'>\n",
    "<b style = 'font-size:20px;font-family:Arial'>1. Configure the environment</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d758939-6961-4091-918d-a0663c7a633c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c03cf2-a3c9-40fe-b3d6-f1a4747afec9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Please</b><i> restart the kernel after executing the above cell to include/update these libraries into memory for this kernel. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i> and then clicking <b>Restart</b>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a9ed189-0658-444f-bb1f-085ec3a0487e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import all the libraries and modules required for this notebook\n",
    "import teradataml\n",
    "import getpass\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "#import teradatagenai\n",
    "from teradatagenai import TeradataAI, TextAnalyticsAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from teradataml import *\n",
    "from teradatasqlalchemy.types import *\n",
    "from IPython.display import display as ipydisplay\n",
    "from os.path import expanduser\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172733fa-6761-415c-9b61-68c5fd271a70",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"height:2px;border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>2. Connect to VantageCloud Lake</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Connect to VantageCloud using `create_context` from the teradataml Python library. Input your connection details, including the host, username, password and Analytic Compute Group name.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df8d2eee-2379-4c42-ac3d-1c7d240c5d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if this environment is ready to connect to VantageCloud Lake...\n",
      "Your environment parameter file exist.  Please proceed with this use case.\n",
      "Connected to VantageCloud Lake with: Engine(teradatasql://dallas54-88vgt0b5i55ikpx7:***@54.156.178.22)\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking if this environment is ready to connect to VantageCloud Lake...\")\n",
    "\n",
    "if os.path.exists(\"/home/jovyan/JupyterLabRoot/VantageCloud_Lake/.config/.env\"):\n",
    "    print(\"Your environment parameter file exist.  Please proceed with this use case.\")\n",
    "    # Load all the variables from the .env file into a dictionary\n",
    "    env_vars = dotenv_values(\"/home/jovyan/JupyterLabRoot/VantageCloud_Lake/.config/.env\")\n",
    "    # Create the Context\n",
    "    eng = create_context(host=env_vars.get(\"host\"), username=env_vars.get(\"username\"), password=env_vars.get(\"my_variable\"))\n",
    "    execute_sql('''SET query_band='DEMO=Entity_Recognition_BYOLLM_VCL.ipynb;' UPDATE FOR SESSION;''')\n",
    "    print(\"Connected to VantageCloud Lake with:\", eng)\n",
    "else:\n",
    "    print(\"Your environment has not been prepared for connecting to VantageCloud Lake.\")\n",
    "    print(\"Please contact the support team.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca87760f-a031-4353-acc2-8a5cfc1d5f15",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "\n",
    "<p style=\"font-size:20px; font-family:Arial\"><b>3. Getting Data for  for In-Database NLP tasks</b></p>\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "We have provided data for this demo on an OFS table <code>financial_entity_dataset</code> inside the default <code>DEMO_EntityRecognition</code> database.\n",
    "</p>\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "<b>üíº Use Case Summary:</b><br>\n",
    "In the wealth management industry, financial advisors hold many client meetings each week ‚Äî discussing portfolios, insurance, loans, and retirement planning. Manually summarizing and tagging these interactions for compliance, CRM updates, or follow-up actions is time-consuming and often inconsistent.\n",
    "</p>\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "With Teradata‚Äôs BYO-LLM capability, we can deploy an Open Source Hugging Face model directly within VantageCloud ‚Äî where the client interaction data already resides.  In this demo, we‚Äôll perform Named Entity Recognition (NER) with <a href=\"https://huggingface.co/tner/roberta-large-ontonotes5\" target=\"_blank\">tner/roberta-large-ontonotes5</a> for Extracting Key Phrases such as:\n",
    "\n",
    "<ul style=\"font-size:16px; font-family:Arial\">\n",
    "  <li>Client names</li>\n",
    "  <li>Financial institutions</li>\n",
    "  <li>Product types</li>\n",
    "  <li>Key dates</li>\n",
    "</ul> \n",
    "\n",
    "</p>\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "This helps financial firms:\n",
    "<ul style=\"font-size:16px; font-family:Arial\">\n",
    "  <li>Automate meeting note tagging for faster documentation and regulatory compliance</li>\n",
    "  <li>Enhance client profiling by identifying frequently discussed financial topics</li>\n",
    "  <li>Streamline CRM updates by structuring insights from unstructured text</li>\n",
    "</ul>\n",
    "</p>\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "All of this is achieved securely ‚Äî without moving data ‚Äî and using open-source models, giving teams full control, scalability, and flexibility.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d19cc1f-b730-4546-801c-f70fb6ea7f0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e765878d00403ab247805686de059b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable { border:ridge 5px}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}\n",
       "\t</style>\n",
       "<html><table style=\"min-width:1000px;\">\n",
       "\t<tr id=\"HeaderRow\">\n",
       "<th>Call_Summary</th>\n",
       "</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Amelia Greene joined Mastercard‚Äôs AI in Finance webinar hosted in Miami. Discussed implications for her fintech startup‚Äôs funding plans.</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Attended BlackRock fixed income seminar with Mason Lee in Boston. Evaluated suitability of municipal bond ladder strategy.</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Attended BlackRock fixed income seminar with Mason Lee in Boston. Evaluated suitability of municipal bond ladder strategy.</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Ava Johnson requested auto insurance review on July 12th in Phoenix. Referred her to our partner agent at Liberty Mutual.</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Benjamin Lin inquired about investing in a Nasdaq IPO opportunity on Sept 18th in New York City. Scheduled follow-up to review suitability.</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Benjamin Lin inquired about investing in a Nasdaq IPO opportunity on Sept 18th in New York City. Scheduled follow-up to review suitability.</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Ava Johnson requested auto insurance review on July 12th in Phoenix. Referred her to our partner agent at Liberty Mutual.</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Amelia Greene joined Mastercard‚Äôs AI in Finance webinar hosted in Miami. Discussed implications for her fintech startup‚Äôs funding plans.</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Alexander Moore activated a Capital One Venture card in Dallas. Discussed how to optimize miles redemption for business expenses.</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Alexander Moore activated a Capital One Venture card in Dallas. Discussed how to optimize miles redemption for business expenses.</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "                                                                                                                                  Call_Summary\n",
       "0     Amelia Greene joined Mastercard‚Äôs AI in Finance webinar hosted in Miami. Discussed implications for her fintech startup‚Äôs funding plans.\n",
       "1                   Attended BlackRock fixed income seminar with Mason Lee in Boston. Evaluated suitability of municipal bond ladder strategy.\n",
       "2                   Attended BlackRock fixed income seminar with Mason Lee in Boston. Evaluated suitability of municipal bond ladder strategy.\n",
       "3                    Ava Johnson requested auto insurance review on July 12th in Phoenix. Referred her to our partner agent at Liberty Mutual.\n",
       "4  Benjamin Lin inquired about investing in a Nasdaq IPO opportunity on Sept 18th in New York City. Scheduled follow-up to review suitability.\n",
       "5  Benjamin Lin inquired about investing in a Nasdaq IPO opportunity on Sept 18th in New York City. Scheduled follow-up to review suitability.\n",
       "6                    Ava Johnson requested auto insurance review on July 12th in Phoenix. Referred her to our partner agent at Liberty Mutual.\n",
       "7     Amelia Greene joined Mastercard‚Äôs AI in Finance webinar hosted in Miami. Discussed implications for her fintech startup‚Äôs funding plans.\n",
       "8            Alexander Moore activated a Capital One Venture card in Dallas. Discussed how to optimize miles redemption for business expenses.\n",
       "9            Alexander Moore activated a Capital One Venture card in Dallas. Discussed how to optimize miles redemption for business expenses."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a teradataml dataframe using sample data in an OFS table.\n",
    "call_summary_dataset = DataFrame(in_schema(\"DEMO_EntityRecognition\",\"Financial_CallCenter_Summary\"))\n",
    "call_summary_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710b7ade-3ded-4882-8c3c-ef522918d98d",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style=\"font-size:20px;font-family:Arial\"><b>4. Authenticate into User Environment Service (UES) for Container Management</b></p>\n",
    "<p style=\"font-size:16px; font-family:Arial;\">\n",
    "  The <code>teradataml</code> library offers simple yet powerful methods for creating and managing custom Python runtime environments within VantageCloud. This gives developers full control over model behavior, performance, and analytic accuracy when running on the Analytic Cluster.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial;\">\n",
    "  Custom environments are persistent‚Äîcreated once and reused as needed. They can be saved, updated, or modified at any time, allowing for efficient and flexible environment management.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:18px; font-family:Arial; color:#00233C;\">\n",
    "  <b>Container Management Process</b>\n",
    "</p>\n",
    "\n",
    "<table style=\"width:100%; table-layout:fixed;\">\n",
    "  <tr>\n",
    "    <td style=\"vertical-align:top;\" width=\"40%\">\n",
    "      <ol style=\"font-size:16px; font-family:Arial; color:#00233C;\">\n",
    "        <li>Create a unique User Environment based on available base images</li>\n",
    "        <li>Install libraries</li>\n",
    "        <li>Install models and additional user artifacts</li>\n",
    "      </ol>\n",
    "    </td>\n",
    "    <td>\n",
    "      <img src=\"./images/OAF_Env.png\" width=\"600\" alt=\"Container Management Diagram\" style=\"border: 4px solid #404040; border-radius: 10px;\"/>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "<b>UES authentication</b> is required to create and manage the Python or R environments that we will be creating.  A VantageCloud Lake user can easily create the authentication objects using the Console in a VantageCloud Lake environment.  The step to create these authentication objects has already been performed for you.\n",
    "</p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "   \n",
    "<ul style=\"font-size:16px;font-family:Arial; margin-top:4px;\">\n",
    "  <li><a href=\"https://docs.teradata.com/r/Teradata-VantageCloud-Lake/Analyzing-Your-Data/Teradata-Package-for-Python-on-VantageCloud-Lake/Working-with-Open-Analytics/APIs-to-Use-with-Open-Analytics-Framework/API-to-Set-Authentication-Token/set_auth_token\">Click here</a> to see more details about using the Teradata APIs to set the authentication objects.</li>\n",
    "\n",
    "  <li>Check out <a href=\"https://medium.com/teradata/deploy-hugging-face-llms-on-teradata-vantagecloud-lake-with-nvidia-gpu-acceleration-d94d999edaa5\">Step 4</a> of this tutorial to to see more details about configuring a VantageCloud Lake Environment to use our Open Analytics Framework</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea88bc5d-d830-4b4f-97bc-340cc310ffbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication token is generated, authenticated and set for the session.\n",
      "UES Authentication successful\n"
     ]
    }
   ],
   "source": [
    "# We've already loaded all the values into our environment variables and into a dictionary, env_vars.\n",
    "# username=env_vars.get(\"username\") isn't required when using base_url, pat and pem.\n",
    "\n",
    "if set_auth_token(base_url=env_vars.get(\"ues_uri\"),\n",
    "                  pat_token=env_vars.get(\"access_token\"), \n",
    "                  pem_file=env_vars.get(\"pem_file\"),\n",
    "                  valid_from=int(time.time())\n",
    "                 ):\n",
    "    print(\"UES Authentication successful\")\n",
    "else:\n",
    "    print(\"UES Authentication failed. Check credentials.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c955c8-8e55-4910-835f-2d2e8ff135a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style=\"font-size:20px; font-family:Arial\"><b>5. Set Up the User Environment in Teradata VantageCloud Lake for Model Deployment</b></p>\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "Now that <b>UES authentication</b> is complete, we can begin managing user environments using Teradata‚Äôs API capabilities.\n",
    "We will start by listing the available base libraries available for the environments.  Next, we'll check if you have already created an environment and then create one if one doesn't exist.  We will attempt to manage the number of OAF environments by deleting any that you may have created the do not use our default environment name. We will be using the <code>get_env</code>, <code>create_env</code>, and <code>list_user_envs</code> API methods.\n",
    "</p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "An easy way to get help and see the details for the different methods is to position your cursor within text of the method or function and then use your <code>Shift TAB</code> keys.  If the kernel is not busy, a help window will open with details about the parameters and how to use the function.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ff69f8e-c3e8-4137-9293-1686b46294f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a list of the versions of the libraries available to be used within an OAF environments.\n",
      "\n",
      "     base_name language  version\n",
      "0   python_3.9   Python   3.9.20\n",
      "1  python_3.10   Python  3.10.15\n",
      "2  python_3.11   Python  3.11.10\n",
      "3        r_4.3        R    4.3.3\n",
      "4        r_4.4        R    4.4.2\n",
      "No user environment(s) found.\n",
      "This user does not have any environments.\n",
      "Creating your environment now.\n",
      "User environment 'dallas54-88vgt0b5i55ikpx7' created.\n",
      "\n",
      "================================================\n",
      "Environment Name: dallas54-88vgt0b5i55ikpx7\n",
      "Base Environment: python_3.10\n",
      "Description: BYOLLM demo env\n",
      "\n",
      "############ Libraries installed in User Environment ############\n",
      "\n",
      "         name version\n",
      "0         pip  25.0.1\n",
      "1  setuptools  78.1.0\n",
      "\n",
      "================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if we have any existing environments\n",
    "# We can continue useing an existing environment\n",
    "# If any other environments exist along with our default OAF environment, we will delete them\n",
    "\n",
    "environment_name = env_vars.get(\"username\")\n",
    "print(\"Here is a list of the versions of the libraries available to be used within an OAF environments.\\n\")\n",
    "print(list_base_envs())\n",
    "env_list = list_user_envs()\n",
    "\n",
    "if env_list is None:\n",
    "    print(\"This user does not have any environments.\\nCreating your environment now.\")\n",
    "    demo_env = create_env(env_name=f'{environment_name}', base_env='python_3.10', desc='BYOLLM demo env')\n",
    "    print(demo_env)\n",
    "else:\n",
    "    print(\"\\nHere is a list of your current environments:\")\n",
    "    ipydisplay(env_list)\n",
    "    for env_name in env_list['env_name']:\n",
    "        if env_name == environment_name:\n",
    "            print(\"Your default environment already exists. You can continue with this notebook.\\n\\n\")\n",
    "        else:\n",
    "            print(f\"Your existing environment, {env_name} doesn't match our default environment for this user.\")\n",
    "            print(\"We're going to delete it.\")      \n",
    "            print(f\"Please wait: Environment {env_name} is being removed!\")\n",
    "            remove_env(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cb4e0e-6904-47f2-a5f0-02a916a1ffea",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Install the required libraries into your user environment on the GPU Compute Cluster. For most use cases involving Hugging Face, these will be the <b>transformers</b> and <b>torch</b> python libraries.  This could take up to 10 minutes to complete.  Please wait until you see the <b>Libraries installed</b> message.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8597547d-052e-4156-ae8d-84141df39383",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Installed\n"
     ]
    }
   ],
   "source": [
    "lib_claim_id = pd.DataFrame()\n",
    "lib_claim_id = demo_env.install_lib([\"transformers\", \"torch\"])\n",
    "print(\"Libraries Installed\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "807355be-718f-4dd0-9d9f-e77975fbd94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim Id</th>\n",
       "      <th>File/Libs/Model</th>\n",
       "      <th>Method Name</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Additional Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6e9b2549-007b-45e7-9e2b-69280de7fd0e</td>\n",
       "      <td>transformers, torch</td>\n",
       "      <td>install_lib</td>\n",
       "      <td>Started</td>\n",
       "      <td>2025-07-23T20:08:28Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6e9b2549-007b-45e7-9e2b-69280de7fd0e</td>\n",
       "      <td>transformers, torch</td>\n",
       "      <td>install_lib</td>\n",
       "      <td>Finished</td>\n",
       "      <td>2025-07-23T20:18:50Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Claim Id      File/Libs/Model  Method Name  \\\n",
       "0  6e9b2549-007b-45e7-9e2b-69280de7fd0e  transformers, torch  install_lib   \n",
       "1  6e9b2549-007b-45e7-9e2b-69280de7fd0e  transformers, torch  install_lib   \n",
       "\n",
       "      Stage             Timestamp Additional Details  \n",
       "0   Started  2025-07-23T20:08:28Z                     \n",
       "1  Finished  2025-07-23T20:18:50Z                     "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the status of the libraries installation\n",
    "demo_env.status(str(lib_claim_id[\"Claim Id\"].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a36f5c-5e01-4394-af1b-63287ccd4bb6",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Now we can configure the TextAnalyticsAI object with the preferred large language model using the TeradataAI object. This will enable us to execute a variety of text analytics tasks. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a490a2a-7689-4485-abd0-76038627ed14",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none\">\n",
    "<p style=\"font-size:20px;font-family:Arial\"><b>6. Download the Hugging Face Language Model and upload to your OAF (UES) environment</b></p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "You can download Hugging Face LLMs in either <a href=\"https://docs.teradata.com/r/Teradata-VantageCloud-Lake/Analyzing-Your-Data/Build-Scalable-Analytics-with-Open-Analytics-Framework/Bring-Your-Own-LLM-and-DL-Workloads/Using-Hugging-Face-LLMs\"> native format or streamlined format</a>. Here we use the streamlined format to download the model which will download it to our local system directory.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7e93477-8b8a-4b38-8487-1af3ba542a26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load model directly #save streamlined format under local path\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tner/roberta-large-ontonotes5\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"tner/roberta-large-ontonotes5\")\n",
    "\n",
    "tokenizer.save_pretrained(\"./roberta-large-ontonotes5\")\n",
    "model.save_pretrained(\"./roberta-large-ontonotes5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f4c41ff-1dd3-4115-9fcd-9a6bf214d9ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/JupyterLabRoot/VantageCloud_Lake/Entity_Recognition_BYOLLM/roberta-large-ontonotes5.zip'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compress the model into zip file\n",
    "# For the use cases when the model folder is in another directory than the current directory, root_dir should be the abosulte path.\n",
    "import shutil\n",
    "shutil.make_archive('roberta-large-ontonotes5', format='zip', root_dir='roberta-large-ontonotes5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3be13a-b7e0-4e5c-a765-26bfbb47ba2f",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "After the LLM directories are compressed into zip files, you can use the <a href = \"https://docs.teradata.com/r/Teradata-VantageCloud-Lake/Analyzing-Your-Data/Build-Scalable-Analytics-with-Open-Analytics-Framework/Bring-Your-Own-LLM-and-DL-Workloads/Using-User-Environment-APIs-to-Manage-LLMs\">UES APIs</a> to install, uninstall, and list LLMs. Here we use the <code>install_model</code> API.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8432964f-ea53-4365-a417-cab95d89a7d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request for install_model is completed successfully.\n"
     ]
    }
   ],
   "source": [
    "model_claim_id = ''\n",
    "model_claim_id = demo_env.install_model(model_path='roberta-large-ontonotes5.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45430746-aa03-4957-95d1-e126d29048f4",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Check the status of the model installation. There should be 3 Stages:\n",
    "<ol start=\"0\">\n",
    "    <li>Endpoint Generated\n",
    "    <li>File Uploaded\n",
    "    <li>File Installed\n",
    "</ol></p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "It's ok to re-execute the status() statement if you don't see all 3 Stages.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98fb008d-75e0-4c61-967e-8b4d53b16fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim Id</th>\n",
       "      <th>File/Libs/Model</th>\n",
       "      <th>Method Name</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Additional Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4c7a492c-701e-4ebc-868c-471297218ce5</td>\n",
       "      <td>roberta-large-ontonotes5.zip</td>\n",
       "      <td>install_model</td>\n",
       "      <td>Endpoint Generated</td>\n",
       "      <td>2025-07-23T20:45:26Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4c7a492c-701e-4ebc-868c-471297218ce5</td>\n",
       "      <td>roberta-large-ontonotes5.zip</td>\n",
       "      <td>install_model</td>\n",
       "      <td>File Uploaded</td>\n",
       "      <td>2025-07-23T20:45:42Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4c7a492c-701e-4ebc-868c-471297218ce5</td>\n",
       "      <td>roberta-large-ontonotes5.zip</td>\n",
       "      <td>install_model</td>\n",
       "      <td>File Installed</td>\n",
       "      <td>2025-07-23T20:47:53Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Claim Id               File/Libs/Model  \\\n",
       "0  4c7a492c-701e-4ebc-868c-471297218ce5  roberta-large-ontonotes5.zip   \n",
       "1  4c7a492c-701e-4ebc-868c-471297218ce5  roberta-large-ontonotes5.zip   \n",
       "2  4c7a492c-701e-4ebc-868c-471297218ce5  roberta-large-ontonotes5.zip   \n",
       "\n",
       "     Method Name               Stage             Timestamp Additional Details  \n",
       "0  install_model  Endpoint Generated  2025-07-23T20:45:26Z                     \n",
       "1  install_model       File Uploaded  2025-07-23T20:45:42Z                     \n",
       "2  install_model      File Installed  2025-07-23T20:47:53Z                     "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the status of the libraries installation\n",
    "demo_env.status(str(model_claim_id[\"Claim Id\"].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b539517-9617-4512-9cfb-2354ec8873bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"height:2px;border:none\">\n",
    "<p style=\"font-size:20px;font-family:Arial\"><b>7. Create a python script and execute it using the Apply Class</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aad5dc-c49c-410f-8a71-5426ec794cc6",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Create a python script that reads text records from VantageCloud using standard input, applies a Hugging Face language model to perform Named Entity Recognition (NER), and outputs the extracted entities in a structured, delimited format using standard output.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39e85e85-bf95-4208-87d6-2140d18e1625",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing entity_recognition.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile entity_recognition.py\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "input_str = sys.stdin.read()\n",
    "\n",
    "DELIMITER = '#'\n",
    "\n",
    "if len(input_str) > 0:\n",
    "    from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "    torch_device = 'cuda'\n",
    "    model_path = \"./models/roberta-large-ontonotes5\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "    translator = pipeline(\"token-classification\", model=model, tokenizer=tokenizer, device=torch_device, aggregation_strategy='max')\n",
    "\n",
    "    for line in input_str.splitlines():\n",
    "        results = translator(line)\n",
    "        dict_val = {}\n",
    "\n",
    "        for r in results:\n",
    "            entity = r['entity_group']\n",
    "            word = r['word']\n",
    "            dict_val.setdefault(entity, []).append(word)\n",
    "\n",
    "        combined_str = \"\"\n",
    "        for key in [\"ORG\", \"PERSON\", \"DATE\", \"PRODUCT\", \"GPE\"]:\n",
    "            combined_str += f\"{DELIMITER}{','.join(dict_val.get(key, []))}\"\n",
    "\n",
    "        print(f\"{line}{combined_str}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3af1f2-e0f5-462c-b60e-1a21774bcafa",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Install the python script file to the environment using install_file().\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ae8d564-1f89-4739-b0e0-436ff30fe2fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'entity_recognition.py' replaced successfully in the remote user environment 'dallas54-88vgt0b5i55ikpx7'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_env.install_file(file_path =\"entity_recognition.py\", replace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb8ba68-cd63-43a7-914f-ffe859444c67",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Set the session to the GPU Analytic compute group you desire otherwise it will set to default. The cluster needs to be running to execute the APPLY class.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "331d0291-b527-4520-9ec0-7d189f915094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute group set to GPUGroup\n"
     ]
    }
   ],
   "source": [
    "gpu_compute_group = env_vars.get(\"gpu_compute_group\")\n",
    "execute_sql(f\"SET SESSION COMPUTE GROUP {gpu_compute_group};\")\n",
    "print(f\"Compute group set to {gpu_compute_group}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18bd44c-fb79-4480-9d42-3ecfb5fd7827",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "The APPLY class executes your Python script directly within the user environment, enabling in-database processing at scale. It reads text from each row of the dataset, performs Named Entity Recognition (NER) using Hugging Face language models accelerated by NVIDIA GPUs, and outputs the extracted entities into a structured dataframe in just seconds. </p>  \n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\"> In this example, we use <code>tner/roberta-large-ontonotes5</code>, a general-purpose NER model trained on the OntoNotes 5 dataset. It supports entities like ORG, PERSON, DATE, PRODUCT, and GPE. However, it's important to note that the ‚ÄúPRODUCT‚Äù entity in OntoNotes refers primarily to physical products (e.g., iPhone, Windows OS), not financial instruments (e.g., Roth IRA, mutual funds). To improve financial domain accuracy, this model can be further fine-tuned on domain-specific data to better recognize investment products, insurance types, and retirement accounts.\n",
    " </p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f997dc6-4e1b-4d81-af19-c82a3576cb28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 45.3939368724823\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4fe762fbbd442282f2e874fe02947d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable { border:ridge 5px}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}\n",
       "\t</style>\n",
       "<html><table style=\"min-width:1000px;\">\n",
       "\t<tr id=\"HeaderRow\">\n",
       "<th>Call_Summary</th><th>ORG</th><th>PERSON</th><th>DATES</th><th>PRODUCT</th><th>GPE</th>\n",
       "</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Quarterly check-in with Noah Patel on April 20th in San Francisco. Portfolio rebalance completed shifted 5% from bonds to growth ETFs.</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td> Noah Patel</td>\n",
       "\t\t<td>Quarterly, April 20th</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td> San</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Call with James Delgado on April 2nd in Chicago to discuss employer 401(k) rollover to a Fidelity IRA. Sent transfer paperwork via DocuSign.</td>\n",
       "\t\t<td> Fidelity</td>\n",
       "\t\t<td> James Delgado</td>\n",
       "\t\t<td> April 2nd</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td> Chicago</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Ava Johnson requested auto insurance review on July 12th in Phoenix. Referred her to our partner agent at Liberty Mutual.</td>\n",
       "\t\t<td> Liberty Mutual.</td>\n",
       "\t\t<td>Ava Johnson</td>\n",
       "\t\t<td> July 12th</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td> Phoenix.</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Mortgage consultation with Isabella Chen on March 1st in Seattle. Compared preapproval options from Wells Fargo and Chase.</td>\n",
       "\t\t<td> Wells Fargo, Chase.</td>\n",
       "\t\t<td> Isabella Chen</td>\n",
       "\t\t<td> March 1st</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td>None</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Ethan Wright completed a full financial plan update on June 30th in Denver. Updated risk tolerance, added crypto exposure via Coinbase.</td>\n",
       "\t\t<td> Coinbase.</td>\n",
       "\t\t<td>Ethan Wright</td>\n",
       "\t\t<td> June 30th</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td>None</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Elijah Brooks executed multiple trades via Robinhood in Las Vegas. Cautioned on concentration risk in tech sector.</td>\n",
       "\t\t<td> Robinhood</td>\n",
       "\t\t<td>Elijah Brooks</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td> Las Vegas.</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Reviewed insurance coverage with Sophia Martinez on May 10th in Austin. Quoted State Farm term life policy and advised on umbrella coverage.</td>\n",
       "\t\t<td> State Farm</td>\n",
       "\t\t<td> Sophia Martinez</td>\n",
       "\t\t<td> May 10th</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td> Austin.</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Crypto education session with Mia Davis on Feb 1st in San Diego. Walked through setting up a Coinbase Pro account and cold wallet storage.</td>\n",
       "\t\t<td> Coinbase</td>\n",
       "\t\t<td> Mia Davis</td>\n",
       "\t\t<td> Feb 1st</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td> San</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Harper Nguyen approved for SBA loan through JPMorgan in Houston. Reviewed repayment options and cash flow strategy.</td>\n",
       "\t\t<td> SBA, JPMorgan</td>\n",
       "\t\t<td>Harper Nguyen</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td> Houston.</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Lucas Taylor has a financial planning session on March 29th in Portland. Primary focus: saving for child√¢¬†¬ôs education via 529 plan.</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td>Lucas Taylor</td>\n",
       "\t\t<td> March 29th</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td>None</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "                                                                                                                                   Call_Summary                   ORG            PERSON                  DATES PRODUCT          GPE\n",
       "0        Quarterly check-in with Noah Patel on April 20th in San Francisco. Portfolio rebalance completed shifted 5% from bonds to growth ETFs.                  None        Noah Patel  Quarterly, April 20th    None          San\n",
       "1  Call with James Delgado on April 2nd in Chicago to discuss employer 401(k) rollover to a Fidelity IRA. Sent transfer paperwork via DocuSign.              Fidelity     James Delgado              April 2nd    None      Chicago\n",
       "2                     Ava Johnson requested auto insurance review on July 12th in Phoenix. Referred her to our partner agent at Liberty Mutual.       Liberty Mutual.       Ava Johnson              July 12th    None     Phoenix.\n",
       "3                    Mortgage consultation with Isabella Chen on March 1st in Seattle. Compared preapproval options from Wells Fargo and Chase.   Wells Fargo, Chase.     Isabella Chen              March 1st    None         None\n",
       "4       Ethan Wright completed a full financial plan update on June 30th in Denver. Updated risk tolerance, added crypto exposure via Coinbase.             Coinbase.      Ethan Wright              June 30th    None         None\n",
       "5                            Elijah Brooks executed multiple trades via Robinhood in Las Vegas. Cautioned on concentration risk in tech sector.             Robinhood     Elijah Brooks                   None    None   Las Vegas.\n",
       "6  Reviewed insurance coverage with Sophia Martinez on May 10th in Austin. Quoted State Farm term life policy and advised on umbrella coverage.            State Farm   Sophia Martinez               May 10th    None      Austin.\n",
       "7    Crypto education session with Mia Davis on Feb 1st in San Diego. Walked through setting up a Coinbase Pro account and cold wallet storage.              Coinbase         Mia Davis                Feb 1st    None          San\n",
       "8                           Harper Nguyen approved for SBA loan through JPMorgan in Houston. Reviewed repayment options and cash flow strategy.         SBA, JPMorgan     Harper Nguyen                   None    None     Houston.\n",
       "9          Lucas Taylor has a financial planning session on March 29th in Portland. Primary focus: saving for child√¢¬†¬ôs education via 529 plan.                  None      Lucas Taylor             March 29th    None         None"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_obj = Apply(data = call_summary_dataset,\n",
    "                  apply_command = 'python entity_recognition.py',\n",
    "                  returns = {\"Call_Summary\": VARCHAR(64000), \"ORG\": VARCHAR(64000), \"PERSON\": VARCHAR(64000), \"DATES\": VARCHAR(64000), \"PRODUCT\": VARCHAR(64000), \"GPE\": VARCHAR(64000)},\n",
    "                  env_name = f'{environment_name}',\n",
    "                  delimiter = '#',\n",
    "                  quotechar = '|'\n",
    "                 )\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Execute the Python script inside the remote user environment.\n",
    "df = apply_obj.execute_script()\n",
    "\n",
    "print(f'Time: {time.time() - start}')\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecddc829-8492-429b-a7d0-e492543d0c74",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "  You can explore additional Natural Language Processing (NLP) tasks directly in-database using task-specific models:\n",
    "</p>\n",
    "\n",
    "<ul style=\"font-size:15px;font-family:Arial\">\n",
    "  <li><strong>Text Classification</strong> ‚Äî <a href=\"https://huggingface.co/facebook/bart-large-mnli\" target=\"_blank\">facebook/bart-large-mnli</a>: Classifies text into predefined categories</li>\n",
    "  <li><strong>Language Detection</strong> ‚Äî <a href=\"https://huggingface.co/papluca/xlm-roberta-base-language-detection\" target=\"_blank\">papluca/xlm-roberta-base-language-detection</a>: Detects the language</li>\n",
    "  <li><strong>Generating Embeddings</strong> ‚Äî <a href=\"https://huggingface.co/sentence-transformers/all-mpnet-base-v2\" target=\"_blank\">sentence-transformers/all-mpnet-base-v2</a>: Converts text into vector representations for similarity searches</li>\n",
    "  <li><strong>Named Entity Recognition</strong> ‚Äî <a href=\"https://huggingface.co/tner/roberta-large-ontonotes5\" target=\"_blank\">tner/roberta-large-ontonotes5</a>: Identifies and categorizes named entities within unstructured text</li>\n",
    "  <li><strong>Extracting Key Phrases</strong> ‚Äî <a href=\"https://huggingface.co/ml6team/keyphrase-extraction-kbir-kpcrowd\" target=\"_blank\">ml6team/keyphrase-extraction-kbir-kpcrowd</a>: Extracts important phrases from a document to summarize its content</li>\n",
    "  <li><strong>Grammar Correction</strong> ‚Äî <a href=\"https://huggingface.co/pszemraj/flan-t5-large-grammar-synthesis\" target=\"_blank\">pszemraj/flan-t5-large-grammar-synthesis</a>: Automatically corrects grammatical errors in text</li>\n",
    "  <li><strong>Masking PII Entities</strong> ‚Äî <a href=\"https://huggingface.co/ab-ai/pii_model\" target=\"_blank\">ab-ai/pii_model</a>: Masks personally identifiable information (PII)</li>\n",
    "  <li><strong>Sentiment Analysis</strong> ‚Äî <a href=\"https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english\" target=\"_blank\">distilbert-base-uncased-finetuned-sst-2-english</a>: Determines the emotional tone (positive, negative, neutral)</li>\n",
    "  <li><strong>Sentence Similarity</strong> ‚Äî <a href=\"https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\" target=\"_blank\">sentence-transformers/all-MiniLM-L6-v2</a>: Measures semantic similarity between sentences</li>\n",
    "  <li><strong>Summarization</strong> ‚Äî <a href=\"https://huggingface.co/facebook/bart-large-cnn\" target=\"_blank\">facebook/bart-large-cnn</a>: Generates concise summaries of longer documents</li>\n",
    "  <li><strong>Translation</strong> ‚Äî <a href=\"https://huggingface.co/Helsinki-NLP/opus-mt-en-fr\" target=\"_blank\">Helsinki-NLP/opus-mt-en-fr</a>: Translates English text to French</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b783dd5c-2e39-4f7d-bba7-8b55fda1c31e",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "<hr style='height:2px;border:none;'>\n",
    "<b style=\"font-size:20px;font-family:Arial\">8. Automate Entity Recognition with <code>teradatagenai</code> Python Package</b>\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "  To simplify and accelerate setup, you can now use the <code>teradatagenai</code> package to automate model deployment and inference. This Python library enables seamless, in-database, AI-driven text analytics within Teradata VantageCloud. It offers a variety of user-friendly functions that wrap API calls for common text analysis tasks, making it easy to apply LLMs to proprietary unstructured data.\n",
    "    \n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "  Built on Teradata VantageCloud‚Äôs open and connected architecture, this solution uses BYOLLM capability and enables teams to rapidly develope generative AI use cases that enhance customer experiences, improve employee productivity, and streamline operations‚Äîall within a secure, scalable environment.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\"> TextAnalyticsAI gives us access to the 11+ genAI functions and enables users to use advanced text analytics capabilities seamlessly on data stored in Vantage.\n",
    "<ul style=\"font-size:16px; font-family:Arial; margin-left:20px; line-height:1.8;\">\n",
    "  <li><code>classify()</code> ‚Äì Classify text into predefined categories</li>\n",
    "  <li><code>analyze_sentiment()</code> ‚Äì Perform sentiment analysis</li>\n",
    "  <li><code>detect_language()</code> ‚Äì Detect the language of a text</li>\n",
    "  <li><code>embeddings()</code> ‚Äì Generate embeddings for similarity search</li>\n",
    "  <li><code>recognize_entities()</code> ‚Äì Extract named entities</li>\n",
    "   <li><code>recognize_pii_entities()</code> ‚Äì Detect and label PII entities</li>\n",
    "  <li><code>extract_key_phrases()</code> ‚Äì Identify key phrases in text</li>\n",
    "  <li><code>mask_pii()</code> ‚Äì Mask personally identifiable information (PII)</li>\n",
    "  <li><code>sentence_similarity()</code> ‚Äì Measure semantic similarity between sentences</li>\n",
    "  <li><code>summarize()</code> ‚Äì Generate summaries of longer documents</li>\n",
    "  <li><code>translate()</code> ‚Äì Translate text between languages</li>\n",
    "</ul>\n",
    "\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3a89fd-69cb-4d2f-8af0-491ce8ae5f69",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">  \n",
    "TeradataAI handles the download and installation of the Hugging Face model (example: <i>'tner/roberta-large-ontonotes5</i>) in the user's environment. Incase the environment is not specified, a sample environment named <i>'td_gen_ai_env'</i> is created with <code>torch</code> and <code>transformer</code> libraries and their dependencies. The TeradataAI class will manage the entire setup process. In the background, this process utilizes Teradata‚Äôs Bring Your Own Large Language Model (BYO LLM) offering.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f77faa-d939-44cc-b7a4-6742593e831d",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">For this next example we're going to continue using our default the environment we just created and re-install the same <code>tner/roberta-large-ontonotes5</code> with the <code>teradatagenai</code> package. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4df0bee4-0f9b-4edc-baa6-a8af5540aa4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a list of the versions of the libraries available to be used within an OAF environments.\n",
      "\n",
      "     base_name language  version\n",
      "0   python_3.9   Python   3.9.20\n",
      "1  python_3.10   Python  3.10.15\n",
      "2  python_3.11   Python  3.11.10\n",
      "3        r_4.3        R    4.3.3\n",
      "4        r_4.4        R    4.4.2\n",
      "\n",
      "Here is a list of your current environments:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env_name</th>\n",
       "      <th>env_description</th>\n",
       "      <th>base_env_name</th>\n",
       "      <th>language</th>\n",
       "      <th>conda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dallas54-88vgt0b5i55ikpx7</td>\n",
       "      <td>BYOLLM demo env</td>\n",
       "      <td>python_3.10</td>\n",
       "      <td>Python</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    env_name  env_description base_env_name language  conda\n",
       "0  dallas54-88vgt0b5i55ikpx7  BYOLLM demo env   python_3.10   Python  False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your default environment already exists. You can continue with this notebook.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if we have any existing environments\n",
    "# We can continue useing an existing environment\n",
    "# If any other environments exist along with our default OAF environment, we will delete them\n",
    "\n",
    "environment_name = env_vars.get(\"username\")\n",
    "print(\"Here is a list of the versions of the libraries available to be used within an OAF environments.\\n\")\n",
    "print(list_base_envs())\n",
    "env_list = list_user_envs()\n",
    "\n",
    "if env_list is None:\n",
    "    print(\"This user does not have any environments.\\nCreating your environment now.\")\n",
    "    demo_env = create_env(env_name=f'{environment_name}', base_env='python_3.10', desc='BYOLLM demo env')\n",
    "    print(demo_env)\n",
    "else:\n",
    "    print(\"\\nHere is a list of your current environments:\")\n",
    "    ipydisplay(env_list)\n",
    "    for env_name in env_list['env_name']:\n",
    "        if env_name == environment_name:\n",
    "            print(\"Your default environment already exists. You can continue with this notebook.\\n\\n\")\n",
    "        else:\n",
    "            print(f\"Your existing environment, {env_name} doesn't match our default environment for this user.\")\n",
    "            print(\"We're going to delete it.\")      \n",
    "            print(f\"Please wait: Environment {env_name} is being removed!\")\n",
    "            remove_env(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce427994-bcc9-4dd2-bad9-2e8481e979d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using env: 'dallas54-88vgt0b5i55ikpx7'.\n",
      "Model is already available in the user environment.\n"
     ]
    }
   ],
   "source": [
    "#Define your model and initialize the TeradataAI Class\n",
    "model_name = 'tner/roberta-large-ontonotes5'\n",
    "model_args = {'transformer_class': 'AutoModelForTokenClassification',\n",
    "              'task' : 'token-classification'}\n",
    "ues_args = {'env_name': f'{environment_name}'}\n",
    "\n",
    "llm = TeradataAI(api_type = \"hugging_face\",\n",
    "                 model_name = model_name,\n",
    "                 model_args = model_args,\n",
    "                 ues_args = ues_args )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12832ed-7e09-4b92-803a-40a8a23aedc3",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "This model should have already been installed in the environment. If it is, then you can skip to the next cell. If you've skipped around and it's not already been installed, the the Python kernel may show it is <b>Idle</b>. Please wait until you see that the installation status above has completed before you continue. This should only take 2 minutes depending on your network.<br>\n",
    "<p style=\"font-size:16px;font-family:Arial\">Because we are continuing to re-use the same environment, we do not need to install the libraries again. Executing the environment's <code>status</code> method will validate the installation of the libraries.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9877758f-5d2f-466e-a93d-3728f97cec65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim Id</th>\n",
       "      <th>File/Libs/Model</th>\n",
       "      <th>Method Name</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Additional Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6e9b2549-007b-45e7-9e2b-69280de7fd0e</td>\n",
       "      <td>transformers, torch</td>\n",
       "      <td>install_lib</td>\n",
       "      <td>Started</td>\n",
       "      <td>2025-07-23T20:08:28Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6e9b2549-007b-45e7-9e2b-69280de7fd0e</td>\n",
       "      <td>transformers, torch</td>\n",
       "      <td>install_lib</td>\n",
       "      <td>Finished</td>\n",
       "      <td>2025-07-23T20:18:50Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Claim Id      File/Libs/Model  Method Name  \\\n",
       "0  6e9b2549-007b-45e7-9e2b-69280de7fd0e  transformers, torch  install_lib   \n",
       "1  6e9b2549-007b-45e7-9e2b-69280de7fd0e  transformers, torch  install_lib   \n",
       "\n",
       "      Stage             Timestamp Additional Details  \n",
       "0   Started  2025-07-23T20:08:28Z                     \n",
       "1  Finished  2025-07-23T20:18:50Z                     "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can run the run the status method against the demo_env again to verify the status of the installed libraries\n",
    "demo_env.status(str(lib_claim_id[\"Claim Id\"].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a57e95",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Now we can configure the TextAnalyticsAI object with the preferred large language model using the TeradataAI object. This will enable us to execute a variety of text analytics tasks. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3ed8a6a-2748-49bc-9402-f51637458e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'td_sample_inference_script.py' replaced successfully in the remote user environment 'dallas54-88vgt0b5i55ikpx7'.\n",
      "File 'td_sample_embeddings_script.py' replaced successfully in the remote user environment 'dallas54-88vgt0b5i55ikpx7'.\n"
     ]
    }
   ],
   "source": [
    "obj = TextAnalyticsAI(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f51dbba-a332-4d46-a490-ef36481f4d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'entity_recognition.py' replaced successfully in the remote user environment 'dallas54-88vgt0b5i55ikpx7'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9683418680ce4206ba133dc6e974ba20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable { border:ridge 5px}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}\n",
       "\t</style>\n",
       "<html><table style=\"min-width:1000px;\">\n",
       "\t<tr id=\"HeaderRow\">\n",
       "<th>txt</th><th>ORG</th><th>PERSON</th><th>DATES</th><th>PRODUCT</th><th>GPE</th>\n",
       "</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Mortgage consultation with Isabella Chen on March 1st in Seattle. Compared preapproval options from Wells Fargo and Chase.</td>\n",
       "\t\t<td> Wells Fargo, Chase.</td>\n",
       "\t\t<td> Isabella Chen</td>\n",
       "\t\t<td> March 1st</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td>None</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Quarterly check-in with Noah Patel on April 20th in San Francisco. Portfolio rebalance completed shifted 5% from bonds to growth ETFs.</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td> Noah Patel</td>\n",
       "\t\t<td>Quarterly, April 20th</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td> San</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Lucas Taylor has a financial planning session on March 29th in Portland. Primary focus: saving for child√¢¬†¬ôs education via 529 plan.</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td>Lucas Taylor</td>\n",
       "\t\t<td> March 29th</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td>None</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Call with James Delgado on April 2nd in Chicago to discuss employer 401(k) rollover to a Fidelity IRA. Sent transfer paperwork via DocuSign.</td>\n",
       "\t\t<td> Fidelity</td>\n",
       "\t\t<td> James Delgado</td>\n",
       "\t\t<td> April 2nd</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td> Chicago</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Reviewed insurance coverage with Sophia Martinez on May 10th in Austin. Quoted State Farm term life policy and advised on umbrella coverage.</td>\n",
       "\t\t<td> State Farm</td>\n",
       "\t\t<td> Sophia Martinez</td>\n",
       "\t\t<td> May 10th</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td> Austin.</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Crypto education session with Mia Davis on Feb 1st in San Diego. Walked through setting up a Coinbase Pro account and cold wallet storage.</td>\n",
       "\t\t<td> Coinbase</td>\n",
       "\t\t<td> Mia Davis</td>\n",
       "\t\t<td> Feb 1st</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td> San</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Olivia Rodriguez promoted at Morgan Stanley in Chicago; discussed changes to her restricted stock unit (RSU) vesting schedule on Feb 22.</td>\n",
       "\t\t<td> Morgan Stanley</td>\n",
       "\t\t<td>Olivia Rodriguez</td>\n",
       "\t\t<td> Feb 22.</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td>None</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Amelia Greene joined Mastercard√¢¬†¬ôs AI in Finance webinar hosted in Miami. Discussed implications for her fintech startup√¢¬†¬ôs funding plans.</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td>Amelia Greene</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td> Miami.</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Ava Johnson requested auto insurance review on July 12th in Phoenix. Referred her to our partner agent at Liberty Mutual.</td>\n",
       "\t\t<td> Liberty Mutual.</td>\n",
       "\t\t<td>Ava Johnson</td>\n",
       "\t\t<td> July 12th</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td> Phoenix.</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Harper Nguyen approved for SBA loan through JPMorgan in Houston. Reviewed repayment options and cash flow strategy.</td>\n",
       "\t\t<td> SBA, JPMorgan</td>\n",
       "\t\t<td>Harper Nguyen</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td>None</td>\n",
       "\t\t<td> Houston.</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "                                                                                                                                            txt                   ORG            PERSON                  DATES PRODUCT        GPE\n",
       "0                    Mortgage consultation with Isabella Chen on March 1st in Seattle. Compared preapproval options from Wells Fargo and Chase.   Wells Fargo, Chase.     Isabella Chen              March 1st    None       None\n",
       "1        Quarterly check-in with Noah Patel on April 20th in San Francisco. Portfolio rebalance completed shifted 5% from bonds to growth ETFs.                  None        Noah Patel  Quarterly, April 20th    None        San\n",
       "2          Lucas Taylor has a financial planning session on March 29th in Portland. Primary focus: saving for child√¢¬†¬ôs education via 529 plan.                  None      Lucas Taylor             March 29th    None       None\n",
       "3  Call with James Delgado on April 2nd in Chicago to discuss employer 401(k) rollover to a Fidelity IRA. Sent transfer paperwork via DocuSign.              Fidelity     James Delgado              April 2nd    None    Chicago\n",
       "4  Reviewed insurance coverage with Sophia Martinez on May 10th in Austin. Quoted State Farm term life policy and advised on umbrella coverage.            State Farm   Sophia Martinez               May 10th    None    Austin.\n",
       "5    Crypto education session with Mia Davis on Feb 1st in San Diego. Walked through setting up a Coinbase Pro account and cold wallet storage.              Coinbase         Mia Davis                Feb 1st    None        San\n",
       "6      Olivia Rodriguez promoted at Morgan Stanley in Chicago; discussed changes to her restricted stock unit (RSU) vesting schedule on Feb 22.        Morgan Stanley  Olivia Rodriguez                Feb 22.    None       None\n",
       "7  Amelia Greene joined Mastercard√¢¬†¬ôs AI in Finance webinar hosted in Miami. Discussed implications for her fintech startup√¢¬†¬ôs funding plans.                  None     Amelia Greene                   None    None     Miami.\n",
       "8                     Ava Johnson requested auto insurance review on July 12th in Phoenix. Referred her to our partner agent at Liberty Mutual.       Liberty Mutual.       Ava Johnson              July 12th    None   Phoenix.\n",
       "9                           Harper Nguyen approved for SBA loan through JPMorgan in Houston. Reviewed repayment options and cash flow strategy.         SBA, JPMorgan     Harper Nguyen                   None    None   Houston."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default script is used\n",
    "obj.recognize_entities(column='Call_Summary', data=call_summary_dataset, script=\"entity_recognition.py\", returns = {\"txt\": VARCHAR(64000),\n",
    "                                                  \"ORG\": VARCHAR(64000),\n",
    "                                                  \"PERSON\": VARCHAR(64000),\n",
    "                                                  \"DATES\": VARCHAR(64000),\n",
    "                                                  \"PRODUCT\": VARCHAR(64000),\n",
    "                                                  \"GPE\": VARCHAR(64000)}, delimiter=\"#\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb913bb-79be-4261-a8d7-8dd101536754",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "\n",
    "<b style=\"font-size:20px; font-family:Arial;\">\n",
    "  9. Call Hosted LLMs From In-Database (AWS Bedrock, Google Gemini, Azure AI Models)\n",
    "</b>\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial; line-height:1.6;\">\n",
    "  Teradata lets you run text analysis using large language models (LLMs) hosted on cloud platforms such as <strong>AWS</strong>, <strong>Google</strong>, and <strong>Azure</strong>, while working directly with data stored in <strong>Vantage</strong>. \n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial; line-height:1.6;\">\n",
    "  These built-in functions support a wide range of NLP tasks on unstructured text:\n",
    "</p>\n",
    "\n",
    "<ul style=\"font-size:16px; font-family:Arial; margin-left:20px; line-height:1.8;\">\n",
    "  <li><code>AI_AnalyzeSentiment</code></li>\n",
    "  <li><code>AI_AskLLM</code></li>\n",
    "  <li><code>AI_DetectLanguage</code></li>\n",
    "  <li><code>AI_MaskPII</code></li>\n",
    "  <li><code>AI_RecognizeEntities</code></li>\n",
    "  <li><code>AI_RecognizePIIEntities</code></li>\n",
    "  <li><code>AI_TextClassifier</code></li>\n",
    "  <li><code>AI_TextEmbeddings</code></li>\n",
    "  <li><code>AI_TextSummarize</code></li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial; line-height:1.6;\">\n",
    "  In the following example, we‚Äôll demonstrate how to use <code>AI_RecognizeEntities</code> for in-database entity recognition with Amazon Bedrock's Anthropic LLM: \"anthropic.claude-v2\".\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05e545ad-e73a-4638-b4e6-114e3dadb4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter AWS Access Key:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
      "Enter AWS Secret Key:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
      "Region:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    }
   ],
   "source": [
    "# Securely prompt for AWS credentials\n",
    "# Please enter the region using this format: Country-Region-Number. For example, us-east-1\n",
    "access_key = getpass.getpass(\"Enter AWS Access Key: \")\n",
    "secret_key = getpass.getpass(\"Enter AWS Secret Key: \")\n",
    "region = getpass.getpass(\"Region: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4491320-1150-4a0a-8a92-0d9d2f10c5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your query dynamically\n",
    "query = f\"\"\"\n",
    "SELECT * FROM AI_RecognizeEntities( \n",
    "  ON DEMO_EntityRecognition.Financial_CallCenter_Summary AS InputTable\n",
    "  USING \n",
    "    TextColumn('Call_Summary')\n",
    "    ApiType('aws')\n",
    "    REGION('{region}')\n",
    "    ACCESSKEY('{access_key}')\n",
    "    SECRETKEY('{secret_key}')\n",
    "    ModelName('anthropic.claude-v2')\n",
    "    isDebug('true')\n",
    "    Accumulate('[0:]')\n",
    ") AS dt;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1350c316",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "While our open-source Hugging Face models provide a powerful and customizable foundation for entity recognition, it will require additional domain-specific fine-tuning to accurately capture specialized financial terms or product names. In contrast, <b>hosted LLMs</b> such as Anthropic‚Äôs Claude or other models available through <b>AWS Bedrock, Google Vertex AI, or Azure OpenAI</b> often benefit from broad training by the provider‚Äîresulting in deeper contextual understanding out of the box. In this example, we will observe that the AWS Bedrock's Anthropic model identified a richer set of financial products with no additional training.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ed914fb-07ed-4cd0-977d-2740658850cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a56b39a32642ea823550505346942b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable { border:ridge 5px}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}\n",
       "\t</style>\n",
       "<html><table style=\"min-width:1000px;\">\n",
       "\t<tr id=\"HeaderRow\">\n",
       "<th>Call_Summary</th><th>Labeled_Entities</th><th>Message</th>\n",
       "</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Reviewed insurance coverage with Sophia Martinez on May 10th in Austin. Quoted State Farm term life policy and advised on umbrella coverage.</td>\n",
       "\t\t<td>(Sophia Martinez, people), (May 10th, date/time), (Austin, places), (State Farm, organizations)</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Mortgage consultation with Isabella Chen on March 1st in Seattle. Compared preapproval options from Wells Fargo and Chase.</td>\n",
       "\t\t<td>(Isabella Chen, people), (March 1st, date/time), (Seattle, places), (Wells Fargo, organizations), (Chase, organizations)</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Ethan Wright completed a full financial plan update on June 30th in Denver. Updated risk tolerance, added crypto exposure via Coinbase.</td>\n",
       "\t\t<td>(Ethan Wright, people), (June 30th, date/time), (Denver, places), (Coinbase, product)</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Olivia Rodriguez promoted at Morgan Stanley in Chicago; discussed changes to her restricted stock unit (RSU) vesting schedule on Feb 22.</td>\n",
       "\t\t<td>(Olivia Rodriguez, people), (Morgan Stanley, organizations), (Chicago, places), (Feb 22, date/time)</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Ava Johnson requested auto insurance review on July 12th in Phoenix. Referred her to our partner agent at Liberty Mutual.</td>\n",
       "\t\t<td>(Ava Johnson, people), (July 12th, date/time), (Phoenix, places), (Liberty Mutual, organizations)</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Benjamin Lin inquired about investing in a Nasdaq IPO opportunity on Sept 18th in New York City. Scheduled follow-up to review suitability.</td>\n",
       "\t\t<td>(Benjamin Lin, people), (Nasdaq, organizations), (Sept 18th, date/time), (New York City, places)</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Met with Emily Thompson on March 15th in New York to review her retirement portfolio. Recommended reallocating 10% into international equities through JPMorgan mutual funds.</td>\n",
       "\t\t<td>(Emily Thompson, people), (March 15th, date/time), (New York, places), (10%, percentages), (JPMorgan, organizations)</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Call with James Delgado on April 2nd in Chicago to discuss employer 401(k) rollover to a Fidelity IRA. Sent transfer paperwork via DocuSign.</td>\n",
       "\t\t<td>(James Delgado, people), (April 2nd, date/time), (Chicago, places), (Fidelity, organizations), (IRA, products), (DocuSign, products)</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Liam O'Brien opened a SEP IRA on January 5th in Los Angeles and contributed $6,500. Discussed tax implications with his CPA.</td>\n",
       "\t\t<td>(Liam O'Brien, people), (SEP IRA, product), (January 5th, date/time), (Los Angeles, places), ($6,500, currencies), (CPA, people)</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>Reviewed insurance coverage with Sophia Martinez on May 10th in Austin. Quoted State Farm term life policy and advised on umbrella coverage.</td>\n",
       "\t\t<td>(Sophia Martinez, people), (May 10th, date/time), (Austin, places), (State Farm, organizations)</td>\n",
       "\t\t<td></td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "                                                                                                                                                                    Call_Summary                                                                                                                      Labeled_Entities Message\n",
       "0                                   Reviewed insurance coverage with Sophia Martinez on May 10th in Austin. Quoted State Farm term life policy and advised on umbrella coverage.                                       (Sophia Martinez, people), (May 10th, date/time), (Austin, places), (State Farm, organizations)        \n",
       "1                                                     Mortgage consultation with Isabella Chen on March 1st in Seattle. Compared preapproval options from Wells Fargo and Chase.              (Isabella Chen, people), (March 1st, date/time), (Seattle, places), (Wells Fargo, organizations), (Chase, organizations)        \n",
       "2                                        Ethan Wright completed a full financial plan update on June 30th in Denver. Updated risk tolerance, added crypto exposure via Coinbase.                                                 (Ethan Wright, people), (June 30th, date/time), (Denver, places), (Coinbase, product)        \n",
       "3                                       Olivia Rodriguez promoted at Morgan Stanley in Chicago; discussed changes to her restricted stock unit (RSU) vesting schedule on Feb 22.                                   (Olivia Rodriguez, people), (Morgan Stanley, organizations), (Chicago, places), (Feb 22, date/time)        \n",
       "4                                                      Ava Johnson requested auto insurance review on July 12th in Phoenix. Referred her to our partner agent at Liberty Mutual.                                     (Ava Johnson, people), (July 12th, date/time), (Phoenix, places), (Liberty Mutual, organizations)        \n",
       "5                                    Benjamin Lin inquired about investing in a Nasdaq IPO opportunity on Sept 18th in New York City. Scheduled follow-up to review suitability.                                      (Benjamin Lin, people), (Nasdaq, organizations), (Sept 18th, date/time), (New York City, places)        \n",
       "6  Met with Emily Thompson on March 15th in New York to review her retirement portfolio. Recommended reallocating 10% into international equities through JPMorgan mutual funds.                  (Emily Thompson, people), (March 15th, date/time), (New York, places), (10%, percentages), (JPMorgan, organizations)        \n",
       "7                                   Call with James Delgado on April 2nd in Chicago to discuss employer 401(k) rollover to a Fidelity IRA. Sent transfer paperwork via DocuSign.  (James Delgado, people), (April 2nd, date/time), (Chicago, places), (Fidelity, organizations), (IRA, products), (DocuSign, products)        \n",
       "8                                                   Liam O'Brien opened a SEP IRA on January 5th in Los Angeles and contributed $6,500. Discussed tax implications with his CPA.      (Liam O'Brien, people), (SEP IRA, product), (January 5th, date/time), (Los Angeles, places), ($6,500, currencies), (CPA, people)        \n",
       "9                                   Reviewed insurance coverage with Sophia Martinez on May 10th in Austin. Quoted State Farm term life policy and advised on umbrella coverage.                                       (Sophia Martinez, people), (May 10th, date/time), (Austin, places), (State Farm, organizations)        "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = DataFrame.from_query(query)\n",
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966b0c10",
   "metadata": {},
   "source": [
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    " This is why <b>Teradata‚Äôs support for both open-source and hosted models</b> is great for developers and enteprises: developers need the flexibility to choose the right model for each use case based on the <b>business goals, data privacy requirements, cost considerations,</b> and <b>infrastructure preferences</b>. Whether you're performing domain-specific NLP with tightly controlled data using <b>BYO-LLM</b> or leveraging the latest generative AI via <b>fast-path cloud functions</b>, Teradata enables you to do both‚Äî<b>securely, efficiently, and at scale</b>. The real differentiator is not just the model, but the ability to <b>operationalize AI seamlessly where your data lives</b> and apply it to solve meaningful business problems with measurable impact.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7302075",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none'>\n",
    "<b style = 'font-size:20px;font-family:Arial'>10. Cleanup</b>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Cleanup the OAF User Environment storage. If you will be executing other VantageCloud Lake OAF notebooks, you can skip this step.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9029d43-81fd-4906-9044-08b2fe3b1ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User environment 'dallas54-88vgt0b5i55ikpx7' removed.\n",
      "Environment removed!\n"
     ]
    }
   ],
   "source": [
    "#Remove the existing user environment \n",
    "from IPython.display import display, HTML\n",
    "try:\n",
    "    result = remove_env(environment_name)\n",
    "    print(\"Environment removed!\")\n",
    "except Exception as e:\n",
    "    print(\"Could not remove the environment!\")\n",
    "    print(\"Error:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ed1ae4-18b6-4d6a-a40b-23c573aa7770",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Please delete your database connection.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69241999-aa11-4abf-8c79-9f5851b88be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context removed!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    result = remove_context()\n",
    "    print(\"Context removed!\")\n",
    "except Exception as e:\n",
    "    print(\"Could not remove the Context!\")\n",
    "    print(\"Error:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc982843-537c-447a-8fb1-a8f0371a8191",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(TeradataAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157acc0b-bc56-4ce2-beed-29aa7ba5e122",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; border-bottom:3px solid #91A0Ab\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics‚Ñ¢</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright ¬© Teradata Corporation - 2025. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
