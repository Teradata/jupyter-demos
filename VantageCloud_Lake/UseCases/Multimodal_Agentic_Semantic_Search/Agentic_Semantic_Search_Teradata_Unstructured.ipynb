{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9944e564-a16d-44fb-b9e0-0dd16a45eb1f",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Teradata &mdash; Multimodal Agentic Semantic Search with Enterprise Vector Store and Unstructured.io\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970802d7-ec13-53bf-3073-9c1d956c-a30",
   "metadata": {},
   "source": [
    "<p style='font-size:20px;font-family:Arial;'><b>Multimodal Semantic Search with Teradata Enterprise Vector Store and Unstructured.io</b></p>\n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "This notebook demonstrates how to build a production-grade semantic search pipeline over unstructured data — composite PDF documents and raw images — entirely within Teradata VantageCloud. Rather than moving data to an external vector database, embeddings are stored, indexed, and queried in-database using the <b>Teradata Enterprise Vector Store</b>, keeping large-scale retrieval fast and data residency compliant.\n",
    "</p>\n",
    "\n",
    "<ul style='font-size:16px;font-family:Arial;'>\n",
    "    <li><strong>Unstructured.io Ingestion:</strong> Parses and chunks composite PDFs and images via the Unstructured API, then stores the resulting text chunks and embeddings directly in Vantage tables.</li>\n",
    "    <li><strong>Enterprise Vector Store:</strong> Uses <code>TeradataVectorStore</code> from the <code>langchain-teradata</code> library to create and manage an in-database index over the stored embeddings.</li>\n",
    "    <li><strong>Similarity Search:</strong> Queries the vector store using image embeddings to find semantically similar documents, then uses an LLM to summarize and format the matched results.</li>\n",
    "    <li><strong>LangChain Agent:</strong> Wires the similarity search and a PDF renderer into a conversational agent, enabling a natural-language interface for exploring the document and image library.</li>\n",
    "</ul>\n",
    "\n",
    "<p style='font-size:18px;font-family:Arial;'><b>Why Vantage?</b></p>\n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "Storing embeddings inside Vantage eliminates the data movement, latency, and operational complexity of maintaining a separate vector database. Teradata's Massively Parallel Processing architecture scales similarity search across billions of vectors while keeping the data collocated with the rest of your enterprise data warehouse.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c2645d-6259-02c5-fb57-fd492282-609",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233c;'>\n",
    "<b style='font-size:20px;font-family:Arial;'>1. Configure the Environment</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f598193-114a-f98e-a84c-942170ed-e6f",
   "metadata": {},
   "source": [
    "<p style='font-size:16px;font-family:Arial;'>Before running this notebook, install the required libraries. This demo depends on <b>teradatagenai</b> (which provides the <code>VSManager</code> and <code>TeradataVectorStore</code> classes) and <b>langchain-teradata</b> (the LangChain integration layer). The cell below performs a quiet install; if the packages were not already present, restart the kernel before proceeding.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bbd4ae-273e-4e1d-9c31-1b92972f4326",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install teradatagenai, langchain-teradata, anywidget --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5a7b4a-41f9-4171-9d8b-ace73987d332",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style='font-size:16px;font-family:Arial'><i><b>Note:</b>If the above commands install the modules please restart the kernel after executing those lines to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing zero zero: <b>0 0</b></i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e531b5-3d73-aa2e-2552-c77e02aa-8ec",
   "metadata": {},
   "source": [
    "<p style='font-size:16px;font-family:Arial;'>The cell below loads all required Python libraries. Key imports include <b>VSManager</b> for vector store lifecycle management, <b>TeradataVectorStore</b> from LangChain Teradata for index creation and querying, <b>teradataml</b> for in-database DataFrame operations, and the LangChain agent and tool utilities used to build the conversational interface later in the notebook.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2016c4-a193-4fdd-8ba7-28fb5a769935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "\n",
    "# General imports\n",
    "from teradatagenai import VSManager\n",
    "from langchain_teradata import TeradataVectorStore\n",
    "from teradataml import *\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Credentials and configuration management\n",
    "from dotenv import load_dotenv\n",
    "from getpass import getpass\n",
    "\n",
    "\n",
    "#Langchain Imports\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.tools import tool\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "display.suppress_vantage_runtime_warnings = True\n",
    "\n",
    "# Widget display\n",
    "from IPython.display import display, HTML, IFrame\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Import utilities\n",
    "from unstructured_utils.teradata_ingest import ingest\n",
    "from utils.image_grid import display_image_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdb098b-a6ca-971c-44c8-9ff862b7-d78",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233c;'>\n",
    "<p style='font-size:20px;font-family:Arial;'><b>2. Connect to VantageCloud</b></p>\n",
    "<p style='font-size:16px;font-family:Arial;'>Establish a connection to VantageCloud Lake using <code>create_context</code> from the teradataml library. Connection details — host, username, and password — are read automatically from the environment configuration file provisioned for your lab. The query band is also set so that all SQL generated by this session is tagged for auditability.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7a1034-78fe-4866-9b31-45972607ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking if this environment is ready to connect to VantageCloud Lake...\")\n",
    "\n",
    "if os.path.exists(\"/home/jovyan/JupyterLabRoot/VantageCloud_Lake/.config/.env\"):\n",
    "    print(\"Your environment parameter file exist.  Please proceed with this use case.\")\n",
    "    # Load all the variables from the .env file into a dictionary\n",
    "    env_vars = dotenv_values(\"/home/jovyan/JupyterLabRoot/VantageCloud_Lake/.config/.env\")\n",
    "    # Create the Context\n",
    "    eng = create_context(host=env_vars.get(\"host\"), username=env_vars.get(\"username\"), password=env_vars.get(\"my_variable\"))\n",
    "    execute_sql('''SET query_band='DEMO=VCL_GettingStarted_VectorStore.ipynb;' UPDATE FOR SESSION;''')\n",
    "    print(\"Connected to VantageCloud Lake with:\", eng)\n",
    "else:\n",
    "    print(\"Your environment has not been prepared for connecting to VantageCloud Lake.\")\n",
    "    print(\"Please contact the support team.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc427b0-9df3-aeae-0ea8-583e5dc2-937",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233c;'>\n",
    "<p style='font-size:20px;font-family:Arial;'><b>3. Authenticate into the User Environment Service (UES)</b></p>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'><b>UES authentication</b> is required to create and manage the Open Analytics environments that power the embedding model inference layer inside Vantage. A VantageCloud Lake user can create the necessary authentication objects through the Console; these objects have already been provisioned for this lab.\n",
    "</p>\n",
    "<p style='font-size:16px;font-family:Arial;'>The <code>set_auth_token</code> function accepts a Personal Access Token (PAT) and a PEM key file to establish a secure session with the UES endpoint. After authentication, <code>VSManager.health()</code> confirms that the vector store service is reachable and ready.\n",
    "</p>\n",
    "<ul style='font-size:16px;font-family:Arial; margin-top:4px;'>\n",
    "  <li><a href='https://docs.teradata.com/r/Teradata-VantageCloud-Lake/Analyzing-Your-Data/Teradata-Package-for-Python-on-VantageCloud-Lake/Working-with-Open-Analytics/APIs-to-Use-with-Open-Analytics-Framework/API-to-Set-Authentication-Token/set_auth_token'>Click here</a> to see more details about using the Teradata APIs to set the authentication objects.</li>\n",
    "  <li>Check out <a href='https://medium.com/teradata/deploy-hugging-face-llms-on-teradata-vantagecloud-lake-with-nvidia-gpu-acceleration-d94d999edaa5'>Step 4</a> of this tutorial for details on configuring a VantageCloud Lake environment to use the Open Analytics Framework.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9744f809-f693-463b-9b01-73119c0e2802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've already loaded all the values into our environment variables and into a dictionary, env_vars.\n",
    "# username=env_vars.get(\"username\") isn't required when using base_url, pat and pem.\n",
    "ues_uri=env_vars.get(\"ues_uri\")\n",
    "if ues_uri.endswith(\"/open-analytics\"):\n",
    "    ues_uri = ues_uri[:-15]   # remove last 5 chars (\"/open-analytics\")\n",
    "\n",
    "if set_auth_token(base_url=ues_uri,\n",
    "                  pat_token=env_vars.get(\"access_token\"), \n",
    "                  pem_file=env_vars.get(\"pem_file\")\n",
    "                 ):\n",
    "    print(\"UES Authentication successful\")\n",
    "else:\n",
    "    print(\"UES Authentication failed. Check credentials.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e60de-a4ef-4e7d-8682-534b7d5e17af",
   "metadata": {},
   "outputs": [],
   "source": [
    "VSManager.health()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76ba06d-4c67-50d7-e154-60adbc60-997",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233c;'>\n",
    "<p style='font-size:20px;font-family:Arial;'><b>4. Ingest Unstructured Data and Generate Embeddings</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef759818-96fc-3020-6e84-8426583f-ddd",
   "metadata": {},
   "source": [
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "This section uses the <b>Unstructured.io API</b> to parse and embed a library of healthcare assets stored in S3. Unstructured.io handles the heavy lifting of document parsing — extracting text from PDFs, detecting layout elements, chunking content into semantically coherent pieces, and computing embeddings. The resulting records (text chunks plus embedding vectors) are written directly into Vantage tables.\n",
    "</p>\n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "You will need an <b>Unstructured API key</b> to run this section. If you do not already have one, create a free account at <a href='https://unstructured.io/'>unstructured.io</a> and retrieve your key from the API Keys page in the platform dashboard.\n",
    "</p>\n",
    "<div class='alert alert-block alert-info'>\n",
    "<p style='font-size:16px;font-family:Arial;'><b>Note:</b> The first cell below retrieves the current default database name, which is used as the target schema for the two embedded tables created during ingestion: <code>composite_pdfdocs_embedded</code> and <code>image_samples_embedded</code>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67286e1-5da9-44c2-acf0-829a06d91f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_db = execute_sql(\"SELECT DATABASE\").fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fdd9c7-9095-4dcb-a8ec-e8a950d34a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "unstructured_api_key = getpass(\"Enter your unstructured API Key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acb82dd-612e-8131-55fc-f14f6645-847",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#ccc;'>\n",
    "<p style='font-size:18px;font-family:Arial;'><b>4.1 Ingest Composite PDF Documents</b></p>\n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "The <code>ingest</code> utility calls the Unstructured API against an S3 prefix containing a library of composite healthcare PDFs. Each PDF is parsed, chunked, and embedded; the resulting records are written to the <b>composite_pdfdocs_embedded</b> table in Vantage. The table stores the raw text chunk, its embedding vector, and metadata such as the source filename and S3 record locator.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b89eec-5bad-4421-8a02-3a57c66f3a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest(api_key=unstructured_api_key, \n",
    "       td_host=env_vars.get(\"host\"), \n",
    "       td_user=env_vars.get(\"username\"), \n",
    "       td_password=env_vars.get(\"my_variable\"), \n",
    "       td_database=default_db, \n",
    "       td_table='composite_pdfdocs_embedded', \n",
    "       s3_uri=\"s3://dev-rel-demos/teradata-unstructured/healthcare-assets/composite-pdfs/\", \n",
    "       s3_anonymous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691d9a04-e8be-d0c8-85f2-7fe9e5a4-7c0",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#ccc;'>\n",
    "<p style='font-size:18px;font-family:Arial;'><b>4.2 Ingest Sample Images</b></p>\n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "The same ingestion pipeline is applied to a set of sample medical images stored at a separate S3 prefix. Unstructured processes each image, generates an embedding, and writes the record to the <b>image_samples_embedded</b> table. These image embeddings will later be used as query vectors to search the PDF document store for semantically similar content.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db3591-3642-4350-9da4-59cc950a57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest(api_key=unstructured_api_key, \n",
    "       td_host=env_vars.get(\"host\"), \n",
    "       td_user=env_vars.get(\"username\"), \n",
    "       td_password=env_vars.get(\"my_variable\"), \n",
    "       td_database=default_db, \n",
    "       td_table='image_samples_embedded', \n",
    "       s3_uri=\"s3://dev-rel-demos/teradata-unstructured/healthcare-assets/images/\", \n",
    "       s3_anonymous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400081dc-a203-2183-a0e7-8065ded0-41d",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#ccc;'>\n",
    "<p style='font-size:18px;font-family:Arial;'><b>4.3 Preview Ingested Data</b></p>\n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "Load both tables into teradataml DataFrames and inspect a sample of the records. The preview displays the <b>record_id</b>, <b>filename</b>, and <b>record_locator</b> columns — the embedding vectors are omitted here for readability, but they are present in the underlying table and will be used for similarity search in later steps.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3121e42b-8656-421b-956c-ae7fb243831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_documentation_bank = DataFrame.from_query(f\"SELECT * FROM {default_db}.composite_pdfdocs_embedded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1c1ab4-d505-4a87-97d3-861417e8c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_documentation_bank[['record_id','filename','record_locator']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf576ca-caa1-4648-9ff9-c820f9e8b37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_images_df = DataFrame.from_query(f\"SELECT * FROM {default_db}.image_samples_embedded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f94d95a-ec90-4a02-ae49-5b1ca8f4f3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_images_df[['record_id','filename','record_locator']].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77a06c0-821c-ecc4-6cf5-113ed567-671",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233c;'>\n",
    "<p style='font-size:20px;font-family:Arial;'><b>5. Review the Vector Store Registry</b></p>\n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "<code>VSManager.list()</code> returns a catalogue of all vector stores currently registered under your user's database. Use this to confirm that there are no conflicting names before creating a new store, or to audit existing stores and their metadata.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b83fcd-7e35-401d-8906-c65f27473ac1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vslist = VSManager.list()\n",
    "vslist[ (vslist['database_name'] == env_vars.get(\"username\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fe3330-2ad9-bfb2-6aa8-ac6444cc-a77",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233c;'>\n",
    "<p style='font-size:20px;font-family:Arial;'><b>6. Build the Enterprise Vector Store</b></p>\n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "<code>TeradataVectorStore.from_embeddings</code> creates a named vector store index backed by the <b>composite_pdfdocs_embedded</b> table. The method registers the index in Vantage and builds an index over the embedding column, enabling sub-second approximate nearest-neighbor lookups at scale. Key parameters include the data table, the column containing the embedding vectors, primary key columns for deduplication, and the metadata columns to carry through into search results.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43816e9d-81f1-4259-ae6b-1edf9d4909a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_emb = TeradataVectorStore.from_embeddings(name = \"unstructured_embeddings_demo\",\n",
    "                                     data = image_documentation_bank,\n",
    "                                     data_columns = \"embeddings\",\n",
    "                                     key_columns = [\"id\", \"record_id\"],\n",
    "                                     embedding_data_columns = \"text\",\n",
    "                                     metadata_columns = [\"text\",\"date_created\", \"date_modified\", \"record_locator\", \"filename\"],)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33310a48-e77a-73fc-1e62-0349514a-5eb",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#ccc;'>\n",
    "<p style='font-size:18px;font-family:Arial;'><b>6.1 Check Vector Store Status and Details</b></p>\n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "Although the create, update, and destroy APIs are synchronous, the <b>status</b> method gives an explicit confirmation that the operation completed and the index is in a healthy state. <code>get_details()</code> returns a richer summary that includes the index configuration, the number of indexed records, and the embedding dimensionality.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f203c3-9774-4ca4-a4fa-7c0a0949adfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_emb.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eac954-8390-496e-9de0-9b06a6be0a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_emb.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e525e888-6560-2468-3b34-7dfc57b4-be1",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#ccc;'>\n",
    "<p style='font-size:18px;font-family:Arial;'><b>6.2 Auxiliary Functions</b></p>\n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "The two cells below show common lifecycle operations on a vector store. <code>TeradataVectorStore(name=..., log=True)</code> reconnects to an existing named store without recreating it, which is useful when returning to an already-indexed dataset. <code>vs_emb.destroy()</code> tears down the index and removes the associated metadata from the registry — use this to clean up after experimentation.\n",
    "</p>\n",
    "<div class='alert alert-block alert-info'>\n",
    "<p style='font-size:16px;font-family:Arial;'><b>Note:</b> The <code>destroy()</code> call in this cell is provided for reference. Do not execute it here unless you intend to delete the vector store before completing the similarity search steps in Section 7.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa455519-014f-4755-a33f-1774a0844407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTION: Specify a name for a new vector store.\n",
    "vs_emb = TeradataVectorStore(name='unstructured_embeddings_demo', log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43693a7e-9a83-499e-9521-9199f83c956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: To destroy a vector store, use the destroy() function.\n",
    "vs_emb.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73bd1d5-3db1-df7b-675e-125e9fb6-8de",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233c;'>\n",
    "<p style='font-size:20px;font-family:Arial;'><b>7. Perform a Similarity Search</b></p>\n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "With the vector store built over the PDF embeddings, we can now query it using an image embedding as the search vector. <code>similarity_search_by_vector</code> computes cosine similarity between the query embedding and all indexed vectors, returning the top matches ranked by score.\n",
    "</p>\n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "The raw similarity response is then passed to <code>prepare_response</code>, which forwards the matched documents together with a natural-language question to the connected LLM. The LLM synthesizes the results into a readable answer — in this case extracting the title, description, filename, and record ID of the best-matching document.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c8f69a-a891-4c76-9c79-880964e3576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = vs_emb.similarity_search_by_vector(data = raw_images_df.head(1), column='embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e295ce-be9d-46ba-b263-d7bff315ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.similar_objects.sort('score',False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0fa563-d19b-4a38-9291-3538d934c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question='I need to recover The title, description and record id, and locator of the most similar record?'\n",
    "prompt='Format the response in a conversational way.'\n",
    "response = vs_emb.prepare_response(question=question, similarity_results=response, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f8d25e-523a-4e43-bd8c-0d4175aec2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The \"response\" object is a string. If we ask to display the string itself,\n",
    "# the special characters like new lines will not be interpreted.\n",
    "# To show the actual text with new lines, explicitly specify to print() the \"response\" object.\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1de897-6305-84b5-f088-94a2b738-dcc",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233c;'>\n",
    "<p style='font-size:20px;font-family:Arial;'><b>8. Build a Conversational Agent with the Vector Store</b></p>\n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "This section wires the Enterprise Vector Store into a <b>LangChain agent</b>, creating a natural-language interface for exploring the document and image library. The agent is equipped with two tools:\n",
    "</p>\n",
    "<ul style='font-size:16px;font-family:Arial;'>\n",
    "    <li><b>search_and_display_similar_image:</b> Takes the currently selected image from the interactive grid, runs a similarity search against the PDF vector store, and displays the best-matching document metadata.</li>\n",
    "    <li><b>display_pdf_from_locator:</b> Renders a PDF inline in the notebook given a filename and S3 path extracted from a previous search result.</li>\n",
    "</ul>\n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "The agent uses an LLM (routed through the VantageCloud Lake LiteLLM proxy) to decide which tool to call based on the user's message. An interactive image grid lets the user select an image before asking the agent to find similar documents or display a specific PDF.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27043a9-54d2-51ac-7a55-82823a7d-f35",
   "metadata": {},
   "source": [
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "The code below initializes the LLM connection using credentials from the environment file, renders the image grid widget, and sets up the chat UI. The <code>on_send</code> handler captures user messages and dispatches them to the agent, routing tool calls back to the vector store or the PDF renderer as needed.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ded20-7e9c-4b7b-a887-02d7a5be9c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df = raw_images_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b3eb0-9735-4f5f-9271-37acc0094af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Environment ───────────────────────────────────────────────────────────────\n",
    "\n",
    "environment_path = \"/home/jovyan/JupyterLabRoot/VantageCloud_Lake/.config/.env\"\n",
    "load_dotenv(dotenv_path=environment_path)\n",
    "\n",
    "llm_key = os.getenv(\"litellm_key\")\n",
    "llm_url = os.getenv(\"litellm_base_url\")\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model=\"openai-gpt-41\",\n",
    "    model_provider=\"openai\",\n",
    "    base_url=llm_url,\n",
    "    api_key=llm_key,\n",
    ")\n",
    "\n",
    "# ── Display the grid ──────────────────────────────────────────────────────────\n",
    "def on_image_selected(record_id: str) -> None:\n",
    "    chat_output.clear_output()\n",
    "\n",
    "result = display_image_grid(display_df, on_select=on_image_selected)\n",
    "\n",
    "display(HTML(\"<hr style='margin:20px 0'>\"))\n",
    "\n",
    "# ── Chat UI ───────────────────────────────────────────────────────────────────\n",
    "\n",
    "chat_output = widgets.Output(layout=widgets.Layout(\n",
    "    max_width=\"720px\",\n",
    "    min_height=\"200px\",\n",
    "    padding=\"12px\",\n",
    "    border=\"1px solid #ddd\",\n",
    "    border_radius=\"6px\",\n",
    "))\n",
    "\n",
    "text_input = widgets.Text(\n",
    "    placeholder=\"Ask something about the selected image...\",\n",
    "    layout=widgets.Layout(width=\"600px\")\n",
    ")\n",
    "\n",
    "send_btn = widgets.Button(\n",
    "    description=\"Send\",\n",
    "    button_style=\"primary\",\n",
    "    layout=widgets.Layout(width=\"80px\")\n",
    ")\n",
    "\n",
    "display(widgets.VBox([\n",
    "    chat_output,\n",
    "    widgets.HBox([text_input, send_btn]),\n",
    "], layout=widgets.Layout(max_width=\"720px\")))\n",
    "\n",
    "# ── Tool ──────────────────────────────────────────────────────────────────────\n",
    "\n",
    "@tool\n",
    "def search_and_display_similar_image(dummy: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Runs a similarity search using the currently selected image and displays\n",
    "    the most similar result. Call this whenever the user asks about similar images.\n",
    "    \"\"\"\n",
    "    if result.selected_id is None:\n",
    "        return \"No image is selected. Please select an image from the grid first.\"\n",
    "\n",
    "    response_similarity = vs_emb.similarity_search_by_vector(\n",
    "        data=raw_images_df[raw_images_df[\"record_id\"] == result.selected_id],\n",
    "        column=\"embeddings\",\n",
    "        return_type=\"json\",\n",
    "    )\n",
    "    question = \"I need to recover the title, description, filename, record id, and file_locator of the most similar record?\"\n",
    "    prompt = \"Format the response as JSON object.\"\n",
    "    response_chat = vs_emb.prepare_response(\n",
    "        question=question,\n",
    "        similarity_results=response_similarity,\n",
    "        prompt=prompt,\n",
    "    )\n",
    "\n",
    "    with chat_output:\n",
    "        display(HTML(\n",
    "            f\"<div style='font-family:sans-serif; padding:12px; background:#f9f9f9;\"\n",
    "            f\"border-radius:6px; margin:8px 0;'>{response_chat}</div>\"\n",
    "        ))\n",
    "\n",
    "    return response_chat\n",
    "\n",
    "@tool\n",
    "def display_pdf_from_locator(filename: str, remote_file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Renders a PDF in the notebook given a filename and S3 remote_file_path.\n",
    "    Use this when the user wants to view a PDF from the search results.\n",
    "    Extract filename and remote_file_path from the search response and pass them here.\n",
    "    \"\"\"\n",
    "    s3_path = remote_file_path.rstrip(\"/\")\n",
    "    without_scheme = s3_path.replace(\"s3://\", \"\", 1)\n",
    "    bucket, _, prefix = without_scheme.partition(\"/\")\n",
    "    key = f\"{prefix}/{filename}\" if prefix else filename\n",
    "    url = f\"https://{bucket}.s3.amazonaws.com/{key}\"\n",
    "\n",
    "    with chat_output:\n",
    "        display(HTML(\n",
    "            f\"<div style='margin:8px 0;'>\"\n",
    "            f\"<b>Displaying:</b> <a href='{url}' target='_blank'>{filename}</a>\"\n",
    "            f\"</div>\"\n",
    "        ))\n",
    "        display(IFrame(src=url, width=\"100%\", height=\"600px\"))\n",
    "\n",
    "    return f\"PDF displayed: {filename}\"\n",
    "\n",
    "\n",
    "# ── Agent setup ───────────────────────────────────────────────────────────────\n",
    "\n",
    "tools = [search_and_display_similar_image, display_pdf_from_locator]\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=(\n",
    "        \"You are an image analysis assistant with two tools. \"\n",
    "        \"Use search_and_display_similar_image to find similar images. \"\n",
    "        \"Use display_pdf_from_locator to render a PDF by passing the filename \"\n",
    "        \"and remote_file_path extracted from the search response. \"\n",
    "        \"When the user asks to view or open a PDF, extract those two values \"\n",
    "        \"from the search result and call display_pdf_from_locator.\"\n",
    "    ),\n",
    ")\n",
    "# ── Send handler (synchronous, no threads) ────────────────────────────────────\n",
    "\n",
    "def on_send(btn):\n",
    "    msg = text_input.value\n",
    "    if not msg.strip():\n",
    "        return\n",
    "    text_input.value = \"\"\n",
    "\n",
    "    with chat_output:\n",
    "        display(HTML(\n",
    "            f\"<div style='margin:6px 0; padding:8px 12px; background:#e8f0fe;\"\n",
    "            f\"border-radius:6px;'><b>You:</b> {msg}</div>\"\n",
    "        ))\n",
    "\n",
    "    response = agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=msg)]\n",
    "    })\n",
    "\n",
    "    agent_reply = response[\"messages\"][-1].content\n",
    "    with chat_output:\n",
    "        display(HTML(\n",
    "            f\"<div style='margin:6px 0; padding:8px 12px; background:#f0f4f0;\"\n",
    "            f\"border-radius:6px;'><b>Agent:</b> {agent_reply}</div>\"\n",
    "        ))\n",
    "\n",
    "send_btn.on_click(on_send)\n",
    "text_input.on_submit(lambda t: on_send(None) or setattr(t, \"value\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3b7e63-facc-45de-a449-675b19be-bb6",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233c;'>\n",
    "<p style='font-size:20px;font-family:Arial;'><b>9. Cleanup</b></p>\n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "Run the cells in this section to tear down all resources created during the notebook. This includes destroying the vector store index, removing the embedded tables from Vantage, disconnecting the UES session, and closing the database connection.\n",
    "</p>\n",
    "<hr style='height:1px;border:none;background-color:#ccc;'>\n",
    "<p style='font-size:18px;font-family:Arial;'><b>9.1 Destroy the Vector Store and Review Registry</b></p>\n",
    "<p style='font-size:16px;font-family:Arial;'>Call <code>vs_emb.destroy()</code> to remove the HNSW index and deregister the vector store. The subsequent <code>status()</code> and <code>VSManager.list()</code> calls confirm that the store has been fully removed.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a562ef1f-7893-4d85-bdfc-8d765eed8f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_emb.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691d5b7a-ba77-4f1a-8f1d-8b55d78a4c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_emb.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41edd1f4-c89d-4f3c-965e-c0aa49b6fa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vslist = VSManager.list()\n",
    "vslist[ (vslist['database_name'] == env_vars.get(\"username\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be51b556-61a7-a64f-4b96-8445c8ba-160",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#ccc;'>\n",
    "<p style='font-size:18px;font-family:Arial;'><b>9.2 Disconnect and Drop Tables</b></p>\n",
    "<p style='font-size:16px;font-family:Arial;'>Use <code>VSManager.disconnect()</code> to close the UES session, then drop the two embedded tables created during ingestion to return the database to a clean state. Finally, <code>remove_context()</code> closes the teradataml connection to Vantage.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d6f002-93b1-4955-84a9-750650d6a9a6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "VSManager.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d6cdfe-cccd-401b-925e-1ad844194fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop tables\n",
    "db_drop_table('composite_pdfdocs_embedded', schema_name=default_db)\n",
    "db_drop_table('image_samples_embedded', schema_name=default_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5068f4-2507-4ac4-8339-9b41d20eaef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d75485b-b4e3-4415-ae26-554149520897",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; border-bottom:3px solid #91A0Ab\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2025. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
