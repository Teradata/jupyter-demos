{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ce3dd8a-f3e5-40d5-ab4c-d40cc358cf7f",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Complaints Analysis Integration with Customer360 using Teradata VantageCloud and open-source language models\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57054f7e-befe-4029-b4ac-b82019240b1f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;'><b>Introduction:</b></p>\n",
    "<p style='font-size:16px;font-family:Arial;'>Complaints Analysis Integration with Customer360 is a comprehensive approach to managing customer complaints and feedback within the framework of a Customer 360-degree view using <b>Teradata Vantage</b> and <b>open-source language models</b>. This integration aims to provide a seamless and personalized customer experience by leveraging data from various sources, including CRM systems, marketing platforms, and social media.</p> <p style='font-size:16px;font-family:Arial;'>The key components of this integration include:</p> \n",
    "\n",
    "<ol style='font-size:16px;font-family:Arial;'> <li><b>Customer 360 Data Manager</b>: Responsible for managing and maintaining a comprehensive view of customer data, including collection, integration, and analysis from multiple sources.</li> <li><b>Complaints Management Dashboard</b>: Analyzes customer complaints, providing insights into complaint volume, trends, and resolution progress.</li> <li><b>Customer Insights</b>: Tools for gaining insights into customer behavior and preferences, enabling targeted marketing campaigns and informed business decisions.</li> </ol> <p style='font-size:16px;font-family:Arial;'>The benefits of this integration include:</p> <ol style='font-size:16px;font-family:Arial;'> <li><b>Improved Customer Experience</b>: By integrating complaints analysis with Customer 360, businesses can address customer complaints more effectively, leading to increased customer satisfaction and loyalty.</li> <li><b>Data-Driven Decision Making</b>: The integration provides a centralized platform for analyzing customer data, enabling businesses to make informed decisions about product development, marketing strategies, and customer engagement.</li> <li><b>Enhanced Customer Insights</b>: The comprehensive view of customer data allows businesses to better understand customer needs and preferences, leading to more targeted and effective marketing efforts.</li> </ol> \n",
    "\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>By integrating complaints analysis with Customer 360, businesses can create a more comprehensive and personalized customer experience, driving business growth and customer satisfaction.</p> \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'><b>Steps in the analysis:</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li>Configuring the environment</li>\n",
    "  <li>Connect to Vantage</li>\n",
    "  <li>Create a Custom Container in Vantage</li>\n",
    "  <li>Install Dependencies</li>\n",
    "  <li>Operationalizing AI-powered analytics</li>\n",
    "    <li>Integrated data with customer 360</li>\n",
    "  <li>Cleanup</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e457db5-d4df-4e7f-a11a-fcb1416e462d",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;'>\n",
    "<b style = 'font-size:20px;font-family:Arial;'>1. Configuring the environment</b>\n",
    "\n",
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>1.1 Install the required libraries</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03eb4587-6632-4b08-a121-c98ea5a8fc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting certifi==2024.7.4 (from -r requirements.txt (line 1))\n",
      "  Using cached certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting charset-normalizer==3.3.2 (from -r requirements.txt (line 2))\n",
      "  Using cached charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting dill==0.3.8 (from -r requirements.txt (line 3))\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting filelock==3.15.4 (from -r requirements.txt (line 4))\n",
      "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec==2024.6.1 (from -r requirements.txt (line 5))\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting huggingface-hub==0.24.6 (from -r requirements.txt (line 6))\n",
      "  Using cached huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting idna==3.7 (from -r requirements.txt (line 7))\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting Jinja2==3.1.4 (from -r requirements.txt (line 8))\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting joblib==1.4.2 (from -r requirements.txt (line 9))\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting MarkupSafe==2.1.5 (from -r requirements.txt (line 10))\n",
      "  Using cached MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: mpmath==1.3.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (1.3.0)\n",
      "Collecting networkx==3.3 (from -r requirements.txt (line 12))\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting numpy==2.1.0 (from -r requirements.txt (line 13))\n",
      "  Using cached numpy-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/envs/py311/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/envs/py311/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/envs/py311/lib/python3.11/site-packages (from -r requirements.txt (line 16)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/envs/py311/lib/python3.11/site-packages (from -r requirements.txt (line 17)) (12.1.105)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from -r requirements.txt (line 18))\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/envs/py311/lib/python3.11/site-packages (from -r requirements.txt (line 19)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/envs/py311/lib/python3.11/site-packages (from -r requirements.txt (line 20)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/envs/py311/lib/python3.11/site-packages (from -r requirements.txt (line 21)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/envs/py311/lib/python3.11/site-packages (from -r requirements.txt (line 22)) (12.1.0.106)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.20 (from -r requirements.txt (line 23))\n",
      "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/envs/py311/lib/python3.11/site-packages (from -r requirements.txt (line 24)) (12.1.105)\n",
      "Collecting packaging==24.1 (from -r requirements.txt (line 25))\n",
      "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pandas==2.2.2 (from -r requirements.txt (line 26))\n",
      "  Using cached pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting pillow==10.4.0 (from -r requirements.txt (line 27))\n",
      "  Using cached pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pip==23.0.1 (from -r requirements.txt (line 28))\n",
      "  Using cached pip-23.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from -r requirements.txt (line 29)) (2.9.0.post0)\n",
      "Collecting pytz==2024.1 (from -r requirements.txt (line 30))\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting PyYAML==6.0.2 (from -r requirements.txt (line 31))\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting regex==2024.7.24 (from -r requirements.txt (line 32))\n",
      "  Using cached regex-2024.7.24-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests==2.32.3 (from -r requirements.txt (line 33))\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting safetensors==0.4.4 (from -r requirements.txt (line 34))\n",
      "  Using cached safetensors-0.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting scikit-learn==1.5.1 (from -r requirements.txt (line 35))\n",
      "  Using cached scikit_learn-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting scipy==1.14.1 (from -r requirements.txt (line 36))\n",
      "  Using cached scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting sentence-transformers==3.4.1 (from -r requirements.txt (line 37))\n",
      "  Using cached sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sentencepiece==0.2.0 (from -r requirements.txt (line 38))\n",
      "  Using cached sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting setuptools==65.5.0 (from -r requirements.txt (line 39))\n",
      "  Using cached setuptools-65.5.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting six==1.16.0 (from -r requirements.txt (line 40))\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting sympy==1.13.2 (from -r requirements.txt (line 41))\n",
      "  Using cached sympy-1.13.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting threadpoolctl==3.5.0 (from -r requirements.txt (line 42))\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tokenizers==0.19.1 (from -r requirements.txt (line 43))\n",
      "  Using cached tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting torch==2.4.0 (from -r requirements.txt (line 44))\n",
      "  Using cached torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting tqdm==4.66.5 (from -r requirements.txt (line 45))\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting transformers==4.50.0 (from -r requirements.txt (line 46))\n",
      "  Using cached transformers-4.50.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting typing_extensions==4.12.2 (from -r requirements.txt (line 47))\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting tzdata==2024.1 (from -r requirements.txt (line 48))\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting urllib3==2.2.2 (from -r requirements.txt (line 49))\n",
      "  Using cached urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting itables==2.1.5 (from -r requirements.txt (line 50))\n",
      "  Using cached itables-2.1.5-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting soundfile (from -r requirements.txt (line 51))\n",
      "  Using cached soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Collecting torchvision (from -r requirements.txt (line 52))\n",
      "  Using cached torchvision-0.24.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Collecting torchaudio (from -r requirements.txt (line 53))\n",
      "  Using cached torchaudio-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
      "INFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting python-dateutil==2.9.0.post0 (from -r requirements.txt (line 29))\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from -r requirements.txt (line 24))\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from -r requirements.txt (line 22))\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from -r requirements.txt (line 21))\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from -r requirements.txt (line 20))\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from -r requirements.txt (line 19))\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "INFO: pip is still looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from -r requirements.txt (line 17))\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from -r requirements.txt (line 16))\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from -r requirements.txt (line 15))\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from -r requirements.txt (line 14))\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting mpmath==1.3.0 (from -r requirements.txt (line 11))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "\u001b[31mERROR: Cannot install -r requirements.txt (line 37), -r requirements.txt (line 46) and huggingface-hub==0.24.6 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "The conflict is caused by:\n",
      "    The user requested huggingface-hub==0.24.6\n",
      "    sentence-transformers 3.4.1 depends on huggingface-hub>=0.20.0\n",
      "    transformers 4.50.0 depends on huggingface-hub<1.0 and >=0.26.0\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
      "\n",
      "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77287544-6ee8-46a6-8363-806508cc5cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: teradataml==20.0.0.7 in /opt/conda/envs/py311/lib/python3.11/site-packages (from -r requirements2.txt (line 1)) (20.0.0.7)\n",
      "Requirement already satisfied: teradatamlwidgets==20.0.0.6 in /home/jovyan/.local/lib/python3.11/site-packages (from -r requirements2.txt (line 2)) (20.0.0.6)\n",
      "Requirement already satisfied: teradatamodelops==7.0.3 in /home/jovyan/.local/lib/python3.11/site-packages (from -r requirements2.txt (line 3)) (7.0.3)\n",
      "Requirement already satisfied: teradatasql==20.0.0.34 in /home/jovyan/.local/lib/python3.11/site-packages (from -r requirements2.txt (line 4)) (20.0.0.34)\n",
      "Requirement already satisfied: teradatasqlalchemy==20.0.0.7 in /opt/conda/envs/py311/lib/python3.11/site-packages (from -r requirements2.txt (line 5)) (20.0.0.7)\n",
      "Requirement already satisfied: sentencepiece in /home/jovyan/.local/lib/python3.11/site-packages (from -r requirements2.txt (line 6)) (0.2.1)\n",
      "Requirement already satisfied: sentence-transformers in /home/jovyan/.local/lib/python3.11/site-packages (from -r requirements2.txt (line 7)) (5.1.1)\n",
      "Requirement already satisfied: wordcloud in /home/jovyan/.local/lib/python3.11/site-packages (from -r requirements2.txt (line 8)) (1.9.4)\n",
      "Requirement already satisfied: pandas>=0.22 in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradataml==20.0.0.7->-r requirements2.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradataml==20.0.0.7->-r requirements2.txt (line 1)) (7.1.0)\n",
      "Requirement already satisfied: requests>=2.25.1 in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradataml==20.0.0.7->-r requirements2.txt (line 1)) (2.32.5)\n",
      "Requirement already satisfied: scikit-learn>=0.24.2 in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradataml==20.0.0.7->-r requirements2.txt (line 1)) (1.5.2)\n",
      "Requirement already satisfied: IPython>=8.10.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradataml==20.0.0.7->-r requirements2.txt (line 1)) (9.6.0)\n",
      "Requirement already satisfied: imbalanced-learn>=0.8.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradataml==20.0.0.7->-r requirements2.txt (line 1)) (0.12.4)\n",
      "Requirement already satisfied: matplotlib>=3.7.5 in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradataml==20.0.0.7->-r requirements2.txt (line 1)) (3.8.3)\n",
      "Requirement already satisfied: seaborn>=0.13.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradataml==20.0.0.7->-r requirements2.txt (line 1)) (0.13.2)\n",
      "Requirement already satisfied: pyjwt>=2.8.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradataml==20.0.0.7->-r requirements2.txt (line 1)) (2.10.1)\n",
      "Requirement already satisfied: cryptography>=42.0.5 in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradataml==20.0.0.7->-r requirements2.txt (line 1)) (46.0.2)\n",
      "Requirement already satisfied: sqlalchemy>=2.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradataml==20.0.0.7->-r requirements2.txt (line 1)) (2.0.25)\n",
      "Requirement already satisfied: lightgbm>=3.3.3 in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradataml==20.0.0.7->-r requirements2.txt (line 1)) (4.6.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradataml==20.0.0.7->-r requirements2.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradataml==20.0.0.7->-r requirements2.txt (line 1)) (3.3.1)\n",
      "Requirement already satisfied: requests-oauthlib>=2.0.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradataml==20.0.0.7->-r requirements2.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: pydantic>=2.10.6 in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradataml==20.0.0.7->-r requirements2.txt (line 1)) (2.12.1)\n",
      "Requirement already satisfied: PyYAML>=6.0.2 in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradataml==20.0.0.7->-r requirements2.txt (line 1)) (6.0.3)\n",
      "Requirement already satisfied: ipywidgets>=8.1.1 in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradatamlwidgets==20.0.0.6->-r requirements2.txt (line 2)) (8.1.7)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradatamodelops==7.0.3->-r requirements2.txt (line 3)) (3.1.6)\n",
      "Requirement already satisfied: aia>=0.2.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradatamodelops==7.0.3->-r requirements2.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: gitpython>=3.1.35 in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradatamodelops==7.0.3->-r requirements2.txt (line 3)) (3.1.45)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradatamodelops==7.0.3->-r requirements2.txt (line 3)) (2025.10.5)\n",
      "Requirement already satisfied: pycryptodome in /opt/conda/envs/py311/lib/python3.11/site-packages (from teradatasql==20.0.0.34->-r requirements2.txt (line 4)) (3.23.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/jovyan/.local/lib/python3.11/site-packages (from sentence-transformers->-r requirements2.txt (line 7)) (4.57.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/py311/lib/python3.11/site-packages (from sentence-transformers->-r requirements2.txt (line 7)) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from sentence-transformers->-r requirements2.txt (line 7)) (2.2.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/py311/lib/python3.11/site-packages (from sentence-transformers->-r requirements2.txt (line 7)) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from sentence-transformers->-r requirements2.txt (line 7)) (0.35.3)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/py311/lib/python3.11/site-packages (from sentence-transformers->-r requirements2.txt (line 7)) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from sentence-transformers->-r requirements2.txt (line 7)) (4.15.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/py311/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->-r requirements2.txt (line 7)) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/py311/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->-r requirements2.txt (line 7)) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->-r requirements2.txt (line 7)) (25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/py311/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->-r requirements2.txt (line 7)) (2025.9.18)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/jovyan/.local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->-r requirements2.txt (line 7)) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/envs/py311/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->-r requirements2.txt (line 7)) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers->-r requirements2.txt (line 7)) (2025.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/envs/py311/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers->-r requirements2.txt (line 7)) (1.1.10)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from cryptography>=42.0.5->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/envs/py311/lib/python3.11/site-packages (from cffi>=2.0.0->cryptography>=42.0.5->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (2.23)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/envs/py311/lib/python3.11/site-packages (from gitpython>=3.1.35->teradatamodelops==7.0.3->-r requirements2.txt (line 3)) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/envs/py311/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.35->teradatamodelops==7.0.3->-r requirements2.txt (line 3)) (5.0.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/envs/py311/lib/python3.11/site-packages (from imbalanced-learn>=0.8.0->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from imbalanced-learn>=0.8.0->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (3.6.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/envs/py311/lib/python3.11/site-packages (from IPython>=8.10.0->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /opt/conda/envs/py311/lib/python3.11/site-packages (from IPython>=8.10.0->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/envs/py311/lib/python3.11/site-packages (from IPython>=8.10.0->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/envs/py311/lib/python3.11/site-packages (from IPython>=8.10.0->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/envs/py311/lib/python3.11/site-packages (from IPython>=8.10.0->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/conda/envs/py311/lib/python3.11/site-packages (from IPython>=8.10.0->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from IPython>=8.10.0->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /opt/conda/envs/py311/lib/python3.11/site-packages (from IPython>=8.10.0->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from IPython>=8.10.0->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/envs/py311/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython>=8.10.0->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (0.2.14)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/envs/py311/lib/python3.11/site-packages (from ipywidgets>=8.1.1->teradatamlwidgets==20.0.0.6->-r requirements2.txt (line 2)) (0.2.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /opt/conda/envs/py311/lib/python3.11/site-packages (from ipywidgets>=8.1.1->teradatamlwidgets==20.0.0.6->-r requirements2.txt (line 2)) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /opt/conda/envs/py311/lib/python3.11/site-packages (from ipywidgets>=8.1.1->teradatamlwidgets==20.0.0.6->-r requirements2.txt (line 2)) (3.0.15)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/conda/envs/py311/lib/python3.11/site-packages (from jedi>=0.16->IPython>=8.10.0->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (0.8.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from jinja2>=3.0.3->teradatamodelops==7.0.3->-r requirements2.txt (line 3)) (3.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/envs/py311/lib/python3.11/site-packages (from matplotlib>=3.7.5->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/py311/lib/python3.11/site-packages (from matplotlib>=3.7.5->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from matplotlib>=3.7.5->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/envs/py311/lib/python3.11/site-packages (from matplotlib>=3.7.5->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/envs/py311/lib/python3.11/site-packages (from matplotlib>=3.7.5->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/envs/py311/lib/python3.11/site-packages (from matplotlib>=3.7.5->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/py311/lib/python3.11/site-packages (from pandas>=0.22->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/py311/lib/python3.11/site-packages (from pandas>=0.22->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/envs/py311/lib/python3.11/site-packages (from pexpect>4.3->IPython>=8.10.0->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from pydantic>=2.10.6->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.3 in /opt/conda/envs/py311/lib/python3.11/site-packages (from pydantic>=2.10.6->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (2.41.3)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/conda/envs/py311/lib/python3.11/site-packages (from pydantic>=2.10.6->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/py311/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.7.5->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/envs/py311/lib/python3.11/site-packages (from requests>=2.25.1->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/py311/lib/python3.11/site-packages (from requests>=2.25.1->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/py311/lib/python3.11/site-packages (from requests>=2.25.1->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/envs/py311/lib/python3.11/site-packages (from sqlalchemy>=2.0->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (3.2.4)\n",
      "Requirement already satisfied: sympy in /opt/conda/envs/py311/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements2.txt (line 7)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/py311/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements2.txt (line 7)) (3.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/envs/py311/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements2.txt (line 7)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/envs/py311/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements2.txt (line 7)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/envs/py311/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements2.txt (line 7)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/envs/py311/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements2.txt (line 7)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/envs/py311/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements2.txt (line 7)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/envs/py311/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements2.txt (line 7)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/envs/py311/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements2.txt (line 7)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/envs/py311/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements2.txt (line 7)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/envs/py311/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements2.txt (line 7)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/envs/py311/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements2.txt (line 7)) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/envs/py311/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements2.txt (line 7)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers->-r requirements2.txt (line 7)) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/envs/py311/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers->-r requirements2.txt (line 7)) (12.9.86)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from stack_data->IPython>=8.10.0->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from stack_data->IPython>=8.10.0->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/conda/envs/py311/lib/python3.11/site-packages (from stack_data->IPython>=8.10.0->teradataml==20.0.0.7->-r requirements2.txt (line 1)) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/envs/py311/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers->-r requirements2.txt (line 7)) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "!pip install -r requirements2.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fd81e4-0df9-4360-b3ac-72214f135296",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;'><b>Note: </b><i>Please restart the kernel after executing these two lines. The simplest way to restart the Kernel is by typing zero zero and then pressing <b> 0 0</b></i> and then pressing <b><i>Enter</i></b>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc278740-1511-4423-bf2b-92a5109a47bf",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>1.2 Import the required libraries</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f183178-9807-4538-b794-922820346ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Python version 3.11 for user environment\n"
     ]
    }
   ],
   "source": [
    "from teradataml import *\n",
    "from teradatasqlalchemy.types import *\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import csv, sys, os, warnings\n",
    "from os.path import expanduser\n",
    "from collections import OrderedDict\n",
    "from wordcloud import WordCloud\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "from IPython.display import clear_output , display as ipydisplay\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "display.suppress_vantage_runtime_warnings = True\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# get the current python version to match deploy a custom container\n",
    "# python_version = str(sys.version_info[0]) + '.' + str(sys.version_info[1])\n",
    "python_version = \"3.11\"\n",
    "print(f'Using Python version {python_version} for user environment')\n",
    "\n",
    "# Hugging Face model for the demo\n",
    "# model_name = 'Falconsai/text_summarization'\n",
    "model_names = {'text_summarization':'facebook/bart-large-cnn', \n",
    "               'sentiment_analysis':'distilbert-base-uncased-finetuned-sst-2-english', \n",
    "               'topic_modelling': 'facebook/bart-large-mnli'}\n",
    "\n",
    "# a list of required packages to install in the custom OAF container\n",
    "# modify this if using different models or design patterns\n",
    "pkgs = ['numpy',\n",
    "        'transformers',\n",
    "        'torch',\n",
    "        'sentencepiece',\n",
    "        'pandas',\n",
    "        'sentence-transformers']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1763fd95-5000-4a2d-8b86-7be261e20847",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>2. Connect to Vantage</b>\n",
    "\n",
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>2.1 Load the Environment Variables and Connect to Vantage</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Load the environment variables from a .env file and use them to create a connection context to Teradata.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0812117-aa75-4a1e-95e3-eb7796dbe7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if this environment is ready to connect to VantageCloud Lake...\n",
      "Your environment parameter file exist.  Please proceed with this use case.\n",
      "Connected to VantageCloud Lake with: Engine(teradatasql://newtd20v18-dfb2-88vgt0b5i55ikpx7:***@54.156.178.22)\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking if this environment is ready to connect to VantageCloud Lake...\")\n",
    "\n",
    "if os.path.exists(\"/home/jovyan/JupyterLabRoot/VantageCloud_Lake/.config/.env\"):\n",
    "    print(\"Your environment parameter file exist.  Please proceed with this use case.\")\n",
    "    # Load all the variables from the .env file into a dictionary\n",
    "    env_vars = dotenv_values(\"/home/jovyan/JupyterLabRoot/VantageCloud_Lake/.config/.env\")\n",
    "    # Create the Context\n",
    "    eng = create_context(host=env_vars.get(\"host\"), username=env_vars.get(\"username\"), password=env_vars.get(\"my_variable\"))\n",
    "    execute_sql('''SET query_band='DEMO=text_analytics_teradatagenai_aws_huggingface.ipynb;' UPDATE FOR SESSION;''')\n",
    "    print(\"Connected to VantageCloud Lake with:\", eng)\n",
    "else:\n",
    "    print(\"Your environment has not been prepared for connecting to VantageCloud Lake.\")\n",
    "    print(\"Please contact the support team.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce81699-6345-4dbf-a3a8-b9402c7b6a98",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dca7332-48f5-4702-8b56-d8a03fbb87a2",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>2.2  Authenticate to the User Environment Service</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>To better support integration with Cloud Services and common automation tools; the <b > User Environment Service</b> is accessed via RESTful APIs.  These APIs can be called directly or in the examples shown below that leverage the Python Package for Teradata (teradataml) methods.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "285deebd-8158-47f5-bb08-cf61e35d51b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication token is generated, authenticated and set for the session.\n",
      "UES Authentication successful\n"
     ]
    }
   ],
   "source": [
    "# We've already loaded all the values into our environment variables and into a dictionary, env_vars.\n",
    "# username=env_vars.get(\"username\") isn't required when using base_url, pat and pem.\n",
    "\n",
    "if set_auth_token(base_url=env_vars.get(\"ues_uri\"),\n",
    "                  pat_token=env_vars.get(\"access_token\"), \n",
    "                  pem_file=env_vars.get(\"pem_file\"),\n",
    "                  valid_from=int(time.time())\n",
    "                 ):\n",
    "    print(\"UES Authentication successful\")\n",
    "else:\n",
    "    print(\"UES Authentication failed. Check credentials.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d8a61e",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "\n",
    "<b style = 'font-size:18px;font-family:Arial;'>3. Create a Custom Container in Vantage</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>If desired, the user can create a <b>new</b> custom environment by starting with a \"base\" image and customizing it.  The steps are:</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li>List the available \"base\" images the system supports</li>\n",
    "    <li>List any existing \"custom\" environments the user has created</li>\n",
    "    <li>If there are no custom environments, then create a new one from a base image</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffbd2ca3-96c1-4ce2-ae0a-bb9ac022cf5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a list of the versions of the libraries available to be used within an OAF environments.\n",
      "\n",
      "     base_name language  version\n",
      "0   python_3.9   Python   3.9.20\n",
      "1  python_3.10   Python  3.10.15\n",
      "2  python_3.11   Python  3.11.10\n",
      "3        r_4.3        R    4.3.3\n",
      "4        r_4.4        R    4.4.2\n",
      "\n",
      "Here is a list of your current environments:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env_name</th>\n",
       "      <th>env_description</th>\n",
       "      <th>base_env_name</th>\n",
       "      <th>language</th>\n",
       "      <th>conda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>newtd20v18-dfb2-88vgt0b5i55ikpx7</td>\n",
       "      <td>BYOLLM demo env</td>\n",
       "      <td>python_3.11</td>\n",
       "      <td>Python</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           env_name  env_description base_env_name language  \\\n",
       "0  newtd20v18-dfb2-88vgt0b5i55ikpx7  BYOLLM demo env   python_3.11   Python   \n",
       "\n",
       "   conda  \n",
       "0  False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your default environment already exists. You can continue with this notebook.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if we have any existing environments\n",
    "# If any other environments exist along with our default OAF environment, we will delete them\n",
    "\n",
    "environment_name = env_vars.get(\"username\")\n",
    "print(\"Here is a list of the versions of the libraries available to be used within an OAF environments.\\n\")\n",
    "print(list_base_envs())\n",
    "env_list = list_user_envs()\n",
    "\n",
    "if env_list is None:\n",
    "    print(\"\\nThis user does not have any environments.\\nCreating your environment now.\")\n",
    "    demo_env = create_env(env_name=f'{environment_name}', base_env=f'{python_version}', desc='BYOLLM demo env')\n",
    "    print(demo_env)\n",
    "else:\n",
    "    print(\"\\nHere is a list of your current environments:\")\n",
    "    ipydisplay(env_list)\n",
    "    for env_name in env_list['env_name']:\n",
    "        if env_name == environment_name:\n",
    "            demo_env = get_env(environment_name)\n",
    "            print(\"Your default environment already exists. You can continue with this notebook.\\n\\n\")\n",
    "        else:\n",
    "            print(f\"Your existing environment, {env_name} doesn't match our default environment for this user.\")\n",
    "            print(\"We're going to delete it.\")      \n",
    "            print(f\"Please wait: Environment {env_name} is being removed!\")\n",
    "            remove_env(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556a860-e27f-432d-a4d1-f4bd903e34fd",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>4. Install Dependencies</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The second step in the customization process is to install Python package dependencies. This demonstration uses the Hugging Face <a href = 'https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english'>distilbert-base-uncased-finetuned-sst-2-english</a> Sentence Transformer.  Since VantageCloud Lake Analytic Clusters are secured by default against unauthorized access to the outside network, the user can load the required libraries and model using teradataml methods:\n",
    "</p> \n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li>List the currently installed models and python libraries</li>\n",
    "    <li><b>If necessary</b>, install any required packages</li>\n",
    "    <li><b>If necessary</b>, install the pre-trained model.  This process takes several steps;\n",
    "        <ol style = 'font-size:16px;font-family:Arial;'>\n",
    "            <li>Import and download the model</li>\n",
    "            <li>Create a zip archive of the model artifacts</li>\n",
    "            <li>Call the install_model() method to load the model to the container</li>\n",
    "        </ol></li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0f2a8a6-5a5b-483d-81e7-46682c764bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No models found in remote user environment newtd20v18-dfb2-88vgt0b5i55ikpx7.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>certifi</td>\n",
       "      <td>2025.10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>charset-normalizer</td>\n",
       "      <td>3.4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filelock</td>\n",
       "      <td>3.20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fsspec</td>\n",
       "      <td>2025.9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hf-xet</td>\n",
       "      <td>1.1.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name    version\n",
       "0             certifi  2025.10.5\n",
       "1  charset-normalizer      3.4.4\n",
       "2            filelock     3.20.0\n",
       "3              fsspec   2025.9.0\n",
       "4              hf-xet     1.1.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipydisplay(demo_env.models)\n",
    "\n",
    "# just showing a sample here - remove .head(5) to see them all\n",
    "ipydisplay(demo_env.libs.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3b179f-4649-483a-a470-db064266c3b6",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>4.1 A note on package versions</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>This use case uses the DataFrame <code>apply()</code> method, which automatically passes the python code to the Analytic Cluster. We need to ensue the python package versions match.  <code>dill</code> and <code>pandas</code> are required, as is any additional libraries for the use case.\n",
    "</p> \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'><b>Note!</b> While not required for many OAF use cases, for this demo the required packages for the model execution must be installed in the local environment first.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6feda0d-d9da-4e57-9fdb-00635c6bdf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required packages are installed in the newtd20v18-dfb2-88vgt0b5i55ikpx7 environment\n"
     ]
    }
   ],
   "source": [
    "# import these functions inside of a function namespace\n",
    "def get_versions(pkgs):\n",
    "    local_v_pkgs = []\n",
    "    for p in pkgs:\n",
    "\n",
    "        # fix up any hyphened package names\n",
    "        p_fixed = p.replace(\"-\", \"_\")\n",
    "\n",
    "        # import the packages and append the strings to the list\n",
    "        exec(\n",
    "            f\"\"\"import {p_fixed}; local_v_pkgs.append('{p}==' + str({p_fixed}.__version__))\"\"\"\n",
    "        )\n",
    "    return local_v_pkgs\n",
    "\n",
    "\n",
    "v_pkgs = get_versions(pkgs)\n",
    "\n",
    "\n",
    "# check to see if these packages need to be installed\n",
    "# by comparing the len of the intersection of the list of required packages with the installed ones\n",
    "if not len(\n",
    "    set([x.split(\"==\")[0] for x in pkgs]).intersection(demo_env.libs[\"name\"].to_list())) == len(pkgs):\n",
    "\n",
    "    # pass the list of packages - split off any extra info from the version property e.g., plus sign\n",
    "    claim_id = demo_env.install_lib(\n",
    "        [x.split(\"+\")[0] for x in v_pkgs], asynchronous=True\n",
    "    )\n",
    "else:\n",
    "    print(f\"All required packages are installed in the {environment_name} environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d186ca1",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>4.2 Monitor library installation status</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Optional -  you can execute this cell to monitor the library installation status using the cell below.  Please be aware that this step will take several minutes to complete.\n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d533b2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No installations to monitor\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>certifi</td>\n",
       "      <td>2025.10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>charset-normalizer</td>\n",
       "      <td>3.4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filelock</td>\n",
       "      <td>3.20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fsspec</td>\n",
       "      <td>2025.9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hf-xet</td>\n",
       "      <td>1.1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>huggingface-hub</td>\n",
       "      <td>0.35.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>idna</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jinja2</td>\n",
       "      <td>3.1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>joblib</td>\n",
       "      <td>1.5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MarkupSafe</td>\n",
       "      <td>3.0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mpmath</td>\n",
       "      <td>1.3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>networkx</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>numpy</td>\n",
       "      <td>1.23.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nvidia-cublas-cu12</td>\n",
       "      <td>12.1.3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nvidia-cuda-cupti-cu12</td>\n",
       "      <td>12.1.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nvidia-cuda-nvrtc-cu12</td>\n",
       "      <td>12.1.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nvidia-cuda-runtime-cu12</td>\n",
       "      <td>12.1.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nvidia-cudnn-cu12</td>\n",
       "      <td>8.9.2.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>nvidia-cufft-cu12</td>\n",
       "      <td>11.0.2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nvidia-curand-cu12</td>\n",
       "      <td>10.3.2.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>nvidia-cusolver-cu12</td>\n",
       "      <td>11.4.5.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>nvidia-cusparse-cu12</td>\n",
       "      <td>12.1.0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>nvidia-nccl-cu12</td>\n",
       "      <td>2.19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>nvidia-nvjitlink-cu12</td>\n",
       "      <td>12.9.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>nvidia-nvtx-cu12</td>\n",
       "      <td>12.1.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>packaging</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>pandas</td>\n",
       "      <td>2.2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>pillow</td>\n",
       "      <td>12.0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pip</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>proxy-client</td>\n",
       "      <td>1.0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>python-dateutil</td>\n",
       "      <td>2.9.0.post0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>pytz</td>\n",
       "      <td>2025.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>PyYAML</td>\n",
       "      <td>6.0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>regex</td>\n",
       "      <td>2025.9.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>requests</td>\n",
       "      <td>2.32.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>safetensors</td>\n",
       "      <td>0.6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>scikit-learn</td>\n",
       "      <td>1.7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>scipy</td>\n",
       "      <td>1.15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>sentence-transformers</td>\n",
       "      <td>5.1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>sentencepiece</td>\n",
       "      <td>0.2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>setuptools</td>\n",
       "      <td>80.9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>six</td>\n",
       "      <td>1.17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>sympy</td>\n",
       "      <td>1.14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>threadpoolctl</td>\n",
       "      <td>3.6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>tokenizers</td>\n",
       "      <td>0.22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>torch</td>\n",
       "      <td>2.2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tqdm</td>\n",
       "      <td>4.67.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>transformers</td>\n",
       "      <td>4.57.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>triton</td>\n",
       "      <td>2.2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>typing_extensions</td>\n",
       "      <td>4.15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>tzdata</td>\n",
       "      <td>2025.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>urllib3</td>\n",
       "      <td>2.5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name      version\n",
       "0                    certifi    2025.10.5\n",
       "1         charset-normalizer        3.4.4\n",
       "2                   filelock       3.20.0\n",
       "3                     fsspec     2025.9.0\n",
       "4                     hf-xet       1.1.10\n",
       "5            huggingface-hub       0.35.3\n",
       "6                       idna         3.11\n",
       "7                     Jinja2        3.1.6\n",
       "8                     joblib        1.5.2\n",
       "9                 MarkupSafe        3.0.3\n",
       "10                    mpmath        1.3.0\n",
       "11                  networkx          3.5\n",
       "12                     numpy       1.23.5\n",
       "13        nvidia-cublas-cu12     12.1.3.1\n",
       "14    nvidia-cuda-cupti-cu12     12.1.105\n",
       "15    nvidia-cuda-nvrtc-cu12     12.1.105\n",
       "16  nvidia-cuda-runtime-cu12     12.1.105\n",
       "17         nvidia-cudnn-cu12     8.9.2.26\n",
       "18         nvidia-cufft-cu12    11.0.2.54\n",
       "19        nvidia-curand-cu12   10.3.2.106\n",
       "20      nvidia-cusolver-cu12   11.4.5.107\n",
       "21      nvidia-cusparse-cu12   12.1.0.106\n",
       "22          nvidia-nccl-cu12       2.19.3\n",
       "23     nvidia-nvjitlink-cu12      12.9.86\n",
       "24          nvidia-nvtx-cu12     12.1.105\n",
       "25                 packaging         25.0\n",
       "26                    pandas        2.2.3\n",
       "27                    pillow       12.0.0\n",
       "28                       pip         25.2\n",
       "29              proxy-client        1.0.5\n",
       "30           python-dateutil  2.9.0.post0\n",
       "31                      pytz       2025.2\n",
       "32                    PyYAML        6.0.3\n",
       "33                     regex    2025.9.18\n",
       "34                  requests       2.32.5\n",
       "35               safetensors        0.6.2\n",
       "36              scikit-learn        1.7.2\n",
       "37                     scipy       1.15.3\n",
       "38     sentence-transformers        5.1.1\n",
       "39             sentencepiece        0.2.1\n",
       "40                setuptools       80.9.0\n",
       "41                       six       1.17.0\n",
       "42                     sympy       1.14.0\n",
       "43             threadpoolctl        3.6.0\n",
       "44                tokenizers       0.22.1\n",
       "45                     torch        2.2.0\n",
       "46                      tqdm       4.67.1\n",
       "47              transformers       4.57.1\n",
       "48                    triton        2.2.0\n",
       "49         typing_extensions       4.15.0\n",
       "50                    tzdata       2025.2\n",
       "51                   urllib3        2.5.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the status of installation using status() API.\n",
    "# Create a loop here for demo purposes\n",
    "try:\n",
    "    claim_id\n",
    "    ipydisplay(demo_env.status(claim_id))\n",
    "    stage = demo_env.status(claim_id)[\"Stage\"].iloc[-1]\n",
    "    while stage == \"Started\":\n",
    "        stage = demo_env.status(claim_id)[\"Stage\"].iloc[-1]\n",
    "        clear_output()\n",
    "        ipydisplay(demo_env.status(claim_id))\n",
    "        sleep(5)\n",
    "except NameError:\n",
    "    print(\"No installations to monitor\")\n",
    "\n",
    "\n",
    "# Verify the Python libraries have been installed correctly.\n",
    "ipydisplay(demo_env.libs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b162969f",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>4.3 Download and install model</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Open Analytics Framework containers do not have access to the internet.  This provides a very secure runtime environment.  As such, you will need to load pre-trained models using the APIs. For illustration purposes, the following code will check to see if the model archive exists locally and if it doesn't, will import and download it by creating a model object. The archive will then be created and installed into the remote environment.\n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c13f53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name facebook/bart-large-cnn. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and installing a model for text_summarization\n",
      "model_fname: models--facebook--bart-large-cnn\n",
      "Creating Model Archive...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d44e709bea4ba18acd5f97d57bb8f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[2m2025-10-16T02:16:56.322020Z\u001b[0m \u001b[31mERROR\u001b[0m  \u001b[31mPython exception updating progress:, error: PyErr { type: <class 'LookupError'>, value: LookupError(<ContextVar name='shell_parent' at 0x74eda4fcbab0>), traceback: Some(<traceback object at 0x74ec4cf55700>) }, \u001b[1;31mcaller\u001b[0m\u001b[31m: \"src/progress_update.rs:313\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /home/runner/work/xet-core/xet-core/error_printer/src/lib.rs:28\n",
      "\n",
      "  \u001b[2m2025-10-16T02:16:56.323633Z\u001b[0m \u001b[31mERROR\u001b[0m  \u001b[31mPython exception updating progress:, error: PyErr { type: <class 'LookupError'>, value: LookupError(<ContextVar name='shell_parent' at 0x74eda4fcbab0>), traceback: Some(<traceback object at 0x74ec4cf555c0>) }, \u001b[1;31mcaller\u001b[0m\u001b[31m: \"src/progress_update.rs:313\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /home/runner/work/xet-core/xet-core/error_printer/src/lib.rs:28\n",
      "\n",
      "  \u001b[2m2025-10-16T02:16:56.324270Z\u001b[0m \u001b[31mERROR\u001b[0m  \u001b[31mPython exception updating progress:, error: PyErr { type: <class 'LookupError'>, value: LookupError(<ContextVar name='shell_parent' at 0x74eda4fcbab0>), traceback: Some(<traceback object at 0x74ec4cf55380>) }, \u001b[1;31mcaller\u001b[0m\u001b[31m: \"src/progress_update.rs:313\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /home/runner/work/xet-core/xet-core/error_printer/src/lib.rs:28\n",
      "\n",
      "  \u001b[2m2025-10-16T02:16:56.324775Z\u001b[0m \u001b[31mERROR\u001b[0m  \u001b[31mPython exception updating progress:, error: PyErr { type: <class 'LookupError'>, value: LookupError(<ContextVar name='shell_parent' at 0x74eda4fcbab0>), traceback: Some(<traceback object at 0x74ec4cf55040>) }, \u001b[1;31mcaller\u001b[0m\u001b[31m: \"src/progress_update.rs:313\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /home/runner/work/xet-core/xet-core/error_printer/src/lib.rs:28\n",
      "\n",
      "  \u001b[2m2025-10-16T02:16:56.327064Z\u001b[0m \u001b[31mERROR\u001b[0m  \u001b[31mPython exception updating progress:, error: PyErr { type: <class 'LookupError'>, value: LookupError(<ContextVar name='shell_parent' at 0x74eda4fcbab0>), traceback: Some(<traceback object at 0x74ec4cf55480>) }, \u001b[1;31mcaller\u001b[0m\u001b[31m: \"src/progress_update.rs:313\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /home/runner/work/xet-core/xet-core/error_printer/src/lib.rs:28\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancellation requested; stopping current tasks.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/py311/lib/python3.11/site-packages/huggingface_hub/file_download.py:629\u001b[39m, in \u001b[36mxet_get\u001b[39m\u001b[34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[39m\n\u001b[32m    627\u001b[39m     progress.update(progress_bytes)\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m \u001b[43mdownload_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxet_download_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccess_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpiration_unix_epoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_refresher\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_refresher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshutil\u001b[39;00m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCreating Model Archive...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     model = \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     shutil.make_archive(\n\u001b[32m     19\u001b[39m         model_fname,\n\u001b[32m     20\u001b[39m         \u001b[38;5;28mformat\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mzip\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m         root_dir=\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpanduser(\u001b[33m\"\u001b[39m\u001b[33m~\u001b[39m\u001b[33m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/.cache/huggingface/hub/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_fname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     22\u001b[39m     )\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:339\u001b[39m, in \u001b[36mSentenceTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[39m\n\u001b[32m    327\u001b[39m         modules, \u001b[38;5;28mself\u001b[39m.module_kwargs = \u001b[38;5;28mself\u001b[39m._load_sbert_model(\n\u001b[32m    328\u001b[39m             model_name_or_path,\n\u001b[32m    329\u001b[39m             token=token,\n\u001b[32m   (...)\u001b[39m\u001b[32m    336\u001b[39m             config_kwargs=config_kwargs,\n\u001b[32m    337\u001b[39m         )\n\u001b[32m    338\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m         modules = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_auto_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m            \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhas_modules\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m modules \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(modules, OrderedDict):\n\u001b[32m    353\u001b[39m     modules = OrderedDict([(\u001b[38;5;28mstr\u001b[39m(idx), module) \u001b[38;5;28;01mfor\u001b[39;00m idx, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(modules)])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:2112\u001b[39m, in \u001b[36mSentenceTransformer._load_auto_model\u001b[39m\u001b[34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs, has_modules)\u001b[39m\n\u001b[32m   2109\u001b[39m tokenizer_kwargs = shared_kwargs \u001b[38;5;28;01mif\u001b[39;00m tokenizer_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {**shared_kwargs, **tokenizer_kwargs}\n\u001b[32m   2110\u001b[39m config_kwargs = shared_kwargs \u001b[38;5;28;01mif\u001b[39;00m config_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {**shared_kwargs, **config_kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m2112\u001b[39m transformer_model = \u001b[43mTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2115\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2117\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2119\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2120\u001b[39m pooling_model = Pooling(transformer_model.get_word_embedding_dimension(), \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m local_files_only:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py:88\u001b[39m, in \u001b[36mTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path, backend)\u001b[39m\n\u001b[32m     85\u001b[39m     config_args = {}\n\u001b[32m     87\u001b[39m config, is_peft_model = \u001b[38;5;28mself\u001b[39m._load_config(model_name_or_path, cache_dir, backend, config_args)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_peft_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# Get the signature of the auto_model's forward method to pass only the expected arguments from `features`,\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# plus some common values like \"input_ids\", \"attention_mask\", etc.\u001b[39;00m\n\u001b[32m     92\u001b[39m model_forward_params = \u001b[38;5;28mlist\u001b[39m(inspect.signature(\u001b[38;5;28mself\u001b[39m.auto_model.forward).parameters)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py:196\u001b[39m, in \u001b[36mTransformer._load_model\u001b[39m\u001b[34m(self, model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)\u001b[39m\n\u001b[32m    194\u001b[39m         \u001b[38;5;28mself\u001b[39m._load_mt5_model(model_name_or_path, config, cache_dir, **model_args)\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m         \u001b[38;5;28mself\u001b[39m.auto_model = \u001b[43mAutoModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m backend == \u001b[33m\"\u001b[39m\u001b[33monnx\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    200\u001b[39m     \u001b[38;5;28mself\u001b[39m.auto_model = load_onnx_model(\n\u001b[32m    201\u001b[39m         model_name_or_path=model_name_or_path,\n\u001b[32m    202\u001b[39m         config=config,\n\u001b[32m    203\u001b[39m         task_name=\u001b[33m\"\u001b[39m\u001b[33mfeature-extraction\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    204\u001b[39m         **model_args,\n\u001b[32m    205\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:604\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    603\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    608\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/transformers/modeling_utils.py:277\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    279\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/transformers/modeling_utils.py:4900\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4890\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4891\u001b[39m     gguf_file\n\u001b[32m   4892\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4893\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map.values()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n\u001b[32m   4894\u001b[39m ):\n\u001b[32m   4895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   4896\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4897\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mloaded from GGUF files.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4898\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m4900\u001b[39m checkpoint_files, sharded_metadata = \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4901\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4902\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4903\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4904\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4905\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4906\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4907\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4908\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4909\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4910\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4911\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4913\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4914\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_auto_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4920\u001b[39m is_sharded = sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4921\u001b[39m is_quantized = hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/transformers/modeling_utils.py:1037\u001b[39m, in \u001b[36m_get_resolved_checkpoint_files\u001b[39m\u001b[34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001b[39m\n\u001b[32m   1022\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1023\u001b[39m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[32m   1024\u001b[39m     cached_file_kwargs = {\n\u001b[32m   1025\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcache_dir\u001b[39m\u001b[33m\"\u001b[39m: cache_dir,\n\u001b[32m   1026\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mforce_download\u001b[39m\u001b[33m\"\u001b[39m: force_download,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1035\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m: commit_hash,\n\u001b[32m   1036\u001b[39m     }\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m     resolved_archive_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcached_file_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;66;03m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[39;00m\n\u001b[32m   1040\u001b[39m     \u001b[38;5;66;03m# result when internet is up, the repo and revision exist, but the file does not.\u001b[39;00m\n\u001b[32m   1041\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename == _add_variant(SAFE_WEIGHTS_NAME, variant):\n\u001b[32m   1042\u001b[39m         \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/transformers/utils/hub.py:322\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    265\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    266\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    267\u001b[39m     **kwargs,\n\u001b[32m    268\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    269\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    271\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/transformers/utils/hub.py:479\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    478\u001b[39m         \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m         \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    494\u001b[39m         snapshot_download(\n\u001b[32m    495\u001b[39m             path_or_repo_id,\n\u001b[32m    496\u001b[39m             allow_patterns=full_filenames,\n\u001b[32m   (...)\u001b[39m\u001b[32m    505\u001b[39m             local_files_only=local_files_only,\n\u001b[32m    506\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/py311/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/py311/lib/python3.11/site-packages/huggingface_hub/file_download.py:1010\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    990\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[32m    991\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m    992\u001b[39m         local_dir=local_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1007\u001b[39m         local_files_only=local_files_only,\n\u001b[32m   1008\u001b[39m     )\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/py311/lib/python3.11/site-packages/huggingface_hub/file_download.py:1171\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1168\u001b[39m \u001b[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n\u001b[32m   1170\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[32m-> \u001b[39m\u001b[32m1171\u001b[39m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.incomplete\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1183\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(pointer_path):\n\u001b[32m   1184\u001b[39m         _create_symlink(blob_path, pointer_path, new_blob=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/py311/lib/python3.11/site-packages/huggingface_hub/file_download.py:1723\u001b[39m, in \u001b[36m_download_to_tmp_and_move\u001b[39m\u001b[34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[39m\n\u001b[32m   1721\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_xet_available():\n\u001b[32m   1722\u001b[39m     logger.debug(\u001b[33m\"\u001b[39m\u001b[33mXet Storage is enabled for this repo. Downloading file from Xet Storage..\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1723\u001b[39m     \u001b[43mxet_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1724\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1725\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1726\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1727\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1728\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisplayed_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1729\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1730\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1731\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m constants.HF_HUB_DISABLE_XET:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/py311/lib/python3.11/site-packages/huggingface_hub/file_download.py:624\u001b[39m, in \u001b[36mxet_get\u001b[39m\u001b[34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[39m\n\u001b[32m    613\u001b[39m     displayed_filename = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplayed_filename[:\u001b[32m40\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m(…)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    615\u001b[39m progress_cm = _get_progress_bar_context(\n\u001b[32m    616\u001b[39m     desc=displayed_filename,\n\u001b[32m    617\u001b[39m     log_level=logger.getEffectiveLevel(),\n\u001b[32m   (...)\u001b[39m\u001b[32m    621\u001b[39m     _tqdm_bar=_tqdm_bar,\n\u001b[32m    622\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprogress_cm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43mprogress_updater\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprogress_bytes\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogress_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/py311/lib/python3.11/site-packages/tqdm/std.py:1138\u001b[39m, in \u001b[36mtqdm.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_value, traceback):\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# check to see if the model needs to be downloaded/archived\n",
    "\n",
    "for task in model_names:\n",
    "    print(f\"Downloading and installing a model for {task}\")\n",
    "    model_name = model_names[task]\n",
    "    # construct the file name for the model:\n",
    "    model_fname = \"models--\" + model_name.replace(\"/\", \"--\")\n",
    "    print(f\"model_fname: {model_fname}\")\n",
    "\n",
    "    if not os.path.isfile(f\"{model_fname}.zip\"):\n",
    "       \n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        import shutil\n",
    "\n",
    "        print(\"Creating Model Archive...\")\n",
    "\n",
    "        model = SentenceTransformer(model_name)\n",
    "        shutil.make_archive(\n",
    "            model_fname,\n",
    "            format=\"zip\",\n",
    "            root_dir=f'{expanduser(\"~\")}/.cache/huggingface/hub/{model_fname}/',\n",
    "        )\n",
    "    else:\n",
    "        print(\"Local model archive exists.\")\n",
    "\n",
    "    # check to see if the model is already installed\n",
    "    try:\n",
    "        if demo_env.models.empty:  # no models installed at all\n",
    "            print(\"Installing Model...\")\n",
    "            claim_id = demo_env.install_model(\n",
    "                model_path=f\"{model_fname}.zip\", asynchronous=True\n",
    "            )\n",
    "        elif not any(\n",
    "            model_fname in x for x in demo_env.models[\"Model\"]\n",
    "        ):  # see if model is there\n",
    "            print(\"Installing Model...\")\n",
    "            claim_id = demo_env.install_model(\n",
    "                model_path=f\"{model_fname}.zip\", asynchronous=True\n",
    "            )\n",
    "        else:\n",
    "            print(\"Model already installed\")\n",
    "    except Exception as e:\n",
    "        if \"\"\"NoneType' object has no attribute 'empty\"\"\" in str(e):\n",
    "            print(\"Installing Model...\")\n",
    "            claim_id = demo_env.install_model(\n",
    "                model_path=f\"{model_fname}.zip\", asynchronous=True\n",
    "            )\n",
    "            pass\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e7c396",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>4.4 Monitor model installation status</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Optionally - users can monitor the model installation status using the cell below:\n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96a0c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status of installation using status() API.\n",
    "# Create a loop here for demo purposes\n",
    "try:\n",
    "    claim_id\n",
    "    ipydisplay(demo_env.status(claim_id))\n",
    "    stage = demo_env.status(claim_id)[\"Stage\"].iloc[-1]\n",
    "    while stage != \"File Installed\":\n",
    "        stage = demo_env.status(claim_id)[\"Stage\"].iloc[-1]\n",
    "        clear_output()\n",
    "        ipydisplay(demo_env.status(claim_id))\n",
    "        sleep(5)\n",
    "except NameError:\n",
    "    print(\"No installations to monitor\")\n",
    "\n",
    "\n",
    "# Verify the model has been installed correctly.\n",
    "demo_env.refresh()\n",
    "ipydisplay(demo_env.models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef6eb89",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>The preceding demo showed how users can perform a <b>one-time</b> configuration task to prepare a custom environment for analytic processing at scale.  Once this configuration is complete, these containers can be re-used in ad-hoc development tasks, or used for operationalizing analytics in production.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cf0993",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;'>\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>5. Operationalizing AI-powered analytics</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The following demonstration will illustrate how developers can take the next step in the process to <b>operationalize</b> this processing, enabling the entire organization to leverage AI across the data lifecycle, including</p>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "    <tr>\n",
    "        <td style = 'vertical-align:top' width = '30%'>\n",
    "           <ol style = 'font-size:16px;font-family:Arial;'>\n",
    "               <li><b>Prepare the environment</b>.  Package the scoring function into a more robust program, and stage it on the remote environment</li>\n",
    "            <br>\n",
    "            <br>\n",
    "               <li><b>Python Pipeline</b>.  Execute the function using Python methods</li>\n",
    "            <br>\n",
    "            <br>\n",
    "               <li><b>SQL Pipeline</b>.  Execute the function using SQL - allowing for broad adoption and use in ETL and operational needs</li>\n",
    "        </ol>\n",
    "        </td>\n",
    "        <td width = '20%'></td>\n",
    "        <td style = 'vertical-align:top'><img src = 'images/OAF_Ops.png' width=350 style=\"border: 4px solid #404040; border-radius: 10px;\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.1 Check connection</b><br>\n",
    "   <b>!!! We don't need to execute these next two cells.</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Reconnect to the database, UES, and start cluster if necessary<get_context()/p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88020f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for existing connection and connect.\n",
    "# eng = check_and_connect(\n",
    "#     host=host, username=username, password=my_variable, compute_group=compute_group\n",
    "# )\n",
    "# print(eng)\n",
    "\n",
    "# # check to see if there is a valid UES auth\n",
    "# if set_auth_token(\n",
    "#     base_url=env_vars.get(\"ues_uri\"),\n",
    "#     pat_token=env_vars.get(\"access_token\"),\n",
    "#     pem_file=env_vars.get(\"pem_file\"),\n",
    "#     valid_from=int(time.time())\n",
    "# ):\n",
    "#     print(\"UES Authentication successful\")\n",
    "# else:\n",
    "#     print(\"UES Authentication failed. Check credentials.\")\n",
    "#     sys.exit(1)\n",
    "\n",
    "# # Get environment\n",
    "# demo_env = get_env(oaf_name)\n",
    "\n",
    "# # Check cluster status\n",
    "# check_cluster_start(compute_group=compute_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e314e93-c417-4ea8-8f9e-f59127e9380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We've already loaded all the values into our environment variables and into a dictionary, env_vars.\n",
    "# # username=env_vars.get(\"username\") isn't required when using base_url, pat and pem.\n",
    "\n",
    "# if set_auth_token(base_url=env_vars.get(\"ues_uri\"),\n",
    "#                   pat_token=env_vars.get(\"access_token\"), \n",
    "#                   pem_file=env_vars.get(\"pem_file\"),\n",
    "#                   valid_from=int(time.time())\n",
    "#                  ):\n",
    "#     print(\"UES Authentication successful\")\n",
    "# else:\n",
    "#     print(\"UES Authentication failed. Check credentials.\")\n",
    "#     sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c15f1",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.2 Create a server-side embedding function</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The goal of this exercise is to create a <b>server-side</b> function which can be staged on the analytic cluster.  This offers many improvements over the method used above;</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li><b>Performance</b>.  Staging the code and dependencies in the container environment reduces the amount of I/O, since the function doesn't need to get serialized to the cluster when called</li>\n",
    "    <li><b>Operationalization</b>.  The execution pipeline can be encapsulated into a SQL statement, which allows for seamless use in ETL pipelines, dashboards, or applications that need access</li>\n",
    "    <li><b>Flexibility</b>. Developers can express much greater flexibility in how the code works to optimize for performance, stability, data cleanliness or flow logic</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>These benefits do come with some amount of additional work.  Developers need to account how data is passed in and out of the code runtime, and how to pass it back to the SQL engine to assemble and return the final resultset.  Code is executed when the user expresses an <a href = 'https://docs.teradata.com/r/Teradata-VantageCloud-Lake/SQL-Reference/SQL-Operators-and-User-Defined-Functions/Table-Operators/APPLY'>APPLY SQL function</a>;</p> \n",
    "<ol style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li><b>Input Query</b>.  The APPLY function takes a SQL query as input.  This query can be as complex as needed and include data preparation, cleansing, and/or any other set-based logic necessary to create the desired input data set.  This complexity can also be abstracted into a database view.  When using the teradata client connectors for Python or R, thise query is represented as a DataFrame or tibble.</li>\n",
    "    <li><b>Pre-processing</b>.  Based on the query plan, data is retrieved from storage (cache, block storage, or object storage) and the input query is executed.</li>\n",
    "    <li><b>Distribution</b>.  Input data can be partitioned and/or ordered to be processed on a specific container or collection of them.  For example, the user may want to process all data for a single post code in one partition, and run thousands of these in parallel.  Data can also be distributed evenly across all units of parallelism in the system</li>\n",
    "    <li><b>Input</b>.  The data for each container is passed to the runtime using tandard input (stdin)</li>\n",
    "    <li><b>Processing</b>.  The user's code executes, parsing stdin for the input data</li>\n",
    "    <li><b>Output</b>.  Data is sent out of the code block using standard output (stdout)</li>\n",
    "    <li><b>Resultset</b>.  Resultset is assembled by the analytic database, and the SQL query returns</li>\n",
    "    </ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1b2628",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.3 Example server-side code block</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>This is the python script used in the demonstration.  It is saved to the filesystem as <code>Complaint_Analysis_Customer360_OAF.py</code>.  Note here the original client-side processing function has been reused, and the additional logic is for input, output, and error handling.</p> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae6f4e",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.4.  Install the file and any additional artifacts</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Use the install_file() method to install this python file to the container.  As a reminder, this container is persistent, so these steps need only be done infrequently. </br>\n",
    "Note: Ensure that a valid .zip file path is provided in the <code>\"model_path\"</code> variable within the .py file below. \n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f035d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_env.install_file(\"Complaint_Analysis_Customer360_OAF.py\", replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe03c822",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.5  Call the APPLY function </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>This function can be executed in two ways;</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li><b><a href = 'https://docs.teradata.com/r/Teradata-VantageCloud-Lake/Analyzing-Your-Data/Teradata-Package-for-Python-on-VantageCloud-Lake/Working-with-Open-Analytics/teradataml-Apply-Class-for-APPLY-Table-Operator'>Python</a></b> by calling the Apply() module function</li>\n",
    "    <li><b><a href = 'https://docs.teradata.com/r/Teradata-VantageCloud-Lake/SQL-Reference/SQL-Operators-and-User-Defined-Functions/Table-Operators/APPLY'>SQL</a></b> which allows for broad adoption across the enterprise</li>\n",
    "    </ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bebf611",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.6 APPLY using Python</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The process is as follows</p> \n",
    "<ol style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li>Construct a dictionary that will define the return columns and data types</li>\n",
    "    <li>Construct a teradataml DataFrame representing the data to be processed - note this is a \"virtual\" object representing data and logic <b>in-database</b></li>\n",
    "    <li>Execute the module function.  This constructs the function call in the database, but does not execute anything.  Note the Apply function takes several arguments - the input data, environment name, and the command to run</li>\n",
    "    <li>In order to execute the function, an \"execute_script()\" method must be called.  This method returns the server-side DataFrame representing the complete operation.  This DataFrame can be used in further processing, stored as a table, etc.</li>\n",
    "    </ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df44c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return types\n",
    "types_dict = OrderedDict({})\n",
    "types_dict[\"complaint_id\"] = VARCHAR(20)\n",
    "types_dict[\"consumer_complaint_narrative\"] = VARCHAR(1000)\n",
    "types_dict[\"topic\"] = VARCHAR(1000)\n",
    "types_dict[\"sentiment\"] = VARCHAR(1000)\n",
    "types_dict[\"summary1\"] = VARCHAR(1000)\n",
    "\n",
    "# remove extra characters from text\n",
    "tdf = DataFrame.from_query(\n",
    "    \"\"\"SELECT TOP 5 complaint_id, \n",
    "    CASE \n",
    "        WHEN consumer_complaint_narrative IS NULL THEN ' '\n",
    "        ELSE OREPLACE(OREPLACE(OREPLACE(OREPLACE(OREPLACE(consumer_complaint_narrative , X'0d' , ' ') , X'0a' , ' ') , X'09', ' '), ',', ' '), '\"', ' ')\n",
    "    END consumer_complaint_narrative,\n",
    "    'Mortgage Application, Payment Trouble, Mortgage Closing, Report Inaccuracy, Payment Struggle' as topics\n",
    "    FROM Demo_ComplaintAnalysis.Consumer_Complaints WHERE consumer_complaint_narrative <> '';\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a77a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_obj = Apply(\n",
    "    data=tdf,\n",
    "    apply_command=\"python Complaint_Analysis_Customer360_OAF.py\",\n",
    "    returns=types_dict,\n",
    "    env_name=demo_env,\n",
    "    delimiter=\"#\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d38094d",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.7 Execute the function</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>call execute_script(), and return a single record to the client to check the data.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4bbf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints_analysis_df = apply_obj.execute_script()\n",
    "ipydisplay(complaints_analysis_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a6edd7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Now the results can be saved back to Vantage.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e7b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(\n",
    "    df=complaints_analysis_df,\n",
    "    table_name=\"complaints_analysis\",\n",
    "    if_exists=\"replace\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b37417",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(\"complaints_analysis\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576fbbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0619b8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment\"] = df[\"sentiment\"].apply(lambda x: x.strip())\n",
    "df[\"topic\"] = df[\"topic\"].apply(lambda x: x.strip())\n",
    "df[\"summary1\"] = df[\"summary1\"].apply(lambda x: x.strip())\n",
    "\n",
    "customer_data = DataFrame(in_schema(\"Demo_ComplaintAnalysis\", \"Customer_360_Details\"))\n",
    "# customer_data\n",
    "# combined_df = customer_data.to_pandas().join(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c785e4-9da6-4e8f-95dd-e1d527d594df",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data = customer_data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae8a3a8-31ee-45b9-bbec-105dffda6662",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data = customer_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc22546b-488b-4744-bbf0-3544acd4de1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = customer_data.join(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6144e65",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>6. Integrated data with customer 360</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The following is an example of the output from LLM integrated with existing customer360 data. Please scroll to the right to see all the columns.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8199055",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "combined_df[[\"complaint_id\", \"Customer Identifier\", \"sentiment\", \"topic\", \"summary1\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5af062",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Now the results can be saved back to Vantage.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f227c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(\n",
    "    df=combined_df,\n",
    "    table_name=\"Customer_360_Complaints_analysis\",\n",
    "    if_exists=\"replace\",\n",
    "    primary_index=\"complaint_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256f8d28-f328-4d7e-822c-1fab1077010d",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none'>\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>7. Cleanup</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>7.1 Delete your OAF Container</b></p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">Executing this cell is optional. If you will be executing more OAF use cases, you can leave your OAF environment.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea453359-8101-406f-9fe7-6dd43a5fd48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove your user environment\n",
    "\n",
    "try:\n",
    "    result = remove_env(environment_name)\n",
    "    print(\"Environment removed!\")\n",
    "except Exception as e:\n",
    "    print(\"Could not remove the environment!\")\n",
    "    print(\"Error:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82400a0b-8b81-4f72-96c2-a7439430d81b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>7.2 Remove your database Context</b></p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">Please remove your context after you've completed this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd820b48-7b2b-4b55-a8c2-76092a228058",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    result = remove_context()\n",
    "    print(\"Context removed!\")\n",
    "except Exception as e:\n",
    "    print(\"Could not remove the Context!\")\n",
    "    print(\"Error:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bdc0df-dc13-4a13-bf73-c7039a54c3ba",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2024,2025. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
