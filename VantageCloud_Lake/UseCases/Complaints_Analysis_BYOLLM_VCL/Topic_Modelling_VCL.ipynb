{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ce3dd8a-f3e5-40d5-ab4c-d40cc358cf7f",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Topic Modelling using Teradata VantageCloud and open-source language models\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57054f7e-befe-4029-b4ac-b82019240b1f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;'><b>Introduction:</b></p>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>In this comprehensive user demo, we will delve into the world of topic modeling using <b>Teradata Vantage</b> and <b>open-source language models</b>. This cutting-edge technology empowers businesses to uncover hidden insights from vast amounts of consumer complaints data, enabling them to identify trends, improve customer satisfaction, and enhance their overall brand reputation.</p> \n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'><b>Key Features:</b></p> \n",
    "\n",
    "<ol style='font-size:16px;font-family:Arial;'> \n",
    "    <li><b>Scalable Data Ingestion</b>: Seamlessly integrate and process large volumes of consumer complaints data from various sources into Teradata Vantage.</li> \n",
    "    <li><b>Advanced Topic Modelling</b>: Utilize state-of-the-art topic modeling algorithms to identify and categorize underlying themes and sentiments within the complaints data, providing actionable insights.</li> \n",
    "    <li><b>Real-time Analytics</b>: Leverage Teradata Vantage's real-time analytics capabilities to monitor and respond to emerging trends and issues in consumer complaints.</li> \n",
    "\t<li><b>Customizable Dashboards</b>: Create tailored dashboards to visualize and track key performance indicators (KPIs) and metrics specific to your business needs.</li> \n",
    "\t<li><b>Integration with open-source language models</b>: Seamlessly integrate with open-source language models to collect and analyze consumer complaints data from these platforms.</li> </ol> \n",
    "\t\n",
    "<p style='font-size:16px;font-family:Arial;'><b>Benefits:</b></p> \n",
    "\t\n",
    "<ol style='font-size:16px;font-family:Arial;'>\n",
    "<li><b>Enhanced Customer Insights</b>: Gain a deeper understanding of customer concerns and preferences, enabling data-driven decision-making.</li> \n",
    "<li><b>Improved Customer Satisfaction</b>: Identify and address recurring issues, leading to increased customer satisfaction and loyalty.</li> \n",
    "<li><b>Competitive Advantage</b>: Stay ahead of the competition by proactively addressing consumer complaints and improving brand reputation.</li> \n",
    "<li><b>Cost Savings</b>: Reduce the financial burden of handling and resolving consumer complaints by identifying and addressing root causes.</li> \n",
    "<li><b>Data-Driven Decision-Making</b>: Make informed business decisions based on actionable insights derived from topic modeling and real-time analytics.</li> </ol>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'><b>Steps in the analysis:</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;'>\n",
    "     <li>Configuring the environment</li>\n",
    "  <li>Connect to Vantage</li>\n",
    "  <li>Create a Custom Container in Vantage</li>\n",
    "  <li>Install Dependencies</li>\n",
    "  <li>Operationalizing AI-powered analytics</li>\n",
    "  <li>Topic Modelling</li>\n",
    "  <li>Cleanup</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e457db5-d4df-4e7f-a11a-fcb1416e462d",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;'>\n",
    "<b style = 'font-size:20px;font-family:Arial;'>1. Configuring the environment</b>\n",
    "\n",
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>1.1 Install the required libraries</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eb4587-6632-4b08-a121-c98ea5a8fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470fc6e-96af-429a-9787-76179982e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install itables teradataml==20.0.0.7 teradatamlwidgets==20.0.0.6 teradatamodelops==7.0.3 teradatasql==20.0.0.34 teradatasqlalchemy==20.0.0.7 sentencepiece sentence-transformers wordcloud --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fd81e4-0df9-4360-b3ac-72214f135296",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;'><b>Note: </b><i>Please restart the kernel after executing these two lines. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc278740-1511-4423-bf2b-92a5109a47bf",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>1.2 Import the required libraries</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f183178-9807-4538-b794-922820346ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import *\n",
    "from teradatasqlalchemy.types import *\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import csv, sys, os, warnings\n",
    "from os.path import expanduser\n",
    "from collections import OrderedDict\n",
    "from wordcloud import WordCloud\n",
    "from IPython.display import clear_output , display as ipydisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from itables import init_notebook_mode\n",
    "import itables.options as opt\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "# Set display options for dataframes, plots, and warnings\n",
    "opt.style=\"table-layout:auto;width:auto;float:left\"\n",
    "opt.columnDefs = [{\"className\": \"dt-left\", \"targets\": \"_all\"}]\n",
    "init_notebook_mode(all_interactive=True)\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "display.suppress_vantage_runtime_warnings = True\n",
    "\n",
    "# import utils for lake environment\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..', '..','config'))\n",
    "sys.path.append(module_path)\n",
    "from oaf_utils import *\n",
    "\n",
    "# get the current python version to match deploy a custom container\n",
    "# python_version = str(sys.version_info[0]) + '.' + str(sys.version_info[1])\n",
    "python_version = \"3.10\"\n",
    "print(f'Using Python version {python_version} for user environment')\n",
    "\n",
    "# Hugging Face model for the demo\n",
    "model_name = 'facebook/bart-large-mnli'\n",
    "# model_name = 'maximalists/BRAG-Llama-3.1-8b-v0.1'\n",
    "\n",
    "# a list of required packages to install in the custom OAF container\n",
    "# modify this if using different models or design patterns\n",
    "pkgs = ['numpy',\n",
    "        'transformers',\n",
    "        'torch',\n",
    "        'sentencepiece',\n",
    "        'pandas',\n",
    "        'sentence-transformers']\n",
    "\n",
    "# container name - set here for easier notebook navigation\n",
    "### User will also be asked to change it ###\n",
    "# oaf_name = 'oaf_topic_classification'\n",
    "oaf_name = 'oaf_demo_gpu'\n",
    "###########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8c5e2a",
   "metadata": {},
   "source": [
    "<hr style=\"height: 2px; border: none;\">\n",
    "<p style = 'font-size: 20px; font-family: Arial;'><b>Part 1</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1763fd95-5000-4a2d-8b86-7be261e20847",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>2. Connect to Vantage</b>\n",
    "\n",
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>2.1 Connect to Vantage</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Load the environment variables from a .env file and use them to create a connection context to Teradata.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5eba56-d38f-4204-b30d-232c7d894eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating the context...\") \n",
    "load_dotenv(\"../../.config/.env\", override=True)\n",
    "host = os.getenv(\"host\")\n",
    "username = os.getenv(\"username\")\n",
    "my_variable = os.getenv(\"my_variable\")\n",
    "\n",
    "eng = create_context(host=host, username=username, password=my_variable)\n",
    "execute_sql('''SET query_band='DEMO=Topic_Modelling_VCL.ipynb;' UPDATE FOR SESSION;''')\n",
    "print(\"Connected to Teradata:\", eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce81699-6345-4dbf-a3a8-b9402c7b6a98",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dca7332-48f5-4702-8b56-d8a03fbb87a2",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>2.2  Connect to the Environment Service</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>To better support integration with Cloud Services and common automation tools; the <b > User Environment Service</b> is accessed via RESTful APIs.  These APIs can be called directly or in the examples shown below that leverage the Python Package for Teradata (teradataml) methods.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87c4008-c993-4109-be9d-191a15ded026",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"/home/jovyan/JupyterLabRoot/VantageCloud_Lake/.config/.env\"):\n",
    "    print(\"Your environment parameter file exist.  Please proceed with this use case.\")\n",
    "    # Load all the variables from the .env file into a dictionary\n",
    "    env_vars = dotenv_values(\"/home/jovyan/JupyterLabRoot/VantageCloud_Lake/.config/.env\")\n",
    "else:\n",
    "    print(\"Your environment has not been prepared for connecting to VantageCloud Lake.\")\n",
    "    print(\"Please contact the support team.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb05c96-e972-44fe-869c-7aec5715566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_analytics_endpoint = os.getenv(\"ues_uri\")\n",
    "access_token = os.getenv(\"access_token\")\n",
    "pem_file = os.getenv(\"pem_file\")\n",
    "compute_group = os.getenv(\"gpu_compute_group\")\n",
    "\n",
    "if set_auth_token(base_url=env_vars.get(\"ues_uri\"),\n",
    "                  pat_token=env_vars.get(\"access_token\"), \n",
    "                  pem_file=env_vars.get(\"pem_file\"),\n",
    "                  valid_from=int(time.time())\n",
    "                 ):\n",
    "    print(\"UES Authentication successful\")\n",
    "else:\n",
    "    print(\"UES Authentication failed. Check credentials.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92493077-f598-46ad-b56a-bdd6f2962787",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>After connecting and authenticating, check cluster status. Start it if necessary - note the cluster only needs to be running to execute the APPLY sections of the demo.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2298dede-a7f9-449e-8fd9-72220ddaff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_sql(f\"SET SESSION COMPUTE GROUP {compute_group};\")\n",
    "res = check_cluster_start(compute_group=compute_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df070106-1a2a-4c0f-817e-8a5d8ebddd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_user_envs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d8a61e",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "\n",
    "<b style = 'font-size:18px;font-family:Arial;'>3. Create a Custom Container in Vantage</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>If desired, the user can create a <b>new</b> custom environment by starting with a \"base\" image and customizing it.  The steps are:</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li>List the available \"base\" images the system supports</li>\n",
    "    <li>List any existing \"custom\" environments the user has created</li>\n",
    "    <li>If there are no custom environments, then create a new one from a base image</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d10b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new environment, or connect to an existing one\n",
    "try:\n",
    "    ipydisplay(list_user_envs())\n",
    "except Exception as e:\n",
    "    if str(e).find(\"No user environments found\") > 0:\n",
    "        print(\"No user environments found\")\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "print(\"Use an existing environment, or create a new one:\")\n",
    "print(f\"OAF Environment is set to {oaf_name}.\")\n",
    "print(\"Enter to accept, or input a new value.\")\n",
    "print(\"If the environment is not in the list, an new one will be created\")\n",
    "i = oaf_name\n",
    "if len(i) != 0:\n",
    "    oaf_name = i\n",
    "    print(f\"OAF Environment is now {oaf_name}\")\n",
    "\n",
    "try:\n",
    "    demo_env = create_env(\n",
    "        env_name=oaf_name,\n",
    "        base_env=f\"python_{python_version}\",\n",
    "        desc=\"OAF Demo env for LLM\",\n",
    "    )\n",
    "except Exception as e:\n",
    "    if str(e).find(\"same name already exists\") > 0:\n",
    "        print(\"Environment already exists, obtaining a reference to it\")\n",
    "        demo_env = get_env(oaf_name)\n",
    "        pass\n",
    "    elif \"Invalid value for base environment name\" in str(e):\n",
    "        print(\"Unsupported base environment version, using defaults\")\n",
    "        demo_env = create_env(env_name=oaf_name, desc=\"OAF Demo env for LLM\")\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Note create_env seems to be asynchronous - sleep a bit for it to register\n",
    "sleep(5)\n",
    "\n",
    "try:\n",
    "    ipydisplay(list_user_envs())\n",
    "except Exception as e:\n",
    "    if str(e).find(\"No user environments found\") > 0:\n",
    "        print(\"No user environments found\")\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556a860-e27f-432d-a4d1-f4bd903e34fd",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>4. Install Dependencies</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The second step in the customization process is to install Python package dependencies. This demonstration uses the Hugging Face <a href = 'https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english'>distilbert-base-uncased-finetuned-sst-2-english</a> Sentence Transformer.  Since VantageCloud Lake Analytic Clusters are secured by default against unauthorized access to the outside network, the user can load the required libraries and model using teradataml methods:\n",
    "</p> \n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li>List the currently installed models and python libraries</li>\n",
    "    <li><b>If necessary</b>, install any required packages</li>\n",
    "    <li><b>If necessary</b>, install the pre-trained model.  This process takes several steps;\n",
    "        <ol style = 'font-size:16px;font-family:Arial;'>\n",
    "            <li>Import and download the model</li>\n",
    "            <li>Create a zip archive of the model artifacts</li>\n",
    "            <li>Call the install_model() method to load the model to the container</li>\n",
    "        </ol></li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f2a8a6-5a5b-483d-81e7-46682c764bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipydisplay(demo_env.models)\n",
    "\n",
    "# just showing a sample here - remove .head(5) to see them all\n",
    "ipydisplay(demo_env.libs.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3b179f-4649-483a-a470-db064266c3b6",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>4.1 A note on package versions</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The next demonstration makes use of the DataFrame apply() method, which automatically passes the python code to the Analytic Cluster.  As such, one needs to ensue the python package versions match.  dill and pandas are required, as is any additional libraries for the use case.\n",
    "</p> \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'><b>Note</b> while not required for many OAF use cases, for this demo the required packages for the model execution must be installed in the local environment first.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6feda0d-d9da-4e57-9fdb-00635c6bdf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import these functions inside of a function namespace\n",
    "def get_versions(pkgs):\n",
    "    local_v_pkgs = []\n",
    "    for p in pkgs:\n",
    "\n",
    "        # fix up any hyphened package names\n",
    "        p_fixed = p.replace(\"-\", \"_\")\n",
    "\n",
    "        # import the packages and append the strings to the list\n",
    "        exec(\n",
    "            f\"\"\"import {p_fixed}; local_v_pkgs.append('{p}==' + str({p_fixed}.__version__))\"\"\"\n",
    "        )\n",
    "    return local_v_pkgs\n",
    "\n",
    "\n",
    "v_pkgs = get_versions(pkgs)\n",
    "\n",
    "\n",
    "# check to see if these packages need to be installed\n",
    "# by comparing the len of the intersection of the list of required packages with the installed ones\n",
    "if not len(\n",
    "    set([x.split(\"==\")[0] for x in pkgs]).intersection(demo_env.libs[\"name\"].to_list())\n",
    ") == len(pkgs):\n",
    "\n",
    "    # pass the list of packages - split off any extra info from the version property e.g., plus sign\n",
    "    claim_id = demo_env.install_lib(\n",
    "        [x.split(\"+\")[0] for x in v_pkgs], asynchronous=True\n",
    "    )\n",
    "else:\n",
    "    print(f\"All required packages are installed in the {oaf_name} environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d186ca1",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>4.2 Monitor library installation status</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Optionally - users can monitor the library installation status using the cell below:\n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d533b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status of installation using status() API.\n",
    "# Create a loop here for demo purposes\n",
    "try:\n",
    "    claim_id\n",
    "    ipydisplay(demo_env.status(claim_id))\n",
    "    stage = demo_env.status(claim_id)[\"Stage\"].iloc[-1]\n",
    "    while stage == \"Started\":\n",
    "        stage = demo_env.status(claim_id)[\"Stage\"].iloc[-1]\n",
    "        clear_output()\n",
    "        ipydisplay(demo_env.status(claim_id))\n",
    "        sleep(5)\n",
    "except NameError:\n",
    "    print(\"No installations to monitor\")\n",
    "\n",
    "\n",
    "# Verify the Python libraries have been installed correctly.\n",
    "ipydisplay(demo_env.libs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b162969f",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>4.3 Download and install model</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Open Analytics Framework containers do not have open access to the external network, which contributes to a very secure runtime environment.  As such, users will load pre-trained models using the below APIs.  For illustration purposes, the following code will check to see if the model archive exists locally and if it doesn't, will import and download it by creating a model object.  The archive will then be created and installed into the remote environment.\n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c13f53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if the model needs to be downloaded/archived\n",
    "\n",
    "# construct the file name for the model:\n",
    "model_fname = \"models--\" + model_name.replace(\"/\", \"--\")\n",
    "# model_fname = \"bart-large-mnli\"\n",
    "print(f\"model_fname: {model_fname}\")\n",
    "\n",
    "if not os.path.isfile(f\"{model_fname}.zip\"):\n",
    "\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import shutil\n",
    "\n",
    "    print(\"Creating Model Archive...\")\n",
    "\n",
    "    model = SentenceTransformer(model_name)\n",
    "    shutil.make_archive(\n",
    "            model_fname,\n",
    "            format=\"zip\",\n",
    "            root_dir=f'{expanduser(\"~\")}/.cache/huggingface/hub/{model_fname}/',\n",
    "        )\n",
    "else:\n",
    "    print(\"Local model archive exists.\")\n",
    "\n",
    "# check to see if the model is already installed\n",
    "try:\n",
    "    if demo_env.models.empty:  # no models installed at all\n",
    "        print(\"Installing Model...\")\n",
    "        claim_id = demo_env.install_model(\n",
    "            model_path=f\"{model_fname}.zip\", asynchronous=True\n",
    "        )\n",
    "    elif not any(\n",
    "        model_fname in x for x in demo_env.models[\"Model\"]\n",
    "    ):  # see if model is there\n",
    "        print(\"Installing Model...\")\n",
    "        claim_id = demo_env.install_model(\n",
    "            model_path=f\"{model_fname}.zip\", asynchronous=True\n",
    "        )\n",
    "    else:\n",
    "        print(\"Model already installed\")\n",
    "except Exception as e:\n",
    "    if \"\"\"NoneType' object has no attribute 'empty\"\"\" in str(e):\n",
    "        print(\"Installing Model...\")\n",
    "        claim_id = demo_env.install_model(\n",
    "            model_path=f\"{model_fname}.zip\", asynchronous=True\n",
    "        )\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e7c396",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>4.4 Monitor model installation status</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Optionally - users can monitor the model installation status using the cell below:\n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96a0c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status of installation using status() API.\n",
    "# Create a loop here for demo purposes\n",
    "try:\n",
    "    claim_id\n",
    "    ipydisplay(demo_env.status(claim_id))\n",
    "    stage = demo_env.status(claim_id)[\"Stage\"].iloc[-1]\n",
    "    while stage != \"File Installed\":\n",
    "        stage = demo_env.status(claim_id)[\"Stage\"].iloc[-1]\n",
    "        clear_output()\n",
    "        ipydisplay(demo_env.status(claim_id))\n",
    "        sleep(5)\n",
    "except NameError:\n",
    "    print(\"No installations to monitor\")\n",
    "\n",
    "\n",
    "# Verify the model has been installed correctly.\n",
    "demo_env.refresh()\n",
    "ipydisplay(demo_env.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c457c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipydisplay(demo_env.models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef6eb89",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>The preceding demo showed how users can perform a <b>one-time</b> configuration task to prepare a custom environment for analytic processing at scale.  Once this configuration is complete, these containers can be re-used in ad-hoc development tasks, or used for operationalizing analytics in production.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3147145",
   "metadata": {},
   "source": [
    "<hr style=\"height: 2px; border: none;\">\n",
    "<p style = 'font-size: 20px; font-family: Arial;'><b>Part 2</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cf0993",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;'>\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>5. Operationalizing AI-powered analytics</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The following demonstration will illustrate how developers can take the next step in the process to <b>operationalize</b> this processing, enabling the entire organization to leverage AI across the data lifecycle, including</p>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "    <tr>\n",
    "        <td style = 'vertical-align:top' width = '30%'>\n",
    "           <ol style = 'font-size:16px;font-family:Arial;'>\n",
    "               <li><b>Prepare the environment</b>.  Package the scoring function into a more robust program, and stage it on the remote environment</li>\n",
    "            <br>\n",
    "            <br>\n",
    "               <li><b>Python Pipeline</b>.  Execute the function using Python methods</li>\n",
    "            <br>\n",
    "            <br>\n",
    "               <li><b>SQL Pipeline</b>.  Execute the function using SQL - allowing for broad adoption and use in ETL and operational needs</li>\n",
    "        </ol>\n",
    "        </td>\n",
    "        <td width = '20%'></td>\n",
    "        <td style = 'vertical-align:top'><img src = 'images/OAF_Ops.png' width=350 style=\"border: 4px solid #404040; border-radius: 10px;\" ></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.1 Check connection</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Reconnect to the database, UES, and start cluster if necessary<get_context()/p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88020f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for existing connection and connect.\n",
    "eng = check_and_connect(\n",
    "    host=host, username=username, password=my_variable, compute_group=compute_group\n",
    ")\n",
    "print(eng)\n",
    "\n",
    "# check to see if there is a valid UES auth\n",
    "if set_auth_token(\n",
    "    base_url=env_vars.get(\"ues_uri\"),\n",
    "    pat_token=env_vars.get(\"access_token\"),\n",
    "    pem_file=env_vars.get(\"pem_file\"),\n",
    "    valid_from=int(time.time())\n",
    "):\n",
    "    print(\"UES Authentication successful\")\n",
    "else:\n",
    "    print(\"UES Authentication failed. Check credentials.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Get environment\n",
    "demo_env = get_env(oaf_name)\n",
    "\n",
    "# Check cluster status\n",
    "check_cluster_start(compute_group=compute_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c15f1",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.2 Create a server-side embedding function</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The goal of this exercise is to create a <b>server-side</b> function which can be staged on the analytic cluster.  This offers many improvements over the method used above;</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li><b>Performance</b>.  Staging the code and dependencies in the container environment reduces the amount of I/O, since the function doesn't need to get serialized to the cluster when called</li>\n",
    "    <li><b>Operationalization</b>.  The execution pipeline can be encapsulated into a SQL statement, which allows for seamless use in ETL pipelines, dashboards, or applications that need access</li>\n",
    "    <li><b>Flexibility</b>. Developers can express much greater flexibility in how the code works to optimize for performance, stability, data cleanliness or flow logic</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>These benefits do come with some amount of additional work.  Developers need to account how data is passed in and out of the code runtime, and how to pass it back to the SQL engine to assemble and return the final resultset.  Code is executed when the user expresses an <a href = 'https://docs.teradata.com/r/Teradata-VantageCloud-Lake/SQL-Reference/SQL-Operators-and-User-Defined-Functions/Table-Operators/APPLY'>APPLY SQL function</a>;</p> \n",
    "<ol style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li><b>Input Query</b>.  The APPLY function takes a SQL query as input.  This query can be as complex as needed and include data preparation, cleansing, and/or any other set-based logic necessary to create the desired input data set.  This complexity can also be abstracted into a database view.  When using the teradata client connectors for Python or R, thise query is represented as a DataFrame or tibble.</li>\n",
    "    <li><b>Pre-processing</b>.  Based on the query plan, data is retrieved from storage (cache, block storage, or object storage) and the input query is executed.</li>\n",
    "    <li><b>Distribution</b>.  Input data can be partitioned and/or ordered to be processed on a specific container or collection of them.  For example, the user may want to process all data for a single post code in one partition, and run thousands of these in parallel.  Data can also be distributed evenly across all units of parallelism in the system</li>\n",
    "    <li><b>Input</b>.  The data for each container is passed to the runtime using tandard input (stdin)</li>\n",
    "    <li><b>Processing</b>.  The user's code executes, parsing stdin for the input data</li>\n",
    "    <li><b>Output</b>.  Data is sent out of the code block using standard output (stdout)</li>\n",
    "    <li><b>Resultset</b>.  Resultset is assembled by the analytic database, and the SQL query returns</li>\n",
    "    </ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1b2628",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.3 Example server-side code block</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>This is the python script used in the demonstration.  It is saved to the filesystem as <code>Topic_Modelling_OAF.py</code>.  Note here the original client-side processing function has been reused, and the additional logic is for input, output, and error handling.</p> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae6f4e",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.4.  Install the file and any additional artifacts</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Use the install_file() method to install this python file to the container.  As a reminder, this container is persistent, so these steps need only be done infrequently.</br>\n",
    "Note: Ensure that a valid .zip file path is provided in the <code>\"model_path\"</code> variable within the .py file below. </p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f035d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_env.install_file(\"Topic_Modelling_OAF.py\", replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe03c822",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.5  Call the APPLY function </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>This function can be executed in two ways;</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li><b><a href = 'https://docs.teradata.com/r/Teradata-VantageCloud-Lake/Analyzing-Your-Data/Teradata-Package-for-Python-on-VantageCloud-Lake/Working-with-Open-Analytics/teradataml-Apply-Class-for-APPLY-Table-Operator'>Python</a></b> by calling the Apply() module function</li>\n",
    "    <li><b><a href = 'https://docs.teradata.com/r/Teradata-VantageCloud-Lake/SQL-Reference/SQL-Operators-and-User-Defined-Functions/Table-Operators/APPLY'>SQL</a></b> which allows for broad adoption across the enterprise</li>\n",
    "    </ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bebf611",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.6 APPLY using Python</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The process is as follows</p> \n",
    "<ol style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li>Construct a dictionary that will define the return columns and data types</li>\n",
    "    <li>Construct a teradataml DataFrame representing the data to be processed - note this is a \"virtual\" object representing data and logic <b>in-database</b></li>\n",
    "    <li>Execute the module function.  This constructs the function call in the database, but does not execute anything.  Note the Apply function takes several arguments - the input data, environment name, and the command to run</li>\n",
    "    <li>In order to execute the function, an \"execute_script()\" method must be called.  This method returns the server-side DataFrame representing the complete operation.  This DataFrame can be used in further processing, stored as a table, etc.</li>\n",
    "    </ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df44c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return types\n",
    "types_dict = OrderedDict({})\n",
    "types_dict[\"complaint_id\"] = VARCHAR(32000)\n",
    "types_dict[\"consumer_complaint_narrative\"] = VARCHAR(10000)\n",
    "types_dict[\"topic\"] = VARCHAR(1000)\n",
    "\n",
    "# remove extra characters from text\n",
    "tdf = DataFrame.from_query(\n",
    "    \"\"\"SELECT TOP 10 complaint_id, date_received, product,\n",
    "    CASE \n",
    "        WHEN consumer_complaint_narrative IS NULL THEN ' '\n",
    "        ELSE OREPLACE(OREPLACE(OREPLACE(OREPLACE(OREPLACE(consumer_complaint_narrative , X'0d' , ' ') , X'0a' , ' ') , X'09', ' '), ',', ' '), '\"', ' ')\n",
    "    END consumer_complaint_narrative,\n",
    "    'Mortgage Application, Payment Trouble, Mortgage Closing, Report Inaccuracy, Payment Struggle' as topics \n",
    "    FROM Demo_ComplaintAnalysis.Consumer_Complaints WHERE consumer_complaint_narrative <> '';\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a77a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_obj = Apply(\n",
    "    data=tdf[[\"complaint_id\", \"consumer_complaint_narrative\", \"topics\"]],\n",
    "    apply_command=\"python Topic_Modelling_OAF.py\",\n",
    "    returns=types_dict,\n",
    "    env_name=demo_env,\n",
    "    delimiter=\"#\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d38094d",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.7 Execute the function</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>call execute_script(), and return a single record to the client to check the data.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4bbf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_analysis_df = apply_obj.execute_script()\n",
    "ipydisplay(topic_analysis_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a6edd7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Now the results can be saved back to Vantage.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e7b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(df=topic_analysis_df, table_name=\"topic_prediction\", if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6144e65",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>6. Topic Modelling</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Topic modeling using Large Language Models (LLMs) revolutionizes the way we understand and categorize vast collections of text data. LLMs excel in understanding the semantics and context of words, enabling sophisticated topic modeling techniques.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Traditionally, topic modeling algorithms like Latent Dirichlet Allocation (LDA) rely on statistical patterns within documents to identify topics. However, LLMs offer a more nuanced approach. By leveraging their deep understanding of language, LLMs can extract complex themes and topics from unstructured text data with higher accuracy and flexibility.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>LLMs can generate coherent topics without needing predefined categories, making them ideal for exploratory analysis of diverse datasets. Moreover, their ability to capture subtle nuances in language allows for more precise topic identification, even in noisy or ambiguous texts.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'><b>Reasoning with a Chain of Thought</b>: Imagine you're trying to solve a problem. With a large language model, you start with an initial idea or question. Then, you use the model's capabilities to explore related concepts, gradually connecting them together. Each step builds upon the previous one, leading you closer to understanding or solving the problem. It's like putting together puzzle pieces, one by one, until you see the whole picture.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cbcce4",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>6.1 Number of Complaints by Predicted Topic</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>A graph illustrating the Number of Complaints by Predicted Topic reveals that the majority of complaints are centered around Mortgage Application, while the fewest are related to Mortgage Closing.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e814aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "grp_gen = (\n",
    "    DataFrame(\"topic_prediction\")\n",
    "    .select([\"topic\", \"complaint_id\"])\n",
    "    .groupby([\"topic\"])\n",
    "    .agg([\"count\"])\n",
    "    .to_pandas()\n",
    ")\n",
    "\n",
    "grp_gen = grp_gen.sort_values(\"count_complaint_id\", ascending=False)[:10]\n",
    "\n",
    "fig = px.bar(\n",
    "    grp_gen,\n",
    "    x=\"topic\",\n",
    "    y=\"count_complaint_id\",\n",
    "    labels={\n",
    "        \"count_complaint_id\": \"Number of Complaints\",\n",
    "        \"topic\": \"topic\",\n",
    "    },\n",
    "    title=\"Number of Complaints by Predicted Topic\",\n",
    ")\n",
    "\n",
    "# Add hover information\n",
    "fig.update_traces(hovertemplate=\"Issue: %{x}<br>Number of Complaints: %{y:,}\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44bc090-a387-41b6-90a5-638a16dc3d4f",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>7. Cleanup</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255bd928-7ee4-4ded-b351-43d1452de057",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>7.1 Remove the Container</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Remove the container if desired</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5390fb3-32d4-4fdf-8ab4-4f86686f6ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_env(\"oaf_demo_gpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6ba28d-07d2-4322-9f59-e81855e1389c",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>7.2 Stop the Cluster</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Hibernate the environment if desired</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e82715-0855-4d59-990c-481d3a9d3f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_cluster_stop(compute_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbd137a-7bfc-49fa-a18e-ca34ba68919d",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial;'>Dataset:</b>\n",
    "<br>\n",
    "<br>\n",
    "<p style='font-size: 16px; font-family: Arial; color: #00233C;'>The dataset is sourced from <a href='https://www.consumerfinance.gov/data-research/consumer-complaints/'>Consumer Financial Protection Bureau</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bdc0df-dc13-4a13-bf73-c7039a54c3ba",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2024. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
