{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "badff87f-8d63-4dfe-a1fa-0db73fcbcc1a",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Parkinson's Disease prediction using Decision Forest Classifier and GLM\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>Introduction</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Research shows that 89 percent of people with Parkinson’s disease (PD) experience speech and voice disorders, including soft, monotone, breathy and hoarse voice and uncertain articulation. As a result, people with PD report they are less likely to participate in conversation or have confidence in social settings than healthy individuals in their age group.\n",
    "<br>\n",
    "<br>    \n",
    "Speech disorders can progressively diminish quality of life for a person with PD. The earlier a person receives a baseline speech evaluation and speech therapy, the more likely he or she will be able to maintain communication skills as the disease progresses. Communication is a key element in quality of life and positive self-concept and confidence for people with PD.\n",
    "<br>\n",
    "<br>    \n",
    "Hence as a consultant, we are approached by an organization to detect Parkinson's Disease at an early stage. We are not showcasing a complete Data Science Usecase but we are trying to show how the Vantage In-Database functions can be used for Model training and scoring and comparing the performance of 2 models. The data we are using is sample data and the results and predictions may not be entirely accurate.</p>\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>Data</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>This dataset is composed of a range of biomedical voice measurements from different people with Parkinson's disease (PD). Each column in the table is a particular voice measure, and each row corresponds one of 195 voice recording from these individuals. Various speech signal processing algorithms including Time Frequency Features, Mel Frequency Cepstral Coefficients (MFCCs), Wavelet Transform based Features, Vocal Fold Features and TWQT features have been applied to the speech recordings of Parkinson's Disease (PD) patients to extract clinically useful information for PD assessment. The main aim of the data is to discriminate healthy people from those with PD, according to \"status\" column which is set to 0 for healthy and 1 for PD.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><a href = 'https://archive.ics.uci.edu/ml/datasets/parkinsons'>Link to the dataset</a>: Max A. Little, Patrick E. McSharry, Eric J. Hunter, Lorraine O. Ramig (2008), 'Suitability of dysphonia measurements for telemonitoring of Parkinson's disease', IEEE Transactions on Biomedical Engineering (to appear).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66077c1a-bd61-4393-83d2-177631ebbaec",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial'><b>Contents:</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Configuring the Environment</li>\n",
    "    <li>Initiate a connection to Vantage</li>\n",
    "    <li>Analyze the raw data set</li>\n",
    "    <li>Train and Test a Decision Forest Model</li>\n",
    "        <ul>\n",
    "            <li>4.1 Train and Test split using SAMPLE. Splitting the dataset in 80:20 ratio for Train and Test respectively</li>\n",
    "            <li>4.2 Train a Model</li> \n",
    "                <ol style = 'font-size:16px;font-family:Arial'>\n",
    "                    <li style = 'font-size:16px;font-family:Arial' >Using the DecisionForest and DecisonForestPredict In Database function to predict if the person can have Parkinson's Disease or not. So there are only 2 responses '0' and '1'.</li>\n",
    "                    <li style = 'font-size:16px;font-family:Arial'>Using the GLM and TDGLMPredict In Database function to predict if the person can have Parkinson's Disease or not. So there are only 2 responses '0' and '1'.</li>\n",
    "            </ol>\n",
    "            <li>4.3 Evaluate the Model :- Evaluation of the model is done using the TD_ClassificationEvaluator which provides various parameters for the model like Accuracy, Precision ,Recall etc.</li>\n",
    "        </ul>\n",
    "    <li>Cleanup</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b025bb-c63d-47e7-8de7-ba08db7da5ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"height:2px;border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>1. Connect to VantageCloud Lake</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Connect to VantageCloud using <code>create_context</code> from the teradataml Python library. If this environment has been prepared for connecting to a VantageCloud Lake OAF Container, all the details required will be loaded and you will see an acknowledgement after executing this cell.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b5391d-d20a-4b98-8677-ea1542dca22c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In the section, we import the required libraries and set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import getpass\n",
    "import pandas as pd\n",
    "\n",
    "from teradataml.dataframe.dataframe import DataFrame\n",
    "from teradataml import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "display.max_rows=5\n",
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "import teradataml\n",
    "import getpass\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "#from teradatagenai import TeradataAI, TextAnalyticsAI\n",
    "\n",
    "from dotenv import load_dotenv,dotenv_values\n",
    "from teradataml import *\n",
    "from teradatasqlalchemy.types import *\n",
    "from IPython.display import display as ipydisplay\n",
    "from os.path import expanduser\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1a9abf-42e4-4f76-804f-b04cc1af26f8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>You will <b>not</b> be prompted to provide the password. Everything required to execute this notebooks has been included in the environment!</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19df8f96-127c-4288-93ab-337ca87efb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking if this environment is ready to connect to VantageCloud Lake...\")\n",
    "\n",
    "if os.path.exists(\"/home/jovyan/JupyterLabRoot/VantageCloud_Lake/.config/.env\"):\n",
    "    print(\"Your environment parameter file exist.  Please proceed with this use case.\")\n",
    "    # Load all the variables from the .env file into a dictionary\n",
    "    env_vars = dotenv_values(\"/home/jovyan/JupyterLabRoot/VantageCloud_Lake/.config/.env\")\n",
    "    # Create the Context\n",
    "    eng = create_context(host=env_vars.get(\"host\"), username=env_vars.get(\"username\"), password=env_vars.get(\"my_variable\"))\n",
    "    execute_sql('''SET query_band='DEMO=Parkinsons_Disease_Prediction_PY_SQL.ipynb;' UPDATE FOR SESSION;''')\n",
    "    print(\"Connected to VantageCloud Lake with:\", eng)\n",
    "else:\n",
    "    print(\"Your environment has not been prepared for connecting to VantageCloud Lake.\")\n",
    "    print(\"Please contact the support team.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4e530b-c2f2-4634-825d-4211723cfd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_auth_token(base_url=env_vars.get(\"ues_uri\"),\n",
    "                  pat_token=env_vars.get(\"access_token\"), \n",
    "                  pem_file=env_vars.get(\"pem_file\"),\n",
    "                  valid_from=int(time.time())\n",
    "                 ):\n",
    "    print(\"UES Authentication successful\")\n",
    "else:\n",
    "    print(\"UES Authentication failed. Check credentials.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40107ac-ab4f-4223-ba42-7d42e7a27c64",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style=\"font-size:20px; font-family:Arial\"><b>2. Load the data</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The data required for this demo has already been loaded in <code>DEMO_ParkinsonsDisease</code> in the VantageCloud Lake environment.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4787deef-1bec-4b47-8c8a-a7c1b2c34686",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>There are more than 750 different features of the speech recordings which are used for analysis. The \"CLASS\" column which is the rightmost column of the answer set above(please scroll to the right), indicates whether the person has Parkinson's Disease(1) or DOES NOT have Parkinson's Disease(0)</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cb89ae-7dfe-4b4c-9b6a-f6b2d057a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_features = DataFrame(in_schema('DEMO_ParkinsonsDisease','Speech_Features'))\n",
    "speech_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16351926-3d1f-4e29-affd-f5faa900b5ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "speech_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-remove",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>3. Create Train and Test Dataset</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Now that we have our prepared data set, we can perform an abbreviated machine learning workflow:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Create Train and Test data sets using <code>SAMPLE Clause(80:20 split)</code></li>\n",
    "    <li>Train the model</li>\n",
    "    <li>Evaluate the model using Test data</li>\n",
    "</ol>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6929ee1e-b506-4e28-b953-b9eb253873d6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Feature engineering transform functions encapsulate variable transformations during the training phase so you can chain them to create a pipeline for operationalization. We used the <code>RandomProjectionMinComponents</code> to find the minimum components required. This allows us to reduce the number of columns from 753 to 200.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Further, we use the <code>nameFit</code> and <code>nameTransform</code> functions. Each <code>nameFit</code> function outputs a table to input to the <code>nameTransform</code> function as FitTable. For example, <code>ScaleFit</code> outputs a FitTable for <code>ScaleTransform</code>. We are using the mean <code>ScaleMethod</code> for this case.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Using the STD ScaleMethod the ScaleFit function calculates the mean values of each feature used and the output of this ScaleFit function is used in the <code>ScaleTransform</code> function as the fit table. The <code>ScaleFit()</code> function outputs statistics to input to the <code>ScaleTransform()</code> function, which scales specified input DataFrame columns.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71303ed4-142b-4c09-b0a9-e30a6a2b6729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import ScaleFit, ScaleTransform\n",
    "\n",
    "sf_fit = ScaleFit(data = speech_features, scale_method = 'STD',\n",
    "                     target_columns = ['2:200'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e052c49f-9af5-4b10-96ee-6f82417e2d7c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The Transform() function applies numeric transformations to input columns, using Fit() output. Here the output of the ScaleFit function is used by the ScaleTransform to apply the numeric transformations to the input columns. </p>\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Note: There may be some Teradata Database warnings for the ScaleTransform functions, but these are just warnings which can be ignored.</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baffe29e-2183-4530-9386-24c86f772c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_trns = sf_fit.transform(data = speech_features, accumulate = ['\"id\"','\"class\"'])\n",
    "sf_trns.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e62e03-93c7-40b1-a7d2-a9c1215d974d",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>Using teradataml OpenSource ML functions to find out feature importance </b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dffc7d5-7a23-455c-af38-f87e8c16600c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Below we are splitting the train and test dataset for the model evaluation.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f26d48f-7660-4ff3-b38f-c6ccbdfc5004",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transform = sf_trns.result\n",
    "df_transform = df_transform.assign(target = df_transform[\"class\"])\n",
    "df_transform = df_transform.drop([\"class\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b2cadf-a09b-4287-8396-8f0235065b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5f0946-bd75-46d4-b15c-7da5036dc194",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTestSplit_out = TrainTestSplit(\n",
    "                                    data = df_transform,   #sf_trns.result,\n",
    "                                    id_column = \"id\",\n",
    "                                    train_size = 0.80,\n",
    "                                    test_size = 0.20,\n",
    "                                    seed = 25\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa1ba96-ba78-4885-9ed6-edeb703a28b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = TrainTestSplit_out.result[TrainTestSplit_out.result['TD_IsTrainRow'] == 1].drop(['TD_IsTrainRow'], axis = 1)\n",
    "df_test = TrainTestSplit_out.result[TrainTestSplit_out.result['TD_IsTrainRow'] == 0].drop(['TD_IsTrainRow'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c32e492-4c6d-4a9a-86f1-ac038b6960ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(df_train, table_name='df_train', if_exists='replace')\n",
    "copy_to_sql(df_test, table_name='df_test', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b585eaa-766c-4325-b5ca-9ce44636cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=DataFrame('df_train')\n",
    "df_test= DataFrame('df_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a76f24-bb5d-4f37-a3eb-e7062019c67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ac614-2cbb-4d71-9c59-f4b98088c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e501c70-75df-4ac5-b273-a416dff5a413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import td_sklearn as osml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3623442f-fa2b-432a-97e2-cfae8f445baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop([\"target\",\"id\"], axis = 1)\n",
    "y_train = df_train.select([\"target\"]) \n",
    "X_test = df_test.drop([\"target\",\"id\"], axis = 1)\n",
    "y_test = df_test.select([\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5439be18-07bf-49f4-94b8-739ebf669330",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Set the session to use an analytic compute group with GPUs to execute the OpenSourceML function.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deaca74-c2f1-4947-adc4-8baed4b9181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_compute_group = env_vars.get(\"gpu_compute_group\")\n",
    "execute_sql(f\"SET SESSION COMPUTE GROUP {gpu_compute_group};\")\n",
    "print(f\"Compute group set to {gpu_compute_group}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32baf1db-88f1-432a-b38b-eb8262d0031b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Check the user environments and create an environment for the usecase.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d770d0c-a36e-42db-aac8-f63621119857",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_user_envs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c637225-dae6-43aa-acfd-9ba7e8d01db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    env = create_env(\n",
    "            env_name=\"openml_env\",\n",
    "            base_env=\"python_3.11\",\n",
    "            desc=\"OAF Demo env for OSML\",\n",
    "        )\n",
    "except:\n",
    "    remove_env(\"openml_env\")\n",
    "    env = create_env(\n",
    "            env_name=\"openml_env\",\n",
    "            base_env=\"python_3.9\",\n",
    "            desc=\"OAF Demo env for OSML\",\n",
    "        )\n",
    "    \n",
    "env    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6206c0ba-edc5-4bd0-8251-6a59fa411c48",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Confirm that the versions in the local environment are same to the virtual environment.<br>\n",
    "If there is a mis-match, please update the version(s) in the call to <code>env.install_lib()</code></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5186baf-6289-41f6-8d8d-250f9aba9e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep scikit-learn\n",
    "!pip list | grep scipy\n",
    "!pip list | grep numpy\n",
    "!pip list | grep pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b103c15-f203-4fd7-a10b-aa725ed97ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_id = env.install_lib([\"scikit-learn==1.5.2\",\n",
    "                \"scipy==1.13.1\",\n",
    "                \"numpy==1.23.5\",\n",
    "                \"pandas==2.2.3\"], asynchronous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2123b11-6475-4a91-a4d0-33d4f5c5d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status of installation using status() API.\n",
    "# Create a loop here for demo purposes\n",
    "\n",
    "ipydisplay(env.status(claim_id))\n",
    "stage = env.status(claim_id)['Stage'].iloc[-1]\n",
    "while stage == 'Started':\n",
    "    stage = env.status(claim_id)['Stage'].iloc[-1]\n",
    "    clear_output()\n",
    "    ipydisplay(env.status(claim_id))\n",
    "    sleep(5)\n",
    "    \n",
    "# Verify the Python libraries have been installed correctly.\n",
    "ipydisplay(env.libs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacccf00-e76b-4961-9d70-b926684f77d4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Please wait until you see a line that indicates that the Stage is <code>Finished</code> and the installed packages are listed before continuing with this notebook.<br>\n",
    "Then you can continue with setting the configuration for the user environment that was just created.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3941dd5c-dde3-4fdd-bcd1-357fb758c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "configure.openml_user_env = env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d262b998-becb-404a-89f4-afbc9a4e9e9f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>Logistic Regression</b> is used to create the model output which will be used further to check the feature importance.\n",
    "<br><code>osml.LogisticRegression(C=0.1, penalty='l2', solver= 'liblinear', random_state=1)</code></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Logistic Regression is a Machine Learning classification algorithm that is used to predict the probability of a categorical dependent variable. In logistic regression, the dependent variable is a binary variable that contains data coded as 1 (yes, success, etc.) or 0 (no, failure, etc.). This is suitable here as we have to determine if the patient has Parkinson or Does not have Parkinson.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here, we are using the <code>LogisticRegression</code> method from the teradataml OpenSource ML library. We will create the model and fit using the training data.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b07732-d733-4b83-bdbc-78ef18dabf45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from teradataml import td_sklearn as osml\n",
    "lr = osml.LogisticRegression(C=0.1, penalty='l2', solver= 'liblinear', random_state=1)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731674d9-6c16-46b8-b6f8-169916f2e311",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We will check the accuracy of the moel by using the score function.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434e25d9-d007-4a9c-89f0-944a0e6df786",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d4efcd-47b5-4015-91c1-5c21b2ff607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model predictions\n",
    "predict_lr =lr.predict(X_test,y_test)\n",
    "predict_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f864c0ee-67aa-4d82-acbb-ec6eb4c26d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcba712-b36e-451d-a0fe-9079b3eab497",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The score of the model is 0.71 which means the accuracy of the model is 71%</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Using the predict function we will predict if the patient has Parkinsons or not</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3124fd1f-beed-42e2-ac8e-6ae2789a2cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model predictions\n",
    "predict_lr =lr.predict(X_test,y_test)\n",
    "predict_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0febc2-d9b1-450b-8024-37bec05ae922",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Based on the predicted and the actual values from the dataset we will check the classification report for the model. We get the Precision, Recall, F1-Score and Accuracy of the model from the classification Report</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a39cda-59d7-4781-8ff1-60243e2db527",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_df = predict_lr.select([\"target\"])\n",
    "y_pred_df = predict_lr.select(\"logisticregression_predict_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5fd79c-6145-410b-9ff8-ce173b982bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = td_sklearn.classification_report(y_true=y_true_df, y_pred=y_pred_df, digits=4)\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178ef3c2-da51-462b-aeef-6f44d933aaf2",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Here we can see that the accuracy for this model is 71%.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Below we try to get the important features using the logistic regression coefficient and plot the graph for features based on their importance</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82268867-62dd-414f-bc7b-c64e92cfb817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': X_train.columns,\n",
    "    'Importance': lr.coef_[0]\n",
    "})\n",
    "importances = importances.sort_values(by='Importance', ascending=False)\n",
    "importances.to_csv(\"logistic_feature_imp.csv\")\n",
    "plt.figure(figsize=(100,30))\n",
    "plt.bar(x=importances['Attribute'], height=importances['Importance'], color='#087E8B')\n",
    "plt.title('Feature importances obtained from coefficients', size=20)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195d87b3-ff3f-402a-a1c5-42a4c2d87082",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above graph shows the important features. Since we have a lot of features (200), we have also created a logistic_feature_imp.csv, which shows the exact values for all the features. </p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>As seen in the graph and output file apart from the top 10-15 variables, rest of the variable co-efficients are very close to zero. So we will consider only the top 12 [those feature co-eff >= 0.3 and <= -0.3] variables for checking the accuracy.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d666ccf0-f60e-4d5f-baf5-231def718505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###Since except top 10 to 20 variables, rest of the variable co-efficienct is close to zero. \n",
    "###So we will be taking Top 12 [those feature co-eff >= 0.3 and <= -0.3] variables and checking the accuracy.\n",
    "parkinson_new_df = df_transform[[\"id\",\n",
    "\"DFA\",\n",
    "\"std_delta_delta_log_energy\",\n",
    "\"std_7th_delta\",\n",
    "\"std_delta_log_energy\",\n",
    "\"std_7th_delta_delta\",\n",
    "\"GNE_mean\",\n",
    "\"mean_MFCC_2nd_coef\",                          \n",
    "\"mean_2nd_delta\",\n",
    "\"mean_MFCC_5th_coef\",\n",
    "\"std_MFCC_3rd_coef\",\n",
    "\"mean_MFCC_6th_coef\",\n",
    "\"GNE_SNR_TKEO\", \"target\"]]\n",
    "\n",
    "parkinson_new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a134bfb7-4648-4533-8555-207dc70c3e63",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>With these 12 features we then check the corelation of these features. </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32201303-7381-44de-a568-db589199f7ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get the correlation matrix\n",
    "import seaborn as sns\n",
    "pd_parkinson_new_df = parkinson_new_df.to_pandas(all_rows=True)\n",
    "corr = pd_parkinson_new_df.corr()\n",
    "\n",
    "##plot heatmap\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title('Correlation Matrix')\n",
    "sns.heatmap(corr, annot = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a96789-f201-48f9-9f37-23194cda4a35",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>As seen in the above corelation matrix , we can see that there are 2 features where the corelation is above 92%. The intersection formed by 5th and 6th feature from the top on the Y axis with the 3rd and 4th feature respectively from left on the X axis, we can observe that the corelation is 0.92 and 0.95. </p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>So now in the below evaluation we will be using only these 10 important features.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6186a1f-470a-4d3a-9872-b51868224848",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>Train and Test split using SAMPLE</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Create the dataset with only these 10 variables along with the id and class columns which will be used as the id and target variables for the below evaluations.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Using 80:20 split data to create the training and testing dataset.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce2228-53ba-49ed-a369-e35b0254e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_samples = df_transform.sample(frac = [0.2, 0.8])[[\"id\",\n",
    "\"DFA\",\n",
    "\"std_delta_delta_log_energy\",\n",
    "\"std_7th_delta\",\n",
    "\"GNE_mean\",\n",
    "\"mean_MFCC_2nd_coef\",                          \n",
    "\"mean_2nd_delta\",\n",
    "\"mean_MFCC_5th_coef\",\n",
    "\"std_MFCC_3rd_coef\",\n",
    "\"mean_MFCC_6th_coef\",\n",
    "\"GNE_SNR_TKEO\",\"sampleid\", \"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5a27f2-fb1b-4cbe-8cb6-ff87b5bc7e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_speech_features_train = tdf_samples[tdf_samples['sampleid'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9f7a24-be41-469e-bb82-26ec921d2b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_speech_features_test = tdf_samples[tdf_samples['sampleid'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b2c6a-02dd-462e-972f-fb1bdf8d67fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(tdf_samples[tdf_samples['sampleid'] == 2], table_name = 'pd_speech_features_train',\n",
    "            if_exists = 'replace')\n",
    "train_df_data = DataFrame('pd_speech_features_train')\n",
    "train_df_data.select(['target','id']).groupby('target').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c19acdc-a36f-4d7c-94ba-491b1a66ce7a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The output shows the number of people we are considering for each class to train the model – class 1 has Parkinson’s</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5d98b1-c09e-4330-9f95-1e34d1368efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(tdf_samples[tdf_samples['sampleid'] == 1], table_name = 'pd_speech_features_test', \n",
    "            if_exists = 'replace')\n",
    "test_df_data = DataFrame('pd_speech_features_test')\n",
    "test_df_data.select(['target','id']).groupby('target').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c08b07-138e-4837-83eb-5ead303908d2",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The output shows the number of people we are considering for each class to test the model – class 1 has Parkinson’s</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-reaction",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>4. Decision Tree Model</b></p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>4.1 - Train a Decision Tree Model</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The <a href = 'https://docs.teradata.com/r/Enterprise/Teradata-Package-for-Python-Function-Reference-17.20/teradataml-Analytic-Database-SQL-Engine-Analytic-Functions/Supported-on-Database-Versions-16.20.xx-17.00.xx-17.05.xx/DecisionForestPredict'>DecisionForest</a> is an ensemble algorithm used for classification and regression predictive modelling problems. It is an extension of bootstrap aggregation (bagging) of decision trees. </p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>This function takes the training data as input, as well as the following function parameters</p>\n",
    "    <ul style = 'font-size:16px;font-family:Arial'>\n",
    "        <li>InputColumns; list or range of columns used as features (we used an ordinal reference of columns 2:200)</li>\n",
    "        <li>ResponseColumn; the dependent or target value (we used “class”, the first column)</li>\n",
    "        <li>TreeType; either CLASSIFICATION or REGRESSION</li>\n",
    "    <li>Other hyperparameter values detailed in the documentation</li>\n",
    "        </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95034ac9-573f-4e0e-b38b-3f7bf8e19e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionForest_out = DecisionForest(data = train_df_data, \n",
    "                            input_columns = ['id', 'DFA', 'std_delta_delta_log_energy', 'std_7th_delta', 'GNE_mean', 'mean_MFCC_2nd_coef', \n",
    "      'mean_2nd_delta', 'mean_MFCC_5th_coef', 'std_MFCC_3rd_coef', 'mean_MFCC_6th_coef', 'GNE_SNR_TKEO', '\"sampleid\"'], \n",
    "                            response_column = 'target', \n",
    "                            max_depth = 5, \n",
    "                            num_trees = 10, \n",
    "                            min_node_size = 1, \n",
    "                            mtry = 3, \n",
    "                            mtry_seed = 1, \n",
    "                            seed = 2, \n",
    "                            tree_type = 'CLASSIFICATION')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a6f3b3-c47b-4010-bc18-721a5d1b9c60",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The DecisionForest function produces a model and a JSON representation of the decision tree. Below is explanation for some columns in the JSON tree. The other details can be found at the link <a href = 'https://docs.teradata.com/search/all?query=TD_DecisionForest&content-lang=en-US'>here.</a></p>\n",
    "\n",
    "</p>\n",
    "<html>\n",
    "   <head>\n",
    "      <style>\n",
    "         table, th, td {\n",
    "            border: 1px solid black;\n",
    "            border-collapse:collapse;\n",
    "         }\n",
    "      </style>\n",
    "   </head>\n",
    "   <body>\n",
    "      <table>\n",
    "         <tr>\n",
    "            <th>JSON Type</th>\n",
    "            <th>Description</th>             \n",
    "         </tr>\n",
    "         <tr>\n",
    "            <td>id_</td>\n",
    "            <td>\"Node identifier\"</td>\n",
    "         </tr>\n",
    "         <tr>\n",
    "            <td>nodeType_</td> \n",
    "            <td>The node type. Possible values: CLASSIFICATION_NODE,CLASSIFICATION_LEAF,REGRESSION_NODE,REGRESSION_LEAF.</td>\n",
    "         </tr>\n",
    "         <tr>\n",
    "            <td>split_</td> \n",
    "            <td>The start of JSON item that describes a split in the node.</td>\n",
    "         </tr> \n",
    "         <tr>\n",
    "            <td>responseCounts_</td> \n",
    "            <td>[Classification trees] Number of observations in each class at node identified by id.</td>\n",
    "         </tr>\n",
    "         <tr>\n",
    "            <td>size_</td> \n",
    "            <td>Total number of observations at node identified by id.</td>\n",
    "         </tr> \n",
    "         <tr>\n",
    "            <td>maxDepth_</td> \n",
    "            <td>Maximum possible depth of tree, starting from node identified by id. For root node, the\n",
    "value is max_depth. For leaf nodes, the value is 0. For other nodes, the value is the\n",
    "maximum possible depth of tree, starting from that node.</td>\n",
    "         </tr>  \n",
    "      </table>\n",
    "   </body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb1c7c6-b3e0-49a1-8823-c3c4a7ab3fef",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>4.2 - Evaluate the Model</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Execute a testing prediction using the split data above.  Evaluate the model by creating a confusion matrix with the <a href = 'https://docs.teradata.com/search/all?query=TD_ClassificationEvaluator&content-lang=en-US'>TD_ClassificationEvaluator</a> SQL Function.</p>\n",
    "\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Execute <a href = 'https://docs.teradata.com/r/Teradata-VantageTM-Analytics-Database-Analytic-Functions-17.20/Model-Scoring-Functions/DecisionForestPredict'>DecisionForestPredict</a> using the model built above</li>\n",
    "    <li>Execute <a href = 'https://docs.teradata.com/search/all?query=TD_ClassificationEvaluator&content-lang=en-US'>TD_ClassificationEvaluator</a> and pass the actual classification and the predicted value</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b205669-b5a1-4687-984d-16e035015e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_forest_predict_out = TDDecisionForestPredict(object = DecisionForest_out.result,\n",
    "                                                        newdata = test_df_data,\n",
    "                                                        id_column = \"id\",\n",
    "                                                        detailed = False,\n",
    "                                                        output_prob = True,\n",
    "                                                        output_responses = ['0','1'],\n",
    "                                                        accumulate = 'target')\n",
    "decision_forest_predict_out.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d5c169-a296-439c-a799-1e0d5970df36",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The DecisionForestPredict function creates probabilities for the prediction made depending on the class and the Id columns. The output of the predict function is passed to the Classification Evaluator to get the parameters of the functions.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>DecisionForestPredict outputs the probability that each observation is in the predicted class. To use DecisionForestPredict output as input to ML Engine ROC function, you must first transform it to show the probability that each observation is in the positive class. One way to do this is to change the probability to (1- current probability) when the predicted class is negative. The prediction algorithm compares floating-point numbers. Due to possible inherent data type differences between ML Engine and Analytics Database executions, predictions can differ.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35d7512-bffa-4925-95ad-2a9c2c4cd7bc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We create the Confusion Matrix to compare the actual and the Predicted values. Confusion matrix is a very popular measure used while solving classification problems. It can be applied to binary classification as well as for multiclass classification problems. Confusion matrices represent counts from predicted and actual values. It is an N x N matrix used for evaluating the performance of a classification model, where N is the number of target classes.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d1933c-0b50-4b28-b23d-5014be8f7fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data = decision_forest_predict_out.result\n",
    "predicted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37e5d5e-a35c-4383-bb23-61d6300069e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "df = predicted_data.to_pandas().reset_index()\n",
    "cm = confusion_matrix(df['target'], df['prediction'], normalize='all')\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=['DoesNotHaveParkinson', 'HasParkinson'])\n",
    "cmd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18116bad-f81d-4751-90fb-26bee87b47c3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above Confusion Matrix shows the actual and the Predicted values. Based on the Decision Forest model the above matrix shows the predicted and actual value comparison for people having parkinson and those not having parkinson.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883a9c2b-3284-4535-baf4-176d9ecc3430",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>4.3 - Use classification Evaluator for DecisionForestPredict</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Evaluate the model by creating a confusion matrix with the <a href = 'https://docs.teradata.com/search/all?query=TD_ClassificationEvaluator&content-lang=en-US'>TD_ClassificationEvaluator</a> SQL Function.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In classification problems, a confusion matrix is used to visualize the performance of a classifier. The confusion matrix contains predicted labels represented across the row-axis and actual labels represented\n",
    "across the column-axis. Each cell in the confusion matrix corresponds to the count of occurrences of labels\n",
    "in the test data.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Apart from accuracy, the secondary output table returns micro, macro, and weighted-average metrics of precision, recall, and F1-score values.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afb8700-ee68-4e95-82c9-b2162046423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassificationEvaluator_obj = ClassificationEvaluator(data=predicted_data,\n",
    "                                                          observation_column='target',\n",
    "                                                          prediction_column='prediction',\n",
    "                                                          labels=['0','1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31df12c8-cf4f-4fcf-9efe-7c87e42680c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = ClassificationEvaluator_obj.output_data\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c681131e-4252-4eb9-be4f-dc887a203864",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above output has the secondary output table that returns micro, macro, and weighted-average metrics of precision, recall, and F1-score values.</p>\n",
    "<table style = 'font-size:16px;font-family:Arial'>\n",
    "  <tr>\n",
    "    <th>Column</th>\n",
    "    <th>Description</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Precision</td>\n",
    "    <td>The positive predictive value. Refers to the fraction of relevant instances among\n",
    "the total retrieved instances.\n",
    "        Precision answers the following question: what proportion of predicted Positives is truly Positive? \n",
    "        Precision = (TP)/(TP+FP)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Recall</td>\n",
    "    <td>Refers to the fraction of relevant instances retrieved over the total amount of\n",
    "relevant instances. Recall answers a different question: what proportion of actual Positives is correctly classified?\n",
    "Recall = (TP)/(TP+FN)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>F1</td>\n",
    "    <td>F1 score, defined as the harmonic mean of the precision and recall and is a number between 0 and 1. F1 score maintains a balance between the precision and recall for your classifier.                                         \n",
    "                      F1 = 2*(precision*recall/precision+recall)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Support</td>\n",
    "    <td>The number of times a label displays in the Observation Column.</td>\n",
    "  </tr>\n",
    "</table>\n",
    "<p style = 'font-size:16px;font-family:Arial'>**TP:- True Positive , FP :- False Positive, TN :- True Negative , FN :- False Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663350b7-61c1-497f-8adb-b77ca03128b2",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>5. Generalized Linear Model(GLM)</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.1 - Train a GLM Model</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The <a href = 'https://docs.teradata.com/search/all?query=TD_GLM&content-lang=en-US'>Generalized Linear Model (GLM)</a> is an extension of the linear regression model that enables the linear equation to relate to the dependent variables by a link function. The GLM function supports several distribution families and associated link functions. </p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>This function takes the training data as input, as well as the following function parameters</p>\n",
    "    <ul style = 'font-size:16px;font-family:Arial'>\n",
    "        <li>InputColumns; list or range of columns used as features (we used an ordinal reference of columns 2:10)</li>\n",
    "        <li>ResponseColumn; the dependent or target value (we used “class”, the first column) </li>\n",
    "        <li>Family; either Binomial or Gaussian</li>\n",
    "    <li>Other hyperparameter values detailed in the documentation</li>\n",
    "        </ul>\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079aec95-f2e3-4eef-806d-3cc7c65beb02",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We use the GLM function to create the GLM model using the train dataset.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7731ca07-f172-4eaa-818f-2b823adb8e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import GLM, TDGLMPredict\n",
    "\n",
    "glm_model = GLM(data = DataFrame('\"pd_speech_features_train\"'),\n",
    "                input_columns = ['1:10'], \n",
    "                response_column = 'target',\n",
    "                learning_rate = 'OPTIMAL',\n",
    "                terms = ['id','target'],\n",
    "                momentum = 0.0,\n",
    "                family = 'Binomial')\n",
    "\n",
    "glm_model.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02e8116-33d7-423a-ba9e-5314ee713b77",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The GLM function creates various output predictors and values based on the above parameters passed in the query</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The function output is a trained GLM model which can be input to the TDGLMPredict function\n",
    "for prediction. The model also contains model statistics of MSE, Loglikelihood, AIC, and BIC.\n",
    "Further model evaluation can be done as a post-processing step using functions such as\n",
    "TD_RegressionEvaluator,TD_ClassificationEvaluator and TD_ROC.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56d4594-3ae6-4c29-9eb0-2ef1c736d4b5",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.2 - Evaluate the Model</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Execute a testing prediction using the split data above.  Evaluate the model by creating a confusion matrix with the <a href = 'https://docs.teradata.com/search/all?query=TD_ClassificationEvaluator&content-lang=en-US'>TD_ClassificationEvaluator</a> SQL Function.</p>\n",
    "\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Execute <a href = 'https://docs.teradata.com/search/all?query=TDGLMPredict&content-lang=en-US'>TDGLMPredict</a> using the model built above</li>\n",
    "    <li>Execute <a href = 'https://docs.teradata.com/search/all?query=TD_ClassificationEvaluator&content-lang=en-US'>TD_ClassificationEvaluator</a> and pass the actual classification and the predicted value</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b31c0f-0c3b-4543-abfc-e1af200874c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import teradataml\n",
    "from teradataml import GLM, TDGLMPredict\n",
    "obj = TDGLMPredict(newdata = DataFrame('\"pd_speech_features_test\"'),\n",
    "                           id_column = 'id',\n",
    "                           object = glm_model.result,\n",
    "                           accumulate = 'target',\n",
    "                           family = 'Binomial',\n",
    "                           output_prob=True,\n",
    "                           output_responses = ['0', '1'],\n",
    "                           terms='target')\n",
    "\n",
    "obj.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd40f9c-3a46-4f87-987c-d86e4459d3e6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The TDGLMPredict function predicts target values (regression) and class labels (classification) for test data using a GLM model trained by the GLM function. Similar to GLM, input features should be standardized, such as using ScaleFit, and ScaleTransform, before using in the function. The function takes only numeric features. The categorical\n",
    "features must be converted to numeric values prior to prediction.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Rows with missing (null) values are skipped by the function during prediction. For prediction results evaluation, you can use TD_RegressionEvaluator, TD_ClassificationEvaluator or TD_ROC function as\n",
    "postprocessing step.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad90cfeb-f928-4ba3-b188-3a38ce76f6a0",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.3 - Use classification Evaluator for GLMPredict</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Evaluate the model by creating a confusion matrix with the <a href = 'https://docs.teradata.com/search/all?query=TD_ClassificationEvaluator&content-lang=en-US'>TD_ClassificationEvaluator</a> SQL Function.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dff5f7-6748-41c4-a2c7-a3ffefbda815",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Create CONFUSION MATRIX for the GLM Predict model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f869ab-cd7c-4262-a219-2a7447fbfc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "df = obj.result.to_pandas()\n",
    "cm = confusion_matrix(df['target'], df['prediction'], normalize='all')\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=['DoesNotHaveParkinson', 'HasParkinson'])\n",
    "cmd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40911b8-06d3-4624-9e9d-1cb4bec2990d",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above Confusion Matrix shows the actual and the Predicted values. Based on GLM the above matrix shows the predicted and actual value comparison for people having parkinson and those not having parkinson.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b475376d-5557-47ee-8390-c0d2b19e1892",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Since TD_ClassificationEvaluator requires same datatype for prediction and class columns so creating another table with same datatype.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a5bd08-0c81-4e2e-b509-e533f662b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import ConvertTo\n",
    "glm_predicted_data = ConvertTo(data = obj.result,\n",
    "                           target_columns = ['id','target', \"prediction\",'prob_0','prob_1'],\n",
    "                           target_datatype = [\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba6412-e268-4609-a94f-105513424b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassificationEvaluator_obj_glm = ClassificationEvaluator(data=glm_predicted_data.result,\n",
    "                                                          observation_column='target',\n",
    "                                                          prediction_column='prediction',\n",
    "                                                          labels=['0','1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b193e-fa1d-4008-bdb6-de891855a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_metrics = ClassificationEvaluator_obj_glm.output_data\n",
    "glm_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3529157f-b9a6-4253-8400-f9afc3091590",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>6. Comparison of the Metrics generated by the 2 Models. Decision Forest vs GLM</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4df8c8-8dfb-48c1-8935-fc1e11584a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = df_metrics.assign(model='DecisionForest')\n",
    "glm_metrics = glm_metrics.assign(model='GLM')\n",
    "df_union = df_metrics.concat(glm_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2d8a62-4732-40e6-b37b-e01d782efaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chart=df_union.to_pandas()\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from matplotlib import pyplot as plt\n",
    "df_chart['Metric'] = df_chart['Metric'].str.replace('\\x00', '')\n",
    "df_pivot = pd.pivot_table(\n",
    "df_chart,\n",
    "values=\"MetricValue\",\n",
    "index=\"Metric\",\n",
    "columns=\"model\"\n",
    ")\n",
    "#df_chart.plot.bar(x='Metric',y='MetricValue' , legend='model')\n",
    "ax=df_pivot.plot(kind='bar')\n",
    "# Get a Matplotlib figure from the axes object for formatting purposes\n",
    "fig = ax.get_figure()\n",
    "# Change the plot dimensions (width, height)\n",
    "fig.set_size_inches(12, 6)\n",
    "# Change the axes labels\n",
    "ax.set_xlabel(\"Metrics\")\n",
    "ax.set_ylabel(\"Metric Values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefce3e7-2df3-4d19-9edb-c77d30d03fbd",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Thus here we have used 2 different models to train and predict the data. The classification evaluator is used to evaluate and compare the models. The Teradata In-Database functions are used for training, prediction and evaluation. In this case since we have sample data the result parameters like the Accuracy, Precision, Recall etc. may not be accurate for both the models, still from the above graph we can conclude that in this case GLM model with an accuracy of 82% is better than DecisionForest with accuracy of 77%.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-lying",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>7. Cleanup</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Work Tables</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66935e-3d9e-437b-a63f-4018c6efcbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['pd_speech_features_train', 'pd_speech_features_test','additional_metrics_speech_test','df_predict_output',\n",
    "          'glm_predict_output', 'additional_metrics_speech_test_glm','metric_union','DF_train','DF_Predict' ]\n",
    "\n",
    "# Loop through the list of tables and execute the drop table command for each table\n",
    "for table in tables:\n",
    "    try:\n",
    "        db_drop_table(table_name=table)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5fef92-dd00-44b6-a87f-7e368b32dfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_env(\"openml_env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ddd629-53b5-4c4d-91b1-01c4aa61bc75",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>Databases and Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f22c844-8d82-4191-a96b-4c8c6823ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-modern",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; border-bottom:3px solid #91A0Ab\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2023,2024,2025. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
