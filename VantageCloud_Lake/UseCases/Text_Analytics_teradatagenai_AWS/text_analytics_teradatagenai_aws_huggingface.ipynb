{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "      Simplify Text Analytics with Teradata's Python package for Generative AI\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>\n",
    "\n",
    "<p style=\"font-size:20px;font-family:Arial\"><b>Introduction:</b></p>\n",
    "\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "  The <code>teradatagenai</code> Python library enables data scientists, analysts, and developers to run analytics on their unstructured data directly within Teradata VantageCloud. It's built-in support for open-source Hugging Face models through Teradata's  Bring Your Own Large Language Model (BYOLLM) capability and cloud service provider or by using In-DB TextAnalytics AI functions to access models provided by AWS, Azure, and GCP.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "  <img src=\"./images/teradatagenai.png\" width=\"1000\" alt=\"teradatagenai Diagram\" style=\"border:4px solid #404040; border-radius: 10px;\">\n",
    "</div>\n",
    "\n",
    "<p style=\"font-size:20px;font-family:Arial;margin-top:10px\"><b>Business Value:</b></p>\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    " Organizations handle massive volumes of unstructured text including emails, voice call transcripts, customer reviews, contracts and more. Traditional approaches to analyze this data often involve costly data transfers, building custom ML pipelines, and extended turnaround times. <code>teradatagenai</code> addresses these challenges by bringing domain specific language models LLMs and hosted LLMs closer to your data.\n",
    "</p>\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "  With built-in support for GPU acceleration and seamless integration with VantageCloud, the library offers simple function calls that abstract complex APIs, enabling secure, scalable, and performant text processing. Whether you're deploying open source models in-database or calling hosted LLMs like Amazon Bedrock, <code>teradatagenai</code> provides the flexibility to align with your organization's security, cost, and performance needs.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "  The <code>TextAnalyticsAI</code> module within the library provides over 11 built-in generative AI functions for powerful in-database NLP capabilities:\n",
    "</p>\n",
    "\n",
    "<ul style=\"font-size:16px; font-family:Arial; margin-left:20px; line-height:1.8;\">\n",
    "  <li><code>classify()</code> â€“ Classify text into predefined categories</li>\n",
    "  <li><code>analyze_sentiment()</code> â€“ Perform sentiment analysis</li>\n",
    "  <li><code>detect_language()</code> â€“ Detect the language of a text</li>\n",
    "  <li><code>embeddings()</code> â€“ Generate embeddings for similarity search</li>\n",
    "  <li><code>recognize_entities()</code> â€“ Extract named entities</li>\n",
    "   <li><code>recognize_pii_entities()</code> â€“ Detect and label PII entities</li>\n",
    "  <li><code>extract_key_phrases()</code> â€“ Identify key phrases in text</li>\n",
    "  <li><code>mask_pii()</code> â€“ Mask personally identifiable information (PII)</li>\n",
    "  <li><code>sentence_similarity()</code> â€“ Measure semantic similarity between sentences</li>\n",
    "  <li><code>summarize()</code> â€“ Generate summaries of longer documents</li>\n",
    "  <li><code>translate()</code> â€“ Translate text between languages</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px;font-family:Arial;\"><b>How to Get Access to Run This Demo in VantageCloud</b></p>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Gain free access to Teradataâ€™s <b>Open Analytics Framework</b>, which includes support for <b>BYO-LLM capabilities</b> and <b>GPU compute clusters</b>. This enables you to run open-source Hugging Face models directly within your VantageCloud environment</p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "To request the access required for this demo, send an email to <a href=\"mailto:Support.ClearScapeAnalytics@Teradata.com?subject=Requesting%20OAF%20Access\">Support.ClearScapeAnalytics@Teradata.com</a> and include the Host name of the environment you are requsting access from.  This can be found on the ClearScape Analytics Dashboard in the section <b>Connection Details for Vantage Database</b>. Our team will provision your connection with the required permissions for BYO-LLM and GPU-accelerated demos.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Please</b><i> restart the kernel after executing the above cell to include/update these libraries into memory for this kernel. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i> and then clicking <b>Restart</b>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none'>\n",
    "<p style=\"font-size:20px;font-family:Arial\"><b>1. Configure the environment</b></p>\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "Before we start working with our data, we need to set up our environment. This involves importing the necessary packages and establishing a connection to Vantage.\n",
    "<br>\n",
    "Here's how we can do this: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from getpass import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from teradataml import *\n",
    "from teradatagenai import TextAnalyticsAI, TeradataAI, load_data\n",
    "from IPython.display import display as ipydisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>2. Connect to VantageCloud Lake</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Connect to VantageCloud using <code>create_context</code> from the teradataml Python library. If this environment has been prepared for connecting to a VantageCloud Lake OAF Container, all the details required will be loaded and you will see an acknowledgement after executing this cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking if this environment is ready to connect to VantageCloud Lake...\")\n",
    "\n",
    "if os.path.exists(\"/home/jovyan/JupyterLabRoot/VantageCloud_Lake/.config/.env\"):\n",
    "    print(\"Your environment parameter file exist.  Please proceed with this use case.\")\n",
    "    # Load all the variables from the .env file into a dictionary\n",
    "    env_vars = dotenv_values(\"/home/jovyan/JupyterLabRoot/VantageCloud_Lake/.config/.env\")\n",
    "    # Create the Context\n",
    "    eng = create_context(host=env_vars.get(\"host\"), username=env_vars.get(\"username\"), password=env_vars.get(\"my_variable\"))\n",
    "    execute_sql('''SET query_band='DEMO=text_analytics_teradatagenai_aws_huggingface.ipynb;' UPDATE FOR SESSION;''')\n",
    "    print(\"Connected to VantageCloud Lake with:\", eng)\n",
    "else:\n",
    "    print(\"Your environment has not been prepared for connecting to VantageCloud Lake.\")\n",
    "    print(\"Please contact the support team.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style=\"font-size:20px; font-family:Arial\"><b>3.Load the data</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "We will be loading sample unstructured data which represents real world advisor-client conversations. We will use this this sample data to explore various NLP tasks including PII masking, entity recognition, summarization, sentiment analysis, language detection and more.\n",
    "</p>\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "<b>ðŸ’¼ Use Case Summary:</b><br>\n",
    "In the wealth management industry, financial advisors hold many client meetings each week â€” discussing portfolios, insurance, loans, and retirement planning. Manually summarizing and tagging these interactions for compliance, CRM updates, or follow-up actions is time-consuming and often inconsistent.\n",
    "</p>\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "With Teradataâ€™s teradatagenai library, you can apply generative AI functions directly inside VantageCloud using either hosted LLMs (e.g., via Amazon Bedrock) or Open Source Hugging Face modelsâ€”keeping the data in place for secure, scalable inference.\n",
    "<br>\n",
    "This enables financial firms to:\n",
    "<br>   \n",
    "<ul>\n",
    "    <li>ðŸ“Œ Automate meeting note tagging for faster documentation and regulatory compliance </li>\n",
    "    <li> ðŸ“ˆ Enhance client profiling by identifying frequently discussed financial topics </li>\n",
    "    <li> ðŸ”„ Streamline CRM updates by structuring insights from unstructured text </li>\n",
    "</ul>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_profile = DataFrame(in_schema(\"DEMO_TextAnalytics\",\"Customer_Profile\"))\n",
    "customer_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advisor_customer_interactions  = DataFrame(in_schema(\"DEMO_TextAnalytics\",\"Advisor_Customer_Interactions \"))\n",
    "advisor_customer_interactions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<b style='font-size:20px;font-family:Arial'>4.Setting up TeradataAI to access Amazon Bedrock Model</b>\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "This section describes how to instantiate the <code>TeradataAI</code> class to set up the environment and initialize the LLM endpoint.\n",
    "<br>\n",
    "Users can provide the required authorization information in four different ways:\n",
    "<ol>\n",
    "    <li>Explicitly pass the authorization information to each argument of the function</li>\n",
    "    <li>Set the environment variables related to the authorization arguments</li>\n",
    "    <li>Supply the authorization information via a configuration file</li>\n",
    "    <li>Pass an existing database authorization object containing the credentials using the authorization parameter</li>\n",
    "</ol>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the environment variables related to the authorization arguments.\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = getpass(prompt='AWS_ACCESS_KEY_ID: ') \n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = getpass(prompt='AWS_SECRET_ACCESS_KEY: ') \n",
    "os.environ['AWS_DEFAULT_REGION'] = getpass(prompt='AWS_DEFAULT_REGION: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the TeradataAI class with the Amazon Bedrock model.\n",
    "llm_aws = TeradataAI(api_type=\"aws\",\n",
    "                     model_name=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none'>\n",
    "<p style='font-size:20px;font-family:Arial'><b>5. Use the <code>TextAnalyticsAI</code> API to Perform Various Text Analytics Tasks</b></p>\n",
    "<p style='font-size:16px;font-family:Arial'>You can execute the help function at the bottom of this notebook to read more about this API.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the TextAnalyticsAI class with the Amazon Bedrock model.\n",
    "obj = TextAnalyticsAI(llm=llm_aws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>6. Sentiment Analysis</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "In this section, we'll explore the `analyze_sentiment()` function provided by TextAnalyticsAI which classifies text into positive, neutral, or negative categories. Sentiment analysis is:\n",
    "<ul>\n",
    "    <li>A powerful way to understand the voice of the customer\n",
    "    <li>A complex task due to nuanced interpretation, sarcasm, and irony. However, teradatagenai and LLMs provide a quick and powerful way to decrypt customer sentiments</li>\n",
    "</ul></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Using teradatagenai coupled with  like Amazon Bedrock is faster compared to traditional machine learning as there is no need to train machine learning models and related activities such as data labeling, feature engineering, and model tuningâ€”making it easier for teams to get immediate insights.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Analyze the sentiment of the reviews in the  customer feedback data.\n",
    "obj.analyze_sentiment(column=\"customer_feedback\",data=advisor_customer_interactions, accumulate=\"customer_feedback\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto;\">\n",
    "  <img src=\"./images/sentiment_analysis.png\" alt=\"Sentiment Analysis Chart\" style=\"float: right; margin-left: 20px; width: 550px; border:4px solid #404040; border-radius: 10px; margin-top: 20px;\">\n",
    "\n",
    "  <p style=\"font-size:16px; font-family:Arial;padding-top:20px;\">\n",
    "    Beyond basic classification, sentiment analysis can be extended to support deeper business use casesâ€”for example, tracking product complaints over time by monitoring the frequency and trend of negative sentiment. This helps organizations identify areas for improvement, prioritize feature updates, and enhance customer satisfaction.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>7. Masking Personal Identifiable Information (PII) Entities</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "The `mask_pii()` function is used to mask Personal Identifiable Information (PII) entities within a given text. This can be particularly useful when you want to protect sensitive data in your text.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask PII (Personally Identifiable Information) in the employee data.\n",
    "obj.mask_pii(column=\"customer_question\",data=advisor_customer_interactions,accumulate='advisor_notes',volatile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style='font-size:20px; font-family:Arial;'><b>8. Generating Embeddings</b></p>\n",
    "<p style='font-size:16px; font-family:Arial;'>\n",
    "<div style=\"display: flex; align-items: center; gap: 30px; margin-top: 10px;\">\n",
    "  <div style=\"flex: 1; font-size:16px; font-family:Arial;\">\n",
    "    <p>\n",
    "      The <code>embeddings()</code> function generates vector representations of text from a specified column, capturing the semantic meaning of each entry.\n",
    "    </p>\n",
    "    <p>\n",
    "      These embeddings can then be used for tasks such as semantic similarity, clustering, retrieval, or as input features for downstream machine learning models.\n",
    "    </p>\n",
    "  </div>\n",
    "\n",
    "  <img src=\"./images/clustering.png\" alt=\"Text Embedding Clustering\" style=\"width: 400px; max-width: 100%;border: 4px solid #404040; border-radius: 10px;\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the TeradataAI class with the Amazon Bedrock model.\n",
    "llm_embedding = TeradataAI(api_type=\"aws\",                      \n",
    "               model_name=\"amazon.titan-embed-text-v2:0\",\n",
    "               region=\"us-west-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the TextAnalyticsAI class with the embedding model.\n",
    "obj_embeddings = TextAnalyticsAI(llm=llm_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings\n",
    "obj_embeddings.embeddings(column=\"advisor_notes\",data=advisor_customer_interactions,accumulate=\"customer_id\",output_format='VARCHAR')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>9. Entity Recognition </b></p>\n",
    "<p style='font-size:16px; font-family:Arial;'>\n",
    "The <code>recognize_entities()</code> function is designed to identify a wide range of entities within text data. Examples of these entities can include:</p>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td style='font-size:16px; font-family:Arial;'>people</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>places</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>products</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>organizations</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>date/time</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>quantities</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>percentages</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>currencies</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>names</td>\n",
    "    </tr>\n",
    "</table>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recognize entities in the articles in the data.\n",
    "obj.recognize_entities(column=\"advisor_notes\",data=advisor_customer_interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>10. Recognizing Personal Information Identification (PII) Entities</b><p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "The <code>recognize_pii_entities()</code> function provided by TextAnalyticsAI is designed to identify Personal Identifiable Information (PII) entities within text data.  PII entities can include sensitive data like:</p>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td style='font-size:16px; font-family:Arial;'>names</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>addresses</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>social security numbers</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>email addresses</td>\n",
    "        <td style='font-size:16px; font-family:Arial;'>phone numbers</td>        \n",
    "    </tr>\n",
    "</table>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recognize PII entities in the advisor notes.\n",
    "obj.recognize_pii_entities(column=\"advisor_notes\", data=advisor_customer_interactions, accumulate='advisor_notes',volatile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>11. Text Classification </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this section, we'll explore the <code>classify()</code> function provided by TextAnalyticsAI. This function is used to classify the given text.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the advisor notes into multiple relevant financial and emotional categories.\n",
    "obj.classify(\n",
    "    column=\"advisor_notes\",\n",
    "    data=advisor_customer_interactions,\n",
    "    accumulate=\"advisor_notes\",\n",
    "    labels=[\n",
    "        \"Life Insurance\",\n",
    "        \"Estate Planning\",\n",
    "        \"Beneficiary Updates\",\n",
    "        \"Roth IRA\",\n",
    "        \"Student Loan Refinance\",\n",
    "        \"APR Discrepancy\",\n",
    "        \"Auto Loan Refinance\",\n",
    "        \"Credit Card Rewards\",\n",
    "        \"Cashback Dispute\",\n",
    "        \"Card Recommendations\",\n",
    "        \"Retirement Fund Performance\",\n",
    "        \"Investment Strategy\",\n",
    "        \"Portfolio Reallocation\",\n",
    "        \"401(k) Strategy\",\n",
    "        \"Managed Account Fees\",\n",
    "        \"Overdraft Fee\",\n",
    "        \"Account Management\",\n",
    "        \"Fee Waiver\",\n",
    "        \"Customer Complaint\",\n",
    "        \"Customer Escalation\"\n",
    "    ],\n",
    "    multi_label=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>12. Text Summarization</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The <code>Summarize()</code> function is used to generate a concise summary of a given text.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the articles in the employee data.\n",
    "obj.summarize(column=\"advisor_notes\",data=advisor_customer_interactions,accumulate='customer_id',volatile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>13. Key Phrase Extraction</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The <code>extract_key_phrases()</code> function provided by TextAnalyticsAI is used to extract key phrases from a given text. These key phrases can provide a quick understanding of the main concepts in the text.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract key phrases from advisor notes\n",
    "obj.extract_key_phrases(column=\"advisor_notes\",data=advisor_customer_interactions,volatile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>14. Language Translation </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "The <code>translate()</code> function provided by TextAnalyticsAI is used to translate the language of a given text.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate the text in the employee data to the default language English.\n",
    "obj.translate(column=\"advisor_notes\",data=advisor_customer_interactions,accumulate='advisor_notes',volatile=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>15. Language Detection </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The <code>detect_language()</code> function is used to identify the language of a given text.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect the language of the quotes in the employee data \n",
    "obj.detect_language(column=\"advisor_notes\",data=advisor_customer_interactions,volatile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>16. Asking the LLM </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The <code>ask()</code> function is used to ask questions to the LLM based on the given context.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asking questions to the LLM using context data.\n",
    "# data_partition_column: 'id' and context_partition_column: 'id' are used to partition the data and context tables.\n",
    "# Prompt is used to provide a template for the question and data.\n",
    "obj.ask(column=\"customer_question\", data=advisor_customer_interactions,\n",
    "        context=advisor_customer_interactions, context_column='advisor_notes',\n",
    "        data_partition_column='customer_id', context_partition_column='customer_id',\n",
    "        prompt='''Provide an answer to the customer question using advisor notes as\n",
    "        information relevant to the question.\n",
    "        \\nQuestion: #QUESTION# \\n Data: #DATA#''',\n",
    "        data_position='#DATA#',\n",
    "        question_position='#QUESTION#')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>17.Text Analytics with Open-Source Hugging Face Language Models</b></p>\n",
    "<p style=\"font-size:16px; font-family:Arial\"> As youâ€™ve seen, hosted LLMs like Amazon Bedrockâ€™s Anthropic Claude require no fine-tuning to perform a wide range of NLP tasks. This is because these hosted LLMs are trained on massive, diverse datasets, enabling them to handle tasks such as entity recognition, sentiment analysis, PII masking and more right out of the box.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "While Amazon Bedrock offers the convenience, scalability, and simplicity of hosted models, many organizations also value the greater domain-specific accuracy, data privacy, control, and customization that open-source models provide.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "A <a href=\"https://arxiv.org/pdf/2203.15556\"> recent study from DeepMind </a> shows that smaller, task-specific modelsâ€”when fine-tuned on domain-specific dataâ€”can outperform larger general-purpose models in targeted applications. This makes open-source models an attractive option for organizations wanting greater accuracy, enhanced privacy, and cost-efficiency in specific use cases. However, this approach does require additional expertise and effort to fine-tune and manage these models effectively.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "In the next sections, weâ€™ll explore how <code>teradatagenai</code> enables seamless integration with Hugging Face models using BYO-LLM capabilities in VantageCloudâ€”allowing you to deploy compact, specialized models directly where your data lives with GPU acceleration.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style=\"font-size:20px;font-family:Arial\"><b>18. Authenticate and Prepare the OAF Environment.</b></p>\n",
    "<p style=\"font-size:16px; font-family:Arial;\">\n",
    "The <code>teradataml</code> library offers simple yet powerful methods for creating and managing custom Python runtime environments within VantageCloud. This gives developers full control over model behavior, performance, and analytic accuracy when running on the Analytic Cluster.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial;\">\n",
    "Custom environments are persistentâ€”created once and reused as needed. They can be saved, updated, or modified at any time, allowing for efficient and flexible environment management.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial;\">\n",
    "<table style=\"width:100%; table-layout:fixed;\">\n",
    "  <tr>\n",
    "    <td style=\"vertical-align:top;\" width=\"40%\">\n",
    "      <ol style=\"font-size:16px; font-family:Arial;\">\n",
    "        <li>Create a unique User Environment based on available base images</li>\n",
    "        <li>Install libraries</li>\n",
    "        <li>Install models and additional user artifacts</li>\n",
    "      </ol>\n",
    "    </td>\n",
    "    <td>\n",
    "      <img src=\"./images/OAF_Env.png\" width=\"600\" alt=\"Container Management Diagram\" style=\"border:4px solid #404040; border-radius: 10px;\">\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "<p style=\"font-size:18px;font-family:Arial\"><b>18.1 UES Authentication</b></p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">This security mechanism is required to create and manage the Python or R environments that we will be creating.  A VantageCloud Lake user can easily create the authentication objects using the Console in a VantageCloud Lake environment.  For this use case, the authentication objects has already been created and copied into this JupyterLab environment for you.\n",
    "</p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "   \n",
    "<ul style=\"font-size:16px;font-family:Arial; margin-top:4px;\">\n",
    "  <li><a href=\"https://docs.teradata.com/r/Teradata-VantageCloud-Lake/Analyzing-Your-Data/Teradata-Package-for-Python-on-VantageCloud-Lake/Working-with-Open-Analytics/APIs-to-Use-with-Open-Analytics-Framework/API-to-Set-Authentication-Token/set_auth_token\">Click here</a> to see more details about using the Teradata APIs to set the authentication objects.</li>\n",
    "\n",
    "  <li>Check out <a href=\"https://medium.com/teradata/deploy-hugging-face-llms-on-teradata-vantagecloud-lake-with-nvidia-gpu-acceleration-d94d999edaa5\">Step 4</a> of this tutorial on Medium.com to to see more details about configuring a VantageCloud Lake Environment to use our Open Analytics Framework</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've already loaded all the values into our environment variables and into a dictionary, env_vars.\n",
    "# username=env_vars.get(\"username\") isn't required when using base_url, pat and pem.\n",
    "\n",
    "if set_auth_token(base_url=env_vars.get(\"ues_uri\"),\n",
    "                  pat_token=env_vars.get(\"access_token\"), \n",
    "                  pem_file=env_vars.get(\"pem_file\"),\n",
    "                  valid_from=int(time.time())\n",
    "                 ):\n",
    "    print(\"UES Authentication successful\")\n",
    "else:\n",
    "    print(\"UES Authentication failed. Check credentials.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px;font-family:Arial\"><b>18.2 Check for an existing OAF environment or Create a new one</b></p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">It's ok to reuse the same OAF environment. Our VantageCloud Lake OAF Use cases and demos will use a default naming convention for the environment names. If you haven't already created one, we'll create it now.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if we have any existing environments\n",
    "# If any other environments exist along with our default OAF environment, we will delete them\n",
    "\n",
    "environment_name = env_vars.get(\"username\")\n",
    "print(\"Here is a list of the versions of the libraries available to be used within an OAF environments.\\n\")\n",
    "print(list_base_envs())\n",
    "env_list = list_user_envs()\n",
    "\n",
    "if env_list is None:\n",
    "    print(\"This user does not have any environments.\\nCreating your environment now.\")\n",
    "    demo_env = create_env(env_name=f'{environment_name}', base_env='python_3.10', desc='BYOLLM demo env')\n",
    "    print(demo_env)\n",
    "else:\n",
    "    print(\"\\nHere is a list of your current environments:\")\n",
    "    ipydisplay(env_list)\n",
    "    for env_name in env_list['env_name']:\n",
    "        if env_name == environment_name:\n",
    "            demo_env = get_env(environment_name)\n",
    "            print(\"Your default environment already exists. You can continue with this notebook.\\n\\n\")\n",
    "        else:\n",
    "            print(f\"Your existing environment, {env_name} doesn't match our default environment for this user.\")\n",
    "            print(\"We're going to delete it.\")      \n",
    "            print(f\"Please wait: Environment {env_name} is being removed!\")\n",
    "            remove_env(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">  \n",
    "TeradataAI handles the download and installation of the Hugging Face model (example: <i>'tner/roberta-large-ontonotes5</i>) in the user's environment. If an environment name is not specified, a default name <i>'td_gen_ai_env'</i> will be used. The TeradataAI class will manage the entire creation and setup process. In the background, this process utilizes Teradataâ€™s <code>Bring Your Own Large Language Model (BYO LLM)</code> offering.</p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">For this use case, we're going to check if the OAF Container already exist.  If it doesn't, we will create it to show the process of using the <code>tner/roberta-large-ontonotes5</code> model with the <code>teradatagenai</code> package. </p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">  \n",
    "Define the Hugging Face model and initialize the TeradataAI Class </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the LLM endpoint and initializing TeradataAI and TextAnalyticsAI\n",
    "ues_args = {'env_name': environment_name}\n",
    "model_name = 'tner/roberta-large-ontonotes5'\n",
    "model_args = {'transformer_class': 'AutoModelForTokenClassification',\n",
    "              'task' : 'token-classification'}\n",
    "llm = TeradataAI(api_type = \"hugging_face\",\n",
    "                 model_name = model_name,\n",
    "                 model_args = model_args,\n",
    "                 ues_args = ues_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<p style=\"font-size:16px;font-family:Arial\"><code>TeradataAI</code> will use an existing OAF environment if the name is specified or it will creating a new OAF Environment. If a name is not specified, it will use a default environment name. If it needs to create a new OAF environment, it will also install a set of libraries.  When the library installations are finished, it will begin downloading and installing the model.  If your Kernel status is showing <b>Idle</b>, please wait until you see that the \"Completed\" message directly above this cell. This could take several minutes.</p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">We know that the <code>transformers</code> and <code>torch</code> libraries are required for our final API call. This cell will install those and provide a claim_id that can be used for doing things like checking the status of the installation.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lib_claim_id = pd.DataFrame()\n",
    "lib_claim_id = demo_env.install_lib([\"transformers\",\"torch\"])\n",
    "print(\"Libraries Installed\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">Now we'll set the user's database session to use the required compute cluster .</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_compute_group = env_vars.get(\"gpu_compute_group\")\n",
    "execute_sql(f\"SET SESSION COMPUTE GROUP {gpu_compute_group};\")\n",
    "print(f\"Compute group set to {gpu_compute_group}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:18px;font-family:Arial\"><b>18.3 Create the TextAnalyticsAI object</b></p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">Now we can execute the portion of this demo that will run in our GPU Analytics Cluster.  We'll provide the TextAnalyticsAI object with the preferred large language model. This will enable us to execute a variety of text analytics tasks.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = TextAnalyticsAI(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj.recognize_entities(column='advisor_notes', data=advisor_customer_interactions, delimiter=\"#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none'>\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>19. Cleanup</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>19.1 Delete your OAF Container</b></p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">Executing this cell is optional. If you will be executing more OAF use cases, you can leave your OAF environment.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove your default user environment\n",
    "\n",
    "try:\n",
    "    result = remove_env(environment_name)\n",
    "    print(\"Environment removed!\")\n",
    "except Exception as e:\n",
    "    print(\"Could not remove the environment!\")\n",
    "    print(\"Error:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>19.2 Remove your database Context</b></p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">Please remove your context after you've completed this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    result = remove_context()\n",
    "    print(\"Context removed!\")\n",
    "except Exception as e:\n",
    "    print(\"Could not remove the Context!\")\n",
    "    print(\"Error:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none'>\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>View the full TeradataAI Help</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "help(TeradataAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(TextAnalyticsAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; border-bottom:3px solid #91A0Ab\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analyticsâ„¢</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:35px\">\n",
    "            Copyright Â© Teradata Corporation - 2025. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
