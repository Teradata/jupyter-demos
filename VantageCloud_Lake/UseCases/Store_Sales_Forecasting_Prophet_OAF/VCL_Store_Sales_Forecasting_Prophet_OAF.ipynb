{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<header>\n",
    "     <p  style='font-size:36px;font-family:Arial;color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Store Sales Forecasting with Prophet using Script Table Operator\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>Introduction</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied.</p>\n",
    "<br>  \n",
    "<p style = 'font-size:16px;font-family:Arial'>Our Main Objective is to predict sales of store in a week. We are using the python Prophet model and using the <b><u>O</u></b>pen <b><u>A</u></b>nalytics <b><u>F</u></b>ramework<b>(OAF)</b> of VantageCloud Lake for forecasting the Store Sales.</p>\n",
    "<img src=\"./images/OAF_flow.png\" width=\"800\" align=\"center\" style=\"padding: 40px\">    \n",
    "<p style = 'font-size:16px;font-family:Arial'>The Open Analytics Framework builds on the existing Vantage facilities for data scientists and analysts to do the following:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Score multiple models concurrently in parallel with minimal effort.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Train single or multiple micro models based on data stored in Vantage.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Enable scripting and the use of open source resources to experiment and iterate with analytics, machine learning (ML), and artificial intelligence (AI) use cases.</li></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>APPLY table operator is the VantageCloud Lake successor to the Vantage Enterprise SCRIPT and ExecR table operators. The APPLY table operator bears more similarities to the SCRIPT operating mode, in that APPLY takes an external language script as input to run, rather than ingesting external language statements in a contract function as ExecR does. The APPLY table operator is nevertheless designed to expand its features in the future in a way that encompasses additional key features from both the SCRIPT and ExecR table operators. The fastpath APPLY table operator runs a user-installed script or any Linux command inside the remote user environment using Open Analytics Framework. Installed script runs in parallel with data from Analytics Database.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>An overview of the steps for using the Open Analytics Framework follow.</p>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Connect to your target VantageCloud Lake system.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Assume you use the Vantage Python client library, teradataml, as the software tool to connect.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Upon connecting, create a user environment with the desired configuration of interpreter and libraries using Open Analytics Framework APIs.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Upload the language script, model, and any other relevant files to your target user environment.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Run the script by invoking the APPLY table operator inside the Analytics Database in your system.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Run the corresponding APPLY table operator query in the primary cluster to retrieve data, then send the data to a compute cluster to run with your language script in your user environment.</li></p>\n",
    "<p></p>    \n",
    "<br>  \n",
    "<img src=\"./images/OAF_Steps.png\" width=\"800\" align=\"center\" style=\"padding: 40px\">\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Hence as a data science consultant, we are showcasing the complete approach about how we can make prediction of sales for different stores in advance. We are demonstrating how we can train our models and use them for scoring using the ClearScape Analytics platform. The data we are using is a sample dataset and the results and predictions may not be entirely accurate.\n",
    "</p>\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>Data</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The dataset contains historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set. Note that some stores in the dataset were temporarily closed for refurbishment.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Most of the fields are self-explanatory. The following are descriptions for those that aren't.</p>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial'>Store - a unique Id for each store</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Sales - the turnover for any given day (this is what you are predicting)</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Customers - the number of customers on a given day</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Open - an indicator for whether the store was open: 0 = closed, 1 = open</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>StateHoliday - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>SchoolHoliday - indicates if the (Store, Date) was affected by the closure of public schools</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>StoreType - differentiates between 4 different store models: a, b, c, d</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Assortment - describes an assortment level: a = basic, b = extra, c = extended</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>CompetitionDistance - distance in meters to the nearest competitor store</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>CompetitionOpenSince[Month/Year] - gives the approximate year and month of the time the nearest competitor was opened</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Promo - indicates whether a store is running a promo on that day</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Promo2 - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Promo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>PromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g., \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store.</li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>1. Connect to Vantage.</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install scikit-learn==1.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Note: </b><i>After installing the above libraries, Please restart the kernel. The simplest way is by typing zero zero: <b> 0 0</b></i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In the section, we import the required libraries and set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import getpass\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import os\n",
    "# from prophet import Prophet\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "import pickle\n",
    "import base64\n",
    "\n",
    "from teradataml import *\n",
    "\n",
    "# import utils for lake environment\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..', '..','config'))\n",
    "sys.path.append(module_path)\n",
    "from oaf_utils import *\n",
    "\n",
    "display.max_rows=5\n",
    "display.suppress_vantage_runtime_warnings = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>You will be prompted to provide the password. Enter your password, press the Enter key, then use down arrow to go to next cell. Begin running steps with Shift + Enter keys.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vars json\n",
    "with open('../../config/vars.json', 'r') as f:\n",
    "    session_vars = json.load(f)\n",
    "\n",
    "# Create the SQLAlchemy Context\n",
    "host = session_vars['environment']['host']\n",
    "username = session_vars['hierarchy']['users']['csae_user'][0]['username']\n",
    "password = getpass.getpass(prompt = '\\nEnter password: ')\n",
    "\n",
    "# UES Authentication information\n",
    "ues_url = session_vars['environment']['UES_URI']\n",
    "configure.ues_url = ues_url\n",
    "pat_token = session_vars['hierarchy']['users']['csae_user'][0]['token']\n",
    "pem_file = session_vars['hierarchy']['users']['csae_user'][0]['private_key_file']\n",
    "compute_group = session_vars['hierarchy']['users']['csae_user'][0]['compute_group']\n",
    "\n",
    "# check for existing connection\n",
    "eng = create_context(host=host, username=username, password=password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=VCL_Store_Sales_Forecasting_Prophet_OAF.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    " \n",
    "<p style = 'font-size:20px;font-family:Arial'><b>2. Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have provided data for this demo in the lake environment. The data is available in the database \"DEMO_AnomalyDetection\". Your user should have read access to the database. In case of any issues please write a mail to the support group (\"SC230208@teradata.com\").</p>\n",
    " \n",
    "<p style = 'font-size:16px;font-family:Arial'>**Note: The tables are available in DEMO_AnomalyDetection_DB database and we have created views in DEMO_AnomalyDetection database which are used in the cells below</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>3. Prepare data to do some basic Analysis of the Sales data.</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>We create dataframe for the Stores and the Sales Data using tables from Vantage. To gain insights into the data's characteristics, we display a sample of 5 rows each.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store=DataFrame(in_schema('DEMO_ProphetSTO','Store'))\n",
    "store  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The Store dataset contains description of the Stores like, StoreType, distance from the Competition Store and also various Promotion codes and Details.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales=DataFrame(in_schema('DEMO_ProphetSTO','Sales_Data'))\n",
    "sales  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The Store Sales dataset contains the Store, DayofWeek, Date of Sales , Sales done, Customer involved, SalesOpen is a flag mentioning if the Store is Open or Closed and Promotion Code applied for the Sales.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>4. Data Analysis and Transformation </b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial'>In this first section we go through the Sales and store data, handle missing values and create new features for further analysis.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We check the missing values for the CompetitionDistance column and replace it with the median values.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import SimpleImputeFit, SimpleImputeTransform\n",
    "fit_obj = SimpleImputeFit(data=store,\n",
    "                              stats_columns=\"CompetitionDistance\",\n",
    "                              stats=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj =  SimpleImputeTransform(data=store,\n",
    "                                 object=fit_obj.output)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store=obj.result\n",
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We join the Store and Sales dataset to get the required columns for our analysis.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_store = sales.merge(right = store, how = \"inner\", on = \"store=store\",lsuffix='l', rsuffix='r')\n",
    "sales_store=sales_store.assign(Store=sales_store.Store_l)\n",
    "sales_store=sales_store.drop(['Store_l', 'Store_r'], axis=1)\n",
    "sales_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_store.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The final dataset used for analysis contains 18 columns and 91,256 rows.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Based on the data available we do some transformations on the data and create various features. From the SalesDate we, generate columns like , Year, Month, DayOfWeek , WeekofYear etc. Using the columns related to Competition like CompetionOpenSinceYear and CompetitionOpenSinceMonth we calculate if the Competition Store is Open or not(CompetitionOpen). Similarly, we do the processing for Promotions and create a flag(PromoOpen)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_store = sales_store.assign(CompetitionOpenSinceYear = \n",
    "                                     case([(sales_store.CompetitionOpenSinceYear.isnull() == True, '0')], else_ = sales_store.CompetitionOpenSinceYear),\n",
    "                                CompetitionOpenSinceMonth = \n",
    "                                     case([(sales_store.CompetitionOpenSinceMonth.isnull() == True, '0')], else_ = sales_store.CompetitionOpenSinceMonth),\n",
    "                                Promo2SinceYear = \n",
    "                                     case([(sales_store.Promo2SinceYear.isnull() == True, '0')], else_ = sales_store.Promo2SinceYear),\n",
    "                                Promo2SinceWeek = \n",
    "                                     case([(sales_store.Promo2SinceWeek.isnull() == True, '0')], else_ = sales_store.Promo2SinceWeek)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_store = sales_store.assign(Year = sales_store.SalesDate.year(),\n",
    "                                 Month = sales_store.SalesDate.month(),\n",
    "                                 Day = sales_store.SalesDate.day_of_month(),\n",
    "                                 DayOfWeek = sales_store.SalesDate.day_of_week(),\n",
    "                                 WeekOfYear = sales_store.SalesDate.week_of_year())\n",
    "\n",
    "sales_store = sales_store.assign(CompetitionOpen = 12 * (sales_store.Year - sales_store.CompetitionOpenSinceYear)+\n",
    "                                                     (sales_store.Month - sales_store.CompetitionOpenSinceMonth),\n",
    "                                PromoOpen = 12 * (sales_store.Year - sales_store.Promo2SinceYear)+\n",
    "                                                 (sales_store.WeekOfYear - sales_store.Promo2SinceWeek) / 4.0)\n",
    "\n",
    "\n",
    "sales_store = sales_store.assign(CompetitionOpen = case([(sales_store.CompetitionOpen > 0, sales_store.CompetitionOpen)], else_ = 0),\n",
    "                                PromoOpen = case([(sales_store.PromoOpen > 0, sales_store.PromoOpen)], else_ = 0))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_store = sales_store.assign(StoreType = case([(sales_store.StoreType == '0', 0),(sales_store.StoreType == 'a', 1),\n",
    "                                                  (sales_store.StoreType == 'b', 2),(sales_store.StoreType == 'c', 3),\n",
    "                                                  (sales_store.StoreType == 'd', 4)]),\n",
    "                                Assortment = case([(sales_store.Assortment == '0', 0),(sales_store.Assortment == 'a', 1),\n",
    "                                                  (sales_store.Assortment == 'b', 2),(sales_store.Assortment == 'c', 3),\n",
    "                                                  (sales_store.Assortment == 'd', 4)]),\n",
    "                                StateHoliday = case([(sales_store.StateHoliday == '0', 0),(sales_store.StateHoliday == 'a', 1),\n",
    "                                                  (sales_store.StateHoliday == 'b', 2),(sales_store.StateHoliday == 'c', 3),\n",
    "                                                  (sales_store.StateHoliday == 'd', 4)])\n",
    "                                \n",
    "                                )  \n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_store = sales_store.assign(monthStr = case([(sales_store.Month == 1, 'Jan'),(sales_store.Month == 2, 'Feb'),\n",
    "                                                  (sales_store.Month == 3, 'Mar'),(sales_store.Month == 4, 'Apr'),\n",
    "                                                  (sales_store.Month == 5, 'May'),(sales_store.Month == 6, 'Jun'),\n",
    "                                                  (sales_store.Month == 7, 'Jul'),(sales_store.Month == 8, 'Aug'),\n",
    "                                                  (sales_store.Month == 9, 'Sep'),(sales_store.Month == 10, 'Oct'),\n",
    "                                                  (sales_store.Month == 11,' Nov'),(sales_store.Month == 12, 'Dec')]),\n",
    "                                IsPromoMonth = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sales = sales_store.select(['Month','Sales']).groupby('Month').mean()\n",
    "plot =  plot_sales.plot(x=plot_sales.Month, y=plot_sales.mean_Sales,\n",
    "                           kind='bar', xlabel='Month', ylabel='Sales', color=\"orange\")\n",
    " \n",
    "# Display the plot.\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above graph shows the total sales across months for all stores. We can see that the sales are highest in December which is the Holiday Season.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Now we will see the same metrics across different Store types and also based on whether there was any Promotion available(Promo=1) or not (Promo=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Catplot month Vs Sales\n",
    "features_df = sales_store.to_pandas(all_rows=True)\n",
    "sns.catplot(data = features_df, x = 'Month', y = \"Sales\", \n",
    "               col = 'StoreType', # per store type in cols\n",
    "               palette = 'plasma',\n",
    "               # hue = 'StoreType',\n",
    "               row = 'Promo' # per promo in the store in rows\n",
    "               # color ='Year'\n",
    "           ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above graph shows the Sales per Month for each of the 4 StoreTypes(a,b,c,d) for all the 1,115 Stores. The Top row shows the sales for Promo=0 and the bottom row is for Promo=1. Each dot represents the sum of sales for a particular store in a month depending on the Store Type and Promo Code. We can see that there are peaks mainly during the Year end period.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>All store types follow the same trend but at different scales depending on the presence of the promotion `Promo` and `StoreType` except for the StoreType = b.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Next we try to get four stores from store types to represent their group:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial'> Store number 2 for `StoreType` A</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Store number 85 for `StoreType` B</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Store number 1 for `StoreType` C</li> \n",
    "<li style = 'font-size:16px;font-family:Arial'>Store number 15 for `StoreType` D</li>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>It also makes sense to down sample the data from days to weeks using the `resample` method to see the present trends more clearly.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = sales_store.select(['Store','SalesDate','Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_a = train_df[train_df.Store == 2].select(['SalesDate','Sales']).groupby('SalesDate').mean()\n",
    "sales_b = train_df[train_df.Store == 85].select(['SalesDate','Sales']).groupby('SalesDate').sum()\n",
    "# .sort_index(ascending = True) # solve the reverse order\n",
    "sales_c = train_df[train_df.Store == 1].select(['SalesDate','Sales']).groupby('SalesDate').sum()\n",
    "sales_d = train_df[train_df.Store == 15].select(['SalesDate','Sales']).groupby('SalesDate').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = subplots(nrows=4, ncols=1)\n",
    " \n",
    "plot = sales_a.plot(x=sales_a.SalesDate, y=sales_a.mean_Sales,\n",
    "                          ax=axes[0], figure=fig, kind=\"line\",xlabel='Sales Date', ylabel='Sales',\n",
    "                          title=\"Sales for Store 2\", color=\"blue\",figsize=(1200, 1600))\n",
    " \n",
    "plot = sales_b.plot(x=sales_b.SalesDate, y=sales_b.sum_Sales,\n",
    "                          ax=axes[1],figure=fig, kind=\"line\",xlabel='Sales Date', ylabel='Sales',\n",
    "                          title=\"Sales for Store 85\", color=\"blue\")\n",
    " \n",
    "plot = sales_c.plot(x=sales_c.SalesDate, y=sales_c.sum_Sales,\n",
    "                          ax=axes[2],figure=fig, kind=\"line\",xlabel='Sales Date', ylabel='Sales',\n",
    "                          title=\"Sales for Store 1\", color=\"blue\")\n",
    "\n",
    "plot = sales_d.plot(x=sales_d.SalesDate, y=sales_d.sum_Sales,\n",
    "                          ax=axes[3],figure=fig, kind=\"line\",xlabel='Sales Date', ylabel='Sales',\n",
    "                          title=\"Sales for Store 15\", color=\"blue\")\n",
    " \n",
    "# Display the plot.\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Retail sales for all store types tend to peak for the Christmas season and then decline after the holidays.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Next we check the Yearly trend for these Store Types thing to check the presence of a trend in series. Time series decomposition is the process of separating time series data into its core components. These components include a potential trend (overall rise or fall in the mean), seasonality (a recurring cycle), and the remaining random residual. Python’s statsmodels library has a method for time series decomposition called seasonal_decompose(). The model type parameter can either be additive or multiplicative, here we consider additive as If the seasonality’s amplitude is independent of the level then you should use the additive model. The \"period\" parameter is the number of observations in a seasonal cycle. For example, if you have daily observations, the period is 1. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting with 'date'\n",
    "pd_sales_store = features_df\n",
    "train_df = pd_sales_store.set_index('SalesDate')\n",
    "# Sales datacheck\n",
    "train_df['Sales'] = train_df['Sales'] * 1.0\n",
    "# storewise sales data\n",
    "sales_a = train_df[train_df.Store == 2]['Sales']\n",
    "sales_b = train_df[train_df.Store == 85]['Sales']\n",
    "# .sort_index(ascending = True) # solve the reverse order\n",
    "sales_c = train_df[train_df.Store == 1]['Sales']\n",
    "sales_d = train_df[train_df.Store == 15]['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal decompose\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(4, figsize = (15, 15))\n",
    "\n",
    "# monthly\n",
    "decomposition_a = seasonal_decompose(sales_a, model = 'additive', extrapolate_trend='freq', period=1)\n",
    "decomposition_a.trend.plot(ax = ax1)\n",
    "\n",
    "decomposition_b = seasonal_decompose(sales_b, model = 'additive', extrapolate_trend='freq', period=1)\n",
    "decomposition_b.trend.plot( ax = ax2)\n",
    "\n",
    "decomposition_c = seasonal_decompose(sales_c, model = 'additive', extrapolate_trend='freq', period=1)\n",
    "decomposition_c.trend.plot( ax = ax3)\n",
    "\n",
    "decomposition_d = seasonal_decompose(sales_d, model = 'additive', extrapolate_trend='freq', period=1)\n",
    "decomposition_d.trend.plot( ax = ax4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Overall sales follow similar Trend for all StoreTypes as seen above. There are spikes around the year end which indicate higher sales over the year end holiday season.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>5. Creating the model and forecasting using Prophet in python (stoSalesForecastnew.py).</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Prophet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Prophet follows the sklearn model API. We create an instance of the Prophet class and then call its fit and predict methods.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>All the below steps which include the Prophet model are executed in the python in the file <a href=\"./stoSalesForecastnew.py\">stoSalesForecastnew.py</a> file. We then use this py file in the Script command and get the forecasted values.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The input to Prophet is always a dataframe with two columns: ds and y. The ds (datestamp) column should be of a format expected by Pandas, ideally YYYY-MM-DD for a date or YYYY-MM-DD HH:MM:SS for a timestamp. The y column must be numeric and represents the measurement we wish to forecast.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The below code shows the creation of the Sales DataFrame and the holidays Dataframe which are used in the model creation and model fit.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>Create Sales data dataframe using data from Vantage</b></p>\n",
    "\n",
    "```python \n",
    "# create Sales data \n",
    "sales = pd_sales_store.rename(columns = {'SalesDate': 'ds','Sales': 'y'})\n",
    "```  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>Create holidays dataframe</b></p>\n",
    "\n",
    "```python\n",
    "#create holidays dataframe\n",
    "     \n",
    "\n",
    "school_dates = df[df.SchoolHoliday == 1].loc[:, 'Date'].values\n",
    "\n",
    "school = pd.DataFrame({'holiday': 'school_holiday',\n",
    "                      'ds': pd.to_datetime(school_dates)})\n",
    "\n",
    "holidays = school      \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We fit the model by instantiating a new Prophet object. Any settings to the forecasting procedure are passed into the constructor. Then you call its fit method and pass in the historical dataframe(sales).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>Instantiate and fit model using Prophet</b></p>\n",
    "\n",
    "```python\n",
    "\n",
    "# Prophet implementation \n",
    "my_model = Prophet(interval_width = 0.95, \n",
    "                   holidays = holidays.head(50000))\n",
    "my_model.fit(sales)                   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Predictions are then made on a dataframe with a column ds containing the dates for which a prediction is to be made. You can get a suitable dataframe that extends into the future a specified number of days using the helper method Prophet.make_future_dataframe. By default, it will also include the dates from the history, so we will see the model fit as well.<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>Create future dates for forecasting</b></p>\n",
    "\n",
    "```python\n",
    "dt = min(sales['ds'].values)\n",
    "date1 = datetime.datetime.strptime(dt, \"%y/%m/%d\").date()\n",
    "\n",
    "\n",
    "\n",
    "#  # Subtract one month\n",
    "start_date = date1 - relativedelta(months=1)\n",
    "\n",
    "# Get man date and then get future dates for 1 month\n",
    "dt1 = max(sales['ds'].values)\n",
    "date2 = datetime.datetime.strptime(dt1, \"%y/%m/%d\").date()\n",
    "# date2 = datetime.datetime.strptime(datetime_str, \"%Y/%m/%dT%H:%M:%S.%f\").date()\n",
    "end_date = date2 + relativedelta(months=1)\n",
    "# end_date= str(end_value)\n",
    "\n",
    "\n",
    "# # date_range = pd.date_range(start_date, periods=num_days)\n",
    "date_range = pd.date_range(str(start_date), str(end_date))\n",
    "\n",
    "future_dates = pd.DataFrame({'ds': date_range})               \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The predict method will assign each row in future a predicted value which it names yhat. If you pass in historical dates, it will provide an in-sample fit. The forecast object here is a new dataframe that includes the \"yhat\" column, which is the forecast values for sales, as well as columns for components and uncertainty intervals.<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>Create dataframe with forecast values</b></p>\n",
    "\n",
    "```python\n",
    "# forecast\n",
    "forecast = my_model.predict(future_dates.head(10000))               \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The forecasted values will be sent back to Vantage using the Returns clause of the Script function as seen in the section below.<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>6. Using APPLY Command to get the forecasted values back to Vantage.</b></p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>6.1 Create virtual environment for executing the script</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Function to set the Authentication token to connect to User Environment Service in VantageCloud Lake.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set configuration parameters for VantageCloud Lake authentication.\n",
    "set_auth_token(pat_token=pat_token,  username=username, ues_url=ues_url, pem_file=os.path.join(module_path, pem_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Set the session to use the Analytic compute group and cluster to execute the OpenSourceML function.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_sql(f\"SET SESSION COMPUTE GROUP {compute_group};\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Check the status of the cluster. If not active, we will wait for the cluster to start.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check cluster status\n",
    "check_cluster_start(compute_group=compute_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Check the user environments and create an environment for the usecase.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_user_envs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    env = create_env(\n",
    "            env_name=\"oaf_demo_env\",\n",
    "            base_env=\"python_3.9\",\n",
    "            desc=\"OAF Demo env for SalesForecasting Prophet\"\n",
    "        )\n",
    "except:\n",
    "    remove_env(\"oaf_demo_env\")\n",
    "    env = create_env(\n",
    "            env_name=\"oaf_demo_env\",\n",
    "            base_env=\"python_3.9\",\n",
    "            desc=\"OAF Demo env for SalesForecasting Prophet\"\n",
    "        )\n",
    "    \n",
    "env    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Confirm that the versions in the local environment are same to the virtual environment.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep scikit-learn\n",
    "!pip list | grep scipy\n",
    "!pip list | grep numpy\n",
    "!pip list | grep pandas\n",
    "!pip list | grep prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_id = env.install_lib([\"pandas==2.1.3\",\n",
    "                \"scipy==1.11.2\",\n",
    "                \"scikit-learn==1.1.3\",\n",
    "                \"numpy==1.24.2\",\n",
    "                \"sklearn-pandas==2.2.0\",            \n",
    "                \"prophet==1.1.4\"], asynchronous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status of installation using status() API.\n",
    "# Create a loop here for demo purposes\n",
    "\n",
    "ipydisplay(env.status(claim_id))\n",
    "stage = env.status(claim_id)['Stage'].iloc[-1]\n",
    "while stage == 'Started':\n",
    "    stage = env.status(claim_id)['Stage'].iloc[-1]\n",
    "    clear_output()\n",
    "    ipydisplay(env.status(claim_id))\n",
    "    sleep(5)\n",
    "    \n",
    "# Verify the Python libraries have been installed correctly.\n",
    "ipydisplay(env.libs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Set the user environment to the created virtual environment for the execution of the python script.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configure.openml_user_env = env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>6.2 Install the file and any additional artifacts</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Use the install_file() method to install this python file to the container. As a reminder, this container is persistent, so these steps need only be done infrequently.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.install_file(\"stoSalesForecastnew.py\", replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>6.3 APPLY using Python</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The process is as follows</p>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial'>Construct a dictionary that will define the return columns and data types</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Construct a teradataml DataFrame representing the data to be processed - note this is a \"virtual\" object representing data and logic in-database</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Execute the module function. This constructs the function call in the database, but does not execute anything. Note the Apply function takes several arguments - the input data, environment name, and the command to run</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>In order to execute the function, an \"execute_script()\" method must be called. This method returns the server-side DataFrame representing the complete operation. This DataFrame can be used in further processing, stored as a table, etc.</li>\n",
    "</p>\n",
    "\n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial'>First we will create a dataset which can be passed to the Apply function.</p>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry='''CREATE SET TABLE Store_Sales_ID \n",
    "     (\n",
    "      SlsID INTEGER,\n",
    "      Store INTEGER,\n",
    "      DayOfWeek INTEGER,\n",
    "      SalesDate DATE FORMAT 'yyyy/mm/dd',\n",
    "      Sales INTEGER,\n",
    "      Customers INTEGER,\n",
    "      SalesOpen INTEGER,\n",
    "      Promo INTEGER,\n",
    "      StateHoliday CHAR(1) CHARACTER SET LATIN NOT CASESPECIFIC,\n",
    "      SchoolHoliday INTEGER)\n",
    "      PRIMARY INDEX ( SlsID ); '''\n",
    "qry1='''insert into Store_Sales_ID select 1,  Store ,\n",
    "      DayOfWeek ,\n",
    "      SalesDate ,\n",
    "      Sales ,\n",
    "      Customers ,\n",
    "      SalesOpen ,\n",
    "      Promo ,\n",
    "      StateHoliday,\n",
    "      SchoolHoliday  from DEMO_prophetSTO.Sales_Data where Store <= 5;'''\n",
    "try:\n",
    "    execute_sql(qry)\n",
    "    execute_sql(qry1) \n",
    "except:\n",
    "    db_drop_table('Store_Sales_ID')\n",
    "    execute_sql(qry)\n",
    "    execute_sql(qry1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table_df2 = DataFrame('Store_Sales_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Install the user script file on Vantage. In case of rerun if the file already exists we first remove it and then install again.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return types\n",
    "types_dict = OrderedDict({})\n",
    "types_dict[\"ds\"] = VARCHAR(100)\n",
    "types_dict[\"yhat\"] =  VARCHAR(100)\n",
    "types_dict[\"yhat_lower\"] = VARCHAR(100)\n",
    "types_dict[\"yhat_upper\"] =  VARCHAR(100)\n",
    "types_dict[\"trend\"] =  VARCHAR(100)\n",
    "types_dict[\"trend_lower\"] =  VARCHAR(100)\n",
    "types_dict[\"trend_upper\"] =  VARCHAR(100)\n",
    "\n",
    "# \"ds\":TIMESTAMP(0), \"yhat\": FLOAT(), \"yhat_lower\": FLOAT(), \"yhat_upper\": FLOAT() , \n",
    "#                                   \"trend\": FLOAT(), \"weekly\": FLOAT(), \"yearly\": FLOAT()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.install_file(\"stoSalesForecastnew.py\", replace=True)\n",
    "apply_obj = Apply(\n",
    "    data=final_table_df2,\n",
    "    apply_command=\"python stoSalesForecastnew.py\",\n",
    "    # returns={\"ds\": VARCHAR(100)},\n",
    "    returns=types_dict,\n",
    "    env_name=env,\n",
    "    delimiter=\"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Execute the script in SQL using APPLY command with the following SQL code:</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Since the entire process of model training , fitting and scoring takes place in the .py file when used in the script command the below query make take some time approximately 50-60 seconds.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_forecast_df = apply_obj.execute_script()\n",
    "sales_forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_forecast_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The output contains 5005 rows(1 for each date) and 7 columns.\n",
    "<p style = 'font-size:16px;font-family:Arial'>The forecasting output contains information for:\n",
    "</p>\n",
    "<li style = 'font-size:16px;font-family:Arial'>The forecasted value (yhat)</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Range for the forecasted values (yhat_lower and yhat_upper)</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>The overall trend for a given date (also incorporates seasonality)</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Additive terms to adjust the trend to get the forecasted value</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>To plot the forecast Values we select only the required columns and convert the teradataml dataframe to pandas dataframe.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_output = sales_forecast_df.to_pandas(all_rows=True).reset_index()\n",
    "plot_output[\"ds\"] = pd.to_datetime(plot_output['ds']).dt.date\n",
    "plot_output[\"yhat\"] = pd.to_numeric(plot_output['yhat'])\n",
    "plot_output[\"yhat_lower\"] = pd.to_numeric(plot_output['yhat_lower'])\n",
    "plot_output[\"yhat_upper\"] = pd.to_numeric(plot_output['yhat_upper'])\n",
    "plot_output[\"trend\"] = pd.to_numeric(plot_output['trend'])\n",
    "plot_output[\"trend_lower\"] = pd.to_numeric(plot_output['trend_lower'])\n",
    "plot_output[\"trend_upper\"] = pd.to_numeric(plot_output['trend_upper'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_output_forecast = plot_output[['ds','yhat','yhat_lower','yhat_upper']].sort_values('ds', ascending=True)\n",
    "# .tail(300)\n",
    "plot_output_forecast = plot_output_forecast.reset_index()\n",
    "plot_output_forecast.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>To plot the forecast Values and the confidence level we set the lower and upper bounds of the confidence interval to yhat_lower and yhat_upper.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Create the data for the line graph, including the x-values and the corresponding upper and lower bounds\n",
    "x_values = plot_output_forecast['ds'].values\n",
    "y_values = plot_output_forecast['yhat'].values\n",
    "lower_bounds = plot_output_forecast['yhat_lower'].values\n",
    "upper_bounds = plot_output_forecast['yhat_upper'].values\n",
    "\n",
    " \n",
    "plt.figure(figsize=(12, 8))\n",
    "# Plot the line graph\n",
    "plt.plot(x_values, y_values, color='black', label='Forecast Values')\n",
    "plt.fill_between(x_values, lower_bounds, upper_bounds, color='lightblue', alpha=0.3, label='Confidence Interval')\n",
    "\n",
    " \n",
    "\n",
    "# Customize the plot\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Forecast Values')\n",
    "plt.title('Forecast Sales Values with Confidence Interval')\n",
    "plt.legend()\n",
    "\n",
    " \n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above graph contains the Forecast values(black line) and the light blue area is the range of the lower(yhat_lower) and upper(yhat_upper) limits of the forecasted values.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>7. Conclusion:</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have trained and validated the Prophet model using the python script and used the APPLY Operator using OAF and data from Vantage. We get the forecasted data in Vantage using the python script.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>8. Cleanup</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Work Tables</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_drop_table(table_name='Store_Sales_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_env(\"oaf_demo_env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>If you have updated the teradataml package, reinstall the package by uncommenting and running the below code cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# !pip install teradataml==17.20.0.6 --force-reinstall\n",
    "!pip install scikit-learn==1.0.2 --force-reinstall\n",
    "!pip install numpy==1.24.2 --force-reinstall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2023, 2024, 2025. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
