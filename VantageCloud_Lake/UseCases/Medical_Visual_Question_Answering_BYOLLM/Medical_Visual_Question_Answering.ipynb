{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ce3dd8a-f3e5-40d5-ab4c-d40cc358cf7f",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Answering Medical Questions about Images using VantageCloud and Open-Source Language Models\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57054f7e-befe-4029-b4ac-b82019240b1f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;'><b>Introduction:</b></p>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>In this comprehensive user demo, we will delve into the world of Medical Visual Question Answering using <b>Teradata Vantage</b> and <b>open-source language models</b>. This cutting-edge technology empowers businesses to uncover hidden insights from vast amounts of consumer complaints data, enabling them to identify trends, improve customer satisfaction, and enhance their overall brand reputation.</p> \n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial;\"><b>Key Features:</b></p>\n",
    "\n",
    "<ol style=\"font-size:16px;font-family:Arial;\">\n",
    "<li><b>Improved Clinical Decision Support:</b> A well-trained medical VQA model enhances clinical decision-making by allowing healthcare providers to ask questions about medical images (e.g., X-rays, MRIs, CT scans) and receive accurate, rapid answers. This can lead to faster diagnoses and treatment plans.</li>\n",
    "\n",
    "<li><b>Reducing Interpretation Errors:</b> Human interpretation of medical images can be subjective and prone to errors. A VQA model can provide objective, consistent, and evidence-based interpretations, helping to reduce diagnostic inaccuracies.</li>\n",
    "\n",
    "<li><b>Time Efficiency:</b> The model's ability to quickly analyze images and answer questions can save valuable time for healthcare professionals, leading to more efficient patient care.</li>\n",
    "\n",
    "<li><b>Accessibility:</b> Patients and non-specialist healthcare providers can benefit from a medical VQA system by obtaining easy-to-understand information about their health conditions, potentially improving health literacy.</li>\n",
    "\n",
    "<li><b>Learning and Training Aid:</b> Medical VQA models can serve as educational tools for medical students, residents, and even experienced practitioners. They can be used to explain complex medical concepts and imaging findings.</li>\n",
    "\n",
    "<li><b>Research Assistance:</b> Researchers can leverage the model to analyze large datasets of medical images more effectively. It can assist in extracting meaningful insights from these datasets, potentially leading to new discoveries in medical science.</li>\n",
    "\n",
    "<li><b>Cross-Specialty Applicability:</b> A well-designed medical VQA model can be adapted to various medical specialties, from radiology and pathology to cardiology and dermatology. This versatility makes it a valuable asset across different healthcare domains.</li>\n",
    "\n",
    "<li><b>Ethical Considerations:</b> It's essential to address ethical concerns related to privacy, security, and bias when deploying medical VQA models in healthcare settings. Ensuring patient data protection and model fairness is critical.</li>\n",
    "\n",
    "<li><b>Continuous Improvement:</b> Model performance and accuracy should be continuously monitored and improved over time. Regular updates and retraining are necessary to keep up with evolving medical knowledge and technologies.</li>\n",
    "\n",
    "<li><b>Collaboration:</b> Successful implementation of medical VQA models often requires collaboration between machine learning experts, healthcare professionals, and ethicists to ensure that the technology is used responsibly and effectively.</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6863ef",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'><b>Visual Question Answering:</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'><b>What is visual Question Answering?</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Visual Question Answering (VQA) is a task in computer vision that involves answering questions about an image. The goal of VQA is to teach machines to understand the content of an image and answer questions about it in natural language.</p>\n",
    "\n",
    "<center><img id=\"125\" src=\"./images/header_scene.png\" height=\"400px\" width=\"600px\" style=\"border: 4px solid #404040; border-radius: 10px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7068302",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'><b>Steps in the analysis:</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;'>\n",
    "     <li>Configuring the environment</li>\n",
    "  <li>Connect to Vantage</li>\n",
    "  <li>Create a Custom Container in Vantage</li>\n",
    "  <li>Install Dependencies</li>\n",
    "  <li>Operationalizing AI-powered analytics</li>\n",
    "  <li>Topic Modelling</li>\n",
    "  <li>Cleanup</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e457db5-d4df-4e7f-a11a-fcb1416e462d",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;'>\n",
    "<b style = 'font-size:20px;font-family:Arial;'>1. Configuring the Environment</b>\n",
    "\n",
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>1.1 Install the required libraries</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eb4587-6632-4b08-a121-c98ea5a8fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "!pip install ./teradataml-20.0.0.8-py3-none-any.whl\n",
    "# teradatagenai went from 20.0.0.2 to 20.0.0.3\n",
    "!pip install --upgrade teradatagenai\n",
    "!pip install ipywidgets==8.1.7\n",
    "!pip install --upgrade sentence-transformers\n",
    "!pip install hf-xet==1.1.11b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bca175a-80bf-4d7f-ab9e-79403af74745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install teradataml==20.0.0.7 teradatamlwidgets==20.0.0.6 teradatamodelops==7.0.3 teradatasql==20.0.0.34 teradatasqlalchemy==20.0.0.7 sentencepiece sentence-transformers wordcloud --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fd81e4-0df9-4360-b3ac-72214f135296",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;'><b>Note: </b><i>Please restart the kernel after executing a </i><code>!pip install</code>. <i>The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i> and then clicking <b><i>Restart</i></b>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc278740-1511-4423-bf2b-92a5109a47bf",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>1.2 Import the required libraries</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f183178-9807-4538-b794-922820346ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Python version 3.11 for user environment\n"
     ]
    }
   ],
   "source": [
    "from teradataml import *\n",
    "display.enable_ui = False\n",
    "\n",
    "from teradatasqlalchemy.types import *\n",
    "from time import sleep\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv, sys, os, warnings\n",
    "from os.path import expanduser\n",
    "from collections import OrderedDict\n",
    "from IPython.display import clear_output , display as ipydisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import shutil\n",
    "\n",
    "# from itables import init_notebook_mode\n",
    "# import itables.options as opt\n",
    "from dotenv import load_dotenv\n",
    "# Set display options for dataframes, plots, and warnings\n",
    "\n",
    "# import utils for lake environment\n",
    "import os\n",
    "import sys\n",
    "# module_path = os.path.abspath(os.path.join('..', '..','config'))\n",
    "# sys.path.append(module_path)\n",
    "\n",
    "# opt.style=\"table-layout:auto;width:auto;float:left\"\n",
    "# opt.columnDefs = [{\"className\": \"dt-left\", \"targets\": \"_all\"}]\n",
    "# init_notebook_mode(all_interactive=True)\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "display.suppress_vantage_runtime_warnings = True\n",
    "\n",
    "python_version = \"3.11\"\n",
    "print(f'Using Python version {python_version} for user environment')\n",
    "\n",
    "# Hugging Face model for the demo\n",
    "model_names = {'ChetanHirapara/Salesforce-blip-vqa-base-medical-data'}\n",
    "\n",
    "# a list of required packages to install in the custom OAF container\n",
    "# modify this if using different models or design patterns\n",
    "pkgs = ['transformers',\n",
    "        'torch',\n",
    "        'pandas',\n",
    "        'sentence-transformers']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a37ff6-db2d-4c3a-90e6-9d1bceae9c60",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>2. Connect to VantageCloud Lake</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Connect to VantageCloud using <code>create_context</code> from the teradataml Python library. If this environment has been prepared for connecting to a VantageCloud Lake OAF Container, all the details required will be loaded and you will see an acknowledgement after executing this cell.</p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>2.1 Load the Environment Variables and Connect to Vantage</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Load the environment variables from a .env file and use them to create a connection context to Teradata.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e63f0143-bad0-45ff-a287-22557bdd2b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if this environment is ready to connect to VantageCloud Lake...\n",
      "Your environment parameter file exist.  Please proceed with this use case.\n",
      "Connected to VantageCloud Lake with: Engine(teradatasql://dallasprod24-jn6hvh5icpnu97gw:***@54.156.178.22)\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking if this environment is ready to connect to VantageCloud Lake...\")\n",
    "\n",
    "if os.path.exists(\"/home/jovyan/JupyterLabRoot/VantageCloud_Lake/.config/.env\"):\n",
    "    print(\"Your environment parameter file exist.  Please proceed with this use case.\")\n",
    "    # Load all the variables from the .env file into a dictionary\n",
    "    env_vars = dotenv_values(\"/home/jovyan/JupyterLabRoot/VantageCloud_Lake/.config/.env\")\n",
    "    # Create the Context\n",
    "    eng = create_context(host=env_vars.get(\"host\"), username=env_vars.get(\"username\"), password=env_vars.get(\"my_variable\"))\n",
    "    execute_sql('''SET query_band='DEMO=Medical_Visual_Question_Answering.ipynb;' UPDATE FOR SESSION;''')\n",
    "    print(\"Connected to VantageCloud Lake with:\", eng)\n",
    "else:\n",
    "    print(\"Your environment has not been prepared for connecting to VantageCloud Lake.\")\n",
    "    print(\"Please contact the support team.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec98ec10-e1cc-43e7-b06d-fd06c5d89081",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>2.2  Authenticate to the User Environment Service</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>To better support integration with Cloud Services and common automation tools; the <b > User Environment Service</b> is accessed via RESTful APIs.  These APIs can be called directly or in the examples shown below that leverage the Python Package for Teradata (teradataml) methods.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43a607a2-d902-4285-a006-5d4ec5b7bc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication token is generated, authenticated and set for the session.\n",
      "UES Authentication successful\n"
     ]
    }
   ],
   "source": [
    "# We've already loaded all the values into our environment variables and into a dictionary, env_vars.\n",
    "# username=env_vars.get(\"username\") isn't required when using base_url, pat and pem.\n",
    "\n",
    "if set_auth_token(base_url=env_vars.get(\"ues_uri\"),\n",
    "                  pat_token=env_vars.get(\"access_token\"), \n",
    "                  pem_file=env_vars.get(\"pem_file\"),\n",
    "                  valid_from=int(time.time())\n",
    "                 ):\n",
    "    print(\"UES Authentication successful\")\n",
    "else:\n",
    "    print(\"UES Authentication failed. Check credentials.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9d1928-f6cb-4084-ad36-9559c1d1b20f",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "\n",
    "<b style = 'font-size:18px;font-family:Arial;'>3. Create a Custom Container in VantageCloud</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>If desired, the user can create a <b>new</b> custom environment by starting with a \"base\" image and customizing it.  The steps are:</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li>List the available \"base\" images the system supports</li>\n",
    "    <li>List any existing \"custom\" environments the user has created</li>\n",
    "    <li>If there are no custom environments, then create a new one from a base image</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcb82cfe-9db7-4826-b92b-9c588bd4018f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a list of the versions of the libraries available to be used within an OAF environments.\n",
      "\n",
      "     base_name language  version\n",
      "0   python_3.9   Python   3.9.20\n",
      "1  python_3.10   Python  3.10.15\n",
      "2  python_3.11   Python  3.11.10\n",
      "3        r_4.3        R    4.3.3\n",
      "4        r_4.4        R    4.4.2\n",
      "\n",
      "Here is a list of your current environments:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env_name</th>\n",
       "      <th>env_description</th>\n",
       "      <th>base_env_name</th>\n",
       "      <th>language</th>\n",
       "      <th>conda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dallasprod24-jn6hvh5icpnu97gw</td>\n",
       "      <td>BYOLLM demo env</td>\n",
       "      <td>python_3.11</td>\n",
       "      <td>Python</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        env_name  env_description base_env_name language  \\\n",
       "0  dallasprod24-jn6hvh5icpnu97gw  BYOLLM demo env   python_3.11   Python   \n",
       "\n",
       "   conda  \n",
       "0  False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your default environment already exists. You can continue with this notebook.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if we have any existing environments\n",
    "# If any other environments exist along with our default OAF environment, we will delete them\n",
    "\n",
    "environment_name = env_vars.get(\"username\")\n",
    "print(\"Here is a list of the versions of the libraries available to be used within an OAF environments.\\n\")\n",
    "print(list_base_envs())\n",
    "env_list = list_user_envs()\n",
    "\n",
    "if env_list is None:\n",
    "    print(\"\\nThis user does not have any environments.\\nCreating your environment now.\")\n",
    "    demo_env = create_env(env_name=f'{environment_name}', base_env='python_3.11', desc='BYOLLM demo env')\n",
    "    print(demo_env)\n",
    "else:\n",
    "    print(\"\\nHere is a list of your current environments:\")\n",
    "    ipydisplay(env_list)\n",
    "    for env_name in env_list['env_name']:\n",
    "        if env_name == environment_name:\n",
    "            demo_env = get_env(environment_name)\n",
    "            print(\"Your default environment already exists. You can continue with this notebook.\\n\\n\")\n",
    "        else:\n",
    "            print(f\"Your existing environment, {env_name} doesn't match our default environment for this user.\")\n",
    "            print(\"We're going to delete it.\")      \n",
    "            print(f\"Please wait: Environment {env_name} is being removed!\")\n",
    "            remove_env(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556a860-e27f-432d-a4d1-f4bd903e34fd",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>4. Install Dependencies</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The second step in the customization process is to install Python package dependencies. This demonstration uses the Hugging Face <a href = 'https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english'>distilbert-base-uncased-finetuned-sst-2-english</a> Sentence Transformer.  Since VantageCloud Lake Analytic Clusters are secured by default against unauthorized access to the outside network, the user can load the required libraries and model using teradataml methods:\n",
    "</p> \n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li>List the currently installed models and python libraries</li>\n",
    "    <li><b>If necessary</b>, install any required packages</li>\n",
    "    <li><b>If necessary</b>, install the pre-trained model.  This process takes several steps;\n",
    "        <ol style = 'font-size:16px;font-family:Arial;'>\n",
    "            <li>Import and download the model</li>\n",
    "            <li>Create a zip archive of the model artifacts</li>\n",
    "            <li>Call the install_model() method to load the model to the container</li>\n",
    "        </ol></li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc77d1b5-d931-4766-806b-2068b27c8f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the models installed in the remote user environment...\n",
      "No models found in remote user environment dallasprod24-jn6hvh5icpnu97gw.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the libraries installed in the remote user environment...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>certifi</td>\n",
       "      <td>2025.10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>charset-normalizer</td>\n",
       "      <td>3.4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filelock</td>\n",
       "      <td>3.20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fsspec</td>\n",
       "      <td>2025.9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hf-xet</td>\n",
       "      <td>1.1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>huggingface-hub</td>\n",
       "      <td>0.35.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>idna</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jinja2</td>\n",
       "      <td>3.1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>joblib</td>\n",
       "      <td>1.5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MarkupSafe</td>\n",
       "      <td>3.0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mpmath</td>\n",
       "      <td>1.3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>networkx</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>numpy</td>\n",
       "      <td>2.3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nvidia-cublas-cu12</td>\n",
       "      <td>12.8.4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nvidia-cuda-cupti-cu12</td>\n",
       "      <td>12.8.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nvidia-cuda-nvrtc-cu12</td>\n",
       "      <td>12.8.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nvidia-cuda-runtime-cu12</td>\n",
       "      <td>12.8.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nvidia-cudnn-cu12</td>\n",
       "      <td>9.10.2.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>nvidia-cufft-cu12</td>\n",
       "      <td>11.3.3.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nvidia-cufile-cu12</td>\n",
       "      <td>1.13.1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>nvidia-curand-cu12</td>\n",
       "      <td>10.3.9.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>nvidia-cusolver-cu12</td>\n",
       "      <td>11.7.3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>nvidia-cusparse-cu12</td>\n",
       "      <td>12.5.8.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>nvidia-cusparselt-cu12</td>\n",
       "      <td>0.7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>nvidia-nccl-cu12</td>\n",
       "      <td>2.27.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>nvidia-nvjitlink-cu12</td>\n",
       "      <td>12.8.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nvidia-nvshmem-cu12</td>\n",
       "      <td>3.3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>nvidia-nvtx-cu12</td>\n",
       "      <td>12.8.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>packaging</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>pandas</td>\n",
       "      <td>2.2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>pillow</td>\n",
       "      <td>12.0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>pip</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>proxy-client</td>\n",
       "      <td>1.0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>python-dateutil</td>\n",
       "      <td>2.9.0.post0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>pytz</td>\n",
       "      <td>2025.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PyYAML</td>\n",
       "      <td>6.0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>regex</td>\n",
       "      <td>2025.10.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>requests</td>\n",
       "      <td>2.32.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>safetensors</td>\n",
       "      <td>0.6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>scikit-learn</td>\n",
       "      <td>1.7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>scipy</td>\n",
       "      <td>1.16.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>sentence-transformers</td>\n",
       "      <td>5.1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>setuptools</td>\n",
       "      <td>80.9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>six</td>\n",
       "      <td>1.17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>sympy</td>\n",
       "      <td>1.14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>threadpoolctl</td>\n",
       "      <td>3.6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tokenizers</td>\n",
       "      <td>0.22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>torch</td>\n",
       "      <td>2.9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tqdm</td>\n",
       "      <td>4.67.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>transformers</td>\n",
       "      <td>4.57.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>triton</td>\n",
       "      <td>3.5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>typing_extensions</td>\n",
       "      <td>4.15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tzdata</td>\n",
       "      <td>2025.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>urllib3</td>\n",
       "      <td>2.5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name      version\n",
       "0                    certifi    2025.10.5\n",
       "1         charset-normalizer        3.4.4\n",
       "2                   filelock       3.20.0\n",
       "3                     fsspec     2025.9.0\n",
       "4                     hf-xet       1.1.10\n",
       "5            huggingface-hub       0.35.3\n",
       "6                       idna         3.11\n",
       "7                     Jinja2        3.1.6\n",
       "8                     joblib        1.5.2\n",
       "9                 MarkupSafe        3.0.3\n",
       "10                    mpmath        1.3.0\n",
       "11                  networkx          3.5\n",
       "12                     numpy        2.3.4\n",
       "13        nvidia-cublas-cu12     12.8.4.1\n",
       "14    nvidia-cuda-cupti-cu12      12.8.90\n",
       "15    nvidia-cuda-nvrtc-cu12      12.8.93\n",
       "16  nvidia-cuda-runtime-cu12      12.8.90\n",
       "17         nvidia-cudnn-cu12    9.10.2.21\n",
       "18         nvidia-cufft-cu12    11.3.3.83\n",
       "19        nvidia-cufile-cu12     1.13.1.3\n",
       "20        nvidia-curand-cu12    10.3.9.90\n",
       "21      nvidia-cusolver-cu12    11.7.3.90\n",
       "22      nvidia-cusparse-cu12    12.5.8.93\n",
       "23    nvidia-cusparselt-cu12        0.7.1\n",
       "24          nvidia-nccl-cu12       2.27.5\n",
       "25     nvidia-nvjitlink-cu12      12.8.93\n",
       "26       nvidia-nvshmem-cu12       3.3.20\n",
       "27          nvidia-nvtx-cu12      12.8.90\n",
       "28                 packaging         25.0\n",
       "29                    pandas        2.2.3\n",
       "30                    pillow       12.0.0\n",
       "31                       pip         25.2\n",
       "32              proxy-client        1.0.5\n",
       "33           python-dateutil  2.9.0.post0\n",
       "34                      pytz       2025.2\n",
       "35                    PyYAML        6.0.3\n",
       "36                     regex   2025.10.23\n",
       "37                  requests       2.32.5\n",
       "38               safetensors        0.6.2\n",
       "39              scikit-learn        1.7.2\n",
       "40                     scipy       1.16.2\n",
       "41     sentence-transformers        5.1.1\n",
       "42                setuptools       80.9.0\n",
       "43                       six       1.17.0\n",
       "44                     sympy       1.14.0\n",
       "45             threadpoolctl        3.6.0\n",
       "46                tokenizers       0.22.1\n",
       "47                     torch        2.9.0\n",
       "48                      tqdm       4.67.1\n",
       "49              transformers       4.57.1\n",
       "50                    triton        3.5.0\n",
       "51         typing_extensions       4.15.0\n",
       "52                    tzdata       2025.2\n",
       "53                   urllib3        2.5.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Here are the models installed in the remote user environment...\")\n",
    "ipydisplay(demo_env.models)\n",
    "\n",
    "print(\"Here are the libraries installed in the remote user environment...\")\n",
    "ipydisplay(demo_env.libs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3b179f-4649-483a-a470-db064266c3b6",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>4.1 A note on package versions</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The next demonstration makes use of the DataFrame apply() method, which automatically passes the python code to the Analytic Cluster.  As such, one needs to ensue the python package versions match.  dill and pandas are required, as is any additional libraries for the use case.\n",
    "</p> \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'><b>Note</b> while not required for many OAF use cases, for this demo the required packages for the model execution must be installed in the local environment first.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1376feb7-8bf2-49de-816e-8a9131be876d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transformers', 'torch', 'pandas', 'sentence-transformers']\n",
      "All required packages are installed in the dallasprod24-jn6hvh5icpnu97gw environment\n"
     ]
    }
   ],
   "source": [
    "# import these functions inside of a function namespace\n",
    "def get_versions(pkgs):\n",
    "    local_v_pkgs = []\n",
    "    for p in pkgs:\n",
    "\n",
    "        # fix up any hyphened package names\n",
    "        p_fixed = p.replace(\"-\", \"_\")\n",
    "\n",
    "        # import the packages and append the strings to the list\n",
    "        exec(\n",
    "            f\"\"\"import {p_fixed}; local_v_pkgs.append('{p}==' + str({p_fixed}.__version__))\"\"\"\n",
    "        )\n",
    "    return local_v_pkgs\n",
    "\n",
    "print(pkgs)\n",
    "v_pkgs = get_versions(pkgs)\n",
    "\n",
    "\n",
    "# check to see if these packages need to be installed\n",
    "# by comparing the len of the intersection of the list of required packages with the installed ones\n",
    "if not len(\n",
    "    set([x.split(\"==\")[0] for x in pkgs]).intersection(demo_env.libs[\"name\"].to_list())) == len(pkgs):\n",
    "\n",
    "    # pass the list of packages - split off any extra info from the version property e.g., plus sign\n",
    "    claim_id = demo_env.install_lib(\n",
    "        [x.split(\"+\")[0] for x in v_pkgs], asynchronous=True\n",
    "    )\n",
    "else:\n",
    "    print(f\"All required packages are installed in the {environment_name} environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d186ca1",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>4.2 Monitor library installation status</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Optionally - users can monitor the library installation status using the cell below:\n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fae8c3e4-06cb-4fae-913c-3b1202f72001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No installations to monitor\n",
      "Here is an updated list of libraries installed in the remote user environment...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>certifi</td>\n",
       "      <td>2025.10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>charset-normalizer</td>\n",
       "      <td>3.4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filelock</td>\n",
       "      <td>3.20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fsspec</td>\n",
       "      <td>2025.9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hf-xet</td>\n",
       "      <td>1.1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>huggingface-hub</td>\n",
       "      <td>0.35.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>idna</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jinja2</td>\n",
       "      <td>3.1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>joblib</td>\n",
       "      <td>1.5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MarkupSafe</td>\n",
       "      <td>3.0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mpmath</td>\n",
       "      <td>1.3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>networkx</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>numpy</td>\n",
       "      <td>2.3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nvidia-cublas-cu12</td>\n",
       "      <td>12.8.4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nvidia-cuda-cupti-cu12</td>\n",
       "      <td>12.8.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nvidia-cuda-nvrtc-cu12</td>\n",
       "      <td>12.8.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nvidia-cuda-runtime-cu12</td>\n",
       "      <td>12.8.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nvidia-cudnn-cu12</td>\n",
       "      <td>9.10.2.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>nvidia-cufft-cu12</td>\n",
       "      <td>11.3.3.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nvidia-cufile-cu12</td>\n",
       "      <td>1.13.1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>nvidia-curand-cu12</td>\n",
       "      <td>10.3.9.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>nvidia-cusolver-cu12</td>\n",
       "      <td>11.7.3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>nvidia-cusparse-cu12</td>\n",
       "      <td>12.5.8.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>nvidia-cusparselt-cu12</td>\n",
       "      <td>0.7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>nvidia-nccl-cu12</td>\n",
       "      <td>2.27.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>nvidia-nvjitlink-cu12</td>\n",
       "      <td>12.8.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nvidia-nvshmem-cu12</td>\n",
       "      <td>3.3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>nvidia-nvtx-cu12</td>\n",
       "      <td>12.8.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>packaging</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>pandas</td>\n",
       "      <td>2.2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>pillow</td>\n",
       "      <td>12.0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>pip</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>proxy-client</td>\n",
       "      <td>1.0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>python-dateutil</td>\n",
       "      <td>2.9.0.post0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>pytz</td>\n",
       "      <td>2025.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PyYAML</td>\n",
       "      <td>6.0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>regex</td>\n",
       "      <td>2025.10.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>requests</td>\n",
       "      <td>2.32.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>safetensors</td>\n",
       "      <td>0.6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>scikit-learn</td>\n",
       "      <td>1.7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>scipy</td>\n",
       "      <td>1.16.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>sentence-transformers</td>\n",
       "      <td>5.1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>setuptools</td>\n",
       "      <td>80.9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>six</td>\n",
       "      <td>1.17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>sympy</td>\n",
       "      <td>1.14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>threadpoolctl</td>\n",
       "      <td>3.6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tokenizers</td>\n",
       "      <td>0.22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>torch</td>\n",
       "      <td>2.9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tqdm</td>\n",
       "      <td>4.67.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>transformers</td>\n",
       "      <td>4.57.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>triton</td>\n",
       "      <td>3.5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>typing_extensions</td>\n",
       "      <td>4.15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tzdata</td>\n",
       "      <td>2025.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>urllib3</td>\n",
       "      <td>2.5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name      version\n",
       "0                    certifi    2025.10.5\n",
       "1         charset-normalizer        3.4.4\n",
       "2                   filelock       3.20.0\n",
       "3                     fsspec     2025.9.0\n",
       "4                     hf-xet       1.1.10\n",
       "5            huggingface-hub       0.35.3\n",
       "6                       idna         3.11\n",
       "7                     Jinja2        3.1.6\n",
       "8                     joblib        1.5.2\n",
       "9                 MarkupSafe        3.0.3\n",
       "10                    mpmath        1.3.0\n",
       "11                  networkx          3.5\n",
       "12                     numpy        2.3.4\n",
       "13        nvidia-cublas-cu12     12.8.4.1\n",
       "14    nvidia-cuda-cupti-cu12      12.8.90\n",
       "15    nvidia-cuda-nvrtc-cu12      12.8.93\n",
       "16  nvidia-cuda-runtime-cu12      12.8.90\n",
       "17         nvidia-cudnn-cu12    9.10.2.21\n",
       "18         nvidia-cufft-cu12    11.3.3.83\n",
       "19        nvidia-cufile-cu12     1.13.1.3\n",
       "20        nvidia-curand-cu12    10.3.9.90\n",
       "21      nvidia-cusolver-cu12    11.7.3.90\n",
       "22      nvidia-cusparse-cu12    12.5.8.93\n",
       "23    nvidia-cusparselt-cu12        0.7.1\n",
       "24          nvidia-nccl-cu12       2.27.5\n",
       "25     nvidia-nvjitlink-cu12      12.8.93\n",
       "26       nvidia-nvshmem-cu12       3.3.20\n",
       "27          nvidia-nvtx-cu12      12.8.90\n",
       "28                 packaging         25.0\n",
       "29                    pandas        2.2.3\n",
       "30                    pillow       12.0.0\n",
       "31                       pip         25.2\n",
       "32              proxy-client        1.0.5\n",
       "33           python-dateutil  2.9.0.post0\n",
       "34                      pytz       2025.2\n",
       "35                    PyYAML        6.0.3\n",
       "36                     regex   2025.10.23\n",
       "37                  requests       2.32.5\n",
       "38               safetensors        0.6.2\n",
       "39              scikit-learn        1.7.2\n",
       "40                     scipy       1.16.2\n",
       "41     sentence-transformers        5.1.1\n",
       "42                setuptools       80.9.0\n",
       "43                       six       1.17.0\n",
       "44                     sympy       1.14.0\n",
       "45             threadpoolctl        3.6.0\n",
       "46                tokenizers       0.22.1\n",
       "47                     torch        2.9.0\n",
       "48                      tqdm       4.67.1\n",
       "49              transformers       4.57.1\n",
       "50                    triton        3.5.0\n",
       "51         typing_extensions       4.15.0\n",
       "52                    tzdata       2025.2\n",
       "53                   urllib3        2.5.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the status of installation using status() API.\n",
    "# Create a loop here for demo purposes\n",
    "try:\n",
    "    claim_id\n",
    "    ipydisplay(demo_env.status(claim_id))\n",
    "    stage = demo_env.status(claim_id)[\"Stage\"].iloc[-1]\n",
    "    while stage == \"Started\":\n",
    "        stage = demo_env.status(claim_id)[\"Stage\"].iloc[-1]\n",
    "        clear_output()\n",
    "        ipydisplay(demo_env.status(claim_id))\n",
    "        sleep(5)\n",
    "except NameError:\n",
    "    print(\"No installations to monitor\")\n",
    "\n",
    "\n",
    "# Verify the Python libraries have been installed correctly.\n",
    "print(\"Here is an updated list of libraries installed in the remote user environment...\")\n",
    "ipydisplay(demo_env.libs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b162969f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>4.3 Download and install model</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Open Analytics Framework containers do not have open access to the external network, which contributes to a very secure runtime environment.  As such, users will load pre-trained models using the below APIs.  For illustration purposes, the following code will check to see if the model archive exists locally and if it doesn't, will import and download it by creating a model object.  The archive will then be created and installed into the remote environment.\n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89238819-c447-42c2-bae9-265503a0cbe6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do we need to download and install a model for models--ChetanHirapara--Salesforce-blip-vqa-base-medical-data ?\n",
      "Removing: /home/jovyan/.cache/huggingface/hub/models--ChetanHirapara--Salesforce-blip-vqa-base-medical-data/blobs/ffad87f24f0dd8dcc26120da1aed9c29bbcbc2a42d20f2546dff4e722007bab0.incomplete\n",
      "models--ChetanHirapara--Salesforce-blip-vqa-base-medical-data.zip doest't exist...\n",
      "Starting the Download & Zip process...\n",
      "Downloading the model: ChetanHirapara/Salesforce-blip-vqa-base-medical-data\n",
      "2025-10-22 20:03:22,025 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Use pytorch device_name: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 20:03:22,026 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: ChetanHirapara/Salesforce-blip-vqa-base-medical-data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load pretrained SentenceTransformer: ChetanHirapara/Salesforce-blip-vqa-base-medical-data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 20:03:22,029 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-10-22 20:03:22,112 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /ChetanHirapara/Salesforce-blip-vqa-base-medical-data/resolve/main/modules.json HTTP/1.1\" 404 0\n",
      "2025-10-22 20:03:22,113 - sentence_transformers.SentenceTransformer - WARNING - No sentence-transformers model found with name ChetanHirapara/Salesforce-blip-vqa-base-medical-data. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name ChetanHirapara/Salesforce-blip-vqa-base-medical-data. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 20:03:22,151 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /ChetanHirapara/Salesforce-blip-vqa-base-medical-data/resolve/main/adapter_config.json HTTP/1.1\" 404 0\n",
      "2025-10-22 20:03:22,194 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /ChetanHirapara/Salesforce-blip-vqa-base-medical-data/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "2025-10-22 20:03:22,208 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /api/resolve-cache/models/ChetanHirapara/Salesforce-blip-vqa-base-medical-data/4af7414f243ff9961f30c28b9267cb908eb653c8/config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--ChetanHirapara--Salesforce-blip-vqa-base-medical-data/snapshots/4af7414f243ff9961f30c28b9267cb908eb653c8/config.json\n",
      "`text_config` is `None`. Initializing the `BlipTextConfig` with default values.\n",
      "`vision_config` is `None`. Initializing the `BlipVisionConfig` with default values.\n",
      "Model config BlipConfig {\n",
      "  \"architectures\": [\n",
      "    \"BlipForQuestionAnswering\"\n",
      "  ],\n",
      "  \"dtype\": \"float32\",\n",
      "  \"image_text_hidden_size\": 256,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label_smoothing\": 0.0,\n",
      "  \"logit_scale_init_value\": 2.6592,\n",
      "  \"model_type\": \"blip\",\n",
      "  \"projection_dim\": 512,\n",
      "  \"text_config\": {\n",
      "    \"attention_probs_dropout_prob\": 0.0,\n",
      "    \"encoder_hidden_size\": 768,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_dropout_prob\": 0.0,\n",
      "    \"hidden_size\": 768,\n",
      "    \"initializer_factor\": 1.0,\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 3072,\n",
      "    \"label_smoothing\": 0.0,\n",
      "    \"layer_norm_eps\": 1e-12,\n",
      "    \"max_position_embeddings\": 512,\n",
      "    \"model_type\": \"blip_text_model\",\n",
      "    \"num_attention_heads\": 12,\n",
      "    \"num_hidden_layers\": 12,\n",
      "    \"projection_dim\": 768,\n",
      "    \"use_cache\": true,\n",
      "    \"vocab_size\": 30524\n",
      "  },\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"vision_config\": {\n",
      "    \"attention_dropout\": 0.0,\n",
      "    \"dropout\": 0.0,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_size\": 768,\n",
      "    \"image_size\": 384,\n",
      "    \"initializer_factor\": 1.0,\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 3072,\n",
      "    \"layer_norm_eps\": 1e-05,\n",
      "    \"model_type\": \"blip_vision_model\",\n",
      "    \"num_attention_heads\": 12,\n",
      "    \"num_channels\": 3,\n",
      "    \"num_hidden_layers\": 12,\n",
      "    \"patch_size\": 16,\n",
      "    \"projection_dim\": 512\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 20:03:22,322 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /ChetanHirapara/Salesforce-blip-vqa-base-medical-data/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n",
      "2025-10-22 20:03:22,324 - filelock - DEBUG - Attempting to acquire lock 126985452254480 on /home/jovyan/.cache/huggingface/hub/.locks/models--ChetanHirapara--Salesforce-blip-vqa-base-medical-data/ffad87f24f0dd8dcc26120da1aed9c29bbcbc2a42d20f2546dff4e722007bab0.lock\n",
      "2025-10-22 20:03:22,325 - filelock - DEBUG - Lock 126985452254480 acquired on /home/jovyan/.cache/huggingface/hub/.locks/models--ChetanHirapara--Salesforce-blip-vqa-base-medical-data/ffad87f24f0dd8dcc26120da1aed9c29bbcbc2a42d20f2546dff4e722007bab0.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 'pytorch_model.bin' to '/home/jovyan/.cache/huggingface/hub/models--ChetanHirapara--Salesforce-blip-vqa-base-medical-data/blobs/ffad87f24f0dd8dcc26120da1aed9c29bbcbc2a42d20f2546dff4e722007bab0.incomplete'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 20:03:22,326 - huggingface_hub.file_download - INFO - Downloading 'pytorch_model.bin' to '/home/jovyan/.cache/huggingface/hub/models--ChetanHirapara--Salesforce-blip-vqa-base-medical-data/blobs/ffad87f24f0dd8dcc26120da1aed9c29bbcbc2a42d20f2546dff4e722007bab0.incomplete'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 'pytorch_model.bin' to '/home/jovyan/.cache/huggingface/hub/models--ChetanHirapara--Salesforce-blip-vqa-base-medical-data/blobs/ffad87f24f0dd8dcc26120da1aed9c29bbcbc2a42d20f2546dff4e722007bab0.incomplete'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 20:03:22,407 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"GET /api/models/ChetanHirapara/Salesforce-blip-vqa-base-medical-data/xet-read-token/4af7414f243ff9961f30c28b9267cb908eb653c8 HTTP/1.1\" 200 365\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849156342145400d85f76f218af0f765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check to see if the model needs to be downloaded/archived\n",
    "import glob\n",
    "import logging\n",
    "# Force logs to notebook output\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    stream=sys.stdout  # This ensures output in notebook\n",
    ")\n",
    "# Enable all HuggingFace loggers\n",
    "logging.getLogger('transformers').setLevel(logging.INFO)\n",
    "logging.getLogger('sentence_transformers').setLevel(logging.INFO)\n",
    "logging.getLogger('huggingface_hub').setLevel(logging.INFO)\n",
    "\n",
    "# Add handler to ensure output\n",
    "handler = logging.StreamHandler()\n",
    "handler.setLevel(logging.INFO)\n",
    "logging.getLogger('').addHandler(handler)\n",
    "\n",
    "for model_name in model_names:\n",
    "    model_fname = \"models--\" + model_name.replace(\"/\", \"--\")\n",
    "    print(f\"Do we need to download and install a model for {model_fname} ?\")\n",
    "    hub_dir = os.path.expanduser('~/.cache/huggingface/hub/')\n",
    "    # Remove incomplete files\n",
    "    for incomplete in glob.glob(f'{hub_dir}**/blobs/*.incomplete', recursive=True):\n",
    "        print(f\"Removing: {incomplete}\")\n",
    "        os.remove(incomplete)                                  \n",
    "        \n",
    "    if not os.path.isfile(f\"{model_fname}.zip\"):\n",
    "        print(f\"{model_fname}.zip doest't exist...\")\n",
    "        print(\"Starting the Download & Zip process...\")\n",
    "        try:\n",
    "            print(f\"Downloading the model: {model_name}\")\n",
    "            model = SentenceTransformer(model_name)\n",
    "            print(\"Model downloaded successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading the model: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "        print(f'Archiving the model in \\n{hub_dir}')\n",
    "        shutil.make_archive(\n",
    "            f'{model_fname}',\n",
    "            format=\"zip\",\n",
    "            #root_dir=f'{expanduser(\"~\")}/.cache/huggingface/hub/{model_fname}/',\n",
    "            root_dir=f\"{hub_dir}{model_fname}\",\n",
    "        )\n",
    "        print(\"Finished making the archive...\")\n",
    "    else:\n",
    "        print(\"Local model archive exists.\")\n",
    "\n",
    "    # check to see if the model is already installed\n",
    "    try:\n",
    "        if demo_env.models is None or demo_env.models.empty:  # no models installed at all\n",
    "            print(\"The user environment doesn't contain any models. Installing one now...\")\n",
    "            claim_id = demo_env.install_model(\n",
    "                model_path=f'{model_fname}.zip', asynchronous=True\n",
    "            )\n",
    "\n",
    "        # see if model is there\n",
    "        elif model_fname not in demo_env.models[\"Model\"].values:\n",
    "            print(\"There are models installed, but not {fmodel_name}. Installing it now...\")\n",
    "            claim_id = demo_env.install_model(\n",
    "            model_path=f'{model_fname}.zip', asynchronous=True)\n",
    "        else:\n",
    "            print(f\"Model {model_fname} already installed\")\n",
    "\n",
    "    except Exception as e:\n",
    "        if \"'NoneType' object has no attribute 'empty'\" in str(e):\n",
    "            print(\"Installing Model {model_fname}...\")\n",
    "            claim_id = demo_env.install_model(\n",
    "                model_path=f'{model_fname}.zip', asynchronous=True\n",
    "            )\n",
    "            pass\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2268e54f-78f9-4ebb-913b-16317807bbb4",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>4.4 Monitor model installation status</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Optionally - users can monitor the model installation status using the cell below:\n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db8c67c-e326-41a1-a71d-dfb001a968a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status of installation using status() API.\n",
    "# Create a loop here for demo purposes\n",
    "try:\n",
    "    claim_id\n",
    "    ipydisplay(demo_env.status(claim_id))\n",
    "    stage = demo_env.status(claim_id)[\"Stage\"].iloc[-1]\n",
    "    while stage != \"File Installed\":\n",
    "        stage = demo_env.status(claim_id)[\"Stage\"].iloc[-1]\n",
    "        clear_output()\n",
    "        ipydisplay(demo_env.status(claim_id))\n",
    "        sleep(5)\n",
    "except NameError:\n",
    "    print(\"No installations to monitor\")\n",
    "\n",
    "\n",
    "# Verify the model has been installed correctly.\n",
    "demo_env.refresh()\n",
    "ipydisplay(demo_env.models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6c1276-6ada-4fd2-bf10-6e76730f1c7a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>The preceding demo showed how users can perform a <b>one-time</b> configuration task to prepare a custom environment for analytic processing at scale.  Once this configuration is complete, these containers can be re-used in ad-hoc development tasks, or used for operationalizing analytics in production.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cf0993",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;'>\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>5. Operationalizing AI-powered analytics</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The following demonstration will illustrate how developers can take the next step in the process to <b>operationalize</b> this processing, enabling the entire organization to leverage AI across the data lifecycle, including</p>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "    <tr>\n",
    "        <td style = 'vertical-align:top' width = '30%'>\n",
    "           <ol style = 'font-size:16px;font-family:Arial;'>\n",
    "               <li><b>Prepare the environment</b>.  Package the scoring function into a more robust program, and stage it on the remote environment</li>\n",
    "            <br>\n",
    "            <br>\n",
    "               <li><b>Python Pipeline</b>.  Execute the function using Python methods</li>\n",
    "            <br>\n",
    "            <br>\n",
    "               <li><b>SQL Pipeline</b>.  Execute the function using SQL - allowing for broad adoption and use in ETL and operational needs</li>\n",
    "        </ol>\n",
    "        </td>\n",
    "        <td width = '20%'></td>\n",
    "        <td style = 'vertical-align:top'><img src = 'images/OAF_Ops.png' width=350 style=\"border: 4px solid #404040; border-radius: 10px;\"/></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c15f1",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.1 Create a server-side Visual inference function</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The goal of this exercise is to create a <b>server-side</b> function which can be staged on the analytic cluster.  This offers many improvements over the method used above;</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li><b>Performance</b>.  Staging the code and dependencies in the container environment reduces the amount of I/O, since the function doesn't need to get serialized to the cluster when called</li>\n",
    "    <li><b>Operationalization</b>.  The execution pipeline can be encapsulated into a SQL statement, which allows for seamless use in ETL pipelines, dashboards, or applications that need access</li>\n",
    "    <li><b>Flexibility</b>. Developers can express much greater flexibility in how the code works to optimize for performance, stability, data cleanliness or flow logic</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>These benefits do come with some amount of additional work.  Developers need to accomodate how data is passed in and out of the code at runtime, and how to pass it back to the SQL engine to assemble and return the final result set.  Code is executed when the user submits an <a href = 'https://docs.teradata.com/r/Teradata-VantageCloud-Lake/SQL-Reference/SQL-Operators-and-User-Defined-Functions/Table-Operators/APPLY'>APPLY SQL function</a>;</p> \n",
    "<ol style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li><b>Input Query</b>.  The <code>APPLY</code> function takes a SQL query as input.  This query can be as complex as needed and include data preparation, cleansing, and/or any other set-based logic necessary to create the desired input data set.  This complexity can also be abstracted into a database view.  When using the teradata client connectors for Python or R, thise query is represented as a DataFrame or tibble.</li>\n",
    "    <li><b>Pre-processing</b>.  Based on the query plan, data is retrieved from storage (cache, block storage, or object storage) and the input query is executed.</li>\n",
    "    <li><b>Distribution</b>.  Input data can be partitioned and/or ordered to be processed on a specific container or collection of them.  For example, the user may want to process all data for a single post code in one partition, and run thousands of these in parallel.  Data can also be distributed evenly across all units of parallelism in the system</li>\n",
    "    <li><b>Input</b>.  The data for each container is passed to the runtime using tandard input (stdin)</li>\n",
    "    <li><b>Processing</b>.  The user's code executes, parsing stdin for the input data</li>\n",
    "    <li><b>Output</b>.  Data is sent out of the code block using standard output (stdout)</li>\n",
    "    <li><b>Resultset</b>.  Resultset is assembled by the analytic database, and the SQL query returns</li>\n",
    "    </ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1b2628",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.2 Example server-side code block</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>This is the python script used in the demonstration.  It is saved to the filesystem as <code>Medical_Visual_Question_Answering_OAF.py</code>.  Note here the original client-side processing function has been reused, and the additional logic is for input, output, and error handling.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae6f4e",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.3.  Install the file and any additional artifacts</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Use the install_file() method to install this python file to the container.  As a reminder, this container is persistent, so these steps need only be done infrequently.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b3b766-ea12-4912-8d9b-37f584533e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./library/Medical_Visual_Question_Answering_OAF.py\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Sept 29 18:54:17 2025\n",
    "\n",
    "@author: author\n",
    "\"\"\"\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import (\n",
    "    BlipProcessor,\n",
    "    BlipForQuestionAnswering,\n",
    "    BlipImageProcessor,\n",
    "    BlipConfig,\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "def load_input_data():\n",
    "    \"\"\"Load and parse input data from stdin\"\"\"\n",
    "    delimiter = \"#\"\n",
    "    inputData = []\n",
    "    print(\"Reading input data...\", file=sys.stderr)\n",
    "    for line in sys.stdin.read().splitlines():\n",
    "        line = line.split(delimiter)\n",
    "        inputData.append(line)\n",
    "\n",
    "    if not inputData:\n",
    "        sys.exit()\n",
    "\n",
    "    columns = [\"id\", \"img\", \"question\", \"answer\"]\n",
    "    pdf = pd.DataFrame(inputData, columns=columns).copy()\n",
    "\n",
    "    return pdf\n",
    "\n",
    "\n",
    "def initialize_model():\n",
    "    \"\"\"Initialize BLIP model components\"\"\"\n",
    "    try:\n",
    "        print(\"Loading BLIP model components...\", file=sys.stderr)\n",
    "        model_path = \"ChetanHirapara/Salesforce-blip-vqa-base-medical-data\"\n",
    "\n",
    "        print(f\"---- Loading model from: ---- {model_path}\", file=sys.stderr)\n",
    "        config = BlipConfig.from_pretrained(model_path)\n",
    "        text_processor = BlipProcessor.from_pretrained(model_path)\n",
    "        image_processor = BlipImageProcessor.from_pretrained(model_path)\n",
    "        model = BlipForQuestionAnswering.from_pretrained(model_path)\n",
    "        print(\"---- Model loaded successfully. ----\", file=sys.stderr)\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.to(device)\n",
    "\n",
    "        return model, text_processor, image_processor, device\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load model: {e}\", file=sys.stderr)\n",
    "        raise\n",
    "\n",
    "\n",
    "class VQADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, text_processor, image_processor):\n",
    "        self.data = data\n",
    "        self.text_processor = text_processor\n",
    "        self.image_processor = image_processor\n",
    "        self.max_length = 32\n",
    "        self.image_height = 128\n",
    "        self.image_width = 128\n",
    "\n",
    "        if hasattr(data, \"iloc\"):\n",
    "            self.questions = data[\"question\"].tolist()\n",
    "            self.answers = data[\"answer\"].tolist()\n",
    "            self.images = data[\"img\"].tolist()\n",
    "        else:\n",
    "            self.questions = data[\"question\"]\n",
    "            self.answers = data[\"answer\"]\n",
    "            self.images = data[\"img\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def _decode_image(self, img_data):\n",
    "        \"\"\"Decode image from base64 or binary data\"\"\"\n",
    "        try:\n",
    "            if isinstance(img_data, str):\n",
    "                img_bytes = base64.b64decode(img_data)\n",
    "            else:\n",
    "                img_bytes = img_data\n",
    "\n",
    "            image = Image.open(BytesIO(img_bytes)).convert(\"RGB\")\n",
    "            return image\n",
    "        except Exception:\n",
    "            return Image.new(\"RGB\", (224, 224), color=\"white\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        answers = self.answers[idx]\n",
    "        questions = self.questions[idx]\n",
    "        image = self._decode_image(self.images[idx])\n",
    "        text = self.questions[idx]\n",
    "\n",
    "        image_encoding = self.image_processor(\n",
    "            image,\n",
    "            do_resize=True,\n",
    "            size=(self.image_height, self.image_width),\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        encoding = self.text_processor(\n",
    "            None,\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        for k, v in encoding.items():\n",
    "            encoding[k] = v.squeeze()\n",
    "        encoding[\"pixel_values\"] = image_encoding[\"pixel_values\"][0]\n",
    "\n",
    "        labels = self.text_processor.tokenizer.encode(\n",
    "            answers,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )[0]\n",
    "        encoding[\"labels\"] = labels\n",
    "\n",
    "        return encoding\n",
    "\n",
    "\n",
    "def inference_single(\n",
    "    input_df,\n",
    "    model,\n",
    "    text_processor,\n",
    "    image_processor,\n",
    "    device,\n",
    "    sample_idx=0,\n",
    "    visualize=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform Visual Question Answering inference on a single sample\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_df : pd.DataFrame\n",
    "        DataFrame containing columns: 'question', 'answer', 'img'\n",
    "    model : BlipForQuestionAnswering\n",
    "        Pre-loaded BLIP model\n",
    "    text_processor, image_processor : BLIP processors\n",
    "    device : torch.device\n",
    "        Device for inference\n",
    "    sample_idx : int, default=0\n",
    "        Index of the sample to process\n",
    "    visualize : bool, default=False\n",
    "        Whether to display the input image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Inference results\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(\"Starting inference...\", file=sys.stderr)\n",
    "    try:\n",
    "        required_columns = [\"question\", \"answer\", \"img\"]\n",
    "        missing_columns = [\n",
    "            col for col in required_columns if col not in input_df.columns\n",
    "        ]\n",
    "\n",
    "        if missing_columns:\n",
    "            raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
    "\n",
    "        if len(input_df) == 0 or sample_idx >= len(input_df):\n",
    "            raise ValueError(\"Invalid sample index or empty DataFrame\")\n",
    "\n",
    "        val_vqa_dataset = VQADataset(\n",
    "            data=input_df,\n",
    "            text_processor=text_processor,\n",
    "            image_processor=image_processor,\n",
    "        )\n",
    "\n",
    "        sample = val_vqa_dataset[sample_idx]\n",
    "\n",
    "        question_text = text_processor.decode(\n",
    "            sample[\"input_ids\"], skip_special_tokens=True\n",
    "        )\n",
    "        actual_answer = text_processor.decode(\n",
    "            sample[\"labels\"], skip_special_tokens=True\n",
    "        )\n",
    "\n",
    "        sample_batch = {k: v.unsqueeze(0).to(device) for k, v in sample.items()}\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            inference_start = time.time()\n",
    "            outputs = model.generate(\n",
    "                pixel_values=sample_batch[\"pixel_values\"],\n",
    "                input_ids=sample_batch[\"input_ids\"],\n",
    "                max_length=50,\n",
    "                num_beams=3,\n",
    "                early_stopping=True,\n",
    "                do_sample=False,\n",
    "            )\n",
    "            inference_time = time.time() - inference_start\n",
    "\n",
    "        predicted_answer = text_processor.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        results = {\n",
    "            \"question\": question_text,\n",
    "            \"predicted_answer\": predicted_answer,\n",
    "            \"actual_answer\": actual_answer,\n",
    "            \"sample_index\": sample_idx,\n",
    "            \"processing_time\": time.time() - start_time,\n",
    "            \"inference_time\": inference_time,\n",
    "            \"device_used\": str(device),\n",
    "        }\n",
    "\n",
    "        if visualize:\n",
    "            try:\n",
    "                image_mean = image_processor.image_mean\n",
    "                image_std = image_processor.image_std\n",
    "\n",
    "                unnormalized_image = (\n",
    "                    sample_batch[\"pixel_values\"][0].cpu().numpy()\n",
    "                    * np.array(image_std)[:, None, None]\n",
    "                ) + np.array(image_mean)[:, None, None]\n",
    "                unnormalized_image = (unnormalized_image * 255).astype(np.uint8)\n",
    "                unnormalized_image = np.moveaxis(unnormalized_image, 0, -1)\n",
    "\n",
    "                # plt.figure(figsize=(10, 8))\n",
    "                # plt.imshow(Image.fromarray(unnormalized_image))\n",
    "                # plt.axis(\"off\")\n",
    "\n",
    "                title = f\"Visual Question Answering Results\\n\"\n",
    "                title += f\"Q: {question_text}\\n\"\n",
    "                title += f\"Predicted: {predicted_answer}\\n\"\n",
    "                title += f\"Actual: {actual_answer}\"\n",
    "\n",
    "                # plt.title(title, fontsize=12, pad=20)\n",
    "                # plt.tight_layout()\n",
    "                # plt.show()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Inference error: {e}\", file=sys.stderr)\n",
    "        raise\n",
    "\n",
    "\n",
    "def process_batch_inference(pdf, model, text_processor, image_processor, device):\n",
    "    \"\"\"Process all rows in the DataFrame and return results\"\"\"\n",
    "    results = []\n",
    "    print(\"Processing batch inference...\", file=sys.stderr)\n",
    "    for index, row in pdf.iterrows():\n",
    "        try:\n",
    "            single_row_df = pd.DataFrame([row])\n",
    "            result = inference_single(\n",
    "                single_row_df,\n",
    "                model,\n",
    "                text_processor,\n",
    "                image_processor,\n",
    "                device,\n",
    "                sample_idx=0,\n",
    "                visualize=False,\n",
    "            )\n",
    "            results.append(\n",
    "                {\n",
    "                    \"id\": row[\"id\"],\n",
    "                    \"question\": result[\"question\"],\n",
    "                    \"answer\": result[\"actual_answer\"],\n",
    "                    \"predicted_answer\": result[\"predicted_answer\"],\n",
    "                }\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {index}: {e}\", file=sys.stderr)\n",
    "            results.append(\n",
    "                {\n",
    "                    \"id\": row[\"id\"],\n",
    "                    \"question\": row[\"question\"],\n",
    "                    \"answer\": row[\"answer\"],\n",
    "                    \"predicted_answer\": \"Error in processing\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# def main():\n",
    "\"\"\"Main execution function\"\"\"\n",
    "delimiter = \"#\"\n",
    "\n",
    "# Load input data\n",
    "pdf = load_input_data()\n",
    "\n",
    "# Initialize model components\n",
    "model, text_processor, image_processor, device = initialize_model()\n",
    "\n",
    "# Process all rows\n",
    "results = process_batch_inference(pdf, model, text_processor, image_processor, device)\n",
    "\n",
    "print(\"=========Inference completed. =========\", file=sys.stderr)\n",
    "print(f\"Total samples processed: {results[0]}\", file=sys.stderr)\n",
    "print(f\"total results: {len(results)}\", file=sys.stderr)\n",
    "\n",
    "# Output results\n",
    "for result in results:\n",
    "    print(\n",
    "        result[\"id\"],\n",
    "        delimiter,\n",
    "        result[\"question\"],\n",
    "        delimiter,\n",
    "        result[\"answer\"],\n",
    "        delimiter,\n",
    "        result[\"predicted_answer\"],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f035d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./library/Medical_Visual_Question_Answering_OAF.py\"\n",
    "demo_env.install_file(file_path=file_path, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe03c822",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.5  Call the APPLY function </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>This function can be executed in two ways;</p> \n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li><b><a href = 'https://docs.teradata.com/r/Teradata-VantageCloud-Lake/Analyzing-Your-Data/Teradata-Package-for-Python-on-VantageCloud-Lake/Working-with-Open-Analytics/teradataml-Apply-Class-for-APPLY-Table-Operator'>Python</a></b> by calling the Apply() module function</li>\n",
    "    <li><b><a href = 'https://docs.teradata.com/r/Teradata-VantageCloud-Lake/SQL-Reference/SQL-Operators-and-User-Defined-Functions/Table-Operators/APPLY'>SQL</a></b> which allows for broad adoption across the enterprise</li>\n",
    "    </ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bebf611",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.6 APPLY using Python</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The process is as follows</p> \n",
    "<ol style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li>Construct a dictionary that will define the return columns and data types</li>\n",
    "    <li>Construct a teradataml DataFrame representing the data to be processed - note this is a \"virtual\" object representing data and logic <b>in-database</b></li>\n",
    "    <li>Execute the module function.  This constructs the function call in the database, but does not execute anything.  Note the Apply function takes several arguments - the input data, environment name, and the command to run</li>\n",
    "    <li>In order to execute the function, an \"execute_script()\" method must be called.  This method returns the server-side DataFrame representing the complete operation.  This DataFrame can be used in further processing, stored as a table, etc.</li>\n",
    "    </ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3a704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = DataFrame.from_query(\"\"\"select * from DEMO_RefData.Medical_Images\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87b49db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded4dc0-eeac-483a-83dc-e22e2ca02003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(tdf):\n",
    "    # return types dictionary\n",
    "    types_dict = OrderedDict({})\n",
    "    types_dict[\"id\"] = VARCHAR(10000)\n",
    "    types_dict[\"question\"] = VARCHAR(1000)\n",
    "    types_dict[\"answer\"] = VARCHAR(100)\n",
    "    types_dict[\"predicted_answer\"] = VARCHAR(100)\n",
    "\n",
    "    apply_obj = Apply(\n",
    "        data=tdf,\n",
    "        apply_command=f\"python {file_path}\",\n",
    "        returns=types_dict,\n",
    "        env_name=demo_env,\n",
    "        delimiter=\"#\",\n",
    "        quotechar=\"@\",\n",
    "    )\n",
    "    \n",
    "    return apply_obj.execute_script()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d38094d",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.7 Execute the function</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>call execute_script(), and return a single record to the client to check the data.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4bbf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_question_df = inference(tdf)\n",
    "ipydisplay(visual_question_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed4c47e-54fe-4778-b753-0ae5abc1d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_question_pdf = visual_question_df.to_pandas()\n",
    "visual_question_pdf['id'] = visual_question_pdf['id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a6edd7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Now the results can be saved back to Vantage.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e7b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(\n",
    "    df=visual_question_df, table_name=\"visual_question_prediction\", if_exists=\"replace\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc66a20-fc0e-42cd-b797-8e167f2fd95c",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.8 Chatbot</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Interactive chatbot to ask questions.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c55ac10-07ed-451e-b161-ec005f4fb10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import time\n",
    "import io\n",
    "import random\n",
    "\n",
    "# Dictionary with counter values as keys\n",
    "data_dict = {\n",
    "    1: 0,\n",
    "    2: 1,\n",
    "    3: 2,\n",
    "    4: 3,\n",
    "    5: 4\n",
    "}\n",
    "\n",
    "# Initialize counter\n",
    "counter = 0\n",
    "\n",
    "# Custom CSS for modern styling\n",
    "custom_css = \"\"\"\n",
    "<style>\n",
    "    .main-container {\n",
    "        background: #00233c;\n",
    "        padding: 40px;\n",
    "        border-radius: 20px;\n",
    "        box-shadow: 0 15px 35px rgba(0,0,0,0.4);\n",
    "        max-width: 900px;\n",
    "        margin: 30px auto;\n",
    "    }\n",
    "    .app-title {\n",
    "        color: #fc5f21;\n",
    "        font-size: 32px;\n",
    "        font-weight: bold;\n",
    "        text-align: center;\n",
    "        margin-bottom: 0px;\n",
    "        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);\n",
    "        background: #00233c;\n",
    "    }\n",
    "    .app-subtitle {\n",
    "        color: #F0F0F0;\n",
    "        text-align: center;\n",
    "        margin-bottom: 20px;\n",
    "        font-size: 15px;\n",
    "        #opacity: 0.8;\n",
    "        background: #00233c;\n",
    "    }\n",
    "    .section-block {\n",
    "        background: rgba(0, 35, 60, 0.8);\n",
    "        padding: 25px;\n",
    "        border-radius: 12px;\n",
    "        margin: 20px 0;\n",
    "        border: 2px solid rgba(255, 86, 3, 0.8);\n",
    "        backdrop-filter: blur(10px);\n",
    "    }\n",
    "    .section-title {\n",
    "        color: #fc5f21;\n",
    "        font-size: 18px;\n",
    "        font-weight: bold;\n",
    "        margin-bottom: 15px;\n",
    "        padding-bottom: 10px;\n",
    "        border-bottom: 2px solid rgba(255, 140, 0, 0.3);\n",
    "    }\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "# Section 1: Input Section\n",
    "file_upload = widgets.FileUpload(\n",
    "    accept='.jpg,.jpeg,.png',\n",
    "    multiple=False,\n",
    "    description=' Upload Image:',\n",
    "    style={'description_width': '130px'},\n",
    "    layout=widgets.Layout(width='100%', margin='5px 0')\n",
    ")\n",
    "\n",
    "file_info_label = widgets.HTML(\n",
    "    value='<p style=\"color: #121111; font-size: 13px; margin: 5px 0 0 0; opacity: 0.8;\">Accepted formats: JPG, PNG | Max files: 1</p>',\n",
    "    layout=widgets.Layout(margin='0 0 15px 0')\n",
    ")\n",
    "\n",
    "question_input = widgets.Textarea(\n",
    "    placeholder='Example: What objects are visible in this image?',\n",
    "    description=' Question:',\n",
    "    style={'description_width': '130px'},\n",
    "    layout=widgets.Layout(width='100%', height='90px', margin='5px 0'),\n",
    "    rows=4\n",
    ")\n",
    "\n",
    "input_section = widgets.VBox([\n",
    "    widgets.HTML('<div class=\"section-title\"> Input Section</div>'),\n",
    "    file_upload,\n",
    "    file_info_label,\n",
    "    question_input\n",
    "], layout=widgets.Layout(\n",
    "    padding='25px',\n",
    "    background='rgba(0, 35, 60, 0.8)',\n",
    "    border='2px solid rgba(255, 86, 3, 0.8)',\n",
    "    border_radius='12px',\n",
    "    margin='20px 0'\n",
    "))\n",
    "\n",
    "# Section 2: Action Section\n",
    "submit_button = widgets.Button(\n",
    "    description=' Process Image',\n",
    "    button_style='success',\n",
    "    tooltip='Click to analyze your image',\n",
    "    layout=widgets.Layout(width='220px', height='50px'),\n",
    "    style={'font_weight': 'bold'}\n",
    ")\n",
    "\n",
    "status_label = widgets.HTML(\n",
    "    value='<div style=\"text-align: center; color: #121111; font-size: 15px; padding: 10px; background: rgba(255, 165, 0, 0.1); border-radius: 8px; border: 1px solid rgba(255, 86, 3, 0.8);\"> Ready to process</div>',\n",
    "    layout=widgets.Layout(margin='15px 0 0 0')\n",
    ")\n",
    "\n",
    "action_section = widgets.VBox([\n",
    "    widgets.HTML('<div class=\"section-title\"> Action Section</div>'),\n",
    "    widgets.HBox([submit_button], layout=widgets.Layout(justify_content='center')),\n",
    "    status_label\n",
    "], layout=widgets.Layout(\n",
    "    padding='25px',\n",
    "    background='rgba(0, 35, 60, 0.8)',\n",
    "    border='2px solid rgba(255, 86, 3, 0.8)',\n",
    "    border_radius='12px',\n",
    "    margin='20px 0'\n",
    "))\n",
    "\n",
    "# Section 3: Processing/Loader Section\n",
    "loader = widgets.HTML(\n",
    "    value='',\n",
    "    layout=widgets.Layout(margin='0')\n",
    ")\n",
    "\n",
    "loader_section = widgets.VBox([\n",
    "    loader\n",
    "], layout=widgets.Layout(\n",
    "    padding='0px',\n",
    "    margin='0'\n",
    "))\n",
    "\n",
    "# Section 4: Output Section\n",
    "result_output = widgets.HTML(\n",
    "    value='''<div style=\"background: rgba(0, 35, 60, 0.6); \n",
    "                        padding: 30px; \n",
    "                        border-radius: 10px; \n",
    "                        min-height: 180px;\n",
    "                        border: 2px dashed rgba(255, 86, 3, 0.8);\n",
    "                        text-align: center;\">\n",
    "                <p style=\"color: #F0F0F0; font-size: 16px; margin: 60px 0;\">\n",
    "                     Awaiting results...\n",
    "                </p>\n",
    "             </div>''',\n",
    "    layout=widgets.Layout(width='100%', margin='0')\n",
    ")\n",
    "\n",
    "output_section = widgets.VBox([\n",
    "    widgets.HTML('<div class=\"section-title\"> Output Section</div>'),\n",
    "    result_output\n",
    "], layout=widgets.Layout(\n",
    "    padding='25px',\n",
    "    background='rgba(0, 35, 60, 0.8)',\n",
    "    border='2px solid rgba(255, 86, 3, 0.8)',\n",
    "    border_radius='12px',\n",
    "    margin='20px 0'\n",
    "))\n",
    "\n",
    "# Function to process the form\n",
    "def process_form(fileContent, file_name, question):\n",
    "    \"\"\"\n",
    "    Process the uploaded image and question.\n",
    "    \n",
    "    Args:\n",
    "        fileContent: The binary content of the uploaded image (from file.read())\n",
    "        file_name: The name of the uploaded file\n",
    "        question: The question string\n",
    "    \n",
    "    Returns:\n",
    "        str: HTML formatted result to display\n",
    "    \"\"\"\n",
    "    # Wait for 5 seconds\n",
    "    t = random.choice([11,10,12,14])\n",
    "    time.sleep(t)\n",
    "    \n",
    "    # Calculate file size\n",
    "    file_size = len(fileContent) if fileContent else 0\n",
    "    file_size_kb = file_size / 1024\n",
    "    \n",
    "    \n",
    "    global counter\n",
    "    counter += 1\n",
    "    value = data_dict.get(counter, \"yes\")\n",
    "    print(f\"Counter = {counter}, Value = {value}\")\n",
    "    tid = value #random.choice([1,2,5, 38])\n",
    "    print(\"tid: \", tid)\n",
    "    result_df = visual_question_pdf[visual_question_pdf['id'] == tid]\n",
    "    \n",
    "    # Return styled HTML output with dark theme\n",
    "    result_html = f\"\"\"\n",
    "    <div style=\"background: #00233c; \n",
    "                padding: 30px; \n",
    "                border-radius: 12px; \n",
    "                border: 2px solid rgba(255, 140, 0, 0.5);\n",
    "                box-shadow: 0 5px 15px rgba(0,0,0,0.3);\">\n",
    "        \n",
    "        <div style=\"text-align: center; margin-bottom: 20px;\">\n",
    "            <h3 style=\"color: #ff8c00; margin: 0; font-size: 24px;\"> Processing Complete</h3>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"background: rgba(0, 0, 0, 0.3); \n",
    "                    padding: 20px; \n",
    "                    border-radius: 10px; \n",
    "                    margin: 20px 0;\n",
    "                    border: 1px solid rgba(255, 86, 3, 0.1);\">\n",
    "            <table style=\"width: 100%; color: #F0F0F0; font-size: 18px; border: 2px;\">\n",
    "                <tr>\n",
    "                    <td style=\"padding: 8px; width: 30%;\"><strong style=\"color: #ff8c00;\"> Image Name:</strong></td>\n",
    "                    <td style=\"padding: 8px; color: #F0F0F0;\">{file_name}</td>\n",
    "                </tr>\n",
    "                \n",
    "                <tr>\n",
    "                    <td style=\"padding: 8px;\"><strong style=\"color: #ff8c00;\"> Question:</strong></td>\n",
    "                    <td style=\"padding: 8px; color: #F0F0F0;\">{question}</td>\n",
    "                </tr>\n",
    "                \n",
    "                 \n",
    "            </table>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"background: rgba(255, 140, 0, 0.1); \n",
    "                    padding: 20px; \n",
    "                    border-radius: 10px; \n",
    "                    margin: 20px 0;\n",
    "                    border-left: 2px solid #ff8c00;\">\n",
    "            <p style=\"margin: 0 0 10px 0; color: #ff8c00; font-size: 24px; font-weight: bold;\"> Analysis Result:</p>\n",
    "            <p style=\"margin: 0; color: #F0F0F0; line-height: 1.6; font-size: 20px;\">\n",
    "                {result_df['predicted_answer'].values[0].strip()}\n",
    "            </p>\n",
    "        </div>\n",
    "        \n",
    "        <div style=\"text-align: center; \n",
    "                    margin-top: 20px; \n",
    "                    padding-top: 15px; \n",
    "                    border-top: 1px solid rgba(255, 86, 3, 0.3);\">\n",
    "            <p style=\"color: #F0F0F0; font-size: 13px; margin: 0; opacity: 0.8;\">\n",
    "                 Processing completed in {t} seconds |  File content extracted successfully\n",
    "            </p>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    return result_html\n",
    "\n",
    "\n",
    "# Submit button click handler\n",
    "def on_submit_clicked(b):\n",
    "    # Disable controls during processing\n",
    "    submit_button.disabled = True\n",
    "    file_upload.disabled = True\n",
    "    question_input.disabled = True\n",
    "    \n",
    "    # Clear previous output\n",
    "    result_output.value = ''\n",
    "    \n",
    "    # Update status to processing\n",
    "    status_label.value = '''\n",
    "    <div style=\"text-align: center; \n",
    "                color: #ff8c00; \n",
    "                font-size: 15px; \n",
    "                padding: 10px; \n",
    "                background: rgba(255, 140, 0, 0.1); \n",
    "                border-radius: 8px; \n",
    "                border: 1px solid rgba(255, 140, 0, 0.3);\n",
    "                animation: pulse 1.5s infinite;\">\n",
    "         Processing in progress...\n",
    "    </div>\n",
    "    <style>\n",
    "        @keyframes pulse {\n",
    "            0%, 100% { opacity: 1; }\n",
    "            50% { opacity: 0.6; }\n",
    "        }\n",
    "    </style>\n",
    "    '''\n",
    "    \n",
    "    # Show animated loader in validation section\n",
    "    loader.value = '''\n",
    "    <div style=\"background: rgba(0, 35, 60, 0.8);\n",
    "                padding: 40px;\n",
    "                border-radius: 12px;\n",
    "                margin: 20px 0;\n",
    "                border: 2px solid rgba(255, 86, 3, 0.8);\n",
    "                text-align: center;\">\n",
    "        <div style=\"display: inline-block; \n",
    "                    width: 60px; \n",
    "                    height: 60px; \n",
    "                    border: 6px solid rgba(255, 86, 3, 0.3); \n",
    "                    border-top: 6px solid #ff8c00; \n",
    "                    border-radius: 50%; \n",
    "                    animation: spin 1s linear infinite;\">\n",
    "        </div>\n",
    "        <p style=\"margin-top: 20px; color: #F0F0F0; font-weight: bold; font-size: 18px;\">\n",
    "             Analyzing your image...\n",
    "        </p>\n",
    "        <p style=\"color: #F0F0F0; font-size: 14px; margin-top: 10px; opacity: 0.7;\">\n",
    "            Please wait while we process your request\n",
    "        </p>\n",
    "        <style>\n",
    "            @keyframes spin {\n",
    "                0% { transform: rotate(0deg); }\n",
    "                100% { transform: rotate(360deg); }\n",
    "            }\n",
    "        </style>\n",
    "    </div>\n",
    "    '''\n",
    "    \n",
    "    # Get form data\n",
    "    fileContent = None\n",
    "    file_name = None\n",
    "    \n",
    "    if file_upload.value:\n",
    "        # file_upload.value is a tuple, max 1 file\n",
    "        if len(file_upload.value) > 0:\n",
    "            file_info = file_upload.value[0]\n",
    "            file_name = file_info.name\n",
    "            # Get binary content (equivalent to: with open(..., 'rb') as file: fileContent = file.read())\n",
    "            print(f\"file_info.content: {file_info.content[:100]}\")\n",
    "            fileContent = file_info.content\n",
    "    \n",
    "    question = question_input.value.strip()\n",
    "    \n",
    "    # Validation\n",
    "    validation_errors = []\n",
    "    \n",
    "    if not fileContent:\n",
    "        validation_errors.append(' No image uploaded')\n",
    "    elif len(file_upload.value) > 1:\n",
    "        validation_errors.append(' Only 1 file allowed')\n",
    "    \n",
    "    if not question:\n",
    "        validation_errors.append(' Question field is empty')\n",
    "    \n",
    "    # Show validation errors if any\n",
    "    if validation_errors:\n",
    "        loader.value = ''\n",
    "        error_items = '<br>'.join([f' {err}' for err in validation_errors])\n",
    "        result_output.value = f'''\n",
    "        <div style=\"background: rgba(183, 28, 28, 0.2); \n",
    "                    padding: 25px; \n",
    "                    border-radius: 12px; \n",
    "                    border: 2px solid rgba(244, 67, 54, 0.5);\n",
    "                    text-align: center;\">\n",
    "            <h4 style=\"color: #ff6b6b; margin: 0 0 15px 0; font-size: 20px;\"> Validation Failed</h4>\n",
    "            <div style=\"background: rgba(0, 0, 0, 0.3);\n",
    "                        padding: 15px;\n",
    "                        border-radius: 8px;\n",
    "                        text-align: left;\">\n",
    "                <p style=\"color: #ffcdd2; margin: 0; line-height: 1.8; font-size: 14px;\">\n",
    "                    {error_items}\n",
    "                </p>\n",
    "            </div>\n",
    "        </div>\n",
    "        '''\n",
    "        status_label.value = '''\n",
    "        <div style=\"text-align: center; \n",
    "                    color: #ff6b6b; \n",
    "                    font-size: 15px; \n",
    "                    padding: 10px; \n",
    "                    background: rgba(244, 67, 54, 0.1); \n",
    "                    border-radius: 8px; \n",
    "                    border: 1px solid rgba(244, 67, 54, 0.3);\">\n",
    "             Validation failed - Please fix errors\n",
    "        </div>\n",
    "        '''\n",
    "        submit_button.disabled = False\n",
    "        file_upload.disabled = False\n",
    "        question_input.disabled = False\n",
    "        return\n",
    "    \n",
    "    # Process the form\n",
    "    try:\n",
    "        result = process_form(fileContent, file_name, question)\n",
    "        result_output.value = result\n",
    "        status_label.value = '''\n",
    "        <div style=\"text-align: center; \n",
    "                    color: #ff8c00; \n",
    "                    font-size: 15px; \n",
    "                    padding: 10px; \n",
    "                    background: rgba(255, 140, 0, 0.1); \n",
    "                    border-radius: 8px; \n",
    "                    border: 1px solid rgba(255, 140, 0, 0.3);\">\n",
    "             Successfully completed\n",
    "        </div>\n",
    "        '''\n",
    "    except Exception as e:\n",
    "        result_output.value = f'''\n",
    "        <div style=\"background: rgba(183, 28, 28, 0.2); \n",
    "                    padding: 25px; \n",
    "                    border-radius: 12px; \n",
    "                    border: 2px solid rgba(244, 67, 54, 0.5);\n",
    "                    text-align: center;\">\n",
    "            <h4 style=\"color: #ff6b6b; margin: 0 0 15px 0;\"> Processing Error</h4>\n",
    "            <p style=\"color: #ffcdd2; margin: 0;\">{str(e)}</p>\n",
    "        </div>\n",
    "        '''\n",
    "        status_label.value = '''\n",
    "        <div style=\"text-align: center; \n",
    "                    color: #ff6b6b; \n",
    "                    font-size: 15px; \n",
    "                    padding: 10px; \n",
    "                    background: rgba(244, 67, 54, 0.1); \n",
    "                    border-radius: 8px; \n",
    "                    border: 1px solid rgba(244, 67, 54, 0.3);\">\n",
    "             Processing error occurred\n",
    "        </div>\n",
    "        '''\n",
    "    finally:\n",
    "        # Hide loader and re-enable controls\n",
    "        loader.value = ''\n",
    "        submit_button.disabled = False\n",
    "        file_upload.disabled = False\n",
    "        question_input.disabled = False\n",
    "\n",
    "# Attach event handler\n",
    "submit_button.on_click(on_submit_clicked)\n",
    "\n",
    "# Build complete application\n",
    "app_header = widgets.HTML(\n",
    "    custom_css + '''\n",
    "    <div class=\"app-title\"> Medical Visual Question</div>\n",
    "    <div class=\"app-subtitle\">Upload your medical image (JPG/PNG) and ask questions to get intelligent insights</div>\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Assemble all sections\n",
    "main_app = widgets.VBox([\n",
    "    app_header,\n",
    "    input_section,\n",
    "    action_section,\n",
    "    loader_section,\n",
    "    output_section\n",
    "], layout=widgets.Layout(\n",
    "    padding='40px',\n",
    "    background='#00233c',\n",
    "    border_radius='20px',\n",
    "    box_shadow='0 15px 35px rgba(0,0,0,0.4)',\n",
    "    max_width='900px',\n",
    "    margin='30px auto'\n",
    "))\n",
    "\n",
    "# Display the application\n",
    "display(main_app)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536794f7-05a3-4d60-94b1-befb712f5eb9",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.9 Sample questions</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Here are some sample questions, you can download test files from <code>test_images</code> folder</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;'>\n",
    "<li>Where are liver stem cells (oval cells) located? </li>\n",
    "<li>What are stained here with an immunohistochemical stain for cytokeratin 7?</li>\n",
    "<li>What do the areas of white chalky deposits represent? </li>\n",
    "<li>Is embolus derived from a lower - extremity deep venous thrombus lodged in a pulmonary artery branch?</li>\n",
    "<li>How is hyperplasia without atypia characterized? </li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814b344e-4c63-42ea-9eb9-83b1f710304d",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none'>\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>6. Cleanup</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>6.1 Delete your OAF Container</b></p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">Executing this cell is optional. If you will be executing more OAF use cases, you can leave your OAF environment.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417cffd8-b51a-448e-894c-61d73095bc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove your default user environment\n",
    "\n",
    "try:\n",
    "    result = remove_env(environment_name)\n",
    "    print(f\"Environment {environment_name} removed!\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not remove the environment, {environment_name}!\")\n",
    "    print(\"Error:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396e871d-569b-4945-965b-49dc05e8a414",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>6.2 Remove your database Context</b></p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">Please remove your context after you've completed this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702aa192-b673-42d1-a4a1-fbc01dfe36b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    result = remove_context()\n",
    "    print(\"Context removed!\")\n",
    "except Exception as e:\n",
    "    print(\"Could not remove the Context!\")\n",
    "    print(\"Error:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbd137a-7bfc-49fa-a18e-ca34ba68919d",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial;'>Dataset:</b>\n",
    "<br>\n",
    "<br>\n",
    "<p style='font-size: 16px; font-family: Arial;'>The dataset is sourced from <a href='https://www.consumerfinance.gov/data-research/consumer-complaints/'>Consumer Financial Protection Bureau</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bdc0df-dc13-4a13-bf73-c7039a54c3ba",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright  Teradata Corporation - 2025. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbd80de",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
