{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9944e564-a16d-44fb-b9e0-0dd16a45eb1f",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "        RAG with TeradataVectorStore-Langchain\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ed6f6f-da47-40ca-8877-6849fc54060a",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px;font-family:Arial\"><b>Introduction</b></p>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Vector stores are specialized databases designed for efficient storage, indexing, and searching of high-dimensional vector embeddings. These embeddings, generated by AI models, enable similarity search and power applications in machine learning, NLP, recommendation systems, and image/video retrieval.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "This notebook demonstrates comprehensive LangChain-style workflows using the TeradataVectorStore for embedding-based Vector Store\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "<p style=\"font-size:20px;font-family:Arial\"><b>Key Concepts</b></p>\n",
    "\n",
    "<p style=\"font-size:18px;font-family:Arial\"><b>What is a Vector Store?</b></p>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "A vector store contains a vectorized representation of data, typically created using embeddings from AI models. It allows for high-speed similarity searches beyond traditional keyword matching.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Vector embeddings are numerical representations of data (text, images, audio, etc.) mapped into a multi-dimensional space.\n",
    "</p>\n",
    "\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Each embedding is a vector that captures semantic or content-based relationships. For example:\n",
    "</p>\n",
    "\n",
    "<table style=\"font-size:16px;font-family:Arial;border:1px solid black;\">\n",
    "  <tr>\n",
    "    <th style=\"border:1px solid black;padding:5px;\">Data Type</th>\n",
    "    <th style=\"border:1px solid black;padding:5px;\">Example</th>\n",
    "    <th style=\"border:1px solid black;padding:5px;\">Vector Representation</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border:1px solid black;padding:5px;\">Text</td>\n",
    "    <td style=\"border:1px solid black;padding:5px;\">\"King\"</td>\n",
    "    <td style=\"border:1px solid black;padding:5px;\">[0.12, 0.45, 0.67, ...]</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border:1px solid black;padding:5px;\">Image</td>\n",
    "    <td style=\"border:1px solid black;padding:5px;\">A picture of a cat</td>\n",
    "    <td style=\"border:1px solid black;padding:5px;\">[0.23, 0.78, 0.55, ...]</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "<b>Embedding Generation is carried out by AI_TextEmbedding Function </b>\n",
    "<ul style=\"font-size:16px;font-family:Arial\">\n",
    "  <li>Enables text embedding generation using LLMs hosted.</b> (Performs a full-table scan)</li>\n",
    "    <li> Accepts different parameters, model endpoint, key, model args etc.</li>\n",
    "\n",
    "<p style=\"font-size:18px;font-family:Arial\"><b>Vector Search</b></p>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Unlike traditional search methods, vector search understands the meaning behind a query. It provides relevant results by analyzing semantic relationships rather than exact keyword matches.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Common types of embeddings include:\n",
    "</p>\n",
    "\n",
    "<ul style=\"font-size:16px;font-family:Arial\">\n",
    "<li>Word Embeddings</li>\n",
    "<li>Sentence Embeddings</li>\n",
    "<li>Document Embeddings</li>\n",
    "<li>Image Embeddings</li>\n",
    "<li>Audio Embeddings</li>\n",
    "</ul>\n",
    "\n",
    "---\n",
    "\n",
    "<p style=\"font-size:20px;font-family:Arial\"><b>Vector Store in the Teradata Database</b></p>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "A vector in Teradata is a specialized column type called <b>Vector</b>.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "The <b>vector store</b> in Teradata consists of schemas and tables that enable vector search functionality.\n",
    "</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p style=\"font-size:20px;font-family:Arial\"><b>Vector Search Algorithms</b></p>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Teradata supports three main search algorithms:\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:18px;font-family:Arial\"><b>1. VectorDistance</b></p>\n",
    "<ul style=\"font-size:16px;font-family:Arial\">\n",
    "  <li><b>Flat index</b> (performs a full-table scan)</li>\n",
    "  <li><b>Scalable and parallel search</b></li>\n",
    "  <li><b>Exact search approach</b></li>\n",
    "  <li>Suitable for <b>smaller datasets (<10K documents)</b></li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"font-size:18px;font-family:Arial\"><b>2. Kmeans</b></p>\n",
    "<ul style=\"font-size:16px;font-family:Arial\">\n",
    "  <li><b>IVF (Inverted Vector File) index</b> (organizes data into clusters)</li>\n",
    "  <li><b>Scalable and parallel training/search</b></li>\n",
    "  <li><b>Approximate search approach</b></li>\n",
    "  <li>Suitable for <b>larger datasets (>10K documents)</b></li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"font-size:18px;font-family:Arial\"><b>3. HNSW</b></p>\n",
    "<ul style=\"font-size:16px;font-family:Arial\">\n",
    "  <li><b>HNSW (Hierarchical Navigable Small World) index</b></li>\n",
    "  <li><b>Graph-based Approximate Nearest Neighbors (ANN) search</b></li>\n",
    "  <li><b>Scalable and parallel training/search</b></li>\n",
    "  <li><b>Approximate search approach</b></li>\n",
    "  <li>Suitable for <b>larger datasets (>10K documents)</b></li>\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "<p style=\"font-size:20px;font-family:Arial\"><b>Types of Vector Store</b></p>\n",
    "\n",
    "<table style=\"font-size:15px; font-family:Arial; width:100%; border:1px solid #ddd; border-collapse:collapse;\">\n",
    "  <tr>\n",
    "    <th style=\"padding:10px; text-align:left; border:1px solid #ddd;\">Type</th>\n",
    "    <th style=\"padding:10px; text-align:left; border:1px solid #ddd;\">Description</th>\n",
    "    <th style=\"padding:10px; text-align:left; border:1px solid #ddd;\">Use Case</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"padding:10px; border:1px solid #ddd;\"><b>1. Content-Based</b></td>\n",
    "    <td style=\"padding:10px; border:1px solid #ddd;\">Built on the <b>contents of a table</b> (or file/PDF converted to a table). Queries return the <b>top relevant rows</b> based on similarity.</td>\n",
    "    <td style=\"padding:10px; border:1px solid #ddd;\">Can be combined with <b>LLM-generated textual responses</b> for more accurate answers.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"padding:10px; border:1px solid #ddd;\"><b>2. Metadata-Based</b></td>\n",
    "    <td style=\"padding:10px; border:1px solid #ddd;\">Built on the <b>metadata</b> of tables. Queries return the <b>top matching tables</b> based on similarity. Used in <b>SQL generation</b> for data retrieval.</td>\n",
    "    <td style=\"padding:10px; border:1px solid #ddd;\">Helps form textual responses by retrieving data from relevant tables for more precise answers.</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td style=\"padding:10px; border:1px solid #ddd;\"><b>3. File-Based</b></td>\n",
    "    <td style=\"padding:10px; border:1px solid #ddd;\">Built from contents of PDF file. Queries return the <b>top relevant rows</b> based on similarity.</td>\n",
    "    <td style=\"padding:10px; border:1px solid #ddd;\">Can be combined with <b>LLM-generated textual responses</b> for more accurate answers.</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td style=\"padding:10px; border:1px solid #ddd;\"><b>4. Embedding-Based</b></td>\n",
    "    <td style=\"padding:10px; border:1px solid #ddd;\">Built from the <b>user generated embeddings</b> . Queries return the <b>top relevant rows</b> based on similarity.</td>\n",
    "    <td style=\"padding:10px; border:1px solid #ddd;\">Can be combined with <b>LLM-generated textual responses</b> for more accurate answers.</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d29c1e-2ba2-4b40-8834-e0fd6fe574f3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial'><b>What You Will Do in This Notebook</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "This notebook demonstrates comprehensive LangChain-style workflows using the TeradataVectorStore for content-based Vector Store and ask APIs. By the end of this tutorial, you will have gained hands-on experience with creating content-based vector store objects as well as asking questions and performing similarity searches.\n",
    "</p>\n",
    "\n",
    "<div style = 'font-size:16px;font-family:Arial'>\n",
    "<ol>\n",
    "<li>\n",
    "<b>Installing latest langchain-teradata</b>\n",
    "</li>\n",
    "<li>\n",
    "<b>Creating an instance of an Embedding-Based Vector Store</b>\n",
    "</li>\n",
    "<li>\n",
    "<b>Using existing Vector Store</b>\n",
    "</li>\n",
    "<li>\n",
    "<b>Updating Vector Store</b>\n",
    "</li>\n",
    "<li>\n",
    "<b>Performing Similarity Search by Vector</b>\n",
    "</li>\n",
    "<li>\n",
    "<b>Destroying Vector Store</b>\n",
    "</li>\n",
    "</ol>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ba9d27-5c5e-468a-a17d-0e3625c5982b",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none'>\n",
    "<b style = 'font-size:20px;font-family:Arial'>1. Configure the environment</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9d8f34-785a-45f5-97cb-c36ed7f2ae3a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'> For this notebook to run properly we will need teradataml version 20.00.00.05 or greater and teradatagenai version 20.00.00.1 or greater; below command will check the versions and install required versions</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3ae7c9-ef1e-4eb8-9958-cbe06e423b92",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Installing latest langchain-teradata</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dfa0bf-2557-43b2-8bab-175f69463ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langchain-teradata langchain --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8c7c2b-0216-451c-b5e5-8972c51fbe63",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial'>1.1 Import necessary modules</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2016c4-a193-4fdd-8ba7-28fb5a769935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from getpass import getpass\n",
    "# Required imports\n",
    "from teradatagenai import VSManager, TeradataAI, TextAnalyticsAI, load_data\n",
    "from teradataml import create_context, DataFrame, in_schema, remove_context, execute_sql, set_auth_token\n",
    "from langchain_teradata import TeradataVectorStore\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "display.suppress_vantage_runtime_warnings = True\n",
    "warnings.filterwarnings(\"ignore\", message=\"Vector Store .* does not exist. Call create\\(\\) to create the same.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561440c8-a673-46c6-a9bc-c0141ead34b1",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-;\">\n",
    "<b style = 'font-size:18px;font-family:Arial;'>1.2 Initiate a connection to Vantage</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be901ca-f493-4ed4-b172-d09344bc1b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking if this environment is ready to connect to VantageCloud Lake...\")\n",
    "\n",
    "if os.path.exists(\"/home/jovyan/JupyterLabRoot/VantageCloud_Lake/.config/.env\"):\n",
    "    print(\"Your environment parameter file exist.  Please proceed with this use case.\")\n",
    "    # Load all the variables from the .env file into a dictionary\n",
    "    env_vars = dotenv_values(\"/home/jovyan/JupyterLabRoot/VantageCloud_Lake/.config/.env\")\n",
    "    # Create the Context\n",
    "    eng = create_context(host=env_vars.get(\"host\"), username=env_vars.get(\"username\"), password=env_vars.get(\"my_variable\"))\n",
    "    execute_sql('''SET query_band='DEMO=VCL_GettingStarted_VectorStore.ipynb;' UPDATE FOR SESSION;''')\n",
    "    print(\"Connected to VantageCloud Lake with:\", eng)\n",
    "else:\n",
    "    print(\"Your environment has not been prepared for connecting to VantageCloud Lake.\")\n",
    "    print(\"Please contact the support team.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a53b171-35c9-45d2-922b-fd0e0968a947",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style=\"font-size:20px;font-family:Arial\"><b>2. Authenticate into User Environment Service (UES) </b></p>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\"><b>UES authentication</b> is required to create and manage the Python or R environments that we will be creating.  A VantageCloud Lake user can easily create the authentication objects using the Console in a VantageCloud Lake environment.  The step to create these authentication objects has already been performed for you.\n",
    "</p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "   \n",
    "<ul style=\"font-size:16px;font-family:Arial; margin-top:4px;\">\n",
    "  <li><a href=\"https://docs.teradata.com/r/Teradata-VantageCloud-Lake/Analyzing-Your-Data/Teradata-Package-for-Python-on-VantageCloud-Lake/Working-with-Open-Analytics/APIs-to-Use-with-Open-Analytics-Framework/API-to-Set-Authentication-Token/set_auth_token\">Click here</a> to see more details about using the Teradata APIs to set the authentication objects.</li>\n",
    "\n",
    "  <li>Check out <a href=\"https://medium.com/teradata/deploy-hugging-face-llms-on-teradata-vantagecloud-lake-with-nvidia-gpu-acceleration-d94d999edaa5\">Step 4</a> of this tutorial to to see more details about configuring a VantageCloud Lake Environment to use our Open Analytics Framework</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b608a011-5327-4a64-a8c2-35632a5be7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've already loaded all the values into our environment variables and into a dictionary, env_vars.\n",
    "# username=env_vars.get(\"username\") isn't required when using base_url, pat and pem.\n",
    "ues_uri=env_vars.get(\"ues_uri\")\n",
    "if ues_uri.endswith(\"/open-analytics\"):\n",
    "    ues_uri = ues_uri[:-15]   # remove last 5 chars (\"/open-analytics\")\n",
    "\n",
    "if set_auth_token(base_url=ues_uri,\n",
    "                  pat_token=env_vars.get(\"access_token\"), \n",
    "                  pem_file=env_vars.get(\"pem_file\")\n",
    "                 ):\n",
    "    print(\"UES Authentication successful\")\n",
    "else:\n",
    "    print(\"UES Authentication failed. Check credentials.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4619607f-46c4-4135-bdd6-ed1ca8a26040",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>3. Create a Vector Store</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61ab1c3",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:16px;font-family:Arial'>3.1 ðŸ›  Instantiating an Embedding Based Vector Store using <code>from_embeddings</code> method.</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>We can create an instance of a embedding-based Vector Store directly using the <code>from_embeddings</code> of the VectorStore class.</p>\n",
    "\n",
    "**from_embeddings()**  \n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "   <li>Creates a new 'embedding-based' vector store from the input dataset(s) containing table(s) or teradataml DataFrames(s) that contain pre generated embeddings.</li>\n",
    "   <li><code>name</code>, <code>data</code> and <code>data_columns/<code> are mandatory arguments and we can also provide other arguments related to creation and search metrics.</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9776bfa-3b6d-47d3-bd61-3c7adbfb9dff",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>There are two ways in which user can get the embeddings </p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li>User can bring their own embeddings to vector store.</li>\n",
    "    <li>User can use TextAnalyticsAI to generate embeddings as one of the way to generate embeddings outside of vector store.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7a288b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Generate the embeddings for articles column of employee_data using teradatagenai's Text Analytics capabilities.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5953e628-d3b5-4449-a031-38375ce009e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = getpass(prompt='AWS_ACCESS_KEY_ID: ')\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = getpass(prompt='AWS_SECRET_ACCESS_KEY: ') \n",
    "\n",
    "# Not required unless using temporary credentials.\n",
    "os.environ[\"AWS_SESSION_TOKEN\"] = getpass(prompt='AWS_SESSION_TOKEN: ')\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = getpass(prompt='AWS_DEFAULT_REGION: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2439e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradatagenai import VSManager, TeradataAI, TextAnalyticsAI, load_data\n",
    "\n",
    "# Instantiate the TeradataAI class with the Amazon Bedrock model.\n",
    "llm_embedding = TeradataAI(api_type=\"aws\",                      \n",
    "               model_name=\"amazon.titan-embed-text-v2:0\",\n",
    "               region=\"us-east-1\")\n",
    "\n",
    "# Instantiate the TextAnalyticsAI class with the embedding model.\n",
    "obj_embeddings = TextAnalyticsAI(llm=llm_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27488d6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Creating embeddings-based Vector Store when embedded data is available in a table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb50849",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data('amazon', 'amazon_reviews_embedded')\n",
    "amazon_reviews_embedded = DataFrame('amazon_reviews_embedded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829de508",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_reviews_embedded.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d4e939",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_amazon_review = TeradataVectorStore.from_embeddings(name = \"vs_example_embed\",\n",
    "                                                   data = amazon_reviews_embedded,\n",
    "                                                   data_columns = \"embedding\",\n",
    "                                                   embedding_data_columns = \"rev_text\",\n",
    "                                                   metadata_columns = [\"rating\", \"prodsummary\"],\n",
    "                                                   key_columns = [\"rev_id\", \"aid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08fa9d8-73dd-4ba1-86ad-54629ab87dc2",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:16px;font-family:Arial'>3.2 Check the Status</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Check the current status of the Teradata Vector Store after it has been created. This step ensures that the Vector Store has been successfully initialized and is ready for processing queries.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>This cell will loop every 15 seconds to check the status, Move on to next cell when the status shows as - <code>READY</code></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeede89-7160-4aae-943d-502e0aec7485",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = vs_amazon_review.status()\n",
    "\n",
    "while True:\n",
    "    if df is not None:\n",
    "        if df.loc[0, 'status'] == 'READY':\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Current status: {df.loc[0, 'status']}. Waiting 15 seconds...\")\n",
    "            time.sleep(15)\n",
    "            df = vs_amazon_review.status()\n",
    "    else:\n",
    "        time.sleep(15)\n",
    "\n",
    "print(f\"The Vector Store Database: {df.loc[0,'vs_name']} is {df.loc[0, 'status']}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91333de",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_amazon_review.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5c2948",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>4. Using the Vector Store Instance as a Retriever</b>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>A <b>vector store retriever</b> allows you to leverage your embedding-based vector store for semantic search and retrieval in LangChain workflows. This enables you to fetch the most relevant documents from your dataset based on vector similarity, making it ideal for question answering, RAG (Retrieval-Augmented Generation), and more.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>How It Works</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;'>\n",
    "    <li><b>Initialize the Retriever:</b>  \n",
    "   Use the <code>.as_retriever()</code> method on your <code>TeradataVectorStore</code> instance.  \n",
    "   You can specify the <code>search_type</code> (e.g., <code>\"similarity\"</code> or <code>\"similarity_score_threshold\"</code>).</li>\n",
    "\n",
    "   <li><b>Invoke the Retriever:</b>\n",
    "   Pass your query to the retriever to get the most relevant documents.</li>\n",
    "\n",
    "   <li><b>Integrate with Chains:</b>\n",
    "   The retriever can be used as a component in LangChain chains for advanced workflows, such as RAG pipelines.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfed70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vs_amazon_review.as_retriever(search_type=\"similarity\",search_kwargs={\"top_k\":4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1be2ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(\"Wonderful product, very useful and well made.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ac5c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a35ef6-a656-429e-a1d6-f6a40611006c",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:16px;font-family:Arial'>4.1 Retrieval-Augmented Generation (RAG)</b>\n",
    "    \n",
    "<p style=\"font-size:16px;font-family:Arial;\">Retrieval-Augmented Generation (RAG) is the technique that powers most modern AI assistants and chatbots. <strong>TeradataVectorStore</strong> integrates seamlessly with <strong>LangChain</strong> to make building RAG applications straightforward.</p>\n",
    "    \n",
    "<h3 style=\"font-size:16px;font-family:Arial;\">What makes a good RAG application:</h3>\n",
    "    <ul style=\"font-size:16px;font-family:Arial;\">\n",
    "        <li><strong>Relevant retrieval:</strong> Your vector store finds the right information.</li>\n",
    "        <li><strong>Contextual generation:</strong> The language model uses that information effectively.</li>\n",
    "        <li><strong>Source transparency:</strong> Users can see where answers come from.</li>\n",
    "    </ul>\n",
    "    \n",
    "<h3 style=\"font-size:16px;font-family:Arial;\">How it works with TeradataVectorStore:</h3>\n",
    "   <p style=\"font-size:16px;font-family:Arial;\">You can use your vector store as a retriever to get the most relevant documents, then pass those documents to a RAG chain within LangChain workflows. This gives you the flexibility to build custom pipelines while leveraging Teradataâ€™s powerful vector search capabilities.</p>\n",
    "    \n",
    "   <p style=\"font-size:16px;font-family:Arial;\"><strong>Now letâ€™s build a complete RAG pipeline</strong> that combines your TeradataVectorStore retriever with a language model. This demonstrates the full power of RAG - retrieving relevant information from your vector store and using it to generate informed responses.</p>\n",
    "    \n",
    "   <h3 style=\"font-size:16px;font-family:Arial;\">Whatâ€™s happening in this pipeline:</h3>\n",
    "    <ul style=\"font-size:16px;font-family:Arial;\">\n",
    "        <li><strong>Retrieval:</strong> Your vector store finds the most relevant documents for the question.</li>\n",
    "        <li><strong>Context preparation:</strong> Those documents become context for the language model.</li>\n",
    "        <li><strong>Generation:</strong> The LM generates an answer based on your actual data.</li>\n",
    "        <li><strong>Output parsing:</strong> Clean, formatted response ready for your application.</li>\n",
    "    </ul>\n",
    "    \n",
    "   <h3 style=\"font-size:16px;font-family:Arial;\">Real-world applications:</h3>\n",
    "   <ul style=\"font-size:16px;font-family:Arial;\">\n",
    "        <li><strong>Customer support:</strong> Answer questions using your product documentation.</li>\n",
    "        <li><strong>Research assistance:</strong> Query your organizationâ€™s knowledge repositories.</li>\n",
    "        <li><strong>Compliance:</strong> Ensure responses are based on approved company information.</li>\n",
    "    </ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7664beff-d90c-4650-8c2a-751fb8d4ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chat_models import init_chat_model\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "#Example: Simple RAG chain\n",
    "# Initialize the chat model\n",
    "llm = init_chat_model(\"anthropic.claude-3-5-sonnet-20240620-v1:0\", \n",
    "                      model_provider=\"bedrock_converse\", \n",
    "                      region_name=\"us-east-1\",\n",
    "                      )\n",
    "\n",
    "\n",
    "# Create a prompt template for the LLM to format its response using retrieved context\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"You're working as business analyst.Use the following context to answer the question. Keep answer in proper markdown format. \\nContext:\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    ")\n",
    "\n",
    "# Build the RAG chain: retrieve context, format prompt, generate answer, and parse output\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Invoke the RAG chain with a sample question and print the response\n",
    "response = rag_chain.invoke(\"How many products have amazing reviews?\")\n",
    "# print(response)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844dbfd4",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:16px;font-family:Arial'>4.1 Destroying the Vector Store</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1771337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup \n",
    "vs_amazon_review.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06efbd8b-5412-4f81-8082-c9adf1a7e190",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:16px;font-family:Arial'>4.2 Disconnect</b>  \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'><b>Terminate All Active Connections</b> - This operation terminates all active connections to the vector store database.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f52c04-7d6e-46ce-b8bf-51b3834ec7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "VSManager.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dfdd43-7119-4823-98ee-22d9f01fd094",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e4fdae-f512-430a-ba4b-53083a4ec2e2",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; border-bottom:3px solid #91A0Ab\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analyticsâ„¢</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright Â© Teradata Corporation - 2026. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
