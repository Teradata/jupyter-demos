{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f51cd2f7-a4c4-4edf-848a-b46e3cdd651b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Unstructured Text Analysis With BYO-LLM and NVIDIA GPU Acceleration\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a701f80-07b2-47ad-b2fd-2dcc597b97b2",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px;font-family:Arial\"><b>Introduction:</b></p>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "This notebook is designed for developers, data scientists, and AI practitioners who want to bring open-source Language Models (LMs) and Large Language Models (LLMs) closer to their data ‚Äî quickly, securely, and at scale. As organizations race to deploy AI applications, developers face key challenges: selecting the right model, minimizing data movement, ensuring security, and controlling costs.  Teradata‚Äôs Bring Your Own LLM (BYO-LLM) capability addresses these challenges by allowing you to deploy open-source <b>Hugging Face</b> models directly inside VantageCloud ‚Äî where your data already lives.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:18px;font-family:Arial\"><b>What is BYO-LLM?</b></p>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "<b>BYO-LLM</b> (Bring Your Own Large Language Model) is one of the VantageCloud Open Analytic Framework (OAF) key capabilities you‚Äôll use in this notebook which gives developers complete control over AI deployment in VantageCloud:\n",
    "</p>\n",
    "\n",
    "<ul style=\"font-size:16px;font-family:Arial\">\n",
    "    <li>Seamlessly integrate open-source models from Hugging Face</li>\n",
    "    <li>Eliminate the need to move data ‚Äî reducing cost and compliance risk</li>\n",
    "    <li>Leverage GPU acceleration for inference speeds up to 200x faster than CPU</li>\n",
    "    <li>Experiment freely without vendor lock-in, while keeping your data secure and your operations scalable</li>\n",
    "</ul>\n",
    "\n",
    "<img src=\"BYOLLM_Flow.png\" alt=\"Architecture for BYOLLM\" style=\"width: 90%\">\n",
    "<p style=\"font-size:18px;font-family:Arial;\"><b>Business Impact of Open Source Language Models (LMs) for NLP tasks such as Unstructured Text Analysis?</b></p>\n",
    "\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Language Models (LMs) are the foundation for solving Natural Language Processing (NLP) tasks such as unstructured text analysis ‚Äî enabling machines to understand, interpret, and generate human language. Language Models enable businesses to:\n",
    "</p>\n",
    "\n",
    "<ul style=\"font-size:16px;font-family:Arial\">\n",
    "    <li>Extract key information from documents, contracts, and research papers</li>\n",
    "    <li>Analyze customer feedback from emails, reviews, and social media</li>\n",
    "    <li>Power chatbots and virtual assistants for real-time support</li>\n",
    "    <li>Personalize marketing and customer experiences based on user interactions</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Through unstructured text analysis and open source LMs, businesses can:\n",
    "</p>\n",
    "<ul style=\"font-size:16px;font-family:Arial\">\n",
    "    <li>Improve operational efficiency through automation</li>\n",
    "    <li>Gain real-time insights into customer sentiment and behavior</li>\n",
    "    <li>Respond proactively to customer concerns</li>\n",
    "    <li>Stay competitive by adapting to market and customer trends</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329b1b1e-8041-4462-899a-04b52fabbed2",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none'>\n",
    "<b style = 'font-size:20px;font-family:Arial'>1. Configure the environment</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d758939-6961-4091-918d-a0663c7a633c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9ed189-0658-444f-bb1f-085ec3a0487e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import teradataml\n",
    "import getpass\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from teradataml import *\n",
    "from teradatasqlalchemy.types import *\n",
    "from IPython.display import display as ipydisplay\n",
    "from os.path import expanduser\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172733fa-6761-415c-9b61-68c5fd271a70",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"height:2px;border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>2. Connect to VantageCloud Lake</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Connect to VantageCloud using `create_context` from the teradataml Python library. Input your connection details, including the host, username, password and Analytic Compute Group name.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd733f5-3176-4e9b-92b4-534b04c3f3bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the database/user_name|password from the environment.\n",
    "print(\"Creating the context...\") \n",
    "\n",
    "load_dotenv(\"../.config/.env\", override=True)\n",
    "host = os.getenv(\"host\")\n",
    "username = os.getenv(\"username\")\n",
    "my_variable = os.getenv(\"my_variable\")\n",
    "\n",
    "eng = create_context(host=host, username=username, password=my_variable)\n",
    "print(\"Connected to Teradata:\", eng)\n",
    "\n",
    "execute_sql('''SET query_band='DEMO=Entity_Recognition_BYOLLM_VCL.ipynb;' UPDATE FOR SESSION;''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca87760f-a031-4353-acc2-8a5cfc1d5f15",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "\n",
    "<p style=\"font-size:20px; font-family:Arial\"><b>3. Getting Data for  for In-Database NLP tasks</b></p>\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "We have provided data for this demo on an OFS table <code>financial_entity_dataset</code> inside the default <code>DEMO_EntityRecognition</code> database.\n",
    "</p>\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "<b>üíº Use Case Summary:</b><br>\n",
    "In the wealth management industry, financial advisors hold many client meetings each week ‚Äî discussing portfolios, insurance, loans, and retirement planning. Manually summarizing and tagging these interactions for compliance, CRM updates, or follow-up actions is time-consuming and often inconsistent.\n",
    "</p>\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "With Teradata‚Äôs BYO-LLM capability, we can deploy an Open Source Hugging Face model directly within VantageCloud ‚Äî where the client interaction data already resides.  In this demo, we‚Äôll perform Named Entity Recognition (NER) with <a href=\"https://huggingface.co/tner/roberta-large-ontonotes5\" target=\"_blank\">tner/roberta-large-ontonotes5</a> for Extracting Key Phrases such as:\n",
    "\n",
    "<ul style=\"font-size:16px; font-family:Arial\">\n",
    "  <li>Client names</li>\n",
    "  <li>Financial institutions</li>\n",
    "  <li>Product types</li>\n",
    "  <li>Key dates</li>\n",
    "</ul> \n",
    "\n",
    "</p>\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "This helps financial firms:\n",
    "<ul style=\"font-size:16px; font-family:Arial\">\n",
    "  <li>Automate meeting note tagging for faster documentation and regulatory compliance</li>\n",
    "  <li>Enhance client profiling by identifying frequently discussed financial topics</li>\n",
    "  <li>Streamline CRM updates by structuring insights from unstructured text</li>\n",
    "</ul>\n",
    "</p>\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "All of this is achieved securely ‚Äî without moving data ‚Äî and using open-source models, giving teams full control, scalability, and flexibility.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d19cc1f-b730-4546-801c-f70fb6ea7f0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a teradataml dataframe using sample data in an OFS table.\n",
    "call_summary_dataset = DataFrame(in_schema(\"DEMO_EntityRecognition\",\"Financial_CallCenter_Summary\"))\n",
    "call_summary_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710b7ade-3ded-4882-8c3c-ef522918d98d",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style=\"font-size:20px;font-family:Arial\"><b>4. Authenticate into User Environment Service (UES) for Container Management</b></p>\n",
    "<p style=\"font-size:16px; font-family:Arial;\">\n",
    "  The <code>teradataml</code> library offers simple yet powerful methods for creating and managing custom Python runtime environments within VantageCloud. This gives developers full control over model behavior, performance, and analytic accuracy when running on the Analytic Cluster.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial;\">\n",
    "  Custom environments are persistent‚Äîcreated once and reused as needed. They can be saved, updated, or modified at any time, allowing for efficient and flexible environment management.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:18px; font-family:Arial; color:#00233C;\">\n",
    "  <b>Container Management Process</b>\n",
    "</p>\n",
    "\n",
    "<table style=\"width:100%; table-layout:fixed;\">\n",
    "  <tr>\n",
    "    <td style=\"vertical-align:top;\" width=\"40%\">\n",
    "      <ol style=\"font-size:16px; font-family:Arial; color:#00233C;\">\n",
    "        <li>Create a unique User Environment based on available base images</li>\n",
    "        <li>Install libraries</li>\n",
    "        <li>Install models and additional user artifacts</li>\n",
    "      </ol>\n",
    "    </td>\n",
    "    <td>\n",
    "      <img src=\"OAF_Env.png\" width=\"600\" alt=\"Container Management Diagram\">\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "<b>UES authentication</b> is required to create and manage the Python or R environments that we will be creating.  A VantageCloud Lake user can easily create the authentication objects using the Console in a VantageCloud Lake environment.  The step to create these authentication objects has already been performed for you.\n",
    "</p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "   \n",
    "<ul style=\"font-size:16px;font-family:Arial; margin-top:4px;\">\n",
    "  <li><a href=\"https://docs.teradata.com/r/Teradata-VantageCloud-Lake/Analyzing-Your-Data/Teradata-Package-for-Python-on-VantageCloud-Lake/Working-with-Open-Analytics/APIs-to-Use-with-Open-Analytics-Framework/API-to-Set-Authentication-Token/set_auth_token\">Click here</a> to see more details about using the Teradata APIs to set the authentication objects.</li>\n",
    "\n",
    "  <li>Check out <a href=\"https://medium.com/teradata/deploy-hugging-face-llms-on-teradata-vantagecloud-lake-with-nvidia-gpu-acceleration-d94d999edaa5\">Step 4</a> of this tutorial to to see more details about configuring a VantageCloud Lake Environment to use our Open Analytics Framework</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a7aac9-5f6f-4bc3-805c-be9e3192b9bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the values for the Open Analytics Endpoint, the Access Token and the location of the .pem file.\n",
    "# We also assign the name of our GPU Compute Group.\n",
    "\n",
    "open_analytics_endpoint = os.getenv(\"ues_uri\")\n",
    "access_token = os.getenv(\"access_token\")\n",
    "pem_file = os.getenv(\"pem_file\")\n",
    "gpu_compute_group = os.getenv(\"gpu_compute_group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d473a8-75b5-44a9-8682-f9b398fd8045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## uncomment to use personal access token and key \n",
    "configure.ues_url = open_analytics_endpoint\n",
    "if set_auth_token(ues_url=open_analytics_endpoint, username=username, pat_token=access_token, pem_file=pem_file):\n",
    "    print(\"UES Authentication successful\")\n",
    "else:\n",
    "    print(\"UES Authentication failed. Check credentials.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c955c8-8e55-4910-835f-2d2e8ff135a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "<p style=\"font-size:20px; font-family:Arial\"><b>5. Set Up the User Environment in Teradata VantageCloud Lake for Model Deployment</b></p>\n",
    "<p style=\"font-size:16px; font-family:Arial\">\n",
    "Now that <b>UES authentication</b> is complete, we can begin managing user environments using Teradata‚Äôs API capabilities.\n",
    "Start by listing the available user environments to see if an existing one can be reused. To select and work within an existing environment, use the <code><b>get_env<b></code> API method.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff69f8e-c3e8-4137-9293-1686b46294f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if I have any existing environments\n",
    "env_list = list_user_envs()\n",
    "if env_list is None:\n",
    "    print(\"This user does not have any environments. Please continue...\")\n",
    "else:\n",
    "    ipydisplay(env_list)\n",
    "    # Iterate over the env_name column and remove\n",
    "    for env_name in env_list['env_name']:\n",
    "        print(f\"Env Name: {env_name} is being removed!\")\n",
    "        remove_env(env_name)\n",
    "    print(\"Finished removing the environments.  Plese continue...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3013355-0786-44ac-ac8c-49db2b40b249",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "To create a new user environment, start by retrieving an available base python version.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2179aa-2aae-4dd4-b920-766fe9ae3907",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Listing the available base environments \n",
    "print(list_base_envs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1539ba-e9f2-46c0-a7cd-3bc51d6b1473",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Use the <a href =\"https://docs.teradata.com/r/Teradata-VantageCloud-Lake/Analyzing-Your-Data/Teradata-Package-for-Python-on-VantageCloud-Lake/Working-with-Open-Analytics/APIs-to-Use-with-Open-Analytics-Framework/APIs-to-Manage-User-Environments/create_env\"<code>create_env</code></a> API to assign a name, specify the version, and add a description for your new environment. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aaef62-8ca2-4803-bac6-7f621d30930e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Create a new python user environment by specifying a name, a version of python, and a description.\n",
    "env_name = username.replace(\"-\",\"_\")\n",
    "demo_env = create_env(env_name,\n",
    "                      base_env = 'python_3.10',\n",
    "                      desc = 'BYOLLM demo env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cb4e0e-6904-47f2-a5f0-02a916a1ffea",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Install the required libraries into your user environment on the GPU Compute Cluster. For most use cases involving Hugging Face, these will be the <b>transformers</b> and <b>torch</b> python libraries.  This could take up to 5 minutes to complete.  Please wait until you see the <b>Libraries installed</b> message.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8597547d-052e-4156-ae8d-84141df39383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lib_claim_id = ''\n",
    "lib_claim_id = demo_env.install_lib([\"transformers\", \"torch\"])\n",
    "print(\"Libraries installed\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807355be-718f-4dd0-9d9f-e77975fbd94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_env.status(lib_claim_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a36f5c-5e01-4394-af1b-63287ccd4bb6",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Now we can configure the TextAnalyticsAI object with the preferred large language model using the TeradataAI object. This will enable us to execute a variety of text analytics tasks. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a490a2a-7689-4485-abd0-76038627ed14",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none\">\n",
    "<p style=\"font-size:20px;font-family:Arial\"><b>6. Download the Hugging Face Language Model and upload to UES environment</b></p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "You can download Hugging Face LLMs in either <a href=\"https://docs.teradata.com/r/Teradata-VantageCloud-Lake/Analyzing-Your-Data/Build-Scalable-Analytics-with-Open-Analytics-Framework/Bring-Your-Own-LLM-and-DL-Workloads/Using-Hugging-Face-LLMs\"> native format or streamlined format</a>. Here we use the streamlined format to download the model which will download it to our local system directory.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e93477-8b8a-4b38-8487-1af3ba542a26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load model directly #save streamlined format under local path\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tner/roberta-large-ontonotes5\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"tner/roberta-large-ontonotes5\")\n",
    "\n",
    "tokenizer.save_pretrained(\"./roberta-large-ontonotes5\")\n",
    "model.save_pretrained(\"./roberta-large-ontonotes5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4c41ff-1dd3-4115-9fcd-9a6bf214d9ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Compress the model into zip file\n",
    "# For the use cases when the model folder is in another directory than the current directory, root_dir should be the abosulte path.\n",
    "import shutil\n",
    "shutil.make_archive('roberta-large-ontonotes5', format='zip', root_dir='roberta-large-ontonotes5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3be13a-b7e0-4e5c-a765-26bfbb47ba2f",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "After the LLM directories are compressed into zip files, you can use the <a href = \"https://docs.teradata.com/r/Teradata-VantageCloud-Lake/Analyzing-Your-Data/Build-Scalable-Analytics-with-Open-Analytics-Framework/Bring-Your-Own-LLM-and-DL-Workloads/Using-User-Environment-APIs-to-Manage-LLMs\">UES APIs</a> to install, uninstall, and list LLMs. Here we use the install_model API.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8432964f-ea53-4365-a417-cab95d89a7d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "claim_id = demo_env.install_model(model_path='roberta-large-ontonotes5.zip', asynchronous=True)\n",
    "\n",
    "demo_env.status(claim_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b539517-9617-4512-9cfb-2354ec8873bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"height:2px;border:none\">\n",
    "<p style=\"font-size:20px;font-family:Arial\"><b>7. Create a python script and execute it using the Apply Class</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aad5dc-c49c-410f-8a71-5426ec794cc6",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Create a python script that reads text records from VantageCloud using standard input, applies a Hugging Face language model to perform Named Entity Recognition (NER), and outputs the extracted entities in a structured, delimited format using standard output.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e85e85-bf95-4208-87d6-2140d18e1625",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile entity_recognition.py\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "input_str = sys.stdin.read()\n",
    "\n",
    "DELIMITER = '#'\n",
    "\n",
    "if len(input_str) > 0:\n",
    "    from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "    torch_device = 'cuda'\n",
    "    model_path = \"./models/roberta-large-ontonotes5\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "    translator = pipeline(\"token-classification\", model=model, tokenizer=tokenizer, device=torch_device, aggregation_strategy='max')\n",
    "\n",
    "    for line in input_str.splitlines():\n",
    "        results = translator(line)\n",
    "        dict_val = {}\n",
    "\n",
    "        for r in results:\n",
    "            entity = r['entity_group']\n",
    "            word = r['word']\n",
    "            dict_val.setdefault(entity, []).append(word)\n",
    "\n",
    "        combined_str = \"\"\n",
    "        for key in [\"ORG\", \"PERSON\", \"DATE\", \"PRODUCT\", \"GPE\"]:\n",
    "            combined_str += f\"{DELIMITER}{','.join(dict_val.get(key, []))}\"\n",
    "\n",
    "        print(f\"{line}{combined_str}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3af1f2-e0f5-462c-b60e-1a21774bcafa",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Install the python script file to the environment using install_file().\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae8d564-1f89-4739-b0e0-436ff30fe2fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "demo_env.install_file(file_path =\"entity_recognition.py\", replace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb8ba68-cd63-43a7-914f-ffe859444c67",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Set the session to the GPU Analytic compute group you desire otherwise it will set to default. The cluster needs to be running to execute the APPLY class.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331d0291-b527-4520-9ec0-7d189f915094",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_sql(f\"SET SESSION COMPUTE GROUP {gpu_compute_group};\")\n",
    "print(f\"Compute group set to {gpu_compute_group}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18bd44c-fb79-4480-9d42-3ecfb5fd7827",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "The APPLY class executes your Python script directly within the user environment, enabling in-database processing at scale. It reads text from each row of the dataset, performs Named Entity Recognition (NER) using Hugging Face language models accelerated by NVIDIA GPUs, and outputs the extracted entities into a structured dataframe in just seconds. </p>  \n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\"> In this example, we use <code>tner/roberta-large-ontonotes5</code>, a general-purpose NER model trained on the OntoNotes 5 dataset. It supports entities like ORG, PERSON, DATE, PRODUCT, and GPE. However, it's important to note that the ‚ÄúPRODUCT‚Äù entity in OntoNotes refers primarily to physical products (e.g., iPhone, Windows OS), not financial instruments (e.g., Roth IRA, mutual funds). To improve financial domain accuracy, this model can be further fine-tuned on domain-specific data to better recognize investment products, insurance types, and retirement accounts.\n",
    " </p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f997dc6-4e1b-4d81-af19-c82a3576cb28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "apply_obj = Apply(data = call_summary_dataset,\n",
    "                  apply_command = 'python entity_recognition.py',\n",
    "                  returns = {\"Call_Summary\": VARCHAR(64000), \"ORG\": VARCHAR(64000), \"PERSON\": VARCHAR(64000), \"DATES\": VARCHAR(64000), \"PRODUCT\": VARCHAR(64000), \"GPE\": VARCHAR(64000)},\n",
    "                  env_name = demo_env,\n",
    "                  delimiter = '#',\n",
    "                  quotechar = '|'\n",
    "                 )\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Execute the Python script inside the remote user environment.\n",
    "df = apply_obj.execute_script()\n",
    "\n",
    "print(f'Time: {time.time() - start}')\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecddc829-8492-429b-a7d0-e492543d0c74",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "  You can explore additional Natural Language Processing (NLP) tasks directly in-database using task-specific models:\n",
    "</p>\n",
    "\n",
    "<ul style=\"font-size:15px;font-family:Arial\">\n",
    "  <li><strong>Text Classification</strong> ‚Äî <a href=\"https://huggingface.co/facebook/bart-large-mnli\" target=\"_blank\">facebook/bart-large-mnli</a>: Classifies text into predefined categories</li>\n",
    "  <li><strong>Language Detection</strong> ‚Äî <a href=\"https://huggingface.co/papluca/xlm-roberta-base-language-detection\" target=\"_blank\">papluca/xlm-roberta-base-language-detection</a>: Detects the language</li>\n",
    "  <li><strong>Generating Embeddings</strong> ‚Äî <a href=\"https://huggingface.co/sentence-transformers/all-mpnet-base-v2\" target=\"_blank\">sentence-transformers/all-mpnet-base-v2</a>: Converts text into vector representations for similarity searches</li>\n",
    "  <li><strong>Named Entity Recognition</strong> ‚Äî <a href=\"https://huggingface.co/tner/roberta-large-ontonotes5\" target=\"_blank\">tner/roberta-large-ontonotes5</a>: Identifies and categorizes named entities within unstructured text</li>\n",
    "  <li><strong>Extracting Key Phrases</strong> ‚Äî <a href=\"https://huggingface.co/ml6team/keyphrase-extraction-kbir-kpcrowd\" target=\"_blank\">ml6team/keyphrase-extraction-kbir-kpcrowd</a>: Extracts important phrases from a document to summarize its content</li>\n",
    "  <li><strong>Grammar Correction</strong> ‚Äî <a href=\"https://huggingface.co/pszemraj/flan-t5-large-grammar-synthesis\" target=\"_blank\">pszemraj/flan-t5-large-grammar-synthesis</a>: Automatically corrects grammatical errors in text</li>\n",
    "  <li><strong>Masking PII Entities</strong> ‚Äî <a href=\"https://huggingface.co/ab-ai/pii_model\" target=\"_blank\">ab-ai/pii_model</a>: Masks personally identifiable information (PII)</li>\n",
    "  <li><strong>Sentiment Analysis</strong> ‚Äî <a href=\"https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english\" target=\"_blank\">distilbert-base-uncased-finetuned-sst-2-english</a>: Determines the emotional tone (positive, negative, neutral)</li>\n",
    "  <li><strong>Sentence Similarity</strong> ‚Äî <a href=\"https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\" target=\"_blank\">sentence-transformers/all-MiniLM-L6-v2</a>: Measures semantic similarity between sentences</li>\n",
    "  <li><strong>Summarization</strong> ‚Äî <a href=\"https://huggingface.co/facebook/bart-large-cnn\" target=\"_blank\">facebook/bart-large-cnn</a>: Generates concise summaries of longer documents</li>\n",
    "  <li><strong>Translation</strong> ‚Äî <a href=\"https://huggingface.co/Helsinki-NLP/opus-mt-en-fr\" target=\"_blank\">Helsinki-NLP/opus-mt-en-fr</a>: Translates English text to French</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b783dd5c-2e39-4f7d-bba7-8b55fda1c31e",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "<hr style='height:2px;border:none;'>\n",
    "<b style=\"font-size:20px;font-family:Arial\">8. Automate Entity Recognition with <code>teradatagenai</code> Python Package</b>\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "  To simplify and accelerate setup, you can now use the <code>teradatagenai</code> package to automate model deployment and inference. This Python library enables seamless, in-database, AI-driven text analytics within Teradata VantageCloud. It offers a variety of user-friendly functions that wrap API calls for common text analysis tasks, making it easy to apply LLMs to proprietary unstructured data.\n",
    "    \n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "  Built on Teradata VantageCloud‚Äôs open and connected architecture, this solution uses BYOLLM capability and enables teams to rapidly develope generative AI use cases that enhance customer experiences, improve employee productivity, and streamline operations‚Äîall within a secure, scalable environment.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\"> TextAnalyticsAI gives us access to the 11+ genAI functions and enables users to use advanced text analytics capabilities seamlessly on data stored in Vantage.\n",
    "<ul style=\"font-size:16px; font-family:Arial; margin-left:20px; line-height:1.8;\">\n",
    "  <li><code>classify()</code> ‚Äì Classify text into predefined categories</li>\n",
    "  <li><code>analyze_sentiment()</code> ‚Äì Perform sentiment analysis</li>\n",
    "  <li><code>detect_language()</code> ‚Äì Detect the language of a text</li>\n",
    "  <li><code>embeddings()</code> ‚Äì Generate embeddings for similarity search</li>\n",
    "  <li><code>recognize_entities()</code> ‚Äì Extract named entities</li>\n",
    "   <li><code>recognize_pii_entities()</code> ‚Äì Detect and label PII entities</li>\n",
    "  <li><code>extract_key_phrases()</code> ‚Äì Identify key phrases in text</li>\n",
    "  <li><code>mask_pii()</code> ‚Äì Mask personally identifiable information (PII)</li>\n",
    "  <li><code>sentence_similarity()</code> ‚Äì Measure semantic similarity between sentences</li>\n",
    "  <li><code>summarize()</code> ‚Äì Generate summaries of longer documents</li>\n",
    "  <li><code>translate()</code> ‚Äì Translate text between languages</li>\n",
    "</ul>\n",
    "\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68e0629-73e6-4032-9b1c-0b186ced7384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install the teradatagenai package\n",
    "!pip install teradatagenai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb0bc0-b430-415d-9f99-a9e52ac5342b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries and modules\n",
    "import teradatagenai\n",
    "from teradatagenai import TeradataAI, TextAnalyticsAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3a89fd-69cb-4d2f-8af0-491ce8ae5f69",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">  \n",
    "TeradataAI handles the download and installation of the Hugging Face model (example: <i>'tner/roberta-large-ontonotes5</i>) in the user's environment. Incase the environment is not specified, a sample environment named <i>'td_gen_ai_env'</i> is created with <code>torch</code> and <code>transformer</code> libraries and their dependencies. The TeradataAI class will manage the entire setup process. In the background, this process utilizes Teradata‚Äôs Bring Your Own Large Language Model (BYO LLM) offering.</p>\n",
    "<p style=\"font-size:16px;font-family:Arial\">    For this next example we're going to delete the environment we just created and then create a new user environment to showcase the process to install the same <code>tner/roberta-large-ontonotes5</code> with the <code>teradatagenai</code> package. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a97dda-ff43-4303-9aa1-d8d9255690da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if I have any existing environments\n",
    "env_list = list_user_envs()\n",
    "claim_id = ''\n",
    "if env_list is None:\n",
    "    print(\"This user does not have any environments. Please continue...\")\n",
    "else:\n",
    "    ipydisplay(env_list)\n",
    "    # Iterate over the env_name column and remove\n",
    "    for env_name in env_list['env_name']:\n",
    "        print(f\"Env Name: {env_name} is being removed!\")\n",
    "        claim_id = remove_env(env_name, asynchronous=True)\n",
    "    print(\"Finished removing the environment.  Please continue...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa89c12-e197-4627-917c-578628e1459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify that the environment has been deleted\n",
    "if claim_id != '':\n",
    "    async_run_status(claim_id)\n",
    "else:\n",
    "    print(\"No status to display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbd9b8c-a4f9-4496-b460-88892b1577c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new user environment with a base enviroment available\n",
    "demo_env = create_env(env_name, base_env = 'python_3.10', desc = 'BYOLLM demo env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0444f9-a871-4805-942a-bfb5bccc4b72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Validating the environments\n",
    "env_list = list_user_envs()\n",
    "print(\"Available Environments:\")\n",
    "ipydisplay(env_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce427994-bcc9-4dd2-bad9-2e8481e979d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define your model and initialize the TeradataAI Class\n",
    "model_name = 'tner/roberta-large-ontonotes5'\n",
    "model_args = {'transformer_class': 'AutoModelForTokenClassification',\n",
    "              'task' : 'token-classification'}\n",
    "ues_args = {'env_name': f'{env_name}'}\n",
    "\n",
    "llm = TeradataAI(api_type = \"hugging_face\",\n",
    "                 model_name = model_name,\n",
    "                 model_args = model_args,\n",
    "                 ues_args = ues_args )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12832ed-7e09-4b92-803a-40a8a23aedc3",
   "metadata": {},
   "source": [
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "    <br>\n",
    "    Even though the Python kernel is <b>Idle</b>, please wait until you see that the installation status above has completed before you continue. This should only take 2 minutes depending on your network.<br>\n",
    "    <br> Because we've recreated our customer environment, we need to install our python dependencies again.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a4762d-cdbb-4dd0-870d-d3090ecdf025",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_claim_id = ''\n",
    "lib_claim_id = demo_env.install_lib([\"transformers\", \"torch\"])\n",
    "print(\"Installing Libraries\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9877758f-5d2f-466e-a93d-3728f97cec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_env.status(lib_claim_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a57e95",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "Now we can configure the TextAnalyticsAI object with the preferred large language model using the TeradataAI object. This will enable us to execute a variety of text analytics tasks. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ed8a6a-2748-49bc-9402-f51637458e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = TextAnalyticsAI(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f51dbba-a332-4d46-a490-ef36481f4d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default script is used\n",
    "obj.recognize_entities(column='Call_Summary', data=call_summary_dataset, script=\"entity_recognition.py\", returns = {\"txt\": VARCHAR(64000),\n",
    "                                                  \"ORG\": VARCHAR(64000),\n",
    "                                                  \"PERSON\": VARCHAR(64000),\n",
    "                                                  \"DATES\": VARCHAR(64000),\n",
    "                                                  \"PRODUCT\": VARCHAR(64000),\n",
    "                                                  \"GPE\": VARCHAR(64000)}, delimiter=\"#\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb913bb-79be-4261-a8d7-8dd101536754",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none\">\n",
    "\n",
    "<b style=\"font-size:20px; font-family:Arial;\">\n",
    "  9. Call Hosted LLMs From In-Database (AWS Bedrock, Google Gemini, Azure AI Models)\n",
    "</b>\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial; line-height:1.6;\">\n",
    "  Teradata lets you run text analysis using large language models (LLMs) hosted on cloud platforms such as <strong>AWS</strong>, <strong>Google</strong>, and <strong>Azure</strong>, while working directly with data stored in <strong>Vantage</strong>. \n",
    "</p>\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial; line-height:1.6;\">\n",
    "  These built-in functions support a wide range of NLP tasks on unstructured text:\n",
    "</p>\n",
    "\n",
    "<ul style=\"font-size:16px; font-family:Arial; margin-left:20px; line-height:1.8;\">\n",
    "  <li><code>AI_AnalyzeSentiment</code></li>\n",
    "  <li><code>AI_AskLLM</code></li>\n",
    "  <li><code>AI_DetectLanguage</code></li>\n",
    "  <li><code>AI_MaskPII</code></li>\n",
    "  <li><code>AI_RecognizeEntities</code></li>\n",
    "  <li><code>AI_RecognizePIIEntities</code></li>\n",
    "  <li><code>AI_TextClassifier</code></li>\n",
    "  <li><code>AI_TextEmbeddings</code></li>\n",
    "  <li><code>AI_TextSummarize</code></li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"font-size:16px; font-family:Arial; line-height:1.6;\">\n",
    "  In the following example, we‚Äôll demonstrate how to use <code>AI_RecognizeEntities</code> for in-database entity recognition with Amazon Bedrock's Anthropic LLM: \"anthropic.claude-v2\".\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e545ad-e73a-4638-b4e6-114e3dadb4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Securely prompt for AWS credentials\n",
    "region = getpass.getpass(\"Region: \")\n",
    "access_key = getpass.getpass(\"Enter AWS Access Key: \")\n",
    "secret_key = getpass.getpass(\"Enter AWS Secret Key: \")\n",
    "session_token = getpass.getpass(\"Enter AWS Session Token: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22daed28-658d-4bf9-9586-7e7b6e110443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your query dynamically\n",
    "query = f\"\"\"\n",
    "SELECT * FROM AI_RecognizeEntities( \n",
    "  ON financial_entity_dataset AS InputTable\n",
    "  USING \n",
    "    TextColumn('text')\n",
    "    ApiType('aws')\n",
    "    REGION('{access_key}')\n",
    "    ACCESSKEY('{access_key}')\n",
    "    SECRETKEY('{secret_key}')\n",
    "    SESSIONKEY('{session_token}')\n",
    "    ModelName('anthropic.claude-v2')\n",
    "    isDebug('true')\n",
    "    Accumulate('[0:]')\n",
    ") AS dt;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1350c316",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    "While our open-source Hugging Face models provide a powerful and customizable foundation for entity recognition, it will require additional domain-specific fine-tuning to accurately capture specialized financial terms or product names. In contrast, <b>hosted LLMs</b> such as Anthropic‚Äôs Claude or other models available through <b>AWS Bedrock, Google Vertex AI, or Azure OpenAI</b> often benefit from broad training by the provider‚Äîresulting in deeper contextual understanding out of the box. In this example, we will observe that the AWS Bedrock's Anthropic model identified a richer set of financial products with no additional training.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed914fb-07ed-4cd0-977d-2740658850cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = DataFrame.from_query(query)\n",
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966b0c10",
   "metadata": {},
   "source": [
    "\n",
    "<p style=\"font-size:16px;font-family:Arial\">\n",
    " This is why <b>Teradata‚Äôs support for both open-source and hosted models</b> is great for developers and enteprises: developers need the flexibility to choose the right model for each use case based on the <b>business goals, data privacy requirements, cost considerations,</b> and <b>infrastructure preferences</b>. Whether you're performing domain-specific NLP with tightly controlled data using <b>BYO-LLM</b> or leveraging the latest generative AI via <b>fast-path cloud functions</b>, Teradata enables you to do both‚Äî<b>securely, efficiently, and at scale</b>. The real differentiator is not just the model, but the ability to <b>operationalize AI seamlessly where your data lives</b> and apply it to solve meaningful business problems with measurable impact.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7302075",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none'>\n",
    "<b style = 'font-size:20px;font-family:Arial'>10. Cleanup</b>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Cleanup work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2d977e-afd9-4412-b5be-f86772b720dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the existing user environment \n",
    "remove_env(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c91baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc982843-537c-447a-8fb1-a8f0371a8191",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(TeradataAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157acc0b-bc56-4ce2-beed-29aa7ba5e122",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; border-bottom:3px solid #91A0Ab\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics‚Ñ¢</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright ¬© Teradata Corporation - 2025. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
