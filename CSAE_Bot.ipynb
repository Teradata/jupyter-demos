{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc92e86f-c5a7-499d-89e2-49046aa01be7",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       CSAE Bot: Quickly find your demos of interest by just typing\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74eee36-e3e8-42ca-9253-4e5ce8178c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install openai langchain langchain_community langchain-openai faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160a585b-2d8a-489d-8e96-2a4729e438ba",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style='font-size:16px;font-family:Arial;color:#00233C'><b>Note:</b> Please restart the kernel. The simplest way is by typing <b>0 0</b> (zero zero) and then pressing <i><b>enter</b></i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cfddce-a2b3-4d7d-aae4-1f2dbc463022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "from langchain_community.document_loaders import NotebookLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b661c301-cfe3-4389-a05e-e996336684e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract content from a Jupyter notebook\n",
    "def extract_notebook_content(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        notebook_data = json.load(f)\n",
    "\n",
    "    content = \"\"\n",
    "    for cell in notebook_data.get('cells', []):\n",
    "        if cell['cell_type'] == 'markdown':\n",
    "            # Clean markdown content by removing HTML tags\n",
    "            content += '\\n'.join(cell['source']) + '\\n\\n'\n",
    "        elif cell['cell_type'] == 'code':\n",
    "            # Format code properly\n",
    "            content += '```python\\n' + ''.join(cell['source']) + '\\n```\\n\\n'\n",
    "    return content\n",
    "\n",
    "# Function to remove HTML tags\n",
    "def remove_html_tags(text):\n",
    "    \"\"\"Remove HTML tags from a string\"\"\"\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)\n",
    "\n",
    "# Function to split the notebook content into markdown and code\n",
    "def split_ipynb_content(content):\n",
    "    # Regular expression to match code blocks\n",
    "    code_pattern = re.compile(r'```python(.*?)```', re.DOTALL)\n",
    "\n",
    "    # Find all code blocks\n",
    "    code_blocks = code_pattern.findall(content)\n",
    "\n",
    "    # Split the content by code blocks\n",
    "    parts = code_pattern.split(content)\n",
    "\n",
    "    # Combine markdown and code blocks\n",
    "    result = []\n",
    "    for i, part in enumerate(parts):\n",
    "        if i % 2 == 0:\n",
    "            # This is a markdown part, remove HTML tags\n",
    "            clean_part = remove_html_tags(part)\n",
    "            result.append(('markdown', clean_part))\n",
    "        else:\n",
    "            # This is a code part\n",
    "            result.append(('code', part))\n",
    "\n",
    "    return result\n",
    "\n",
    "# Function to clean and split notebook content\n",
    "def clean_and_split_notebook_content(file_path):\n",
    "    \"\"\"Extract markdown content and clean up the notebook's information.\"\"\"\n",
    "    # Extract the content from the notebook file\n",
    "    content = extract_notebook_content(file_path)\n",
    "    \n",
    "    # Split content into markdown and code cells\n",
    "    split_content = split_ipynb_content(content)\n",
    "\n",
    "    # Initialize a list to hold combined documents\n",
    "    combined_documents = []\n",
    "    current_markdown = \"\"\n",
    "    current_code = \"\"\n",
    "\n",
    "    # Iterate through the split content to group markdown with code\n",
    "    for part_type, part in split_content:\n",
    "        if part_type == 'markdown':\n",
    "            # If we have code and markdown, combine them\n",
    "            if current_markdown or current_code:\n",
    "                combined_documents.append({\"markdown\": current_markdown, \"code\": current_code})\n",
    "            # Update current markdown to the new one\n",
    "            current_markdown = part\n",
    "            current_code = \"\"  # Reset code, ready for next code block\n",
    "        elif part_type == 'code':\n",
    "            # Append the code to the current code block\n",
    "            current_code += part\n",
    "    \n",
    "    # Add the last document (markdown + code)\n",
    "    if current_markdown or current_code:\n",
    "        combined_documents.append({\"markdown\": current_markdown, \"code\": current_code})\n",
    "\n",
    "    return combined_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d11abb9-225e-4ba8-9041-9e29e738ed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa7e48d-e236-4245-8643-939694bc0f5a",
   "metadata": {},
   "source": [
    "### Create FAISS vector database\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note: You do not have to run the next cell multiple times.  Each time it is executed it will generate over 1M embeddings and the charge is typically $0.02USD / 1M tokens</b>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c357a955-d49d-4fec-99a5-6c42f9d204bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load notebooks and clean them\n",
    "path = '/home/jovyan/JupyterLabRoot/'\n",
    "loader = DirectoryLoader(path, glob=\"**/*.ipynb\", loader_cls=NotebookLoader)\n",
    "notebooks = loader.load()\n",
    "\n",
    "# Clean each notebook before processing it\n",
    "cleaned_documents = []\n",
    "for notebook in notebooks:\n",
    "    # Assuming notebook metadata contains file path\n",
    "    file_path = notebook.metadata.get(\"source\", \"Unknown\")  # Adjust this as needed\n",
    "    cleaned_data = clean_and_split_notebook_content(file_path)\n",
    "\n",
    "    # Convert cleaned data to documents, including the source file path\n",
    "    for data in cleaned_data:\n",
    "        if data['markdown'] or data['code']:\n",
    "            doc = Document(\n",
    "                page_content=f\"Markdown:\\n{data['markdown']} \\n\\nCode:\\n{data['code']}\",\n",
    "                metadata={\"source\": file_path}  # Ensure the source file path is added\n",
    "            )\n",
    "            cleaned_documents.append(doc)\n",
    "            \n",
    "            \n",
    "# Split text into manageable chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(cleaned_documents)\n",
    "\n",
    "\n",
    "# for count of token\n",
    "from tiktoken import encoding_for_model\n",
    "\n",
    "def count_document_tokens(document, model_name=\"gpt-4\"):\n",
    "    encoder = encoding_for_model(model_name)\n",
    "    return len(encoder.encode(document.page_content))\n",
    "\n",
    "tiktokn = 0\n",
    "for doc in cleaned_documents:\n",
    "    tiktokn = tiktokn + count_document_tokens(doc)\n",
    "\n",
    "print(\"total token from all the notebooks: \", tiktokn)\n",
    "\n",
    "# Create vector store using embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\") \n",
    "vector_store = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# Save the index for reuse\n",
    "vector_store.save_local(\".notebooks_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d754281-77b6-4f68-a41d-2323cdc020ad",
   "metadata": {},
   "source": [
    "### Load existing vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5565e54c-6303-4648-81cf-9f2fe44c1de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the FAISS index with dangerous deserialization enabled\n",
    "vector_store = FAISS.load_local(\n",
    "    \".notebooks_index\", embeddings, allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbb1de5-2966-474f-86a4-a1aff224e9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Prompt Template\n",
    "CUSTOM_PROMPT = \"\"\"\n",
    "You are a helpful assistant. Use the following retrieved information from Jupyter notebooks to provide:\n",
    "1. A **clean and concise textual explanation** based on the question and notebook markdown.\n",
    "2. **Relevant Clean Python code** extracted from the notebooks' code cells that are related to the question. Please filter the code that is related to the query.\n",
    "\n",
    "If no relevant information is found, politely say so.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Your response should be in below format:\n",
    "- Answer:\n",
    "- Relevant Code:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=CUSTOM_PROMPT\n",
    ")\n",
    "\n",
    "# Make sure to use a Chat model like 'gpt-4' or 'gpt-3.5-turbo'\n",
    "chat_model = ChatOpenAI(model=\"gpt-4\")\n",
    "\n",
    "# Retrieval QA Chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat_model,\n",
    "    retriever=vector_store.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 10}),  # Assuming vector_store is your vector database\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2efb7c-dfa6-4240-b3ae-e40337685705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Query Chatbot\n",
    "def query_chatbot(question):\n",
    "    # Query the chatbot using the chain\n",
    "    result = qa_chain.invoke(question)\n",
    "    answer = result[\"result\"]\n",
    "\n",
    "    # Extract and format relevant source paths from source documents\n",
    "    source_docs = result.get(\"source_documents\", [])\n",
    "    sources = \"\\n\".join(set([doc.metadata.get(\"source\", \"Unknown\") for doc in source_docs]))\n",
    "\n",
    "    return f\"\"\"\n",
    "{answer}\n",
    "\n",
    "Reference Notebook(s):\n",
    "{sources if sources else \"No source notebooks found.\"}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e60ece-6bd2-495a-8d11-ec545c11be87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, HTML, Javascript\n",
    "import re\n",
    "\n",
    "def extract_answer_code_references(input_string):\n",
    "    # Extract the answer section (after \"- Answer:\" and before \"- Relevant Code:\")\n",
    "    answer_match = re.search(r'- Answer:\\s*(.*?)\\s*- Relevant Code:', input_string, re.DOTALL)\n",
    "    answer = answer_match.group(1).strip() if answer_match else \"Answer not found.\"\n",
    "\n",
    "    # Extract the relevant code section (after \"- Relevant Code:\" and before any other section)\n",
    "    code_match = re.search(r'- Relevant Code:\\s*```python\\s*(.*?)```', input_string, re.DOTALL)\n",
    "    relevant_code = code_match.group(1).strip() if code_match else \"Relevant code not found.\"\n",
    "\n",
    "    # Extract references and create JupyterLab-compatible links\n",
    "    references = re.findall(r'(/home/[^\\s]+)', input_string)\n",
    "    \n",
    "    # Check and format paths to open in JupyterLab (ensure paths are relative to /notebooks/)\n",
    "    html_output = \"\\n\\n\".join([f'<a href=\"{ref.replace(\"/home/jovyan/JupyterLabRoot/\", \"\")}\"> -> {ref} </a>' for ref in references]) if references else \"No references found.\"\n",
    "    \n",
    "    return answer, relevant_code, html_output\n",
    "\n",
    "def display_answer(question):\n",
    "    # Query the chatbot for the answer\n",
    "    result = query_chatbot(question)  \n",
    "    \n",
    "    # Extract formatted outputs\n",
    "    answer, relevant_code, source_notebooks = extract_answer_code_references(result)\n",
    "    \n",
    "    # Display answer as markdown\n",
    "    display(Markdown(f\"**Answer:**\\n\\n{answer}\"))\n",
    "    \n",
    "    # Display relevant code as code\n",
    "    display(Markdown(\"**Relevant Code:**\\n\\n```python\\n\" + relevant_code.strip() + \"\\n```\"))\n",
    "    \n",
    "    # Display reference notebooks\n",
    "    display(Markdown(f\"**Reference Notebook(s):**\\n\\n{source_notebooks}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f443eeaf-b913-4dd4-839b-e950b228a3c5",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>You can try your own question</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here are some sample questions that you can try out:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>How does VectorDistance work?</li>\n",
    "    <li>What is Script table operator?</li>\n",
    "    <li>Give me demos which have AWS Bedrock?</li>\n",
    "    <li>What is GEOSEQUENCE? Show me some examples</li>\n",
    "    <li>Which notebooks are using OpenAI?</li>\n",
    "    <li>Which notebooks are about fraud detection?</li>\n",
    "    <li>How to use TDApiClient to generate the embeddings?</li>\n",
    "    <li>Show me demo for Broken Digital Journey?</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88f09b4-128f-4680-9d84-e15a491f431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "query = input(\"Enter your query here. To stop, type 'exit'. Query:\")\n",
    "while query.lower() != 'exit':\n",
    "    loading_spinner3 = widgets.HTML(\n",
    "        value=\"<i class='fas fa-cog fa-spin' style='font-size:24px'></i> Please wait while we are extracing the answer for you...\",\n",
    "    )\n",
    "\n",
    "    display(loading_spinner3)\n",
    "    \n",
    "    display_answer(query)\n",
    "    loading_spinner3.value = \"\"\n",
    "    display(Markdown(\"<hr style='height:1px;border:none;background-color:#00233C;'>\"))\n",
    "    query = input(\"Please enter your query here...\")\n",
    "    \n",
    "display(Markdown(\"**Thank you for chatting with us. I hope I was able to assist you.**\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc3a070-33cf-4787-8c66-cc221075fdd5",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2023. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
