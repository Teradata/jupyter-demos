{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cdfc2e-3341-4192-99c9-31aaa6694401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# teradata lib\n",
    "from teradataml import *\n",
    "\n",
    "# LLM\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from langchain import PromptTemplate, SQLDatabase, LLMChain\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "\n",
    "configure.byom_install_location = 'mldb'\n",
    "configure.val_install_location = 'val'\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "display.max_rows = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d8b92f-2324-4390-b05e-ed305b2c4521",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>2. Connect to Vantage</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dc18b2-3a44-4634-b77d-cb9303a42a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11000e5f-fa1e-47bf-8713-f16713268a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql(\"SET query_band='DEMO=Support_Agents.ipynb;' UPDATE FOR SESSION;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8618c519-1872-456e-a978-a47b1d4cd56c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551faaae-affd-4ee8-a823-beca7eabb446",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>3. Load Customer360 data into Vantage</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93daed5-d96a-41e2-9d63-12ca02d36f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/customer360.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48523a1c-3aa7-4253-a700-9c9c46a960be",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(df, 'customer360', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28974627-f4b9-4db0-8e0e-f94eb1754211",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_tdf = DataFrame('customer360')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa60862f-9851-4ccc-9f3b-304e32add926",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_tdf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae3e158-a740-4669-a405-827d46367904",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>4. Load trained PMML Model into Vantage</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We pass the local PMML file to the save_byom function. This function loads the <b>mm_fraud_glm_model.pmml</b> file into Vantage in a table called <b>mm_glm</b>. If there is already a model with the same name, we will delete the previous one, and a new one will be loaded.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d4ec2c-cebf-454c-8d89-214674f153ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PMML file into Vantage\n",
    "try:\n",
    "    res = save_byom(model_id = 'mm_glm1', model_file = 'propensity_model_regressor.pmml', table_name = 'mm_glm')\n",
    "\n",
    "except Exception as e:\n",
    "    # if our model exists, delete and rewrite\n",
    "    if str(e.args).find('TDML_2200') >= 1:\n",
    "        res = delete_byom(model_id = 'mm_glm1', table_name = 'mm_glm')\n",
    "        res = save_byom(model_id = 'mm_glm1', model_file = 'propensity_model_regressor.pmml', table_name = 'mm_glm')\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3bbd3d-c4de-4689-a904-becdffee5e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame('mm_glm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ce896-249c-4318-a9bc-70124a450428",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>5. Score the model directly in Vantage</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use PMMLPredict to score the model on data residing in Vantage without moving data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fddc97-9cd8-41be-8b7f-d41988e8e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input_data = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"Customer ID\": \"C1001\",\n",
    "            \"Age\": 53,\n",
    "            \"Gender\": \"Male\",\n",
    "            \"Income Level\": 50000,\n",
    "            \"Occupation\": \"Engineer\",\n",
    "            \"Education Level\": \"Bachelor\",\n",
    "            \"Travel Frequency\": 2,\n",
    "            \"Destination\": \"Domestic\",\n",
    "            \"Trip Duration\": 7,\n",
    "            \"Travel Purpose\": \"Leisure\",\n",
    "            \"Previous Dental Treatment\": True,\n",
    "            \"General Health Status\": \"Poor\",\n",
    "            \"Dental Issue History\": True,\n",
    "            \"Dental Visit Frequency\": 10,\n",
    "            \"Previous Insurance Policy\": True,\n",
    "            \"Claims History\": 1,\n",
    "            \"Insurance Duration\": 5,\n",
    "            \"Online Behavior\": \"High\",\n",
    "            \"Marketing Engagement\": \"High\",\n",
    "            \"Social Media Activity\": \"Medium\",\n",
    "            \"Credit Score\": 700,\n",
    "            \"Spending Pattern\": \"Medium\",\n",
    "            \"Payment History\": \"Good\",\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21db3cfd-b7e1-4bc7-aeb6-6370369dcea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(example_input_data, 'df_test', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c46fef8-961a-4e4d-bc47-50f8e45430aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = DataFrame('df_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54906f62-efac-470d-8201-4e0df19640ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tdf = retrieve_byom(\"mm_glm1\", table_name = 'mm_glm')\n",
    "\n",
    "# Run the PMMLPredict function in Vantage\n",
    "result = PMMLPredict(\n",
    "            modeldata = model_tdf,\n",
    "            newdata = df_test,\n",
    "            accumulate = ['Customer ID'],\n",
    "            overwrite_cached_models = '*',\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48de2c5e-8201-4f53-969a-ef6a712e417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.show_query())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08482da6-d9b5-4da9-985b-6ede2a335661",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2333c90-4003-4dae-832e-453fb18db80c",
   "metadata": {},
   "source": [
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a686b65-9534-4f37-897c-e648bf26f8d5",
   "metadata": {},
   "source": [
    "## Install libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c739527-1170-485b-afa7-67870b92fcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U --quiet langchain-community tiktoken langchain-openai langchainhub faiss-cpu langchain langgraph langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bd6ab8-f0b6-42f9-ad0d-ae202095a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "def _set_env(key: str):\n",
    "    if key not in os.environ:\n",
    "        os.environ[key] = getpass.getpass(f\"{key}:\")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc506cdd-4f49-4e85-a465-27e6725095d7",
   "metadata": {},
   "source": [
    "### setup lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16c8b32-78d7-4d94-b2fb-1339b3182259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# loader = PyPDFLoader(\n",
    "#     \"./data/travel-insurance-policy.pdf\",\n",
    "# )\n",
    "# # docs = [WebBaseLoader(url).load() for url in urls]\n",
    "# docs_list = loader.load()\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "#     chunk_size=1000, chunk_overlap=200\n",
    "# )\n",
    "# doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# # Add to vectorDB\n",
    "# vector_store = FAISS.from_documents(doc_splits, embeddings)\n",
    "\n",
    "#     # Save the index for reuse\n",
    "# vector_store.save_local(\"policy_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb02f85a-a997-4573-8d47-bdb167590062",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "retriever = FAISS.load_local(\"policy_index\", embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06615e8-1ece-4391-92f4-d79aec70f905",
   "metadata": {},
   "source": [
    "### Tool 2: Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292028c3-fd6f-43c7-b5bb-1adcf6b92e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def lookup_policy(query: str) -> str:\n",
    "    \"\"\"Consult the company insurance policies to check whether certain options are permitted.\"\"\"\n",
    "    docs = retriever.similarity_search(query, k=3)\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fc7527-0b8a-446f-bc5f-2a55fe2e38ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup_policy(\"dental treatment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f10bf0-190f-4d2d-8cf4-13d2ee0941be",
   "metadata": {},
   "source": [
    "### fetch user info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b91d61-ba5d-4b70-a5b3-7db5275793bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection = eng.raw_connection()\n",
    "# connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7b677f-c962-443a-a7c1-fcdbda7cb5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qry = \"select * from customer360  WHERE CustomerID = ? \"\n",
    "# CustomerID= 'C1002'\n",
    "\n",
    "# # with eng.raw_connection() as connection:\n",
    "# conn = eng.raw_connection()\n",
    "# cursor = conn.cursor()\n",
    "# rows =cursor.execute(qry, (CustomerID,)).fetchall()\n",
    "# column_names = [column[0] for column in cursor.description]\n",
    "# results = [dict(zip(column_names, row)) for row in rows]\n",
    "# cursor.close()\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f035aab4-d4a6-48d7-ae3c-c4a888dcb4b3",
   "metadata": {},
   "source": [
    "### Tool 2: Insurance policy - DB query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724b5b87-51cf-4c5d-a926-4ae7da2f97df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from datetime import date, datetime\n",
    "from typing import Optional\n",
    "\n",
    "import pytz\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "thought_history = []\n",
    "\n",
    "def logs(msg: str):\n",
    "    print(f\"\\nℹ️ LOGS : {msg}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "def think(thought: str):\n",
    "    \"\"\"Record agent's thinking process\"\"\"\n",
    "    thought_history.append({\"thought\": thought, \"timestamp\": datetime.now().isoformat()})\n",
    "    print(f\"\\n🤔 THINKING: {thought}\")\n",
    "    \n",
    "def act(action: str, result: any):\n",
    "    \"\"\"Record agent's actions and results\"\"\"\n",
    "    thought_history.append({\n",
    "        \"action\": action,\n",
    "        \"result\": result,\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    })\n",
    "    print(f\"🎯 ACTION: {action}\")\n",
    "    print(f\"📝 RESULT: {result}\\n\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "@tool\n",
    "def fetch_user_insurance_information(config: RunnableConfig) -> dict:\n",
    "    \"\"\"Fetch all the insurance policies for the user along with corresponding personal information and policy information.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary which contains the user's personal and policy details, Claim details, etc. to the user.\n",
    "    \"\"\"\n",
    "    logs(\"fetch_user_insurance_information called\")\n",
    "    configuration = config.get(\"configurable\", {})\n",
    "    customer_id = configuration.get(\"customer_id\", None)\n",
    "    if not customer_id:\n",
    "        raise ValueError(\"No passenger ID configured.\")\n",
    "\n",
    "\n",
    "    qry = \"select * from customer360  WHERE CustomerID = ? \"\n",
    "\n",
    "    # with eng.raw_connection() as connection:\n",
    "    conn = eng.raw_connection()\n",
    "    cursor = conn.cursor()\n",
    "    rows = cursor.execute(qry, (customer_id,)).fetchall()\n",
    "    column_names = [column[0] for column in cursor.description]\n",
    "    results = [dict(zip(column_names, row)) for row in rows]\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    act(\"fetch_user_insurance_information\", results[0])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90752f7e-2026-4421-9501-e5a84f4feedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qry = \"select * from customer360  WHERE CustomerID = ? \"\n",
    "\n",
    "# # with eng.raw_connection() as connection:\n",
    "# conn = eng.raw_connection()\n",
    "# cursor = conn.cursor()\n",
    "# rows = cursor.execute(qry, ('C1001',)).fetchall()\n",
    "# column_names = [column[0] for column in cursor.description]\n",
    "# results = [dict(zip(column_names, row)) for row in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b873eccb-e193-451d-a255-4e1a81d669c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceafa64-22eb-44e1-9a85-061a45f9d830",
   "metadata": {},
   "source": [
    "### Tool 3: Generate the Insurance Proposal - DB Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f743de-6e53-4711-b190-50f69018ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def generate_insurance_proposal(config: RunnableConfig) -> dict:\n",
    "    \"\"\"Fetch all the insurance policies for the user along with corresponding personal information and policy information.\n",
    "\n",
    "    Returns:\n",
    "        Generate a Dental Treatment Proposal for given user.\n",
    "    \"\"\"\n",
    "    logs(\"generate_insurance_proposal called\")\n",
    "    think(\"I have create a proposal for the Dental Treatment as addon to existing Insurance\")\n",
    "    \n",
    "    configuration = config.get(\"configurable\", {})\n",
    "    customer_id = configuration.get(\"customer_id\", None)\n",
    "    if not customer_id:\n",
    "        raise ValueError(\"No passenger ID configured.\")\n",
    "    # customer_id = 'C1001'\n",
    "\n",
    "    qry = \"select * from customer360  WHERE CustomerID = ? \"\n",
    "\n",
    "    # with eng.raw_connection() as connection:\n",
    "    conn = eng.raw_connection()\n",
    "    cursor = conn.cursor()\n",
    "    rows = cursor.execute(qry, (customer_id,)).fetchall()\n",
    "    column_names = [column[0] for column in cursor.description]\n",
    "    results = [dict(zip(column_names, row)) for row in rows]\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    act(\"generate_insurance_proposal - Get user details\", results[0])\n",
    "    \n",
    "    # setup LLM\n",
    "    llm = ChatOpenAI(temperature=0, streaming=True, model=\"gpt-4o-mini\")\n",
    "    logs(\"Now, generating the Proposal\")\n",
    "    primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a helpful customer support assistant for ABC Overseas Travel Insurance. \"\n",
    "                \"Use the provided customer information and write a dental treatment proposal, as addon to existing insurance policies,\"\n",
    "                \"Write a travel insurance proposal for Dental Treatment as addon using given features. Write it with proper markdown and style.\"\n",
    "                \"\\n\\nCurrent user:\\n<User>\\n{user_info}\\n</User>\"\n",
    "                \"\\nCurrent time: {time}.\",\n",
    "            ),\n",
    "             (\"placeholder\", \"{messages}\"),\n",
    "        ]\n",
    "    ).partial(time=datetime.now)\n",
    "\n",
    "    prompt1 = primary_assistant_prompt.format_messages(user_info=results[0])\n",
    "    response = llm.invoke(prompt1)\n",
    "    act(\"generate_insurance_proposal - generate the proposal\", response.content)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc29d95-9a02-4bb7-b622-acf811806e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_insurance_proposal(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ceb482-efca-47d4-a72a-77ef9bb76608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e8c1a4-3c47-4ef7-b457-7d3617753c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0, streaming=True, model=\"gpt-4o-mini\")\n",
    "\n",
    "# primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"You are a helpful customer support assistant for ABC Overseas Travel Insurance. \"\n",
    "#             \"Use the provided customer information and write a dental treatment proposal, as addon to existing insurance policies,\"\n",
    "#             \"Write a travel insurance proposal for Dental Treatment as addon using given features. Write it with proper markdown and style.\"\n",
    "#             \"\\n\\nCurrent user:\\n<User>\\n Customer ID= C1001\"\n",
    "#             \"\\nCurrent time: {time}.\",\n",
    "#         ),\n",
    "#          (\"human\", \"{messages}\"),\n",
    "#     ]\n",
    "# ).partial(time=datetime.now)\n",
    "\n",
    "# prompt1 = primary_assistant_prompt.format_messages(messages=\"Mr. Bob\")\n",
    "\n",
    "# response = llm.invoke(prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38c3b9c-0135-4f65-a8f6-bb379c34c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfb90d7-f4ed-4a3c-9a28-3ea0893023bb",
   "metadata": {},
   "source": [
    "### Tool 4: Predict the user's Propensity - DB Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ae1bd7-5845-4619-9be7-a3f8197360a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def fetch_user_propensity(config: RunnableConfig) -> dict:\n",
    "    \"\"\"Fetch propensity to buy a dental treatment based on customer's personal information and previous health and dental related information.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary which contains the customer's Customer ID and prediction.\n",
    "    \"\"\"\n",
    "    logs(\"fetch_user_propensity called\")\n",
    "    think(\"I have to pass customer's details to ClearScape Analytics hosted Model to get the propensity of buying the Dental Treatment\")\n",
    "    configuration = config.get(\"configurable\", {})\n",
    "    customer_id = configuration.get(\"customer_id\", None)\n",
    "    if not customer_id:\n",
    "        raise ValueError(\"No passenger ID configured.\")\n",
    "        \n",
    "    qry = \"\"\"\n",
    "    SELECT * FROM \"mldb\".PMMLPredict(\n",
    "        ON \"df_test\" AS InputTable\n",
    "        PARTITION BY ANY \n",
    "        ON (select model_id,model from \"DEMO_USER\".\"mm_glm\") AS ModelTable\n",
    "        DIMENSION\n",
    "        USING\n",
    "        Accumulate('Customer ID')\n",
    "        OverwriteCachedModel('*')\n",
    "    ) as sqlmr\n",
    "    \"\"\"\n",
    "\n",
    "    conn = eng.raw_connection()\n",
    "    cursor = conn.cursor()\n",
    "    rows = cursor.execute(qry).fetchall()\n",
    "    column_names = [column[0] for column in cursor.description]\n",
    "    results = [dict(zip(column_names, row)) for row in rows]\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    act(\"fetch_user_propensity\", results[0])\n",
    "    return results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c81dad3-08c8-4630-a497-d91355ed3c04",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7682cc90-86e1-49a9-bcb2-17ce5ae32b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "def handle_tool_error(state) -> dict:\n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            )\n",
    "            for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def create_tool_node_with_fallback(tools: list) -> dict:\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _print_event(event: dict, _printed: set, max_length=1500):\n",
    "    current_state = event.get(\"dialog_state\")\n",
    "    if current_state:\n",
    "        print(\"Currently in: \", current_state[-1])\n",
    "    message = event.get(\"messages\")\n",
    "    if message:\n",
    "        if isinstance(message, list):\n",
    "            message = message[-1]\n",
    "        if message.id not in _printed:\n",
    "            msg_repr = message.pretty_repr(html=True)\n",
    "            if len(msg_repr) > max_length:\n",
    "                msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
    "            print(msg_repr)\n",
    "            _printed.add(message.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d732d10d-f8a3-4ee3-b6e5-8c982aa51d01",
   "metadata": {},
   "source": [
    "# Part 1: Zero-shot Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f772fd37-ad0d-40b6-ba6d-e5097682487d",
   "metadata": {},
   "source": [
    "### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67261663-8597-4481-9470-cc47f8f28365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8823527b-b384-42dd-8c3c-ad7dcb516536",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c84f94-b356-47f5-9e36-a29daeca5937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        while True:\n",
    "            configuration = config.get(\"configurable\", {})\n",
    "            customer_id = configuration.get(\"customer_id\", None)\n",
    "            state = {**state, \"user_info\": customer_id}\n",
    "            result = self.runnable.invoke(state)\n",
    "            # If the LLM happens to return an empty response, we will re-prompt it\n",
    "            # for an actual response.\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}\n",
    "\n",
    "# setup LLM\n",
    "llm = ChatOpenAI(temperature=0, streaming=True, model=\"gpt-4o-mini\")\n",
    "\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful customer support assistant for ABC Overseas Travel Insurance. \"\n",
    "            \" Use the provided tools to search for customer information, insurance policies, and other information to assist the user's queries. \"\n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \" If a search comes up empty, expand your search before giving up.\"\n",
    "            \"\\n\\nCurrent user:\\n<User>\\n{user_info}\\n</User>\"\n",
    "            \"\\nCurrent time: {time}.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ").partial(time=datetime.now)\n",
    "\n",
    "part_1_tools = [\n",
    "    fetch_user_insurance_information,\n",
    "    fetch_user_propensity,\n",
    "    lookup_policy,\n",
    "]\n",
    "part_1_assistant_runnable = primary_assistant_prompt | llm.bind_tools(part_1_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47d0eaf-38ee-4b7a-afd7-9809cb2d5891",
   "metadata": {},
   "source": [
    "### Define Graph\n",
    "Now, create the graph. The graph is the final assistant for this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ab02b7-3b10-4190-bc64-9e9db7405741",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", Assistant(part_1_assistant_runnable))\n",
    "builder.add_node(\"tools\", create_tool_node_with_fallback(part_1_tools))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "# The checkpointer lets the graph persist its state\n",
    "# this is a complete memory for the entire graph.\n",
    "memory = MemorySaver()\n",
    "part_1_graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355af3a0-3761-4bfe-b181-9eb89cbfec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(part_1_graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87803bc2-3df3-442d-a81e-477ed8975ecc",
   "metadata": {},
   "source": [
    "### Example Conversation\n",
    "\n",
    "Now it's time to try out our mighty chatbot! Let's run it over the following list of dialog turns. If it hits a \"RecursionLimit\", that means the agent wasn't able to get an answer in the allocated number of steps. That's OK! We have more tricks up our sleeve in later sections of this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b5376f-3827-469d-bce8-9cf8858b1ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import uuid\n",
    "\n",
    "# Let's create an example conversation a user might have with the assistant\n",
    "tutorial_questions = [\n",
    "    # \"Hi there, I am travelling to Malasiya, Does my insurance cover medical expense?\",\n",
    "    # \"What is the Coverage Amount for my policy?\"\n",
    "    \"What is the propnsity to buy dental treatment?\"\n",
    "]\n",
    "\n",
    "thread_id = str(uuid.uuid4())\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        # The customer_id is used in our insurance policy tools to\n",
    "        # fetch the user's insurance policy information\n",
    "        \"customer_id\": \"C1001\",\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": thread_id,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "_printed = set()\n",
    "for question in tutorial_questions:\n",
    "    events = part_1_graph.stream(\n",
    "        {\"messages\": (\"user\", question)}, config, stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "        _print_event(event, _printed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae62b292-e4ca-4f1c-9610-19f93bda3e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4dedca2f-ba4a-408f-8fcf-6fb6f3191c61",
   "metadata": {},
   "source": [
    "# Part-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a242c07-b7f7-4c73-b9c9-56391cace710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    user_info: str\n",
    "\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)\n",
    "            # If the LLM happens to return an empty response, we will re-prompt it\n",
    "            # for an actual response.\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}\n",
    "\n",
    "\n",
    "# setup LLM\n",
    "llm = ChatOpenAI(temperature=0, streaming=True, model=\"gpt-4o-mini\")\n",
    "\n",
    "assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful customer support assistant for ABC Overseas Travel Insurance. \"\n",
    "            \" Use the provided tools to search for customer information, insurance policies, and other information to assist the user's queries. \"\n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \" If a search comes up empty, expand your search before giving up.\"\n",
    "            \"\\n\\nCurrent user:\\n<User>\\n{user_info}\\n</User>\"\n",
    "            \"\\nCurrent time: {time}.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ").partial(time=datetime.now)\n",
    "\n",
    "part_2_tools = [\n",
    "    fetch_user_insurance_information,\n",
    "    fetch_user_propensity,\n",
    "    generate_insurance_proposal,\n",
    "    lookup_policy,\n",
    "]\n",
    "\n",
    "part_2_assistant_runnable = assistant_prompt | llm.bind_tools(part_2_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c34d8d9-ebf9-4647-9bd0-1f9f51598baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "\n",
    "def user_info(state: State):\n",
    "    return {\"user_info\": fetch_user_insurance_information.invoke({})}\n",
    "\n",
    "\n",
    "# NEW: The fetch_user_info node runs first, meaning our assistant can see the user's flight information without\n",
    "# having to take an action\n",
    "builder.add_node(\"fetch_user_info\", user_info)\n",
    "builder.add_edge(START, \"fetch_user_info\")\n",
    "builder.add_node(\"assistant\", Assistant(part_2_assistant_runnable))\n",
    "builder.add_node(\"tools\", create_tool_node_with_fallback(part_2_tools))\n",
    "builder.add_edge(\"fetch_user_info\", \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "part_2_graph = builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # NEW: The graph will always halt before executing the \"tools\" node.\n",
    "    # The user can approve or reject (or even alter the request) before\n",
    "    # the assistant continues\n",
    "    interrupt_before=[\"tools\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845176b7-b20f-4d7d-9106-ce2dfc490d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(part_2_graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1302821-9ea0-4165-95d8-3cb4190df80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import uuid\n",
    "\n",
    "# Update with the backup file so we can restart from the original place in each section\n",
    "# db = update_dates(db)\n",
    "thread_id = str(uuid.uuid4())\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        # The passenger_id is used in our flight tools to\n",
    "        # fetch the user's flight information\n",
    "        \"customer_id\": \"C1001\",\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": thread_id,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "_printed = set()\n",
    "# We can reuse the tutorial questions from part 1 to see how it does.\n",
    "for question in tutorial_questions:\n",
    "    events = part_2_graph.stream(\n",
    "        {\"messages\": (\"user\", question)}, config, stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "        _print_event(event, _printed)\n",
    "    snapshot = part_2_graph.get_state(config)\n",
    "    while snapshot.next:\n",
    "        # We have an interrupt! The agent is trying to use a tool, and the user can approve or deny it\n",
    "        # Note: This code is all outside of your graph. Typically, you would stream the output to a UI.\n",
    "        # Then, you would have the frontend trigger a new run via an API call when the user has provided input.\n",
    "        try:\n",
    "            user_input = input(\n",
    "                \"Do you approve of the above actions? Type 'y' to continue;\"\n",
    "                \" otherwise, explain your requested changed.\\n\\n\"\n",
    "            )\n",
    "        except:\n",
    "            user_input = \"y\"\n",
    "        if user_input.strip() == \"y\":\n",
    "            # Just continue\n",
    "            result = part_2_graph.invoke(\n",
    "                None,\n",
    "                config,\n",
    "            )\n",
    "        else:\n",
    "            # Satisfy the tool invocation by\n",
    "            # providing instructions on the requested changes / change of mind\n",
    "            result = part_2_graph.invoke(\n",
    "                {\n",
    "                    \"messages\": [\n",
    "                        ToolMessage(\n",
    "                            tool_call_id=event[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "                            content=f\"API call denied by user. Reasoning: '{user_input}'. Continue assisting, accounting for the user's input.\",\n",
    "                        )\n",
    "                    ]\n",
    "                },\n",
    "                config,\n",
    "            )\n",
    "        snapshot = part_2_graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8c90d2-cdef-4ec4-b09f-64fe415abeae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7af69147-6de7-477e-8971-75684dc7697e",
   "metadata": {},
   "source": [
    "# Part 3: Conditional Interrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2cbfac-1257-451a-96b5-3c5c1a7712fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    user_info: str\n",
    "\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)\n",
    "            # If the LLM happens to return an empty response, we will re-prompt it\n",
    "            # for an actual response.\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}\n",
    "\n",
    "\n",
    "# setup LLM\n",
    "llm = ChatOpenAI(temperature=0, streaming=True, model=\"gpt-4o-mini\")\n",
    "\n",
    "assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful customer support assistant for ABC Overseas Travel Insurance. \"\n",
    "            \" Use the provided tools to search for customer information, insurance policies, and other information to assist the user's queries. \"\n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \" If a search comes up empty, expand your search before giving up.\"\n",
    "            \"\\n\\nCurrent user:\\n<User>\\n{user_info}\\n</User>\"\n",
    "            \"\\nCurrent time: {time}.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ").partial(time=datetime.now)\n",
    "\n",
    "\n",
    "# \"Read\"-only tools (such as retrievers) don't need a user confirmation to use\n",
    "part_3_safe_tools = [\n",
    "    fetch_user_insurance_information,\n",
    "    fetch_user_propensity,\n",
    "    lookup_policy,\n",
    "    generate_insurance_proposal\n",
    "]\n",
    "\n",
    "# These tools all change the user's reservations.\n",
    "# The user has the right to control what decisions are made\n",
    "part_3_sensitive_tools = []\n",
    "\n",
    "sensitive_tool_names = {t.name for t in part_3_sensitive_tools}\n",
    "# Our LLM doesn't have to know which nodes it has to route to. In its 'mind', it's just invoking functions.\n",
    "part_3_assistant_runnable = assistant_prompt | llm.bind_tools(\n",
    "    part_3_safe_tools + part_3_sensitive_tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e4c7a3-5435-4fbe-9c1f-156240675ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "\n",
    "def user_info(state: State):\n",
    "    return {\"user_info\": fetch_user_insurance_information.invoke({})}\n",
    "\n",
    "\n",
    "# NEW: The fetch_user_info node runs first, meaning our assistant can see the user's flight information without\n",
    "# having to take an action\n",
    "builder.add_node(\"fetch_user_info\", user_info)\n",
    "builder.add_edge(START, \"fetch_user_info\")\n",
    "builder.add_node(\"assistant\", Assistant(part_3_assistant_runnable))\n",
    "builder.add_node(\"safe_tools\", create_tool_node_with_fallback(part_3_safe_tools))\n",
    "builder.add_node(\n",
    "    \"sensitive_tools\", create_tool_node_with_fallback(part_3_sensitive_tools)\n",
    ")\n",
    "# Define logic\n",
    "builder.add_edge(\"fetch_user_info\", \"assistant\")\n",
    "\n",
    "\n",
    "def route_tools(state: State):\n",
    "    next_node = tools_condition(state)\n",
    "    # If no tools are invoked, return to the user\n",
    "    if next_node == END:\n",
    "        return END\n",
    "    ai_message = state[\"messages\"][-1]\n",
    "    # This assumes single tool calls. To handle parallel tool calling, you'd want to\n",
    "    # use an ANY condition\n",
    "    first_tool_call = ai_message.tool_calls[0]\n",
    "    if first_tool_call[\"name\"] in sensitive_tool_names:\n",
    "        return \"sensitive_tools\"\n",
    "    return \"safe_tools\"\n",
    "\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\", route_tools, [\"safe_tools\", \"sensitive_tools\", END]\n",
    ")\n",
    "builder.add_edge(\"safe_tools\", \"assistant\")\n",
    "builder.add_edge(\"sensitive_tools\", \"assistant\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "part_3_graph = builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # NEW: The graph will always halt before executing the \"tools\" node.\n",
    "    # The user can approve or reject (or even alter the request) before\n",
    "    # the assistant continues\n",
    "    interrupt_before=[\"sensitive_tools\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa340b2-d713-4ba3-a932-918e731a1b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(part_3_graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae401a7f-6fe7-47e7-8ed5-cee6ff36ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import uuid\n",
    "\n",
    "# Update with the backup file so we can restart from the original place in each section\n",
    "# db = update_dates(db)\n",
    "thread_id = str(uuid.uuid4())\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        # The passenger_id is used in our flight tools to\n",
    "        # fetch the user's flight information\n",
    "        \"customer_id\": \"C1001\",\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": thread_id,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Let's create an example conversation a user might have with the assistant\n",
    "tutorial_questions = [\n",
    "    \"Hi there, I am travelling to Malasiya, Does my insurance cover medical expense?\",\n",
    "    \"What is the propnsity to buy dental treatment?\"\n",
    "    \"Can you generate the new Insruance Proposal for me?\"\n",
    "]\n",
    "\n",
    "\n",
    "_printed = set()\n",
    "# We can reuse the tutorial questions from part 1 to see how it does.\n",
    "for question in tutorial_questions:\n",
    "    events = part_3_graph.stream(\n",
    "        {\"messages\": (\"user\", question)}, config, stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "        _print_event(event, _printed)\n",
    "    snapshot = part_3_graph.get_state(config)\n",
    "    while snapshot.next:\n",
    "        # We have an interrupt! The agent is trying to use a tool, and the user can approve or deny it\n",
    "        # Note: This code is all outside of your graph. Typically, you would stream the output to a UI.\n",
    "        # Then, you would have the frontend trigger a new run via an API call when the user has provided input.\n",
    "        try:\n",
    "            user_input = input(\n",
    "                \"Do you approve of the above actions? Type 'y' to continue;\"\n",
    "                \" otherwise, explain your requested changed.\\n\\n\"\n",
    "            )\n",
    "        except:\n",
    "            user_input = \"y\"\n",
    "        if user_input.strip() == \"y\":\n",
    "            # Just continue\n",
    "            result = part_3_graph.invoke(\n",
    "                None,\n",
    "                config,\n",
    "            )\n",
    "        else:\n",
    "            # Satisfy the tool invocation by\n",
    "            # providing instructions on the requested changes / change of mind\n",
    "            result = part_3_graph.invoke(\n",
    "                {\n",
    "                    \"messages\": [\n",
    "                        ToolMessage(\n",
    "                            tool_call_id=event[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "                            content=f\"API call denied by user. Reasoning: '{user_input}'. Continue assisting, accounting for the user's input.\",\n",
    "                        )\n",
    "                    ]\n",
    "                },\n",
    "                config,\n",
    "            )\n",
    "        snapshot = part_3_graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750fab57-d7c1-403a-9708-5adf7675e824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a9a1aeb-bfd5-4ec5-8123-8491b98edfca",
   "metadata": {},
   "source": [
    "# Part 4: Specialized Workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "42baaf93-95b1-43ca-bc49-6be92767beb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, Optional\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "\n",
    "def update_dialog_stack(left: list[str], right: Optional[str]) -> list[str]:\n",
    "    \"\"\"Push or pop the state.\"\"\"\n",
    "    if right is None:\n",
    "        return left\n",
    "    if right == \"pop\":\n",
    "        return left[:-1]\n",
    "    return left + [right]\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    user_info: str\n",
    "    dialog_state: Annotated[\n",
    "        list[\n",
    "            Literal[\n",
    "                \"assistant\",\n",
    "                \"insurance_policy_lookup\",\n",
    "            ]\n",
    "        ],\n",
    "        update_dialog_stack,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "51096f93-bb03-4ea5-b1de-b6a44c5731a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)\n",
    "\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}\n",
    "\n",
    "\n",
    "class CompleteOrEscalate(BaseModel):\n",
    "    \"\"\"A tool to mark the current task as completed and/or to escalate control of the dialog to the main assistant,\n",
    "    who can re-route the dialog based on the user's needs.\"\"\"\n",
    "\n",
    "    cancel: bool = True\n",
    "    reason: str\n",
    "\n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"cancel\": True,\n",
    "                \"reason\": \"User changed their mind about the current task.\",\n",
    "            },\n",
    "            \"example 2\": {\n",
    "                \"cancel\": True,\n",
    "                \"reason\": \"I have fully completed the task.\",\n",
    "            },\n",
    "            \"example 3\": {\n",
    "                \"cancel\": False,\n",
    "                \"reason\": \"I need to search the user's emails or calendar for more information.\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "# Car Rental Assistant\n",
    "insurance_policy_lookup_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a specialized assistant for travel health insurance. \"\n",
    "            \"The primary assistant delegates work to you whenever the user needs help insurance policy. \"\n",
    "            \"Search for available correct answer based on the user's query. \"\n",
    "            \"If you need more information or the customer changes their mind, escalate the task back to the main assistant.\"\n",
    "            \"\\nCurrent time: {time}.\"\n",
    "            \"\\n\\nIf the user needs help, and none of your tools are appropriate for it, then \"\n",
    "            '\"CompleteOrEscalate\" the dialog to the host assistant. Do not waste the user\\'s time. Do not make up invalid tools or functions.'\n",
    "            \"\\n\\nSome examples for which you should CompleteOrEscalate:\\n\"\n",
    "            \" - 'Does my policy includes personal belongings lost?'\\n\"\n",
    "            \" - 'What is covered in my policy?'\\n\"\n",
    "            \" - 'What is the reimbursement limit for passport loss?'\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ").partial(time=datetime.now)\n",
    "\n",
    "insurance_policy_lookup_safe_tools = [lookup_policy]\n",
    "insurance_policy_lookup_sensitive_tools = []\n",
    "\n",
    "insurance_policy_lookup_tools = insurance_policy_lookup_safe_tools + insurance_policy_lookup_sensitive_tools\n",
    "insurance_policy_lookup_runnable = insurance_policy_lookup_prompt | llm.bind_tools(\n",
    "    insurance_policy_lookup_tools + [CompleteOrEscalate]\n",
    ")\n",
    "\n",
    "class ToBookCarRental(BaseModel):\n",
    "    \"\"\"Transfers work to a specialized assistant to handle user's query on travel insurance.\"\"\"\n",
    "    request: str = Field(\n",
    "        description=\"Any additional information or requests from the user regarding the travel insurance.\"\n",
    "    )\n",
    "\n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"end_date\": \"2023-07-05\",\n",
    "                \"request\": \"What is the Maximum Coverage Limit for Medical Expenses?\",\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, streaming=True, model=\"gpt-4o-mini\")\n",
    "\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful customer support assistant for ABC Overseas Travel Insurance. \"\n",
    "            \"Your primary role is to search for insurance information and insurance policies to answer customer queries. \"\n",
    "            \"delegate the task to the appropriate specialized assistant by invoking the corresponding tool. You are not able to make these types of changes yourself.\"            \n",
    "            \" Only the specialized assistants are given permission to do this for the user.\"\n",
    "            \"The user is not aware of the different specialized assistants, so do not mention them; just quietly delegate through function calls. \"\n",
    "            \"Provide detailed information to the customer, and always double-check the database before concluding that information is unavailable. \"\n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \" If a search comes up empty, expand your search before giving up.\"\n",
    "            \"\\n\\nCurrent user flight information:\\n<Flights>\\n{user_info}\\n</Flights>\"\n",
    "            \"\\nCurrent time: {time}.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ").partial(time=datetime.now)\n",
    "\n",
    "primary_assistant_tools = [\n",
    "    lookup_policy,\n",
    "]\n",
    "assistant_runnable = primary_assistant_prompt | llm.bind_tools(\n",
    "    primary_assistant_tools\n",
    "    + [\n",
    "        ToBookCarRental,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c5abee45-5b02-4539-a56e-8048845f4ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "def create_entry_node(assistant_name: str, new_dialog_state: str) -> Callable:\n",
    "    def entry_node(state: State) -> dict:\n",
    "        tool_call_id = state[\"messages\"][-1].tool_calls[0][\"id\"]\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                ToolMessage(\n",
    "                    content=f\"The assistant is now the {assistant_name}. Reflect on the above conversation between the host assistant and the user.\"\n",
    "                    f\" The user's intent is unsatisfied. Use the provided tools to assist the user. Remember, you are {assistant_name},\"\n",
    "                    \" and the booking, update, other other action is not complete until after you have successfully invoked the appropriate tool.\"\n",
    "                    \" If the user changes their mind or needs help for other tasks, call the CompleteOrEscalate function to let the primary host assistant take control.\"\n",
    "                    \" Do not mention who you are - just act as the proxy for the assistant.\",\n",
    "                    tool_call_id=tool_call_id,\n",
    "                )\n",
    "            ],\n",
    "            \"dialog_state\": new_dialog_state,\n",
    "        }\n",
    "\n",
    "    return entry_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1dcf967f-66ac-4c14-b35b-b4266d19c3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7fe13d40f850>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "\n",
    "def user_info(state: State):\n",
    "    return {\"user_info\": fetch_user_insurance_information.invoke({})}\n",
    "\n",
    "\n",
    "builder.add_node(\"fetch_user_info\", user_info)\n",
    "builder.add_edge(START, \"fetch_user_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "04f54511-6078-4a98-b9a8-0ae52dc85a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7fe13d40f850>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This node will be shared for exiting all specialized assistants\n",
    "def pop_dialog_state(state: State) -> dict:\n",
    "    \"\"\"Pop the dialog stack and return to the main assistant.\n",
    "\n",
    "    This lets the full graph explicitly track the dialog flow and delegate control\n",
    "    to specific sub-graphs.\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    if state[\"messages\"][-1].tool_calls:\n",
    "        # Note: Doesn't currently handle the edge case where the llm performs parallel tool calls\n",
    "        messages.append(\n",
    "            ToolMessage(\n",
    "                content=\"Resuming dialog with the host assistant. Please reflect on the past conversation and assist the user as needed.\",\n",
    "                tool_call_id=state[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "            )\n",
    "        )\n",
    "    return {\n",
    "        \"dialog_state\": \"pop\",\n",
    "        \"messages\": messages,\n",
    "    }\n",
    "\n",
    "\n",
    "builder.add_node(\"leave_skill\", pop_dialog_state)\n",
    "builder.add_edge(\"leave_skill\", \"primary_assistant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "41e36eaa-dde1-45ab-b13d-9774e1aef874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7fe13d40f850>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Car rental assistant\n",
    "\n",
    "builder.add_node(\n",
    "    \"enter_policy_lookup\",\n",
    "    create_entry_node(\"Car Rental Assistant\", \"insurance_policy_lookup\"),\n",
    ")\n",
    "builder.add_node(\"insurance_policy_lookup\", Assistant(insurance_policy_lookup_runnable))\n",
    "builder.add_edge(\"enter_policy_lookup\", \"insurance_policy_lookup\")\n",
    "builder.add_node(\n",
    "    \"insurance_policy_lookup_safe_tools\",\n",
    "    create_tool_node_with_fallback(insurance_policy_lookup_safe_tools),\n",
    ")\n",
    "builder.add_node(\n",
    "    \"insurance_policy_lookup_sensitive_tools\",\n",
    "    create_tool_node_with_fallback(insurance_policy_lookup_sensitive_tools),\n",
    ")\n",
    "\n",
    "\n",
    "def route_insurance_policy_lookup(\n",
    "    state: State,\n",
    "):\n",
    "    route = tools_condition(state)\n",
    "    if route == END:\n",
    "        return END\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    did_cancel = any(tc[\"name\"] == CompleteOrEscalate.__name__ for tc in tool_calls)\n",
    "    if did_cancel:\n",
    "        return \"leave_skill\"\n",
    "    safe_toolnames = [t.name for t in insurance_policy_lookup_safe_tools]\n",
    "    if all(tc[\"name\"] in safe_toolnames for tc in tool_calls):\n",
    "        return \"insurance_policy_lookup_safe_tools\"\n",
    "    return \"insurance_policy_lookup_sensitive_tools\"\n",
    "\n",
    "\n",
    "builder.add_edge(\"insurance_policy_lookup_sensitive_tools\", \"insurance_policy_lookup\")\n",
    "builder.add_edge(\"insurance_policy_lookup_safe_tools\", \"insurance_policy_lookup\")\n",
    "builder.add_conditional_edges(\n",
    "    \"insurance_policy_lookup\",\n",
    "    route_insurance_policy_lookup,\n",
    "    [\n",
    "        \"insurance_policy_lookup_safe_tools\",\n",
    "        \"insurance_policy_lookup_sensitive_tools\",\n",
    "        \"leave_skill\",\n",
    "        END,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5303d27c-2957-440d-a376-29c2af507fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary assistant\n",
    "builder.add_node(\"primary_assistant\", Assistant(assistant_runnable))\n",
    "builder.add_node(\n",
    "    \"primary_assistant_tools\", create_tool_node_with_fallback(primary_assistant_tools)\n",
    ")\n",
    "\n",
    "\n",
    "def route_primary_assistant(\n",
    "    state: State,\n",
    "):\n",
    "    route = tools_condition(state)\n",
    "    if route == END:\n",
    "        return END\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    if tool_calls:\n",
    "        if tool_calls[0][\"name\"] == ToBookCarRental.__name__:\n",
    "            return \"enter_policy_lookup\"\n",
    "        return \"primary_assistant_tools\"\n",
    "    raise ValueError(\"Invalid route\")\n",
    "\n",
    "\n",
    "\n",
    "# Each delegated workflow can directly respond to the user\n",
    "# When the user responds, we want to return to the currently active workflow\n",
    "def route_to_workflow(\n",
    "    state: State,\n",
    ") -> Literal[\n",
    "    \"primary_assistant\",\n",
    "    \"insurance_policy_lookup\",\n",
    "]:\n",
    "    \"\"\"If we are in a delegated state, route directly to the appropriate assistant.\"\"\"\n",
    "    dialog_state = state.get(\"dialog_state\")\n",
    "    if not dialog_state:\n",
    "        return \"primary_assistant\"\n",
    "    return dialog_state[-1]\n",
    "\n",
    "\n",
    "builder.add_conditional_edges(\"fetch_user_info\", route_to_workflow)\n",
    "\n",
    "# Compile graph\n",
    "memory = MemorySaver()\n",
    "part_4_graph = builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # Let the user approve or deny the use of sensitive tools\n",
    "    interrupt_before=[\n",
    "        \"insurance_policy_lookup_sensitive_tools\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e3d25976-ae8d-41e2-b72b-e7ca6ff0c56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(part_4_graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "70008a25-5f09-46b2-86b7-f57cb517cf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi there, I am travelling to Malasiya, Does my insurance cover medical expense?\n",
      "\n",
      "ℹ️ LOGS : fetch_user_insurance_information called\n",
      "==================================================\n",
      "🎯 ACTION: fetch_user_insurance_information\n",
      "📝 RESULT: {'CustomerID': 'C1001', 'Name': 'John Smith', 'Age': 53, 'Income': 69116, 'Occupation': 'Nurse', 'MaritalStatus': 'Divorced', 'Children': 0, 'Location': 'Suburban', 'PolicyID': 'P1A', 'PolicyType': 'Auto', 'CoverageAmount': 507042, 'PremiumAmount': 3132, 'RenewalDate': '1/21/2025', 'ClaimID': 'C1A', 'ClaimType': 'Natural Disaster', 'ClaimAmount': 27612, 'ClaimStatus': 'Approved', 'InteractionID': 'I1A', 'InteractionType': 'Call', 'InteractionDate': '11/13/2024', 'InteractionNotes': 'Interaction notes for customer 1', 'Preferences': 'Budget-Friendly', 'BehavioralPatterns': 'Customer 1 prefers online transactions.', 'RiskLevel': 'High', 'RiskFactors': 'Customer 1 has a moderate risk profile due to driving history.', 'FraudulentActivitiesDetected': 1, 'UnusualPatterns': \"Unusual patterns detected in customer 1's transactions.\", 'SatisfactionScore': 8, 'FeedbackNotes': 'Customer 1 mentioned satisfactory experience.', 'PotentialChurnRisk': 'Low', 'LifetimeValuePrediction': 84300}\n",
      "\n",
      "==================================================\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  lookup_policy (call_jaiPKzaxT2LE3omuXDsOBnk1)\n",
      " Call ID: call_jaiPKzaxT2LE3omuXDsOBnk1\n",
      "  Args:\n",
      "    query: medical expense coverage\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the propnsity to buy dental treatment?Can you generate the new Insruance Proposal for me?\n",
      "\n",
      "ℹ️ LOGS : fetch_user_insurance_information called\n",
      "==================================================\n",
      "🎯 ACTION: fetch_user_insurance_information\n",
      "📝 RESULT: {'CustomerID': 'C1001', 'Name': 'John Smith', 'Age': 53, 'Income': 69116, 'Occupation': 'Nurse', 'MaritalStatus': 'Divorced', 'Children': 0, 'Location': 'Suburban', 'PolicyID': 'P1A', 'PolicyType': 'Auto', 'CoverageAmount': 507042, 'PremiumAmount': 3132, 'RenewalDate': '1/21/2025', 'ClaimID': 'C1A', 'ClaimType': 'Natural Disaster', 'ClaimAmount': 27612, 'ClaimStatus': 'Approved', 'InteractionID': 'I1A', 'InteractionType': 'Call', 'InteractionDate': '11/13/2024', 'InteractionNotes': 'Interaction notes for customer 1', 'Preferences': 'Budget-Friendly', 'BehavioralPatterns': 'Customer 1 prefers online transactions.', 'RiskLevel': 'High', 'RiskFactors': 'Customer 1 has a moderate risk profile due to driving history.', 'FraudulentActivitiesDetected': 1, 'UnusualPatterns': \"Unusual patterns detected in customer 1's transactions.\", 'SatisfactionScore': 8, 'FeedbackNotes': 'Customer 1 mentioned satisfactory experience.', 'PotentialChurnRisk': 'Low', 'LifetimeValuePrediction': 84300}\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_jaiPKzaxT2LE3omuXDsOBnk1\", 'type': 'invalid_request_error', 'param': 'messages.[3].role', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m tutorial_questions:\n\u001b[1;32m     21\u001b[0m     events \u001b[38;5;241m=\u001b[39m part_4_graph\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m     22\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, question)}, config, stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m     )\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[1;32m     25\u001b[0m         _print_event(event, _printed)\n\u001b[1;32m     26\u001b[0m     snapshot \u001b[38;5;241m=\u001b[39m part_4_graph\u001b[38;5;241m.\u001b[39mget_state(config)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/langgraph/pregel/__init__.py:1724\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1718\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1721\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1722\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1724\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1725\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   1726\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   1727\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   1728\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   1729\u001b[0m         ):\n\u001b[1;32m   1730\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[1;32m   1732\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/langgraph/pregel/runner.py:230\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    228\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/langgraph/utils/runnable.py:495\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m    492\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    493\u001b[0m )\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 495\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/langgraph/utils/runnable.py:259\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 259\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[86], line 14\u001b[0m, in \u001b[0;36mAssistant.__call__\u001b[0;34m(self, state, config)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, state: State, config: RunnableConfig):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39mtool_calls \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     18\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m     19\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39mcontent[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m         ):\n\u001b[1;32m     21\u001b[0m             messages \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRespond with a real output.\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/langchain_core/runnables/base.py:3016\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3014\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3015\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3016\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3017\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3018\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/langchain_core/runnables/base.py:5352\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   5347\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5348\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   5349\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5350\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5351\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5353\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5354\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5355\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5356\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:284\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    281\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    283\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 284\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    294\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:860\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    854\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    859\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:690\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 690\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m         )\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:925\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 925\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    929\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/langchain_openai/chat_models/base.py:771\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstreaming:\n\u001b[1;32m    768\u001b[0m     stream_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\n\u001b[1;32m    769\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    770\u001b[0m     )\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgenerate_from_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    772\u001b[0m payload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_request_payload(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    773\u001b[0m generation_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py:87\u001b[0m, in \u001b[0;36mgenerate_from_stream\u001b[0;34m(stream)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_from_stream\u001b[39m(stream: Iterator[ChatGenerationChunk]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[1;32m     79\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate from a stream.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m        ChatResult: Chat result.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m     generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m generation:\n\u001b[1;32m     89\u001b[0m         generation \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(stream)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/langchain_openai/chat_models/base.py:722\u001b[0m, in \u001b[0;36mBaseChatOpenAI._stream\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m         base_generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 722\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m response\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/openai/resources/chat/completions.py:850\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    847\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    848\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    849\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 850\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/openai/_base_client.py:1283\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1271\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1279\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1280\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1281\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1282\u001b[0m     )\n\u001b[0;32m-> 1283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/openai/_base_client.py:960\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/openai/_base_client.py:1064\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1063\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1064\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1067\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1068\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1073\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_jaiPKzaxT2LE3omuXDsOBnk1\", 'type': 'invalid_request_error', 'param': 'messages.[3].role', 'code': None}}"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import uuid\n",
    "\n",
    "# Update with the backup file so we can restart from the original place in each section\n",
    "# db = update_dates(db)\n",
    "thread_id = str(uuid.uuid4())\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        # The passenger_id is used in our flight tools to\n",
    "        # fetch the user's flight information\n",
    "        \"customer_id\": \"C1001\",\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": thread_id,\n",
    "    }\n",
    "}\n",
    "\n",
    "_printed = set()\n",
    "# We can reuse the tutorial questions from part 1 to see how it does.\n",
    "for question in tutorial_questions:\n",
    "    events = part_4_graph.stream(\n",
    "        {\"messages\": (\"user\", question)}, config, stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "        _print_event(event, _printed)\n",
    "    snapshot = part_4_graph.get_state(config)\n",
    "    while snapshot.next:\n",
    "        # We have an interrupt! The agent is trying to use a tool, and the user can approve or deny it\n",
    "        # Note: This code is all outside of your graph. Typically, you would stream the output to a UI.\n",
    "        # Then, you would have the frontend trigger a new run via an API call when the user has provided input.\n",
    "        try:\n",
    "            user_input = input(\n",
    "                \"Do you approve of the above actions? Type 'y' to continue;\"\n",
    "                \" otherwise, explain your requested changed.\\n\\n\"\n",
    "            )\n",
    "        except:\n",
    "            user_input = \"y\"\n",
    "        if user_input.strip() == \"y\":\n",
    "            # Just continue\n",
    "            result = part_4_graph.invoke(\n",
    "                None,\n",
    "                config,\n",
    "            )\n",
    "        else:\n",
    "            # Satisfy the tool invocation by\n",
    "            # providing instructions on the requested changes / change of mind\n",
    "            result = part_4_graph.invoke(\n",
    "                {\n",
    "                    \"messages\": [\n",
    "                        ToolMessage(\n",
    "                            tool_call_id=event[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "                            content=f\"API call denied by user. Reasoning: '{user_input}'. Continue assisting, accounting for the user's input.\",\n",
    "                        )\n",
    "                    ]\n",
    "                },\n",
    "                config,\n",
    "            )\n",
    "        snapshot = part_4_graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64a1b00-61b9-41e1-bb93-461d9805d0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
