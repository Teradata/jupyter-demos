{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acquired-consideration",
   "metadata": {},
   "source": [
    "<header style=\"padding:1px;background:#f9f9f9;border-top:3px solid #00b2b1\"><img id=\"Teradata-logo\" src=\"https://www.teradata.com/Teradata/Images/Rebrand/Teradata_logo-two_color.png\" alt=\"Teradata\" width=\"220\" align=\"right\" />\n",
    "\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>Energy Consumption Forecasting using Vantage and scikit</b>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0701a2ac-9d7c-4498-a23c-7ae3955f6a32",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Introduction:</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>For energy trading companies, forecasting of electricity consumption is one key driver in building a successful business. Proper forecasting of market demand prevents losses (in case of overselling energy to market) as well as lost profits (in case of underestimating of demand). Also, the regulator of the energy market can apply fees or even disqualify a trading company for certain time periods in case of frequent inaccurate forecasts. This is why increasing the accuracy even by 0.1% can significantly improve the profitability of the energy trading company.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this demo we demonstrate how the full lifecycle of consumption forecast can be implemented using Vantage technologies and specifically, the combination of Bring Your Own Model (BYOM), Vantage Analytics Library (VAL) and teradataml python client library solution. This demo consists of four parts (details on Teradata \"Analytics 1-2-3\" strategy can be found <a href = 'https://assets.teradata.com/resourceCenter/downloads/WhitePapers/Analytics-123-Enabling-Enterprise-AI-at-Scale-MD006623.pdf'>here</a>):</p>\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Data discovery using client python libraries</li>\n",
    "    <li>Feature Prep and Transformation using Vantage Analytic Library</li>\n",
    "    <li>Model training using the scikit-learn LinearRegression algorithm</li>\n",
    "    <li>Scoring the model in Vantage and analyzing the results</li>\n",
    "    </ol>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The dataset used in this demo represents electricity consumption in Norway for the period from 1st of January 2016 to 31st of August 2019. Each line in this dataset reflects consumption for one hour. Apart of electricity consumption this datamart also reflects additional data: weather from multiple sources, daylight information and labor calendar. All data were collected from open data sources.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-turkey",
   "metadata": {},
   "source": [
    "<b style = 'font-size:18px;font-family:Arial;color:#E37C4D'>Utilize Vantage to Operationalize the Machine Learning Process</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Open-source tools and techniques provide a rich ecosystem for data scientists and analysts to gain new insights into their data.  However, the process of obtaining these insights is manual, error-prone, and time-consuming process.  Most machine learning tools and platforms seek to make model training more efficient, and ignore the more significant challenges with;</p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Data Discovery and Statistical Analysis</li>\n",
    "    <li>Data Preparation and Feature Engineering</li>\n",
    "    <li>Model Deployment and Evaluation At Operational Scale</li>\n",
    "    </ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Traditional approaches require the developer to move data <b>from</b> the sources <b>to</b> the analytics.  Even \"integrated\" analytic systems like Apache Spark provide parallel processing for analyzing data, but don't optimize for loading data - neither locality nor quantity that needs to be moved.</p>\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Teradata Vantage reverses this model; and provides the ability to PUSH processing down to the individual processing nodes where the data resides.  This allows for unprecedented scale of the analytical proccessing, reduced costs in data movement/egress charges, and drastically improved performance.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d444f9-e2f7-4282-a293-96802ff2db7b",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Installing some dependencies</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c074f7-9866-4af0-b822-434435c361a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# '%%capture' suppresses the display of installation steps of the following packages\n",
    "!pip install sklearn2pmml\n",
    "!pip install jdk4py\n",
    "!pip install teradataml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10db2ec-ce66-411d-bb03-b9262752d667",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "    <i><b>*BEFORE proceeding, please RESTART the kernel to bring new software into Jupyter.</b></i>\n",
    "</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from teradataml import *\n",
    "from teradataml.analytics.valib import *\n",
    "import teradataml.analytics.Transformations as tdtf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from jdk4py import JAVA, JAVA_HOME, JAVA_VERSION\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn2pmml.pipeline import PMMLPipeline\n",
    "from sklearn2pmml import sklearn2pmml\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Modify the following to match the specific client environment settings\n",
    "configure.val_install_location = 'val'\n",
    "configure.byom_install_location = 'mldb'\n",
    "os.environ['PATH'] = os.environ['PATH'] + os.pathsep + str(JAVA_HOME)\n",
    "os.environ['PATH'] = os.environ['PATH'] + os.pathsep + str(JAVA)[:-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ceca99-2c7d-466d-8f3d-9982baeb6778",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>1. Initiate a connection to Vantage</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>You will be prompted to provide the password. Enter your password, press the Enter key, then use down arrow to go to next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c10686e-25cd-432d-919a-c3710b0d17cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6959bfc1-2fa8-48e4-a7f1-a1f1d416fed3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Below command will create a context to the Vantage connection.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c14d14-b61a-4e67-9b4e-c7efcd67e1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254ca2df-fa67-4ebd-b5d4-08a318e1fb48",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f98c5b-3b22-44ae-bf64-8695569d2970",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SET query_band='DEMO=Consumption_Forecasting_BYOM.ipynb;' UPDATE FOR SESSION;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cb576b-61be-4091-a8d8-13060d4329a5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have provided data for this demo on cloud storage.  You have the option of either running the demo using foreign tables to access the data without using any storage on your environment or downloading the data to local storage which may yield somewhat faster execution, but there could be considerations of available storage.  There are two statements in the following cell, and one is commented out.  You may switch which mode you choose by changing the comment string.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deb8012-7c68-42d1-a9c8-cb49789c2c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call get_data('demo_energy_cloud');\"        # Takes 10 seconds\n",
    "# %run -i ../run_procedure.py \"call get_data('demo_energy_local');\"        # Takes 30 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4085ecd7-3fd2-427f-8a18-254e91c0bdec",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Next is an optional step – if you want to see status of databases/tables created and space used. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daff2d91-73a8-4df3-8636-b993799c5a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-championship",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>2. Data Discovery using teradataml</b>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "<tr>\n",
    "    <td style = 'vertical-align:top' width = '50%'>\n",
    "        <p style = 'font-size:16px;font-family:Arial'>Users can access large volumes of data by connecting remotely using the teradataml client connection library.  Python methods are translated to SQL and run remotely on the Vantage system.  Only the minimal amount of data required is copied to the client; allowing users to interact with data sets of any size and scale.\n",
    "        <ol style = 'font-size:16px;font-family:Arial'>\n",
    "            <li>Create a \"Virtual DataFrame\" that points to the data set in Vantage</li>\n",
    "            <br>\n",
    "            <li>Use Pandas syntax to investigate the data</li>\n",
    "        </ol>\n",
    "    </td>\n",
    "    <td><img src = 'images/connect_and_discover.png' width = '400'></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = DataFrame(in_schema(\"DEMO_Energy\", \"consumption\"))\n",
    "print(tdf.shape)\n",
    "tdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5989392d-db19-4be6-ad75-9df5ce829a5e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The dataset above shows hourly consumption of energy. There are multiple columns that are potential factors affecting energy consumption such as: is_dark, is_holiday, etc.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-spencer",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>3. Feature Prep and Transformation with Vantage Analytic Library</b>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "<tr>\n",
    "    <td style = 'vertical-align:top' width = '50%'>\n",
    "        <p style = 'font-size:16px;font-family:Arial'>The Vantage Analytic Library is a suite of powerful functions that allows for whole-data-set desrcriptive analysis, data transformation, hypothesis testing, and algorithmic algorithms at extreme scale.  As with all Vantage capabilities, these functions run in parallel, at the source of the data</p>\n",
    "        <ol style = 'font-size:16px;font-family:Arial'>\n",
    "            <li>Create Feature Transformation objects</li>\n",
    "            <br>\n",
    "            <li>Define the columns to be retained in the analytic data set</li>\n",
    "            <br>\n",
    "            <li>Push the transformations to the data in Vantage</li>\n",
    "            <br>\n",
    "            <li>Inspect the results</li>\n",
    "        </ol>\n",
    "    </td>\n",
    "    <td><img src = 'images/VAL_transformation.png' width = '400'></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_mapping = {1:'monday', 2:'tuesday', 3:'wednesday', 4:'thursday', 5:'friday', 6:'saturday', 7:'sunday'}\n",
    "weekday_t = tdtf.OneHotEncoder(values = weekday_mapping, columns = 'weekday')\n",
    "\n",
    "hour_t = tdtf.OneHotEncoder(values = [x for x in range(0,24)],  columns = 'h')\n",
    "\n",
    "rs = tdtf.MinMaxScalar(columns = 'nasa_temp')\n",
    "\n",
    "rt = Retain(columns = ['consumption',  \n",
    "                       'cap_air_temperature', 'cap_cloud_area_fraction', 'cap_precipitation_amount', \n",
    "                       'is_dark', 'is_light', 'is_from_light_to_dark', 'is_from_dark_to_light', \n",
    "                       'is_holiday', 'is_pre_holiday'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26620753-a458-492d-bef2-3cb1c8f75701",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above step created transformation objects i.e. weekday_t, hour_t, rs and rt. These will be used to convert weekdays and hours from numeric to one hot encoded columns, to scale nasa_temp using MinMaxScalar and rt object to retain given columns.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_output = valib.Transform(data = tdf,\n",
    "                           one_hot_encode = [weekday_t, hour_t], \n",
    "                           rescale = [rs], \n",
    "                           index_columns = 'TD_TIMECODE',\n",
    "                           retain = [rt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-point",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_output.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080268d2-4cc4-4f98-b2fd-1a8a09a0bfc1",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Please scroll to right and observe that we now have columns named <b>monday-sunday</b> and <b>0_h - 23_h</b>. Also, nasa_temp has been scaled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-instrument",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>4. Model Training</b>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "<tr>\n",
    "    <td style = 'vertical-align:top' width = '50%'>\n",
    "        <p style = 'font-size:16px;font-family:Arial'>With Vantage Bring Your Own Model; users can take advantage of a rich ecosystem of Machine Learning, Data Preparation, and Advanced analytical libraries available in the open-source and commercial space.  This demonstration illustrates how to utilize simple client-side training pipelines</p>\n",
    "        <ol style = 'font-size:16px;font-family:Arial'>\n",
    "            <li>Create Train and Test data sets in Vantage</li>\n",
    "            <br>\n",
    "            <li>Copy the training data to the client</li>\n",
    "            <br>\n",
    "            <li>Prepare data and train the model</li>\n",
    "            <br>\n",
    "            <li>Load the model into Vantage</li>\n",
    "        </ol>\n",
    "    </td>\n",
    "    <td><img src = 'images/BYOM_model_training.png' width = '400'></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(t_output.result.iloc[int(t_output.result.shape[0])-168:],\n",
    "            table_name = 'energy_consumption_variables_rescaled_test',\n",
    "            if_exists = 'replace')\n",
    "\n",
    "copy_to_sql(t_output.result.iloc[:int(t_output.result.shape[0])-168],\n",
    "            table_name = 'energy_consumption_variables_rescaled_train',\n",
    "            if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236efbb9-85e3-4700-82b5-50b51db7d0cf",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above step creates training and testing datasets. Last 168 hours i.e. 7 days are used for testing and remaining data is used for training.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT * FROM energy_consumption_variables_rescaled_train order by TD_TIMECODE;', eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-shark",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We calculate the average consumption for a last day of train period. We will use this number for normalization of the target variable.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_value = int(df.tail(24).mean()['consumption'])\n",
    "normalize_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = df.drop(['TD_TIMECODE', 'consumption'], axis = 1).astype(float)\n",
    "feature_names = list(train_x.columns)\n",
    "train_x.shape\n",
    "train_y = df['consumption'] - normalize_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c71e6c-6fc5-4948-9394-fc5035bfdfa3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>TD_TIMECODE and consumption columns have been dropped from the training dataset as these are not useful for prediction. The target variable consumption has been normalized by subtracting the normaliza_value that we calculated in the previous step.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_obj = PMMLPipeline([('lr', LinearRegression())])\n",
    "\n",
    "pipeline_obj.fit(train_x,train_y)\n",
    "sklearn2pmml(pipeline_obj, \"energy_consumption_LR.pmml\", with_repr = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6805b0b-37d0-4c1b-bfd2-e763b89c94d2",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above step creates a PMML Pipeline which had Linear Regression object inside of it. This Pipeline is used for training the pipeline using the \"fit\" method. Also, the model is stored in a pmml file locally in the last line.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PMML file into Vantage\n",
    "\n",
    "model_id = 'energy_consumption_lr2'\n",
    "model_file = 'energy_consumption_LR.pmml'\n",
    "table_name = 'energy_models'\n",
    "\n",
    "try:\n",
    "    res = save_byom(model_id = model_id, model_file = model_file, table_name = table_name)\n",
    "\n",
    "except Exception as e:\n",
    "    # if our model exists, delete and rewrite\n",
    "    if str(e.args).find('TDML_2200') >= 1:\n",
    "        res = delete_byom(model_id = model_id, table_name = table_name)\n",
    "        res = save_byom(model_id = model_id, model_file = model_file, table_name = table_name)\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Obtain a pointer to the model\n",
    "model_tdf = DataFrame.from_query(f\"SELECT * FROM {table_name} WHERE model_id = '{model_id}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_byom(table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502f4b01-4a91-4f10-95db-08b2adf16e64",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In the above steps, the pmml model is stored in a table named \"energy_models\". If it already exists, we delete the existing model with same model_id and save the latest model again using save_byom method.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-poetry",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>5. Score and Evaluate the Model</b>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "<tr>\n",
    "    <td style = 'vertical-align:top' width = '50%'>\n",
    "        <p style = 'font-size:16px;font-family:Arial'>The final step in this process is to test the trained model.  The PMMLPredict function will take the stored pipeline object (including any data preparation and mapping tasks) and execute it against the data on the Vantage Nodes.  Note there can be many models stored in the model table; with versioning, last scored timestamp, or any other management data to allow for operational management of the process.</p>\n",
    "        <ol style = 'font-size:16px;font-family:Arial'>\n",
    "            <li>Create a pointer to the model in Vantage</li>\n",
    "            <br>\n",
    "            <li>Execute the Scoring function using the model against the testing data</li>\n",
    "            <br>\n",
    "            <li>Copy the results of the test to the client - only needs to be a subset of rows if desired</li>\n",
    "            <br>\n",
    "            <li>Visualize the results</li>\n",
    "        </ol>\n",
    "    </td>\n",
    "    <td><img src = 'images/Score_and_Evaluate.png' width = '400'></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_test = DataFrame('energy_consumption_variables_rescaled_test')\n",
    "# Run the PMMLPredict function in Vantage\n",
    "result = PMMLPredict(\n",
    "            modeldata = model_tdf,\n",
    "            newdata = tdf_test,\n",
    "            accumulate = ['TD_TIMECODE','consumption']\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d0ef65-1f31-4345-b89e-6481d676411a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In the above step, we use the PMMLPredict method from teradataml library to score the model in the database. Note that neither the model nor the data has been moved outside Vantage system.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-knight",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction = result.result.to_pandas()\n",
    "df_prediction['prediction'] = df_prediction['prediction'].astype(float) + normalize_value\n",
    "df_prediction['TD_TIMECODE'] = pd.to_datetime(df_prediction['TD_TIMECODE'])\n",
    "df_prediction = df_prediction.set_index('TD_TIMECODE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-damages",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3608987e-333a-4a44-82c1-d8d65d146374",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above graph shows the actual consumption(in Blue) for a week and the predicted consumption(in Orange).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-ground",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>This demonstration has illustrated a simplified - but complete - overview of how a typical machine learning workflow can be improved using Vantage in conjunction with open-source tools and techniques.  This combination allows users to leverage the innovation of open-source with the operational scale, power, and stability of Vantage.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42763059-3f38-496c-83ea-a867d2e0f25f",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>6. Cleanup</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d377fef9-b377-4b59-a313-5eb9784dba93",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9472c2ca-65d0-4116-9c45-6411fcea52ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('demo_energy');\"        # Takes 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b0b73e-0c50-4110-be9c-05aaf1181960",
   "metadata": {},
   "source": [
    "<footer style=\"padding:10px;background:#f9f9f9;border-bottom:3px solid #394851\">Copyright © Teradata Corporation - 2023. All Rights Reserved.</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
