{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acquired-consideration",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Energy Consumption Forecasting using AzureML\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0701a2ac-9d7c-4498-a23c-7ae3955f6a32",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Introduction:</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Electricity consumption is a key driver to a successful energy trading company. But this success is only translated into profits if they can correctly predict how much energy will be consumed. In fact, proper forecasting of market energy demand prevents losses, in case of overselling energy to market, and lost profits, in case of underestimating demand. Not only will an energy company’s only cash flow be affected by false predictions, but the regulator of the energy market can apply fees or even disqualify a trading company for specific periods for frequent inaccurate forecasts.\n",
    "    <br>\n",
    "    <br>In this business use case, we leverage the power of AzureML and Teradata Vantage to enhance our machine learning capabilities and enable scalable model scoring. Our goal is to efficiently utilize the strengths of both platforms to streamline our data analysis and decision-making processes.\n",
    "<br>\n",
    "<!-- <img src=\"images/microsoft-global-partnership-with-teradata.jpg\" alt=\"Microsoft X Teradata\"> -->\n",
    "<br>\n",
    "<strong>Azure Machine Learning (AzureML):</strong> AzureML is a cloud-based platform provided by Microsoft, designed to simplify and accelerate the end-to-end machine learning workflow. It enables data scientists and developers to collaborate on data preparation, model training, and model deployment with ease, utilizing various frameworks and libraries for building intelligent applications.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Key Highlights of the Demo:</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><strong>Data Preparation and Exploration:</strong> We will explore the data in Teradata Vantage and get it ready for training our model.</li>\n",
    "    <li><strong>Model Training and Evaluation:</strong> Using AzureML, we'll create a tailored machine learning model for our usecase.</li>\n",
    "    <li><strong>Inference using Teradata Vantage ClearScape Analytics:</strong> Finally, we'll show how ClearScape Analytics can run the AzureML model we trained. This lets us make predictions quickly and efficiently using ClearScape Analytics BYOM (Bring Your Own Model) functionality.</li>\n",
    "</ol>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Business Values</b></p>\n",
    "    <ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "        <li>Decrease profit losses by over predicting or under predicting the amount of energy consumed.</li>\n",
    "        <li>Decrease regulations placed on trading companies from the energy market.</li>\n",
    "        <li>Increase energy consumption prediction accuracy.</li>\n",
    "    </ul>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Why Vantage?</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The ML and AI industry continues to innovate at an unprecedented rate.  Tools, technologies, and algorithms are being developed and improved in both the open source and commercial communities. Unfortunately, many of these techniques haven’t matured to the point where they are readily deployable to a stable, mature operational environment.  Furthermore, many open-source techniques rely on fragile, manual enabling technologies.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>ClearScape Analytics Bring Your Own Model capabilities allow organizations to leverage third party and open-source models for scoring inside the Vantage Platform; providing enterprise-class scalability and operational stability for any number of users, applications, or volume of data.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c181a4-340a-40cb-aaf6-f282fcece0d4",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>1. Initial setup</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed299c22-39b4-4694-80fc-50cba2bda027",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>1.1 Downloading and installing additional software needed</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cce3f40-bf70-4c64-9152-6fb67c325924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install azureml-core azure-ai-ml azureml-train-automl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a702679-8a84-4a1a-9f6a-e0e97d75c8fb",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<div style=\"background-color: #ffdddd; padding: 10px; border: 1px solid #f44336; border-radius: 5px; margin-bottom: 10px;\">\n",
    "    <p><strong>Warning:</strong> We are downgrading <b>numpy</b> library for this specific demo. Make sure that you run the cleanup section at the end. The cleanup section is necessary for other notebooks to run.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9feb4-db53-45f2-9ee8-0091f98ee851",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install numpy==1.23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54677602-e740-4be6-b7e5-88d22d8b59b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade pyopenssl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f454b5-59b8-43be-9c3b-6d720b42738d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note: </b><i>The above statements may need to be uncommented if you run the notebooks on a platform other than ClearScape Analytics Experience that does not have the libraries installed. If you uncomment those installs, be sure to restart the kernel after executing those lines to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884e509c-0630-4efd-9778-1c5142689dea",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<a id=\"anchor\"></a>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>1.2 Setting up Azure credentials</b>\n",
    "\n",
    "<p style=\"font-size: 16px; font-family: Arial;color:#00233C\"><b>Required Azure Credentials:</b></p>\n",
    "<ul style=\"font-size: 16px; font-family: Arial;;color:#00233C\">\n",
    "    <li><strong>Tenant ID:</strong> This is a unique identifier for the Azure Active Directory (AAD) tenant associated with the Azure subscription.</li>\n",
    "    <li><strong>Subscription ID:</strong> It is a unique identifier for the Azure subscription, which represents the purchased plan and services.</li>\n",
    "    <li><strong>Resource Group</strong>: Azure organizes resources into resource groups, which help manage and monitor related resources as a single unit.</li>\n",
    "    <li><strong>Workspace Name:</strong> This is the name of the Azure Machine Learning Workspace, which provides a centralized location to work with machine learning resources.</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"font-size: 16px; font-family: Arial;color:#00233C\"><b>How to Get These Inputs:</b></p>\n",
    "<ol style=\"font-size: 16px; font-family: Arial;;color:#00233C\">\n",
    "    <li><strong>Tenant ID, Subscription ID, and Resource Group:</strong> These credentials are related to your Azure account and subscription. If you already have an Azure account and an active subscription, you can find these credentials in the Azure portal. Here's how:\n",
    "        <ul style=\"font-size: 16px; font-family: Arial;;color:#00233C\">\n",
    "            <li><a href=\"https://docs.microsoft.com/azure/active-directory/fundamentals/active-directory-how-to-find-tenant\">Find your tenant ID</a></li>\n",
    "            <li><a href=\"https://learn.microsoft.com/en-us/azure/azure-portal/get-subscription-tenant-id\">Find your subscription ID</a></li>\n",
    "            <li><a href=\"https://docs.microsoft.com/azure/azure-resource-manager/management/manage-resource-groups-portal\">Create and manage Azure resource groups</a></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><strong>Workspace Name:</strong> If you have already set up an Azure Machine Learning Workspace, you can use the name of the workspace you created. If not, you can create one by following the steps in the Azure Machine Learning documentation:\n",
    "        <ul style=\"font-size: 16px; font-family: Arial;;color:#00233C\">\n",
    "            <li><a href=\"https://docs.microsoft.com/azure/machine-learning/how-to-manage-workspace#create-a-workspace\">Create an Azure Machine Learning Workspace</a></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ol>\n",
    "\n",
    "<p style=\"font-size: 16px; font-family: Arial; color:#00233C\"><b>No Azure Credentials:</b></p>\n",
    "<p style=\"font-size: 16px; font-family: Arial;;color:#00233C\">\n",
    "If you do not have the required Azure credentials or do not wish to create an Azure account, you can still follow the demo. You will be informed when to skip the steps that require Azure credentials, and we will guide you through the alternative process.\n",
    "</p>\n",
    "<p style=\"font-size: 16px; font-family: Arial;;color:#00233C\">\n",
    "However, if you are interested in using Azure Machine Learning services and want to try the full functionality of the demo, you can follow the instructions in the <a href=\"./Getting Started with Azure.ipynb\">Getting Started with Azure</a> guide. This will walk you through setting up an Azure account and acquiring the necessary credentials to fully experience the demo's capabilities.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9fbb15-af17-4b49-adb0-4906e8074b00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display as disp, HTML\n",
    "\n",
    "def get_yes_no_input(prompt):\n",
    "    while True:\n",
    "        user_input = input(prompt).strip().lower()\n",
    "        if user_input == 'yes' or user_input == 'no':\n",
    "            return user_input\n",
    "        else:\n",
    "            print(\"\\033[1mInvalid input. Please enter 'yes' or 'no'.\\033[0m\")\n",
    "\n",
    "user_choice = get_yes_no_input('''Do you have the following Azure credentials? (yes/no):\n",
    "\n",
    "- Tenant ID\n",
    "- Subscription ID\n",
    "- Resource Group\n",
    "- Workspace Name\n",
    "\n",
    "Enter 'yes' or 'no': ''')\n",
    "\n",
    "if user_choice == 'yes':\n",
    "    print(\"\\033[1mPlease enter the credentials:\\033[0m\")\n",
    "    tenant_id = input('Tenant ID:')\n",
    "    subscription_id = input('Subscription ID:')\n",
    "    resource_group = input('Resource Group:')\n",
    "    workspace_name = input('Workspace Name:')\n",
    "elif user_choice == 'no':\n",
    "    disp(HTML(f'''<div class=\"alert alert-block alert-info\">\n",
    "<p style=\"font-size: 16px; font-family: Arial;color:#00233C\">\n",
    "If you do not have the required Azure credentials or do not wish to create an Azure account, you can still follow the demo. You will be informed when to skip the steps that require Azure credentials, and we will guide you through the alternative process.\n",
    "</p>\n",
    "<p style=\"font-size: 16px; font-family: Arial;color:#00233C\">\n",
    "However, if you are interested in using Azure Machine Learning services and want to try the full functionality of the demo, you can follow the instructions in the <a href=\"./Getting_Started_with_Azure.ipynb\">Getting Started with Azure</a> guide. This will walk you through setting up an Azure account and acquiring the necessary credentials to fully experience the demo's capabilities.\n",
    "</p>\n",
    "</div>'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eddf997-c064-43cd-923a-6a2092fd64a9",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>1.3 Importing libraries</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9d4207-bc98-428b-93d3-7955c99a34fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import sys\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from jdk4py import JAVA, JAVA_HOME, JAVA_VERSION\n",
    "\n",
    "from teradataml import *\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "\n",
    "from azureml.core import Workspace, Experiment, ScriptRunConfig\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.automl.runtime.onnx_convert import OnnxConverter\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "from azureml.core.run import Run\n",
    "\n",
    "# Modify the following to match the specific client environment settings\n",
    "display.max_rows = 5\n",
    "configure.val_install_location = 'val'\n",
    "configure.byom_install_location = 'mldb'\n",
    "os.environ['PATH'] = os.pathsep.join([os.environ['PATH'], str(JAVA_HOME), str(JAVA)[:-5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08d32da-e7b5-4512-8116-608b8f64004c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>2. Connect to Vantage.</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell.We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8440f566-a0be-4dc7-abc3-b5c5e70291bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username = 'demo_user', password = password)\n",
    "print(eng)\n",
    "execute_sql('''SET query_band='DEMO=Energy_Consumption_Forecasting_AzureML.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b60563-efd1-4969-9177-a16dd5ff0d30",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78841dac-5d26-4eb3-b9b8-726cce4e2b83",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>2.1 Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We have provided data for this demo on cloud storage. We have the option of either running the demo using foreign tables to access the data without using any storage on our environment or downloading the data to local storage, which may yield somewhat faster execution. However, we need to consider available storage. There are two statements in the following cell, and one is commented out. We may switch which mode we choose by changing the comment string.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c69f6a0-d700-45be-bab4-c93cd13458f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ../run_procedure.py \"call get_data('DEMO_Energy_cloud');\"        # Takes 1 minute\n",
    "%run -i ../run_procedure.py \"call get_data('DEMO_Energy_local');\"        # Takes 2 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57400b0a-c702-4013-9d8c-1f03f0496283",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Optional step – We should execute the below step only if we want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c9562f-32a1-4fe4-9feb-5d78bbf3a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce86f838-6785-40cb-9b99-a67781e2a395",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>3. Data Exploration</b>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "<tr>\n",
    "    <td style = 'vertical-align:middle' width = '50%'>\n",
    "        <p style = 'font-size:16px;font-family:Arial;color:#00233C'>We can access large volumes of data by connecting remotely using the teradataml client connection library. Our Python methods are translated to SQL and run remotely on the Vantage system. We only copy the minimal amount of data required to the client, allowing us to interact with data sets of any size and scale.\n",
    "    </td>\n",
    "    <td><img src = 'images/connect_and_discover.png' width = '400'></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Let's create a \"Virtual DataFrame\" that points to the data set in Vantage. This will allow for processing the dataset without having to bring the data down to the client.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebcb0e5-caf7-4e6a-8417-09d4105dc493",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(in_schema(\"DEMO_Energy\", \"consumption\"))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb75208-dcee-4c2a-b32f-4baedb21e909",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In this demo, we used a dataset that represents electricity consumption in Norway from the 1st of January 2016 to the 31st of August 2019. Each line in our dataset reflects consumption for one hour. Apart from electricity consumption, our dataset also reflects additional data: weather from multiple sources, daylight information, and the labor calendar. We collected all our data from open data sources.\n",
    "    <br><br>\n",
    "Let's investigate the data by looking at a data sample.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765d14de-d3af-4940-a19c-b41fc96f8d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a0983-f482-46bc-a64e-50372bb4f19f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The dataset above shows our hourly consumption of energy. We have multiple columns that are potential factors affecting our energy consumption, such as is_dark, is_holiday, etc.</p>\n",
    "\n",
    "<!-- <ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>TD_TIMECODE:</b> Date and time information in a specific format.</li>\n",
    "    <li><b>consumption:</b> Hourly energy consumption values.</li>\n",
    "    <li><b>y, m, d, h:</b> Year, month, day, and hour components of the timestamp.</li>\n",
    "    <li><b>weekday:</b> Indicator for the day of the week (e.g., Monday, Tuesday).</li>\n",
    "    <li><b>nasa_temp:</b> Temperature readings from NASA.</li>\n",
    "    <li><b>cap_air_temperature:</b> Ambient air temperature measurements.</li>\n",
    "    <li><b>cap_cloud_area_fraction:</b> Cloud cover percentage.</li>\n",
    "    <li><b>cap_precipitation_amount:</b> Amount of precipitation.</li>\n",
    "    <li><b>is_dark:</b> Flag indicating if it is dark.</li>\n",
    "    <li><b>is_light:</b> Flag indicating if it is light.</li>\n",
    "    <li><b>is_from_light_to_dark:</b> Flag indicating the transition from light to dark.</li>\n",
    "    <li><b>is_from_dark_to_light:</b> Flag indicating the transition from dark to light.</li>\n",
    "    <li><b>is_holiday:</b> Flag indicating if it is a holiday.</li>\n",
    "    <li><b>is_pre_holiday:</b> Flag indicating if it is a day before a holiday.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    These columns provide valuable insights into energy consumption patterns and the factors that might influence it, such as weather conditions, time of day, and holidays.\n",
    "</p> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e2637a-ea25-4049-be6b-8971f6c072bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(width=1200, height=600, heading=\"Energy Demand\")\n",
    "\n",
    "plot = df.plot(\n",
    "    x=df.TD_TIMECODE,\n",
    "    y=df.consumption,\n",
    "    xtick_format='YYYY-MM',\n",
    "    xlabel='Date',\n",
    "    ylabel='Energy Units',\n",
    "    color='carolina blue',\n",
    "    figure=figure,\n",
    "    legend='Energy',\n",
    "    legend_style='upper right',\n",
    "    grid_linestyle='--',\n",
    "    grid_linewidth=0.5\n",
    ")\n",
    "\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9565a1-4dd7-4cfd-b8b6-0c8f1148e65a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Scaling up data visualization presents challenges with processing and interpreting large datasets, causing issues like slow performance. Specialized methods, such as \"td_plot,\" address these challenges by providing efficient solutions for insights without compromising speed.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The \"td_plot\" method in Teradata Vantage simplifies large-scale visualization by allowing users to create visualizations directly within the Vantage environment. It eliminates the need for data movement, enhancing efficiency and addressing challenges associated with handling extensive datasets.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669dd46c-fce0-4223-ad0e-c245a707a07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate MinMaxScalar\n",
    "rs = MinMaxScalar(columns=['cap_air_temperature', 'cap_cloud_area_fraction', 'cap_precipitation_amount'])\n",
    "\n",
    "# Transform the data using MinMaxScaler\n",
    "t_output = valib.Transform(data=df,\n",
    "                          rescale=[rs],\n",
    "                          index_columns='TD_TIMECODE').result\n",
    "\n",
    "# Create subplots\n",
    "fig, axis = subplots(3, 1)\n",
    "\n",
    "# Set figure height and width\n",
    "fig.height, fig.width = 900, 1200\n",
    "\n",
    "cols = ['cap_air_temperature', 'cap_cloud_area_fraction', 'cap_precipitation_amount']\n",
    "\n",
    "# Plot the data\n",
    "for i in range(len(cols)):\n",
    "    plot = t_output.plot(x=t_output.TD_TIMECODE,\n",
    "                         y=t_output[cols[i]],\n",
    "                         ax=axis[i],\n",
    "                         xtick_format='YYYY-MM',\n",
    "                         xlabel='Date',\n",
    "                         ylabel='Normalized Values',\n",
    "                         color='carolina blue',\n",
    "                         figure=fig,\n",
    "                         legend_style='upper right',\n",
    "                         grid_linestyle='--',\n",
    "                         grid_linewidth=0.5)\n",
    "\n",
    "# Show the plot\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22431d21-ad4c-4207-a80b-96e6ea670df3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In our analysis, the graph of cap_air_temperature shows an inverse relationship with our energy consumption. This means that in countries with colder climates like Norway, electricity usage tends to increase as the temperature drops, likely due to increased demand for heating. Conversely, electricity usage tends to decrease when the temperature rises, potentially due to reduced need for heating.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e219a2-ecc6-4d75-92a1-f80e405b0661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import func\n",
    "\n",
    "agg_tdf = df.assign(Quarter=func.td_quarter_of_year(df.TD_TIMECODE.expression)).filter(items=['consumption', 'Quarter']).groupby('Quarter').mean()\n",
    "\n",
    "agg_tdf.plot(\n",
    "    x=agg_tdf.Quarter,\n",
    "    y=agg_tdf.mean_consumption,\n",
    "    color='carolina blue',\n",
    "    kind='bar'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554c7861-fb86-4d03-8d00-60af9e23c076",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In our analysis, the above graph shows the distribution of energy consumption across quarters. We observe that the 1st and 4th quarters across years witness high energy consumption due to cold weather, while the 3rd quarter witnesses the least energy consumption across years, indicating the summer season.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc27733-d8ae-4035-a789-6501fbcefcd4",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>4. Data Preparation</b>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "<tr>\n",
    "    <td style = 'vertical-align:top' width = '50%'>\n",
    "        <p style = 'font-size:16px;font-family:Arial;color:#00233C'>We, as users of the Vantage Analytic Library, benefit from a suite of powerful functions that enable us to perform whole-data-set descriptive analysis, data transformation, hypothesis testing, and algorithmic algorithms at an extreme scale. As with all Vantage capabilities, we run these functions in parallel at the source of the data.</p>\n",
    "        <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "            <li>Create Feature Transformation objects</li>\n",
    "            <br>\n",
    "            <li>Define the columns to be retained in the analytic data set</li>\n",
    "            <br>\n",
    "            <li>Push the transformations to the data in Vantage</li>\n",
    "            <br>\n",
    "            <li>Inspect the results</li>\n",
    "        </ol>\n",
    "    </td>\n",
    "    <td><img src = 'images/VAL_transformation.png' width = '400'></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf9b81c-cedc-4e49-8fee-9339666b23f8",
   "metadata": {},
   "source": [
    "<ul style=\"font-size: 16px; font-family: Arial;color:#00233C\">\n",
    "    <li><code>OneHotEncoder:</code> is useful when a categorical data element must be re-expressed as one or more numeric data elements, creating a binary numeric field for each categorical data value.</li>\n",
    "    <li><code>MinMaxScalar:</code> allows rescaling that limits the upper and lower boundaries of the data in a continuous numeric column using a linear rescaling function based on maximum and minimum data values.</li>\n",
    "    <li><code>Retain:</code> allows you to copy one or more columns into the final analytic data set.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36183ce8-be23-412f-a0f6-4aeefd1d8cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_mapping = {1:'monday', 2:'tuesday', 3:'wednesday', 4:'thursday', 5:'friday', 6:'saturday', 7:'sunday'}\n",
    "weekday_t = OneHotEncoder(values = weekday_mapping, columns = 'weekday')\n",
    "\n",
    "hour_mapping = {}\n",
    "for i in range(24):\n",
    "    hour_mapping[i] = 'time_' + str(i)\n",
    "\n",
    "hour_t = OneHotEncoder(values = hour_mapping,  columns = 'h')\n",
    "\n",
    "rs = MinMaxScalar(columns = ['nasa_temp','cap_air_temperature', 'cap_cloud_area_fraction', 'cap_precipitation_amount'])\n",
    "\n",
    "rt = Retain(columns = ['consumption',\n",
    "                       'is_dark', 'is_light', 'is_from_light_to_dark', 'is_from_dark_to_light', \n",
    "                       'is_holiday', 'is_pre_holiday'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098b44a6-56ab-412f-b661-b4b3ae652077",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the transformation objects created in the previous step to prepare our data for modeling. Specifically, we will use weekday_t and hour_t to convert our weekday and hour columns from numeric to one-hot encoded columns. We will use rs to scale our nasa_temp using MinMaxScalar, and rt will be used to retain the specified columns. These transformations will enable us to use our data effectively in a machine learning model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6879ab57-8e84-480d-baaa-13c6012763c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_output = valib.Transform(data = df,\n",
    "                           one_hot_encode = [weekday_t, hour_t], \n",
    "                           rescale = [rs], \n",
    "                           index_columns = 'TD_TIMECODE',\n",
    "                           retain = [rt]).result\n",
    "\n",
    "t_output = t_output.assign(consumption_time = t_output.TD_TIMECODE.cast(type_=VARCHAR(30)))\n",
    "t_output = t_output.drop('TD_TIMECODE', axis = 1)\n",
    "\n",
    "copy_to_sql(t_output,\n",
    "            table_name = 'output',\n",
    "            if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaab645-8bad-4669-89e0-e6cd304e5c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c02128-1322-4121-81e2-46bd83d345b0",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Please scroll to the right and observe that we now have columns named monday-sunday and 0_h - 23_h. Also, nasa_temp has been scaled.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae54485-789b-41f5-9445-be7c64d1b183",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execute_sql('''\n",
    "    REPLACE VIEW test_df AS\n",
    "    SELECT * FROM output\n",
    "    QUALIFY row_number() OVER (order by consumption_time DESC) <= 168\n",
    "''')\n",
    "\n",
    "execute_sql('''\n",
    "    REPLACE VIEW train_df AS\n",
    "    SELECT * FROM output\n",
    "    QUALIFY row_number() OVER (order by consumption_time DESC) > 168\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a8c547-fed4-4289-bde4-5f1a88724c9e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We create training and testing datasets. We use the last 168 hours, i.e., seven days, for testing, and we use the remaining data for training.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9a806c-fa38-47fe-ba2f-d42e8d914e8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>5. AzureML</b>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Note: If you do not have AzureML please click here <a href=\"#no-azure\">here</a> to skip.</b></i></p>\n",
    "</div>\n",
    "\n",
    "<p style=\"font-size: 16px; font-family: Arial;color:#00233C\"><b>Overview:</b></p>\n",
    "\n",
    "<ol style=\"font-size: 16px; font-family: Arial;color:#00233C\">\n",
    "    <li>\n",
    "        <b>Pushing data to Azure Blob Storage:</b>\n",
    "        <p style=\"font-size: 16px; font-family: Arial;color:#00233C\">\n",
    "            This section uses WriteNOS to write data to Azure Blob Storage.\n",
    "        </p>\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>Checking for Required Variables:</b>\n",
    "        <p style=\"font-size: 16px; font-family: Arial;color:#00233C\">\n",
    "            This section checks if all the credentials are defined.\n",
    "            If any required credentials are missing, it shows a message with the names of the missing variables and a link for more information.\n",
    "        </p>\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>Azure Machine Learning Workspace Setup:</b>\n",
    "        <p style=\"font-size: 16px; font-family: Arial;color:#00233C\">\n",
    "            The code sets up a workspace for Azure Machine Learning using specific credentials.\n",
    "            This workspace allows running machine learning experiments.\n",
    "        </p>\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>Running a Azure AutoML Experiment:</b>\n",
    "        <p style=\"font-size: 16px; font-family: Arial;color:#00233C\">\n",
    "            The code creates an experiment for running regression model using Azure-AutoML.\n",
    "            The script's execution is monitored until completion.\n",
    "        </p>\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75addb33-b691-4b1b-83c7-da1a48501afd",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>5.1 Pushing data to Azure Blob Storage</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19923df3-79f3-4f4e-a6d5-4f0d6fc5651a",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px; font-family: Arial;color:#00233C\">WRITE_NOS allows you to extract selected or all columns from a database table or from derived results and write to external object storage, such as Amazon S3, Azure Blob storage, Azure Data Lake Storage Gen2, and Google Cloud Storage.</p>\n",
    "\n",
    "<ul style=\"font-size: 16px; font-family: Arial;color:#00233C\">\n",
    "    <li><code>LOCATION:</code> the URI to the external object storage where you want to write the data.</li>\n",
    "    <li><code>Access_ID:</code> access ID to your external storage.</li>\n",
    "    <li><code>Access_Key:</code> secret key value to your external storage.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642e89e3-6cfc-4959-9066-aee855eae285",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_location = 'location-1'\n",
    "test_df_location = 'location-2'\n",
    "access_id = \"xxx\"\n",
    "access_key = \"yyyy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725eb518-e44a-48bf-82bc-a05422540296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_qry = '''\n",
    "    SELECT NodeId, AmpId, Sequence, ObjectName, ObjectSize, RecordCount\n",
    "    from WRITE_NOS (ON train_df\n",
    "    USING LOCATION('{}')  \n",
    "    AUTHORIZATION('{{\"Access_ID\":\"{}\",\"Access_Key\":\"{}\"}}')  \n",
    "    STOREDAS('PARQUET') Compression('SNAPPY') ) AS d;\n",
    "'''.format(train_df_location, access_id, access_key)\n",
    "\n",
    "execute_sql(train_qry)\n",
    "\n",
    "test_qry = '''\n",
    "    SELECT NodeId, AmpId, Sequence, ObjectName, ObjectSize, RecordCount\n",
    "    from WRITE_NOS (ON test_df\n",
    "    USING LOCATION('{}')\n",
    "    AUTHORIZATION('{{\"Access_ID\":\"{}\",\"Access_Key\":\"{}\"}}')  \n",
    "    STOREDAS('PARQUET') Compression('SNAPPY') ) AS d;\n",
    "'''.format(test_df_location, access_id, access_key)\n",
    "\n",
    "execute_sql(test_qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a8e016-fe40-47aa-91c5-c4b421c9f8a9",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>5.2 Checking for Required Variables</b></p>\n",
    "<p style=\"font-size: 16px; font-family: Arial;color:#00233C\">The function <code>check_variables(variable_names)</code> checks if certain variables specified in the <code>required_variables</code> list are defined in the local environment.\n",
    "<br>\n",
    "If any of the required variables are missing, it prints the names of the missing variables and displays a message with a link to more information.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6085ffb-7a82-421b-abf9-9a94da238932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_variables(variable_names):\n",
    "    missing_variables = [var for var in variable_names if var not in globals()]\n",
    "    \n",
    "    if missing_variables:\n",
    "        print(\"The following variables are missing:\")\n",
    "        for var in missing_variables:\n",
    "            print(f\" - {var}\")\n",
    "        disp(HTML(f'''\n",
    "            <p>Please ensure all the required credentials are defined.</p>\n",
    "            <p>For more information, please go to <a href=\"#anchor\">this section</a>.</p>\n",
    "        '''))\n",
    "    else:\n",
    "        print(\"All required credentials are present.\")\n",
    "\n",
    "required_variables = ['tenant_id', 'subscription_id', 'resource_group', 'workspace_name']\n",
    "check_variables(required_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc2553a-a109-43cd-b2dc-fcb3e83f9c97",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>5.3 Azure Machine Learning Workspace Setup</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "<li>\n",
    "        <strong>Authentication:</strong>\n",
    "        <p>\n",
    "        The first line of code creates an instance of <code>InteractiveLoginAuthentication</code>. This class is used to authenticate and establish a connection to Azure services interactively. It allows you to log in to your Azure account using an interactive login prompt.\n",
    "        </p>\n",
    "        <ul>\n",
    "            <li>\n",
    "                <code>tenant_id:</code>This parameter is required and should be replaced with your Azure Active Directory (Azure AD) tenant ID. The tenant ID identifies the organization or tenant associated with your Azure subscription.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        <strong>Creating the Azure Machine Learning Workspace:</strong>\n",
    "        <p>\n",
    "        The second part of the code creates an instance of the <code>Workspace</code> class, which represents the Azure Machine Learning Workspace. This is the primary entry point for interacting with Azure Machine Learning resources.\n",
    "        </p>\n",
    "        <ul>\n",
    "            <li>\n",
    "                <code>subscription_id:</code>The subscription ID identifies your Azure subscription, which is associated with the Azure Machine Learning resources.\n",
    "            </li>\n",
    "            <li>\n",
    "                <code>resource_group:</code>Name of the resource group where your Azure Machine Learning Workspace is located. A resource group is a logical container for resources in Azure.\n",
    "            </li>\n",
    "            <li>\n",
    "                <code>workspace_name:</code>Name of your Azure Machine Learning Workspace.\n",
    "            </li>\n",
    "            <li>\n",
    "                <code>auth:</code> The <code>auth</code> parameter is set to the previously created <code>InteractiveLoginAuthentication</code> instance. This provides the authentication context for the workspace.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Note</b>: If running the following cell for first time, you need to perform authentication. The output might look as follows:\n",
    "    <img src = './images/authenticate.png'></i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2cb8eb-5b01-47d3-97d5-cbc7abccf371",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_auth = InteractiveLoginAuthentication(tenant_id = tenant_id)\n",
    "\n",
    "ws = Workspace(subscription_id = subscription_id,\n",
    "               resource_group = resource_group,\n",
    "               workspace_name = workspace_name,\n",
    "               auth = interactive_auth)\n",
    "\n",
    "ws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e24927-3a0f-4295-a7ef-e53ed03f75a1",
   "metadata": {},
   "source": [
    "<ul style='font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>\n",
    "        <strong>Configuring AutoML:</strong>\n",
    "        <p>\n",
    "            The code configures an AutoML experiment for regression using the <code>AutoMLConfig</code> class in Azure Machine Learning. This configuration automates the process of finding the best regression model for the given task.\n",
    "        </p>\n",
    "        <ul>\n",
    "            <li>\n",
    "                <code>task:</code> The machine learning task to be performed is regression, as set by the <code>task</code> parameter.\n",
    "            </li>\n",
    "            <li>\n",
    "                <code>compute_target:</code> The target compute resource for running the experiment is specified as 'demo-compute'. You should replace this with your specific compute target.\n",
    "            </li>\n",
    "            <li>\n",
    "                <code>enable_onnx_compatible_models:</code> This Boolean parameter is set to <code>True</code>, enabling the generation of ONNX-compatible models for export.\n",
    "            </li>\n",
    "            <li>\n",
    "                <code>training_data:</code> The training dataset is obtained from the Azure ML workspace using <code>Dataset.get_by_name</code> and is named 'train_data'. Update this with your actual dataset name.\n",
    "            </li>\n",
    "            <li>\n",
    "                <code>label_column_name:</code> Specifies the target variable in the dataset, set to 'consumption' in this case.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        <strong>Submitting the Experiment:</strong>\n",
    "        <p>\n",
    "            The code submits the configured AutoML experiment to an instance of the <code>Experiment</code> class for execution.\n",
    "        </p>\n",
    "        <ul>\n",
    "            <li>\n",
    "                <code>workspace:</code> The <code>Experiment</code> is created within the Azure ML workspace, specified as <code>ws</code>.\n",
    "            </li>\n",
    "            <li>\n",
    "                <code>name:</code> The name of the experiment is set to 'python_snippet'. Change this to a descriptive name that suits your experiment.\n",
    "            </li>\n",
    "            <li>\n",
    "                <code>show_output:</code> The <code>submit</code> method is called with <code>show_output=False</code>, indicating that detailed output during execution will not be displayed.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5229b0d-1841-4216-81c0-b2657a99fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_config = AutoMLConfig(task = 'regression',\n",
    "                             compute_target='demo-compute',\n",
    "                             enable_onnx_compatible_models=True,\n",
    "                             training_data = Dataset.get_by_name(ws, 'train_data'),\n",
    "                             label_column_name = 'consumption'\n",
    "                            )\n",
    "\n",
    "experiment = Experiment(ws, 'python_snippet')\n",
    "print(experiment.submit(automl_config, show_output = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730a7ead-c828-486c-a5e9-0bfc45c6a82f",
   "metadata": {},
   "source": [
    "<ul style='font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>\n",
    "        <strong>Retrieving AutoML Run Output:</strong>\n",
    "        <p>\n",
    "            The code is retrieving the output of a specific AutoML run using the <code>AutoMLRun</code> class in Azure Machine Learning.\n",
    "        </p>\n",
    "        <ul>\n",
    "            <li>\n",
    "                <code>run_id:</code> The identifier of the AutoML run is set to 'xxx'. Replace this with the actual run ID you want to retrieve.\n",
    "            </li>\n",
    "            <li>\n",
    "                <code>run:</code> An instance of the <code>AutoMLRun</code> class is created by fetching the run details from the Azure ML workspace using <code>Run.get</code> method.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        <strong>Getting Best Run and ONNX Model:</strong>\n",
    "        <p>\n",
    "            The code further retrieves the best run and the corresponding ONNX model from the AutoML run.\n",
    "        </p>\n",
    "        <ul>\n",
    "            <li>\n",
    "                <code>best_run:</code> The best run is obtained using the <code>get_output</code> method from the <code>AutoMLRun</code> instance.\n",
    "            </li>\n",
    "            <li>\n",
    "                <code>onnx_mdl:</code> The ONNX model is obtained by setting <code>return_onnx_model=True</code> in the <code>get_output</code> method, indicating the desire to retrieve the ONNX model if available.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d558b111-feb4-43bf-af70-92dbbadb1297",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = 'xxx'\n",
    "run = AutoMLRun(Run.get(ws, run_id).experiment, run_id)\n",
    "best_run, onnx_mdl = run.get_output(return_onnx_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b72e4-557a-4027-aed6-295898cdde87",
   "metadata": {},
   "source": [
    "<ul style='font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>\n",
    "        <strong>Saving ONNX Model:</strong>\n",
    "        <p>\n",
    "            The code snippet is responsible for saving an ONNX model obtained from an AutoML run using the <code>OnnxConverter</code> class in Azure Machine Learning.\n",
    "        </p>\n",
    "        <ul>\n",
    "            <li>\n",
    "                <code>onnx_fl_path:</code> The file path where the ONNX model will be saved is set to './energy_model.onnx'. Modify this to the desired file path and name for your ONNX model.\n",
    "            </li>\n",
    "            <li>\n",
    "                <code>OnnxConverter:</code> The <code>OnnxConverter</code> class is utilized to perform the conversion and saving of the ONNX model.\n",
    "            </li>\n",
    "            <li>\n",
    "                <code>onnx_mdl:</code> The ONNX model obtained earlier is passed as a parameter to the <code>save_onnx_model</code> method for saving.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b761ec-2e70-4747-965f-16e963dac3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_fl_path = \"./energy_model.onnx\"\n",
    "OnnxConverter.save_onnx_model(onnx_mdl, onnx_fl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96821035-f664-4e5f-af2e-997bd61d1f74",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>6. Model Scoring and Evaluation</b>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" id=\"no-azure\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Note</b>: If you do not have AzureML or did not perform the above steps, the following cell will do the required setup to run the remaining notebook.</i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc8e11e-3dd9-4972-9797-f2bee82c2dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PMML file into Vantage\n",
    "model_id = 'best_model'\n",
    "model_file = 'energy_model.onnx'\n",
    "table_name = 'azureml_models'\n",
    "\n",
    "if not get_connection().dialect.has_table(get_connection(), table_name):\n",
    "    try:\n",
    "        save_byom(model_id = model_id, model_file = model_file, table_name = table_name)\n",
    "    except Exception as e:\n",
    "        # if our model exists, delete and rewrite\n",
    "        if str(e.args).find('TDML_2200') >= 1:\n",
    "            delete_byom(model_id = model_id, table_name = table_name)\n",
    "            save_byom(model_id = model_id, model_file = model_file, table_name = table_name)\n",
    "        else:\n",
    "            raise ValueError(f\"Unable to save the model '{model_id}' in '{table_name}' due to the following error: {e}\")\n",
    "\n",
    "# Show the azureml_models table\n",
    "list_byom(table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8160ea5-de3f-4303-810e-838e52c185a3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the above steps, we save our trained ONNX model in a table named azureml_models. If a model with the same model_id already exists, we delete it first, and then we save the latest trained model again using the save_byom method. This ensures that we always store the most recent version of the model in the table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af174ba5-fbde-4787-a00c-737de324eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNXPredict_out = ONNXPredict(\n",
    "    accumulate=\"consumption_time\",\n",
    "    newdata = DataFrame('test_df'),\n",
    "    modeldata = retrieve_byom(model_id = model_id, table_name = table_name),\n",
    "    overwrite_cached_models = 'true',\n",
    "    model_output_fields = 'variable_out'\n",
    ")\n",
    "\n",
    "out_df = ONNXPredict_out.result\n",
    "out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a96b32-3beb-4514-9aed-f9bdf235f423",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the above step, we use the ONNXPredict method from the teradataml library to score our model in the database. The ONNXPredict function in Teradata allows us to score the ONNX model directly on the data in our Vantage system, without having to move the data or the model outside the system. This can help to improve the efficiency and security of our scoring process.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04251224-d906-4200-ab4a-26e03cea4ecb",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We perform data prep in the following cell to prepare data for plotting.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3566764-7b2a-40f1-adba-13d3d9bd672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = out_df.assign(consumption_time = out_df.consumption_time.cast(type_=TIMESTAMP(6)))\n",
    "out_df = out_df.assign(prediction = out_df.variable_out.replace(\"[\",\"\").replace(\"]\",\"\"))\n",
    "out_df = out_df.assign(prediction = out_df.prediction.cast(type_=FLOAT()))\n",
    "out_df = out_df.drop('variable_out', axis = 1)\n",
    "\n",
    "test_df = DataFrame('test_df')\n",
    "test_df = test_df.assign(consumption_time = test_df.consumption_time.cast(type_=TIMESTAMP(6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2398d41-e3fa-49a2-93aa-906421782060",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = Figure(width=1400, height=600,  heading=\"Energy Consumption Prediction\")\n",
    "\n",
    "test_df.plot(\n",
    "                x=test_df.consumption_time,\n",
    "                y=[test_df.consumption, out_df.prediction],\n",
    "                figure=figure,\n",
    "                xtick_format='YYYY-MM-DD',\n",
    "                xlabel='TD_TIMECODE',\n",
    "                ylabel='Energy Consumption',\n",
    "                legend=['Actual Consumption', f'Linear Regression'],\n",
    "                legend_style='upper right',\n",
    "                grid_linestyle='--',\n",
    "                grid_linewidth=0.5,\n",
    "                linestyle=['-', '--']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c274c9-a881-4a84-80e5-08da98477c34",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Conclusion</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In this demonstration, we have illustrated a simplified - but complete - overview of how we can improve a typical machine learning workflow using Vantage in conjunction with open-source tools and techniques. This combination allows us to leverage open-source innovation with Vantage's operational scale, power, and stability.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb37688-c672-4722-859a-8533c3e598bb",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>7. Cleanup</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d681a19d-1048-4ee5-a743-139830739b5b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>7.1 Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We need to clean up our work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52ce515-d02e-4872-91ae-7735a9db9ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_drop_view(view_name='train_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80323e7-2d7b-40e1-be91-2ed040b795bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_drop_view(view_name='test_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2024e65c-581b-4b59-9d09-75995a7d07a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_drop_table(table_name='azureml_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ede6380-80b3-4a4f-84ea-c339d868862b",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<div style=\"background-color: #ffdddd; padding: 10px; border: 1px solid #f44336; border-radius: 5px; margin-bottom: 10px;\">\n",
    "    <p><strong>Warning:</strong> Make sure that you run the following cell. This is necessary for other notebooks to run.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65936cf-e5e0-46e3-9f15-4005461ef8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade numpy pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29019c42-9bbe-461c-bf19-9bd90534c1a2",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>7.2 Databases and Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the following code to clean up tables and databases created for this demonstration.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9472c2ca-65d0-4116-9c45-6411fcea52ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_Energy');\"        # Takes 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b0b73e-0c50-4110-be9c-05aaf1181960",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2023, 2024. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
