{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79e9543f-e1dc-48da-8a07-007bc1c65df7",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Train Delay Prediction\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe5a94f-446b-44d5-bff0-134f597692ac",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Introduction</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "Customer satisfaction starts with the experience. However, in every customer experience there is risk of unknown or unexpected issues. For instance, trains run on a very structured schedule, but delays still occur. Train delays significantly affect both the operational effectiveness of railway companies and the overall experience of passengers in the transportation sector. Teradata Vantage and ClearScape Analytics provide the features to examine historical data to determine the root cause of these delay, which in turn with enhance train operations and reduce interruptions. In Vantage, users can develop predictive modeling to anticipate these delays and enable pro-active planning, so resources can be allocated as necessary.</p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Business Values</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Understand delays and what factors lead to these delays.</li>\n",
    "    <li>Reduce the number of delays and increase customer satisfaction.</li>\n",
    "    <li>Ensure timeliness and accurate scheduling.</li>\n",
    "</ul>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Why Vantage?</b></p>  \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> To build more effective ML and AI models, developers and data scientists need to look outside the box for data, tools, and techniques that can continuously enhance the accuracy, speed, and efficacy of their models. Unfortunately, most of the time, this creativity comes at a cost. Plus, combining different types of analytics and data into the development pipeline usually adds complexity, fragility, and difficulties with operationalizing the process.<br>\n",
    "Teradata Vantage provides ClearScape Analytics functions which allow users to seamlessly combine a wide range of behavioral, text processing, statistical analysis, and advanced analytic functions with model training and deployment tools on the same platform.<br>  \n",
    "This allows for rapid development, testing, and validation of new techniques at scale in near-real time so new, more accurate models can easily be deployed to production.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb9e6ab-9ff3-42b7-8fad-12d5fac094f8",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>1. Connect to Vantage</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ebb615-6783-408d-af9d-a03495dce0a9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Let's start by importing the libraries needed.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c983d10-1966-422b-8c4e-9fb95bcd213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import getpass\n",
    "import warnings\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Teradata libraries\n",
    "from teradataml import *\n",
    "display.max_rows = 5\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a41075-b70f-4aee-83c2-99aaccd43f15",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell. Begin running steps with Shift + Enter keys.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f23854d-5051-4c2f-9f44-b1ff6c971616",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d3badf-0634-415d-88a2-31709be55aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=Train_Delay_Python.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5768fc-74e8-4c83-81b0-658cbe7599b5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'> <b>Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We have provided data for this demo on cloud storage. We have the option of either running the demo using foreign tables to access the data without using any storage on our environment or downloading the data to local storage, which may yield somewhat faster execution. However, we need to consider available storage. There are two statements in the following cell, and one is commented out. We may switch which mode we choose by changing the comment string.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0b31f9-399b-4c34-a942-1442e6abbe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ../run_procedure.py \"call get_data('DEMO_TrainDelay_cloud');\"        # Takes 30 seconds\n",
    "%run -i ../run_procedure.py \"call get_data('DEMO_TrainDelay_local');\"        # Takes 1 minute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e3111-7a88-4d25-b851-0f3e27ab6f40",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Optional step – We should execute the below step only if we want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb9b7a9-2d15-4435-a15e-544ed4cd8712",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6023b0fa-f4d8-4804-9e19-ab948fb42dc9",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>2. Data Exploration</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    Let us start by creating a \"Virtual DataFrame\" that points directly to the dataset in Vantage. We then begin our analysis by checking the shape of the DataFrame and examining the data types of all its columns.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7102e12-92e3-4efb-884f-7a1827b1bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = DataFrame(in_schema(\"DEMO_TrainDelay\" ,\"Train_Dataset\"))\n",
    "mydata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af9bbe1-0c45-41e4-aff9-073cb03c0974",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><i>mydata</i> is a Vantage DataFrame object which behaves in similar manner to a Pandas DataFrame and has similar methods and functions like:\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'> \n",
    "    <li> shape to get the number of rows and columns</li>\n",
    "    <li> dtypes to get the data types per columns</li>\n",
    "    <li> groupby, select, agg, ... to compute and manipulate aggregation</li>\n",
    "    <li> iloc, loc to filter rows and columns</li>\n",
    "    <li> columns to get the column names</li>\n",
    "    </ul>\n",
    " <p style = 'font-size:16px;font-family:Arial;color:#00233C'>This likeness facilitates a seamless transition and interchangeability between the two, allowing us to leverage our familiarity with pandas while harnessing the power of Teradata for robust data manipulation and analysis.   \n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77362182-1eab-4907-9b46-dcd468433253",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41287d99-4fc6-43a0-9c85-5e9a42c89106",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36389b88-6df3-4b16-9b12-48261ca1ec5d",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>mydata dataframe contains 54616 rows and 3 columns.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7c48c-5683-413c-825a-5f0fbb8013db",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e87e891-20d3-4194-8ac8-fbcbe3cbe17f",
   "metadata": {},
   "source": [
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>The columns are 3:\n",
    "    <li> TravelID as int </li>\n",
    "<li> events as string</li>\n",
    "    <li> datetime as datetime</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dbc27f-63c3-4fc1-a83e-6e29abe203bd",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>As an example, we can see all different events contained in the dataset:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52a39d3-aedd-4055-bd00-07e40a467d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.groupby(['Events']).agg('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea658f6-9d06-4818-baf3-fe327d54e715",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "We can see that the aggregated data is available to us in teradataml dataframe. Let's visualize this data for better understanding. Clearscape Analytics can easily integrate with 3rd party visualization tools like Tableau, PowerBI or many python modules available like plotly, seaborn etc. We can do all the calculations and pre-processing in Vantage and pass only the necessary information to visulazation tools, this will not only make the calculations faster but also reduce overall processing time due to less data movement between tools and applications. For converting a teradataml dataframe to a Pandas DataFrame we use to_pandas() method.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e20173-8535-4522-be40-d9dc2ba2afca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4plot = mydata.groupby(['Events']).agg('count').to_pandas()\n",
    "df4plot.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4114b963-380d-4b1e-acec-dc712c00ed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "plt.rc('ytick', labelsize=20)\n",
    "df4plot.sort_values('count_TravelID',ascending=True).plot.barh(x='Events',y='count_TravelID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c706bc3-9561-471e-8ef2-2a669a53a70e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here we see that we have as much departure as arrival which is expected. The most frequent events are <i>Door light failure</i> and <i>Normal stop</i>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e24e0e-8485-4bd9-ad62-e9590c12acd9",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>3. Advanced Data Exploration : Path Analysis </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The <b>nPath</b> function scans a set of rows looking for patterns that we specify. For each set of input rows that matches the specified pattern, nPath produces a single output row. This is extremely useful when our goal is to identify the paths that lead to an outcome.<br>\n",
    "In our example, we want to build all the paths of events a travel (or trip) passes through, meaning:</p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li> for each travel we want to get the sequence of events</li>\n",
    "</ul>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>A travel can be modelled as a sequence of event starting from the *departure* event, and ending with the *arrival* event.</p>\n",
    "<center><img src=\"images/npath_sankey.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1792e0-8a2b-4ef9-b4f7-de4c34c5aeec",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "For our example:\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>We will pass our dataset 'mydata' to the function.</li>\n",
    "    <li>Provide partitioning (TravelID) and ordering column.</li>\n",
    "    <li>Mode <b>OVERLAPPING</b> vs. <b>NONOVERLAPPING</b>\n",
    "        <ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "            <li><b>OVERLAPPING</b> finds every occurrence of the match, regardless of the current row being part of a previous match.</li>\n",
    "            <li><b>NONOVERLAPPING</b> starts matching again at the row that follows the previous match.\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Symbols.  Create a set of column expression aliases that can be assembled into a pattern to match.\n",
    "        <ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "            <li>Example: \"EVENT = 'departure' AS Dep\" will alias a match on the EVENT column when the event equals 'Departure'.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "      <li>Pattern.  Compose a pattern to search for across the rows of events.  This pattern is composed of Symbols and directives.\n",
    "        <ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "            <li>Example: '^Dep' uses a directive ^ to indicate the P Symbol must occur at the beginning of the group of rows</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Result.  Since nPath emits a single row per group-of-row matches, Result indicates what columns make up this row and how to aggregate the data.</li>\n",
    "    </ol>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b37c8c-e9a4-4e23-b36d-0d35a1f2026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "myPathAnalysis = NPath(data1     = mydata,\n",
    "               data1_partition_column = 'TravelID',\n",
    "               data1_order_column     = 'Datetime',\n",
    "               result                 = ['FIRST (TravelID OF any (Dep,Arr)) AS TravelID',\n",
    "                                         'ACCUMULATE (cast(events as VARCHAR(50) CHARACTER SET UNICODE NOT CASESPECIFIC)OF any(Other,Dep,Arr)) AS MyPath',\n",
    "                                         'first(Datetime of Dep) AS departure_time',\n",
    "                                         'last(Datetime of Arr) As arrival_time'\n",
    "                                        ],\n",
    "               mode                   = 'nonoverlapping',\n",
    "               pattern                = '^Dep.Other*.Arr$',\n",
    "               symbols                = [\"events='departure' AS Dep\",\n",
    "                                         \"events='arrival' AS Arr\",\n",
    "                                         \"true as Other\"\n",
    "                                        ],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177ea418-aa15-4767-9aad-a769db6f3ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "npath_df=myPathAnalysis.result\n",
    "npath_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db9207a-28c4-4729-a414-d2ee002518a8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The results of the npath can be customized. We can add the path (here the *mypath* column) but also the departure and arrival time for each travel. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604d5dc-6bd2-41cb-b79a-4a4cbc0262c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "npath_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e9e62e-ed6a-4114-96a2-89af2ee749d6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> We can see that we have 7300 path where the starting event is departure and endinng event is arrival.<br>We can store these results in table for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eded30e-39e2-4531-b368-35036c2e5148",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(npath_df, table_name = 'npath_data', if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99e2594-fccc-4584-ba75-e64342b58a3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In order to visualize the distribution of the different path of events, we typically use Sankey diagram of the aggregated over the paths reported by the NPATH command.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9ba2c0-8c12-4298-b1db-b077a4c9a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdnpathviz.visualizations import plot_first_main_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e565c17c-551e-422b-9d62-722cd9ca04b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_first_main_paths(npath_df,path_column='mypath',id_column='travelid',width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36d1ab6-0533-42cd-a5cd-37b280fcfdb3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "To check the details of any path or node we can move the mouse pointer over it and check details. The number on the path represent the count of travelids which have that path and source and target mentions the incoming and outcoming events.<br>\n",
    "When the pointer is moved over a Node, for example when the pointer is on the long purple Node at the right top arrival it shows incoming flow count: 4 and outgoing flow count: 0 which means that there are 4 different events which lead to this node similarly outgoing flow count gives the count of events after this event.<br>\n",
    "<br>\n",
    "For sake of clarity, it is important to focus on the most important paths from a business viewpoint. Here we decided to look at the most frequent ones, i.e. a frequency > 20.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac9b978-e686-44dc-b36c-2754effe288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nPathdf_group=npath_df.groupby(\"mypath\")\\\n",
    "                .count()\\\n",
    "                .sort('count_travelid',ascending=False)\n",
    "nPathdf_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99dd1eb-bcf8-46ae-8019-b38803010bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_travel=nPathdf_group.count_travelid\n",
    "nPathdf_group_plot=nPathdf_group[count_travel >= 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf99baf6-f30f-4d5e-8a1a-2b6c56632326",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_first_main_paths(nPathdf_group_plot,path_column='mypath',id_column='count_travelid',width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfc4f3e-25aa-48ae-a6f5-72a66331ac67",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The visualization of paths in event table is critical to design the best modeling strategy. For instance the business may decide to ignore some events because to doubt about the meaning of a given event and rapidly assess its importance in its entire dataset.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b2229f-a555-4656-b73f-2ab744c1a455",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>4. Data Preparation using the Massive Parallel Processing of Vantage</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "In this example, we want to predict the delay induced by each event assuming each delay adds up independently from each other. For this purpose, we will use Machine Learning algorithm to predict the delay from the frequency of each event.\n",
    "<center><img src=\"images/data_science_model.png\"/></center>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "It is a good practice to perform data preparation using tables and/or views. In this way we can leverage the Massive Parallel Processing of Vantage. Moreover, the data preparation is shareable across the enterprise and guarantees the operationalization of the solution.<br>In this example, we decided to use a view, named *usecase_dataset*. Doing this will provide a consistently updated dataset with the latest data. This view can be used later to historize as many dataset as needed for training and testing.<br>\n",
    "To do so, we can push a SQL query to build this view in a data lab space in Vantage. Note that this view relies on the NPATH Vantage function and timestamp manipulation to create the target feature which is the travel duration in seconds (*travel_duration_sec*).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03255044-8ad5-4ac1-8139-48cafc0a9a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "myquery = \"\"\"REPLACE VIEW usecase_dataset (TravelID,travel_duration_sec, travel)\n",
    " AS\n",
    " SELECT TravelID,travel_duration_sec, travel  FROM (\n",
    "  SELECT \n",
    "        TravelID AS TravelID,\n",
    "        departure_time AS departure_time,\n",
    "        arrival_time AS arrival_time,\n",
    "        (arrival_time - departure_time) HOUR TO SECOND(4) as travel_duration,\n",
    "        INTERVAL(PERIOD(departure_time,arrival_time)) MINUTE(3) as travel_duration_min,\n",
    "        EXTRACT(HOUR FROM travel_duration)*3600 + EXTRACT(MINUTE FROM travel_duration)*60 + EXTRACT(SECOND FROM travel_duration) as travel_duration_sec,\n",
    "        mypath as travel\n",
    "  FROM npath_data\n",
    ") A;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52b6567-9ce4-467e-ae9e-81938632912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_sql(myquery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd359d1-7595-469d-825a-d4d831cd10c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mydata = DataFrame(\"usecase_dataset\")\n",
    "df_mydata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc21b6c2-53a7-4791-8a25-709787eca7d0",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>5. Model development : prepare the data for the Machine Learning Algorithm</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Feature Creation</b><br>\n",
    "The dataset built in Vantage contains all the information to address the business question. Based on the dataset and the business question additional features can be created which will machine learning algorithm to get the meaningful insights.<br>\n",
    "In our example, the strategy proposed by the data scientist consists of spliting the paths and count frequency of each event in it.</p>\n",
    "<center><img src=\"images/model_strategy.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd01d81-e34a-4047-8bd0-c87933aa31f9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We use the <i>NGramSplitter</i> function to process the paths of each travel. The function will split the corpus of texts into \"terms\" (grams) of selected size.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee3316c-4440-4194-8f20-b6bec8df2074",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = NGramSplitter(data=df_mydata,\n",
    "                          text_column='travel',\n",
    "                          delimiter = \",\",\n",
    "                          grams = \"1\",\n",
    "                          overlapping=False,\n",
    "                          to_lower_case=True,\n",
    "                          total_gram_count=True,\n",
    "                          punctuation = \"[\\\\]\\\\\\\\[\\\\`]\"\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e01e4f-b64d-4f71-ba5e-af82c74d353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406bda19-39fb-4999-ae00-407567a8162b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The NGRAMS function add new columns (and rows). We will use two of them:</p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li> ngram : is the event found in the travel</li>\n",
    "    <li> frequency : is the frequency of this event in the path</li>\n",
    " </ul>   \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We need to get the number of possible ngrams: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02abce5-bbc0-4831-bab4-ac0a9134d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = (ngrams.result).select(['ngram','frequency']).groupby(['ngram']).sum()\n",
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2d80cf-2061-4972-b669-960211478e51",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We can visualize again the distribution of events in the dataset:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6829541-8469-4492-ba73-ebcc92d327b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "keys=keys.to_pandas()\n",
    "keys.sort_values('sum_frequency',ascending=True).plot.barh(x='ngram',figsize=(10,5),fontsize=20,legend=False)\n",
    "plt.ylabel('events',fontsize=20)\n",
    "plt.xlabel('frequency',fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec93171c-eb3d-4b38-a4f0-d209a684d58f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In order to make the dataset ready for the Machine Learning algorithm, we need to pivot the data and fill missing values with 0.<br>\n",
    "For this purpose, we use two functions:</p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "  <li>Pivot, to pivot the data and generate as many columns as event type. When an event does not occur during the travel, pivot assign its frequency to NULL or NaN</li>\n",
    "    <li>assign, is used here to fill the missing values using the *isnan* function</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9569b56-16bb-449a-ad30-706ad8ee535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram = ngrams.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8160f8-e18f-430c-8272-50c138658042",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e1c607-437c-4a1c-bd22-f77a237990f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30513212-45cf-4d44-b91d-ef8524d5a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3713ff-43c9-4ca5-9063-c05e9215262b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><i>* below command is pivoting the data and takes approx 1min 30sec to execute </i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ea37fb-cc46-4806-a6e7-0e9de79dfd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pivot = df_ngram.pivot(columns=df_ngram.ngram, aggfuncs=df_ngram.frequency.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f3f999-f87a-4f09-9a91-d9f47fee7198",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pivot.assign(drop_columns                 = True,\n",
    "           travelid                              = pivot.TravelID,\n",
    "           travel                                = pivot.travel,\n",
    "           travel_duration_sec                   = pivot.travel_duration_sec, \n",
    "           frequency_abnormal_weather_condition  = pivot['sum_frequency_abnormalweathercondition']  if not pivot['sum_frequency_abnormalweathercondition'].isna() else (1.-pivot['sum_frequency_abnormalweathercondition'].isna()),\n",
    "           frequency_accident_involving_person   = pivot['sum_frequency_accidentinvolvingperson']  if not pivot['sum_frequency_accidentinvolvingperson'].isna() else (1.-pivot['sum_frequency_accidentinvolvingperson'].isna()),\n",
    "           frequency_body_on_track               = pivot['sum_frequency_bodyontrack']  if not pivot['sum_frequency_bodyontrack'].isna() else (1.-pivot['sum_frequency_bodyontrack'].isna()),          \n",
    "           frequency_crowded_stop                = pivot['sum_frequency_crowdedstop']  if not pivot['sum_frequency_crowdedstop'].isna() else (1.-pivot['sum_frequency_crowdedstop'].isna()),\n",
    "           frequency_door_failure                = pivot['sum_frequency_doorfailure']  if not pivot['sum_frequency_doorfailure'].isna() else (1.-pivot['sum_frequency_doorfailure'].isna()),          \n",
    "           frequency_door_light_failure          = pivot['sum_frequency_doorlightfailure']  if not pivot['sum_frequency_doorlightfailure'].isna() else (1.-pivot['sum_frequency_doorlightfailure'].isna()),\n",
    "           frequency_electrical_failure          = pivot['sum_frequency_electricalfailure']  if not pivot['sum_frequency_electricalfailure'].isna() else (1.-pivot['sum_frequency_electricalfailure'].isna()),          \n",
    "           frequency_engine_failure              = pivot['sum_frequency_electricalfailure']  if not pivot['sum_frequency_electricalfailure'].isna() else (1.-pivot['sum_frequency_electricalfailure'].isna()),\n",
    "           frequency_normal_stop                 = pivot['sum_frequency_normalstop']  if not pivot['sum_frequency_normalstop'].isna() else (1.-pivot['sum_frequency_normalstop'].isna()),          \n",
    "           frequency_road_work                   = pivot['sum_frequency_roadwork'] if not pivot['sum_frequency_roadwork'].isna() else (1.-pivot['sum_frequency_roadwork'].isna()),\n",
    "           frequency_stop_sign_failure           = pivot['sum_frequency_stopsignfailure'] if not pivot['sum_frequency_stopsignfailure'].isna() else (1.-pivot['sum_frequency_stopsignfailure'].isna()),          \n",
    "           frequency_unexpected_stop             = pivot['sum_frequency_unexpectedstop'] if not pivot['sum_frequency_unexpectedstop'].isna() else (1.-pivot['sum_frequency_unexpectedstop'].isna())\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800a3d61-fe0c-4d5a-ad22-cd3e9a442290",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here we decide to create a table with the dataset in order to test different machine learning algorithm.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9587da21-06f5-43a7-9856-00788a09752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(dataset,table_name='my_dataset',if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c097fa86-94a2-4725-af2e-54d5ef6b606b",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>6. Model development : apply Machine Learning Algorithm</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "In our case, using a Generalized Linear Model answers the following business questions:</p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>   \n",
    "    <li>what is the travel duration when no event occur ? (even if this travel does not exist) => the answer is the intercept</li>\n",
    "    <li>what is the delay induced by each event type ? (under the assumption there is no interaction between events) => the answers are the coefficients of the model</li>\n",
    "    <li>can I simulate a new scenario ? => this is addressed by the scoring on new data. By the way, it can be done with any Machine Learning trained model</li>\n",
    " </ul>   \n",
    "<center><img src=\"images/GLM.png\"/></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2a6e6a-c94a-47b6-b204-b07910fab55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_num = DataFrame('my_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7698774e-4214-487f-97f1-889ef0f383a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1baa04-38d5-4fff-a7f8-aae8ab003923",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_num.loc[:,['travelid','travel_duration_sec']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ac8553-9506-4a74-9e1c-6de9e9432077",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Create train and test data</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Now we have transformed our data and it is fit to be used in machine learning model, let us split the whole dataset into train and test sets for model training and scoring. We will use TrainTestSplit function for this task..</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32da8553-184b-4c4f-ad8a-13a9d038dfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTestSplit_out = TrainTestSplit(\n",
    "                                    data = dataset_num,\n",
    "                                    id_column = \"travelid\",\n",
    "                                    train_size = 0.75,\n",
    "                                    test_size = 0.25,\n",
    "                                    seed = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feee7305-0427-4e35-83dd-a149a369884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_training = TrainTestSplit_out.result[TrainTestSplit_out.result['TD_IsTrainRow'] == 1].drop(['TD_IsTrainRow'], axis = 1)\n",
    "dataset_testing  = TrainTestSplit_out.result[TrainTestSplit_out.result['TD_IsTrainRow'] == 0].drop(['TD_IsTrainRow'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797414b4-be02-4605-ac4f-5f5d02e23556",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b66a95-fa18-4531-aaca-5a6022cb9ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_testing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbabec7-83ae-4b27-b7c4-bf2bc879900e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We want to predict travel_duration_sec using the frequencies of all events: we define the formula accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ac96e-722d-42ef-b862-8ae91973587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'travel_duration_sec ~ '+' + '.join(dataset_num.columns[3:-1])\n",
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71abc173-b811-4e2c-ab05-b26fda20a45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import GLM, TDGLMPredict\n",
    "glm_out = GLM(     formula      = formula,\n",
    "                   linkfunction = 'IDENTITY',\n",
    "                   family       = \"GAUSSIAN\",\n",
    "                   data         = dataset_training,\n",
    "                   threshold    = 0.001,\n",
    "                   iter_max=300,\n",
    "                   tolerance=0.001,\n",
    "                   momentum=0.1,\n",
    "                   nesterov=True,\n",
    "                   learning_rate='CONSTANT'\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0286e377-9879-4280-bc86-532abf7dee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_out.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efac8494-828c-4dba-9848-2333ba6ef5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_coefficients = glm_out.result.to_pandas().reset_index()\n",
    "feat_imp = model_coefficients[model_coefficients['attribute'] > 0].sort_values(by = 'estimate', ascending = False)\n",
    "\n",
    "# Specify figure size\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Use ax.barh() for horizontal bar chart\n",
    "ax.barh(feat_imp['predictor'], feat_imp['estimate'], edgecolor='red')\n",
    "\n",
    "# Add text labels on right of the bars\n",
    "for x, y in zip(feat_imp['estimate'], feat_imp['predictor']):\n",
    "    ax.text(x, y, str(round(x, 2)), ha='left', va='center')\n",
    "\n",
    "# Set y-axis label\n",
    "ax.set_xlabel('Estimate')\n",
    "\n",
    "plt.title('Feature importance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce82f97-1888-40e6-a742-056dec0696b3",
   "metadata": {},
   "source": [
    "<br>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The figure above displays feature importance which are significant factors in predicting the target variable which in our case is travel_duration_sec. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6129f1e6-79cc-4de3-8636-9b47a8016c81",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>7. Model Performance</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The model accuracy is tested on the testing dataset (dataset_testing) using the GLMPredict function</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea3ed0-a2e3-45de-9d3e-24cf80534f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = TDGLMPredict(object=glm_out.result,\n",
    "                                        newdata=dataset_testing,\n",
    "                                        accumulate=\"travel_duration_sec\",\n",
    "                                        id_column=\"travelid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc11b57-f4ba-4e90-a2c4-3b9fe81da2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65969d5a-f0bd-4632-b330-f46ab02b8efb",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The TD_RegressionEvaluator function computes metrics to evaluate and compare multiple models and summarizes how close predictions are to their expected values.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe8493-468e-459c-be31-c999887cea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import RegressionEvaluator\n",
    "RegressionEvaluator_out = RegressionEvaluator(data = predictions.result,\n",
    "                                                      observation_column = \"travel_duration_sec\",\n",
    "                                                      prediction_column = \"prediction\",\n",
    "                                                      freedom_degrees = [1, 2],\n",
    "                                                      metrics = ['RMSE','R2','FSTAT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e34a619-3a49-4767-9f4e-4e7d94fcdb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "RegressionEvaluator_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d9cc6b-b5de-4fac-8945-c02d9909fe91",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The Metrics of the regression evaluator has the RMSE, R2 and the F-STAT metrics which are specified in the Metrics.<br>The Regression evaluator is used to evaluate and compare the models. </p>  \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Root mean squared error (RMSE)The most common metric for evaluating linear regression model performance is called root mean squared error, or RMSE. The basic idea is to measure how bad/erroneous the model’s predictions are when compared to actual observed values. So a high RMSE is “bad” and a low RMSE is “good”.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The coefficient of determination — more commonly known as R² — allows us to measure the strength of the relationship between the response and predictor variables in the model. It’s just the square of the correlation coefficient R, so its values are in the range 0.0–1.0. Higher values of R- Squared is Good.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> F-statistics (FSTAT) conducts an F-test. An F-test is any statistical test in which the test statistic has an F-distribution under the null hypothesis.\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>F_score = F_score value from the F-test.</li>\n",
    "<li>F_Critcialvalue = F critical value from the F-test.</li>\n",
    "<li>p_value = Probability value associated with the F_score value.</li>\n",
    "<li>F_conclusion = F-test result, either 'reject null hypothesis' or 'fail to reject null hypothesis'. If F_score > F_Critcialvalue, then 'reject null hypothesis' Else 'fail to reject null hypothesis'</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc5cf71-6fa0-4186-883b-4f072a9e7c6a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Conclusion</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In this notebook we have seen the end-to-end model creation using the The Teradata Vantage In-Database functions. We have seen how we can use nPath function to create get sequence of events which led to the desired output event. We can further analyse these events via model creation on which event has the most impact on the output event. Here we have built a basic model which has fairly ok R2 value ( regression models with R2 higher than 0.8 are considered good) and you can experiment by adjusting the model parameters to observe their impact on predictions and evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704fb989-e14d-48f5-9b34-08f9d77c904f",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>8. Cleanup</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C;color:#00233C'><b>Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C;'>\n",
    "We need to clean up our work tables to prevent errors next time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ee73be-730e-43f3-b395-144f4fb17686",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['npath_data','my_dataset']\n",
    "\n",
    "# Loop through the list of tables and execute the drop table command for each table\n",
    "for table in tables:\n",
    "    try:\n",
    "        db_drop_table(table_name = table)\n",
    "    except:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee29562-7d27-48bc-8614-c9bd15b7dbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_sql('DROP VIEW usecase_dataset;')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fa7b9b-5eb6-4357-a86c-327c0ea3f397",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C;color:#00233C'><b>Databases and Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the following code to clean up tables and databases created for this demonstration.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a0f759-a8ce-4c0a-a8b2-f972070ed90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_TrainDelay');\" \n",
    "#Takes 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3081d7f0-1fc6-4200-b3cb-36c0941b88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d75b32-d7e3-4efc-a9ce-cda662a5df1d",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    " \n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>Required Materials</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Let’s look at the elements we have available for reference for this notebook:</p>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Filters:</b></p>\n",
    "    <ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Industry:</b> Transportation</li>\n",
    "    <li><b>Functionality:</b> Machine Learning</li>\n",
    "    <li><b>Use Case:</b> Delay Predictions</li>\n",
    "    </ul>\n",
    "    <p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Related Resources:</b></p>\n",
    "    <ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><a href = 'https://www.teradata.com/Blogs/Using-a-Lake-Centric-Modernization-Approach'>Using a Lake-Centric Modernization Approach to Clean Up a Data and Compute Mess</a></li>\n",
    "    <li><a href = 'https://www.teradata.com/Blogs/Hyper-scale-time-series-forecasting-done-right'>Hyper-scale time series forecasting done right</a></li>\n",
    "    <li><a href = 'https://www.teradata.com/Blogs/Data-Analytics-Keeps-the-Wheels-on-the-Bus'>Data & Analytics Keep the Wheels on the Bus!</a></li>\n",
    "        </ul> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5a0ee8-4615-4c24-846d-11f7703c89f7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Reference Links:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'> \n",
    "       <li>Teradata Vantage™ - Analytics Database Analytic Functions - 17.20: <a href = 'https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Teradata-VantageTM-Analytics-Database-Analytic-Functions-17.20/Introduction-to-Analytics-Database-Analytic-Functions '>https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Teradata-VantageTM-Analytics-Database-Analytic-Functions-17.20/Introduction-to-Analytics-Database-Analytic-Functions </a></li>    \n",
    "  <li>Teradata® Package for Python User Guide - 17.20: <a href = 'https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Teradata-Package-for-Python-User-Guide-17.20/Introduction-to-Teradata-Package-for-Python'>https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Teradata-Package-for-Python-User-Guide-17.20/Introduction-to-Teradata-Package-for-Python</a></li>\n",
    "  <li>Teradata® Package for Python Function Reference - 17.20: <a href = 'https://docs.teradata.com/r/Enterprise/Teradata-Package-for-Python-Function-Reference-17.20/Teradata-Package-for-Python-Function-Reference'>https://docs.teradata.com/r/Enterprise/Teradata-Package-for-Python-Function-Reference-17.20/Teradata-Package-for-Python-Function-Reference</a></li>      \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd057557-2dea-4247-8848-0f29c01d304c",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2023,2024. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3fa04e-a949-4f1f-8c1c-a7790c71c202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
