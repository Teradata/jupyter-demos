{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5169c9ee-1e13-461e-b599-d615c9873035",
   "metadata": {},
   "source": [
    "<header style=\"padding:1px;background:#f9f9f9;border-top:3px solid #00b2b1\"><img id=\"Teradata-logo\" src=\"https://www.teradata.com/Teradata/Images/Rebrand/Teradata_logo-two_color.png\" alt=\"Teradata\" width=\"220\" align=\"right\" />\n",
    "\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>Multi Touch Attribution using Vantage</b>\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>Target Audience</b></p>\n",
    " \n",
    "<p style = 'font-size:16px;font-family:Arial'>This notebook is a simplified version of the MultiTouch_Attribution_PY_SQL notebook as it is targeted for the Business Analyst persona rather than the Data Scientist persona.</p>  \n",
    "    \n",
    "    \n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>Introduction</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Marketing attribution modelling techniques aim to determine the contribution of each marketing touchpoint or channel in influencing customer behaviour and driving conversions. These models provide valuable insights into the effectiveness of marketing efforts, helping businesses make informed decisions regarding resource allocation and optimization.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'><a href='#rule'>Rule-based</a> attribution modelling relies on predetermined rules or heuristics to assign credit to various touchpoints along the customer journey. Common rule-based models include the First Touch, Last Touch, Uniform (linear) and Exponential(time decay) models. The First Touch model attributes all credit to the first touchpoint a customer interacts with, while the Last Touch model assigns all credit to the final touchpoint before conversion. The Uniform model evenly distributes credit across all touchpoints in the customer journey. The Exponential model assigns more credit to touchpoints closer to the conversion event.<p>\n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial'><a href='#stat'>Statistical</a> and <a href='#ml'>Algorithmic-based</a> attribution modelling, on the other hand, utilizes advanced statistical and machine learning techniques to determine the contribution of each touchpoint. These models take into account various factors such as the order, timing, and interaction patterns of touchpoints.<p>\n",
    "   \n",
    "<p style = 'font-size:16px;font-family:Arial'>All approaches have their strengths and limitations. <a href='#rule'>Rule-based</a> models are relatively straight forward to implement and interpret, but they may oversimplify the complexity of customer journeys. <a href='#ml'>Algorithmic-based</a> models offer more sophisticated and granular insights but may require advanced analytics expertise and extensive data sets to achieve accurate results.\n",
    "It's important for businesses to select the most suitable attribution modelling approach based on their specific goals, available data, and resources. Implementing an effective marketing attribution model can significantly enhance decision-making and optimize marketing strategies.<p>\n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial'>In this use case we will show several different analytic techniques to perform Multi Touch Attribution modelling and analysis using Vantage.<p>\n",
    "<img src=\"images/Attribution.png\">    \n",
    "<p style = 'font-size:16px;font-family:Arial'>Our innovative approach includes the use of <a href='#path'>Path Analysis</a> not only to identify and visualize customer conversion journeys but also to prepare data for advanced and sometimes creative techniques.<p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab390ec7-a37a-4554-8856-a10df8376831",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>1. Start by connecting to the Vantage system.</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89a8fb9-851a-4b22-9438-3e6bf5e0b0dd",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In the section, we import the required libraries and set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d11eed5-7cdc-421d-aeb7-780a2274353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import teradataml as tdml\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# import markov_model_attribution as mma\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tdnpathviz\n",
    "from teradataml import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "display.max_rows = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4884487c-aaad-42bb-a4f6-d5c465349194",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>You will be prompted to provide the password. Enter your password, press the Enter key, then use down arrow to go to next cell. Begin running steps with Shift + Enter keys.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc11684-f63b-4fdc-9ca2-c4f229d377bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)\n",
    "eng.execute('''SET query_band='DEMO=MultiTouchAttribution_PY_SQL.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731c11a2-f615-4c84-afd5-6341ed8fdd55",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>2. Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have provided data for this demo on cloud storage.  In this demo as we are using the nPath function with needs all character data in LATIN character set, we will only use the local option of creating tables and DDL.</p>   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db442539-86f1-491a-985b-f6c634c62866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ../run_procedure.py \"call get_data('DEMO_MultiTouchAttribution_cloud');\"\n",
    " # Takes about 30 secs\n",
    "%run -i ../run_procedure.py \"call get_data('DEMO_MultiTouchAttribution_local');\"\n",
    " # Takes about 1 minute 30 secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8076a002-0d9d-4ce1-a470-4fd63662de0c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Next is an optional step – if you want to see status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed7ac55-4477-4429-bae3-569f76a85ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a05f9a-2d1b-417c-9ca7-bef0ddb1422c",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>3. Analyze the raw data set</b></p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Data</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The dataset is digital marketing data containing 586,000 marketing touch-points from July (2018), comprising 240,000 unique customers who generated ~18,000 conversions. A more detailed description of the features is shown below:\n",
    "\n",
    "<li style = 'font-size:14px;font-family:Arial'>Cookie: Anonymous customer id enabling us to track the progression of a given customer</li>\n",
    "<li style = 'font-size:14px;font-family:Arial'>Timestamp: Date and time when the visit took place</li>\n",
    "<li style = 'font-size:14px;font-family:Arial'>Interaction: Categorical variable indicating the type of interaction that took place</li>\n",
    "<li style = 'font-size:14px;font-family:Arial'>Conversion: Boolean variable indicating whether a conversion took place</li>\n",
    "<li style = 'font-size:14px;font-family:Arial'>Conversion Value: Value of the potential conversion event (revenue)</li>\n",
    "<li style = 'font-size:14px;font-family:Arial'>Channel: The marketing channel that brought the customer to our site</li>\n",
    "</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Create a DataFrame to get the data from the table created.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290e859e-acdb-4908-84de-fddc3761be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_df=DataFrame(in_schema('DEMO_MultiTouchAttribution', 'Attribution_Data'))\n",
    "attr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470bce51-9053-407e-a1e1-1bba46265fbd",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The Attribution data contains the channel details with the timestamp of the conversion , its conversion value and cost.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdf488b-d905-497e-b11e-c5661dc7efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=attr_df.to_pandas().reset_index()\n",
    "#Plotting conversions over time by channel\n",
    "conversions = df.loc[df['conversion'] == 1]\n",
    "conversions['time'] = conversions['tmstp'].dt.date\n",
    "conversions = conversions[conversions['time']< pd.to_datetime(\"2018-7-30\").date()]\n",
    "conversions.drop(columns = ['cookie', 'interaction'], inplace = True)\n",
    "# conversions = conversions.groupby(['time','channel'], as_index=False).sum()\n",
    "conversions = conversions.groupby(['channel'], as_index=False).sum()\n",
    "\n",
    "fig = px.bar(conversions, x='channel', y='conversion', color='channel')\n",
    "\n",
    "fig.update_layout(title='Channel Conversions',\n",
    "                   xaxis_title='Channel',\n",
    "                   yaxis_title='Conversions')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cd4e5a-828b-4cd2-a65b-58769b7b8ba4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above chart shows the number of conversions by each Channel.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757fe695-eda3-4f8d-b166-a5351d55bee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel_df=DataFrame(in_schema('DEMO_MultiTouchAttribution', 'Channel_Cost'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ba2f3c-db0b-44fa-9fc4-fb62122f23f5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The Channel data contains the channels and cost.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180bfac7-22a1-4d03-8bef-4b1fe4a4c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot= channel_df.to_pandas().reset_index()\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.barplot(x = 'channel',y = 'cost',data = df_plot)\n",
    "plt.xlabel('Channel')\n",
    "plt.ylabel('Cost of Conversion')\n",
    "plt.title('Channel Cost')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9436093-5e7d-4c97-a7fa-f34d63494fdb",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The cost of Online Video is highest and that of Instagram is lowest.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328e077e-4c13-48ac-af1f-a8dbb7f72856",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr>\n",
    "<a id=\"path\"></a>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>4. PATH ANALYSIS</b></p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d859aeb5-d31c-441e-b732-b475a0578785",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>4.1. Use nPath® to visualise conversion journeys</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e16ad0-af95-49cb-b7a0-9efd997bd36d",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We want to see how our customers are converting.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Pathing is the process of discovering a sequence of antecedent actions that occur prior to a specific event of interest on sessionized data. Pathing discovers the most salient patterns across a group of individuals or entities based on which further actions are considered. Pathing allows you to provide an explanation of the relation and the relative importance of each factor.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The nPath® function provides a flexible pattern-matching capability that lets you specify complex patterns in the input data and define the values that are output for each matched input set. So we can use powerful nPath® analytic function in Vantage to do pattern/time series analysis that is very hard to do in simple SQL. We want to see the common channel paths that customers take when they convert.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In the code here you can see a few key points:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial'>The 'Pattern' we are searching for is 8 events followed by conversion (conversion =1).</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>The 'Symbols' we are using is anything but converting is 'EVENT' and conversion column = 1 is 'CONVERSION'.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>We create a dummy 'Conversion' event to enable its visualization.</li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4338d52-4cda-4d2b-af6c-7f990df00f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "npath_sessions = NPath(data1 = attr_df, \n",
    "                      data1_partition_column = ['cookie'], \n",
    "                      data1_order_column = ['tmstp'], \n",
    "                      mode = 'NONOVERLAPPING', \n",
    "                      symbols = ['conversion=\\'1\\' as CONVERSION, conversion=\\'0\\' as EVENT'], \n",
    "                      pattern = 'EVENT{0,8}.CONVERSION', \n",
    "                      result = ['ACCUMULATE (case when conversion=\\'1\\' then \\'Conversion\\' else channel end OF ANY(CONVERSION,EVENT)) AS path',\n",
    "                                  'COUNT (* of ANY(CONVERSION,EVENT)) as event_cnt',\n",
    "                                  'FIRST (cookie OF ANY(CONVERSION,EVENT)) AS cookie'])\n",
    "\n",
    "\n",
    "# npath_sessions.result\\\n",
    "#                     .groupby(['path'])\\\n",
    "#                     .count()\\\n",
    "#                     .sort('count_event_cnt',ascending=False)\\\n",
    "#                     .to_pandas()\\\n",
    "#                     .head(10)\n",
    "convcntpath = npath_sessions.result\n",
    "convcntpath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4291f6cb-1808-47c0-a131-ef64e14d4a3e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>A visualization of this gives us lots of insight into the most common paths (the top 50) that users are taking before converting. A Sankey Diagram can be created using the output(path) of the nPath function used in the query above.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'><i>**The visualization takes around 1 minute 30 seconds to execute</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7497508-50e4-4115-87cc-7a3f9e2122a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Teradata nPath output to plotly Sankey\n",
    "#can handle paths up to 999 links in length\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def sankeyPlot(res, direction, title_text=\"Sankey nPath\", topN=15):\n",
    "    npath_pandas = res.copy()\n",
    "\n",
    "    if topN:\n",
    "        npath_pandas = npath_pandas.sort_values(by='count_event_cnt', ascending=False).head(topN)\n",
    "\n",
    "    if direction == \"from\":\n",
    "        dataDict = defaultdict(int)\n",
    "\n",
    "        for index, row in npath_pandas.iterrows():\n",
    "            pathCnt = row['count_event_cnt']\n",
    "            rowList = [item.strip() for item in row['path'].replace('[','').replace(']','').split(',')]\n",
    "            for i in range(len(rowList)-1):\n",
    "                leftValue = rowList[i] + str(i)\n",
    "                rightValue = rowList[i+1] + str(i+1)\n",
    "                valuePair = leftValue + '+' + rightValue\n",
    "                dataDict[valuePair] += pathCnt\n",
    "\n",
    "        eventList = []\n",
    "        for key in dataDict.keys():\n",
    "            leftValue, rightValue = key.split('+')\n",
    "            if leftValue not in eventList:\n",
    "                eventList.append(leftValue)\n",
    "            if rightValue not in eventList:\n",
    "                eventList.append(rightValue)\n",
    "\n",
    "        sankeyLabel = [s[:-1] for s in eventList]\n",
    "        \n",
    "        sankeySource = []\n",
    "        sankeyTarget = []\n",
    "        sankeyValue = []\n",
    "\n",
    "        for key,val in dataDict.items():\n",
    "            sankeySource.append(eventList.index(key.split('+')[0]))\n",
    "            sankeyTarget.append(eventList.index(key.split('+')[1]))\n",
    "            sankeyValue.append(val)\n",
    "\n",
    "        sankeyColor = []\n",
    "        for i in sankeyLabel:\n",
    "            sankeyColor.append('#'+''.join([random.choice('0123456789ABCDEF') for _ in range(6)]))\n",
    "\n",
    "        link = dict(source = sankeySource, target = sankeyTarget, value = sankeyValue, color='light grey')\n",
    "        node=dict(label=sankeyLabel, color=sankeyColor)\n",
    "        data=go.Sankey(link=link, node=node)\n",
    "\n",
    "        fig=go.Figure(data)\n",
    "\n",
    "        fig.update_layout(\n",
    "            hovermode ='closest',\n",
    "            title = title_text,\n",
    "            title_font_size=20,\n",
    "            plot_bgcolor='white',\n",
    "            paper_bgcolor='white'\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "    elif direction == \"to\":\n",
    "        \n",
    "        dataDict = defaultdict(int)\n",
    "        eventDict = defaultdict(int)\n",
    "        maxPath = npath_pandas['count_event_cnt'].max()\n",
    "    \n",
    "        for index, row in npath_pandas.iterrows():\n",
    "            rowList = row['path'].replace('[','').replace(']','').split(',')\n",
    "            pathCnt = row['count_event_cnt']\n",
    "            pathLen = len(rowList)\n",
    "            for i in range(len(rowList)-1):\n",
    "                leftValue = str(1000 + i + maxPath - pathLen) + rowList[i].strip()\n",
    "                rightValue = str(1000 + i + 1 + maxPath - pathLen) + rowList[i+1].strip()\n",
    "                valuePair = leftValue + '+' + rightValue\n",
    "                dataDict[valuePair] += pathCnt\n",
    "                eventDict[leftValue] += 1\n",
    "                eventDict[rightValue] += 1\n",
    "    \n",
    "        eventList = []\n",
    "        for key,val in eventDict.items():\n",
    "            eventList.append(key)\n",
    "    \n",
    "        sortedEventList = sorted(eventList)\n",
    "        sankeyLabel = []\n",
    "        for event in sortedEventList:\n",
    "            sankeyLabel.append(event[4:])\n",
    "    \n",
    "        sankeySource = []\n",
    "        sankeyTarget = []\n",
    "        sankeyValue = []\n",
    "\n",
    "        for key,val in dataDict.items():\n",
    "            sankeySource.append(sortedEventList.index(key.split('+')[0]))\n",
    "            sankeyTarget.append(sortedEventList.index(key.split('+')[1]))\n",
    "            sankeyValue.append(val)\n",
    "    \n",
    "        sankeyColor = []\n",
    "        for i in sankeyLabel:\n",
    "            sankeyColor.append('#'+''.join([random.choice('0123456789ABCDEF') for _ in range(10)]))\n",
    "    \n",
    "        link = dict(source = sankeySource, target = sankeyTarget, value = sankeyValue, color='light grey')\n",
    "        data=go.Sankey(link=link, node=dict(label=sankeyLabel))\n",
    "    \n",
    "        fig=go.Figure(data)\n",
    "        fig.update_layout(\n",
    "                hovermode ='closest',\n",
    "                title = title_text,\n",
    "                title_font_size=20,\n",
    "                plot_bgcolor='white',\n",
    "                paper_bgcolor='white'\n",
    "                )\n",
    "    \n",
    "        fig.show()\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid direction.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ef449c-df36-4f86-8de9-584a4e78d6a6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Consider an example where we create a path for a cookie which leads to conversion.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbcbb7e-7ed0-4478-bdbd-01bc0877604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_df[attr_df['cookie'] == 'FFfBikCE3onF3hACFCCE9iDf3'].sort('tmstp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c4322e-cc34-4305-844c-9a1d83a7c53e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above table shows the output of 1 cookie ordered by Timestamp(tmstp). We can see that there were 3 touch points of the facebook channel when conversion did not happen. Finally on the 4th touch point of the Facebook channel, conversion takes place. So the path will be </p>\n",
    "<p style = 'font-size:14px;font-family:Arial'><b>Facebook</b><b style = 'font-size:12px;font-family:Arial'>(2018-07-02 16:08:02)--><b><b style = 'font-size:14px;font-family:Arial'>Facebook</b><b style = 'font-size:12px;font-family:Arial'>(2018-07-08 18:38:32)--><b><b style = 'font-size:14px;font-family:Arial'>Facebook</b><b style = 'font-size:12px;font-family:Arial'>(2018-07-10 12:30:15)--><b><b style = 'font-size:14px;font-family:Arial'>Facebook</b><b style = 'font-size:12px;font-family:Arial'>(2018-07-14 10:33:31)--><b><b style = 'font-size:14px;font-family:Arial'>Conversion</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Below we plot the paths for Top 100 path that led to conversion based on the count of events.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d9efd8-577e-48fc-90bc-2755ec08a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = convcntpath\\\n",
    "                    .groupby(['path'])\\\n",
    "                    .count()\\\n",
    "                    .sort('count_event_cnt',ascending=False)\\\n",
    "                    .to_pandas()\\\n",
    "                    .head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7999d508-7222-4c20-8d7d-f2e1d1094a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sankeyPlot(res,\"to\",\"Path to Conversion\",100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42d1876-0d2e-4030-b64f-b51451938aad",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above Sankey Diagram shows the paths that led to Conversion.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>To check the details of any path or node we can move the mouse pointer over it and check details. For example if you move the pointer over the path having the largest width at the top most path going towards the right most node(Conversion) it shows <b>2.30k, source: Facebook, target: Conversion.</b> It means there were 2.30k touch points where after going to Facebook the next event was Conversion. Similarly 1.92k Online Video touch points, 1.98k Paid Search touch points, 873 Instagram touch points, 816 Online Display touch points which lead to Conversion. </p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>When the pointer is moved over a Node, for example when the pointer is on the largest Node at the top before conversion is <b>Facebook </b>  it shows <b>incoming flow count: 5 and outgoing flow count: 1</b> which means that there are 5 different paths which lead to Facebook after which the next 1 event led to Conversion. Similarly other nodes and paths can be analyzed.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f366c9-c1d9-416e-ae26-24e14fc9fe5c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>4.2 Use nPath as a data preparation function and input to additional analytics techniques</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca45f6b9-aa46-45cd-8b9c-a24160433492",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In this step we are using nPath function to create input tables to be used by statistical and machine learning based approaches. We have used these tables in analysis below for example in TERM FREQUENCY - INVERSE DOCUMENT FREQUENCY (TF-IDF) analysis where we score these converting and non-converting journeys.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5057c86-ffb6-413b-b354-0e31ec585e2a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#E37C4D'><b> Create a table with all converting journeys</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>We are creating a table with all kinds of paths that lead to Conversion.  To achieve this we look at any sequence of events ending with a conversion.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43924304-f877-4828-a122-c4f66f89bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the table if it already exists\n",
    "qry = 'DROP TABLE CONV_JOURNEYS;'\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except Exception as e:\n",
    "    if str(e.args).find('3807') >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "\n",
    "# Create the table\n",
    "qry = '''\n",
    "CREATE MULTISET TABLE CONV_JOURNEYS as(\n",
    "SELECT * FROM nPath (\n",
    "  ON (select cookie, tmstp, interaction, conversion, conversion_value, cost, \n",
    "  TRANSLATE(channel USING UNICODE_TO_LATIN) as channel from \n",
    "  DEMO_MultiTouchAttribution.Attribution_Data) PARTITION BY cookie ORDER BY tmstp\n",
    "  USING\n",
    "  Mode (NONOVERLAPPING)\n",
    "  Pattern ('E*.C')\n",
    "  Symbols (conversion='1' as C\n",
    "          ,conversion='0' as E)\n",
    "  Result (ACCUMULATE (channel OF ANY(C,E)) AS path\n",
    "          ,COUNT (* of ANY(C,E)) as event_cnt\n",
    "          ,FIRST (cookie OF ANY(C,E)) AS cookie\n",
    "  )\n",
    ") AS dt\n",
    "where event_cnt > 1\n",
    ")WITH DATA PRIMARY INDEX(cookie);\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0444c48e-3e5d-436f-a62d-9e4488169c1a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#E37C4D'><b>Create a table with all non-converting journeys (leaving out potential converting journeys)</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We are creating a table with all kinds of paths that do not lead to any Conversion. To achieve this we look for all paths where cookies are not part of any converting journey (just previously defined) and leaving out any potential converting journey.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93597fe5-8426-44e6-b533-d7626b137bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the table if it already exists\n",
    "qry = 'DROP TABLE NONCONV_JOURNEYS;'\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except Exception as e:\n",
    "    if str(e.args).find('3807') >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "\n",
    "# Create the table\n",
    "qry = '''\n",
    "CREATE MULTISET TABLE NONCONV_JOURNEYS AS (\n",
    "    SELECT path, event_cnt, cookie FROM NPATH\n",
    "    (ON (select cookie, tmstp, interaction, conversion, conversion_value, cost, \n",
    "  TRANSLATE(channel USING UNICODE_TO_LATIN) as channel from DEMO_MultiTouchAttribution.Attribution_Data \n",
    "  where tmstp < (select max(tmstp) from DEMO_MultiTouchAttribution.Attribution_Data where conversion ='1'))\n",
    "  PARTITION BY cookie ORDER BY tmstp\n",
    "    USING\n",
    "        MODE (NONOVERLAPPING)\n",
    "        SYMBOLS (TRUE as A)\n",
    "        PATTERN ('A*')\n",
    "        RESULT (ACCUMULATE (channel of ANY(A)) as path,\n",
    "                ACCUMULATE (conversion of ANY(A)) as conv\n",
    "                ,COUNT (* of ANY(A)) as event_cnt\n",
    "                ,FIRST (cookie OF ANY(A)) AS cookie\n",
    "                )\n",
    "    )\n",
    "WHERE cookie IS NOT IN (SEL distinct cookie FROM CONV_JOURNEYS)\n",
    "AND conv Not like '%1%'\n",
    "AND event_cnt >1\n",
    ")WITH DATA PRIMARY INDEX(cookie);\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de96765-c606-44de-8fbd-de50ab75768d",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a id=\"rule\"></a>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>5. RULE BASED MODELS</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2230b49b-f0b2-40c7-8ffd-f88d9fe50c4a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Rule Based attribution models assign conversion credits (weights) to touchpoints in a conversion path according to certain predefined rules.\n",
    "</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>These rules are used to identify the position of an interaction on the conversion path and then assign conversion credit solely on the basis of its position.\n",
    "</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>To execute rule based models we can leverage Vantage native Attribution function and easily consider the following methods:\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Uniform: Conversion event is attributed uniformly to preceding attributable events.</li>\n",
    "    <li>First Click: Conversion event is attributed entirely to first attributable event.</li>\n",
    "    <li>Last Click: Conversion event is attributed entirely to most recent attributable event</li> \n",
    "    <li>Exponential:  Conversion event is attributed exponentially to preceding attributable events (the more recent the event, the higher the attribution).</li>\n",
    " </ul>\n",
    "</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The function takes data and parameters from multiple tables and outputs attributions. Please refer to Teradata Vantage™ - Analytics Database Analytic Functions documentation for more on Attribution function.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Attribution Input :\n",
    "<ol style = 'font-size:14px;font-family:Arial'>\n",
    "<li style = 'font-size:14px;font-family:Arial'>Input tables (maximum of five) (Contain data for computing attributions).</li>\n",
    "<li style = 'font-size:14px;font-family:Arial'>ConversionEventTable (Contains conversion events).</li>\n",
    "<li style = 'font-size:14px;font-family:Arial'>FirstModelTable (Defines type and distributions of model - we'll create one table per model)</li></ol>\n",
    "</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Attribution Syntax Elements:\n",
    "<ol style = 'font-size:14px;font-family:Arial'>\n",
    "<li style = 'font-size:14px;font-family:Arial;'>EventColumn specifies the name of the input column that contains the events.</li>\n",
    "<li style = 'font-size:14px;font-family:Arial;'>TimeColumn specifies the name of the input column that contains the timestamps of the  events.</li>\n",
    "<li style = 'font-size:14px;font-family:Arial;'>WindowSize specifies how to determine the maximum window size for the attribution calculation</li></ol>\n",
    "    </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3ccf89-fe9a-45f0-aea6-805438da4674",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>5.1. Create Conversion Event Table.</b></p> \n",
    "<p style = 'font-size:16px;font-family:Arial'> Since we are focusing on the events that led to Conversion our ATTRIBUTION CONVERSION Table will have only one value <b>'conversion'</b>.</p>     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da3aa4c-a45e-4da5-8e1a-1e22da9f40ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the table if it already exists\n",
    "qry = 'DROP TABLE ATTRIBUTION_CONVERSION;'\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except Exception as e:\n",
    "    if str(e.args).find('3807') >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Create the table\n",
    "qry = '''\n",
    "CREATE TABLE ATTRIBUTION_CONVERSION\n",
    "(\n",
    "    CONVERSION VARCHAR(100)\n",
    ");\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)\n",
    "\n",
    "#Insert model specification values (line1)\n",
    "qry = '''\n",
    "INSERT INTO ATTRIBUTION_CONVERSION VALUES ('conversion');;\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40403c92-8653-41d6-ba20-bc53f83d9fbf",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>5.2 Create model specifications tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We will need to create 1 model table for each type of Attribution: First Click , Last Click, Uniform and Exponential Attribution hence we are creating 4 different model tables below and creating data for each of these model types.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81fba0d-7c17-4e27-9b18-5d8044776eab",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#E37C4D'><b>Uniform Model (applies equal weighting to all contributing touchpoints in the customer journey)</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5660803a-17de-4edb-862d-8050c8e3c652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the table if it already exists\n",
    "qry = 'DROP TABLE ATTRIBUTION_MODEL_UNIFORM;'\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except Exception as e:\n",
    "    if str(e.args).find('3807') >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Create the table\n",
    "qry = '''\n",
    "CREATE TABLE ATTRIBUTION_MODEL_UNIFORM\n",
    "(\n",
    "    ID   INT,\n",
    "    MODEL VARCHAR(100)\n",
    ");\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)\n",
    "\n",
    "#Insert model specification values (line1)\n",
    "qry = '''\n",
    "INSERT INTO ATTRIBUTION_MODEL_UNIFORM VALUES (0,'EVENT_REGULAR');\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)\n",
    "\n",
    "#Insert model specification values (line2)\n",
    "qry = '''\n",
    "INSERT INTO ATTRIBUTION_MODEL_UNIFORM VALUES (1,'ALL:1.0:UNIFORM:NA');\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d2b3ab-bf8c-418d-abc4-b50ccf544865",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#E37C4D'><b> First Click Model (100% of the credit is directly attributed to the first interaction in the customer journey)</b></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbffd38-c7cd-410a-b66a-9d4b8984b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the table if it already exists\n",
    "qry = 'DROP TABLE ATTRIBUTION_MODEL_FIRSTCLICK;'\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except Exception as e:\n",
    "    if str(e.args).find('3807') >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Create the table\n",
    "qry = '''\n",
    "CREATE TABLE ATTRIBUTION_MODEL_FIRSTCLICK\n",
    "(\n",
    "    ID   INT,\n",
    "    MODEL VARCHAR(100)\n",
    ");\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)\n",
    "\n",
    "#Insert model specification values (line1)\n",
    "qry = '''\n",
    "INSERT INTO ATTRIBUTION_MODEL_FIRSTCLICK VALUES (0,'EVENT_REGULAR');\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)\n",
    "\n",
    "#Insert model specification values (line2)\n",
    "qry = '''\n",
    "INSERT INTO ATTRIBUTION_MODEL_FIRSTCLICK VALUES (1,'ALL:1.0:FIRST_CLICK:NA');\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfa120a-67a2-401f-b081-d08a1a901195",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#E37C4D'><b> Last Click Model (100% of the credit is directly attributed to the last interaction in the customer journey)</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2545da9f-cfc1-4c9f-8739-a44c06f9e0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the table if it already exists\n",
    "qry = 'DROP TABLE ATTRIBUTION_MODEL_LASTCLICK;'\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except Exception as e:\n",
    "    if str(e.args).find('3807') >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Create the table\n",
    "qry = '''\n",
    "CREATE TABLE ATTRIBUTION_MODEL_LASTCLICK\n",
    "(\n",
    "    ID   INT,\n",
    "    MODEL VARCHAR(100)\n",
    ");\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)\n",
    "\n",
    "#Insert model specification values (line1)\n",
    "qry = '''\n",
    "INSERT INTO ATTRIBUTION_MODEL_LASTCLICK VALUES (0,'EVENT_REGULAR');\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)\n",
    "\n",
    "#Insert model specification values (line2)\n",
    "qry = '''\n",
    "INSERT INTO ATTRIBUTION_MODEL_LASTCLICK VALUES (1,'ALL:1.0:LAST_CLICK:NA');\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20831381-807c-499f-a2ff-68efbda43c3e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#E37C4D'><b> Exponential Model (assigns exponentially more weight to the interactions which are closest in time to conversion)</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8df882-1864-4716-8869-7d38c7539cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the table if it already exists\n",
    "qry = 'DROP TABLE ATTRIBUTION_MODEL_EXPONENTIAL;'\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except Exception as e:\n",
    "    if str(e.args).find('3807') >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Create the table\n",
    "qry = '''\n",
    "CREATE TABLE ATTRIBUTION_MODEL_EXPONENTIAL\n",
    "(\n",
    "    ID   INT,\n",
    "    MODEL VARCHAR(100)\n",
    ");\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)\n",
    "\n",
    "#Insert model specification values (line1)\n",
    "qry = '''\n",
    "INSERT INTO ATTRIBUTION_MODEL_EXPONENTIAL VALUES (0,'EVENT_REGULAR');\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)\n",
    "\n",
    "#Insert model specification values (line2)\n",
    "qry = '''\n",
    "INSERT INTO ATTRIBUTION_MODEL_EXPONENTIAL VALUES (1,'ALL:1.0:EXPONENTIAL:0.5,ROW');\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbaf6c8-caf0-43ff-92a8-95d6a1f95af1",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>5.3. Compute all four models and store outputs in a table</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>After creating the four model tables we will use them in the calculation of ATTRIBUTION for each channel based on all these models as in the query below.</p> \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In order to consider 20 rows from most to least recent preceding conversion to compute all Rule-based models we use the WindowSize argument of the Attribution function. More specifically we use the \"rows:K\" option which assigns attributions to at most K events before conversion event. In our case K=20.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d7a70-4032-4e0f-b420-0a1cb16311c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the table if it already exists\n",
    "qry = 'DROP TABLE ATTRIBUTION_4MODEL_OUTPUT;'\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except Exception as e:\n",
    "    if str(e.args).find('3807') >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Create the table\n",
    "qry = '''\n",
    "CREATE TABLE ATTRIBUTION_4MODEL_OUTPUT\n",
    "AS (\n",
    "SELECT \n",
    "U.cookie,\n",
    "U.tmstp,\n",
    "U.channel\n",
    " ,F.ATTRIBUTION AS FIRST_CLICK_ATTRIBUTION\n",
    "  ,L.ATTRIBUTION AS LAST_CLICK_ATTRIBUTION\n",
    " ,U.ATTRIBUTION AS UNIFORM_ATTRIBUTION\n",
    " ,E.ATTRIBUTION AS EXPONENTIAL_ATTRIBUTION\n",
    " ,F.TIME_TO_CONVERSION AS FIRST_CLICK_TTC\n",
    "  ,L.TIME_TO_CONVERSION AS LAST_CLICK_TTC\n",
    " ,U.TIME_TO_CONVERSION AS UNIFORM_TTC\n",
    " ,E.TIME_TO_CONVERSION AS EXPONENTIAL_TTC\n",
    "FROM ATTRIBUTION\n",
    "     (\n",
    "         ON (select cookie, tmstp, TRANSLATE(interaction USING UNICODE_TO_LATIN) as interaction, conversion, conversion_value, cost, channel \n",
    "          from DEMO_MultiTouchAttribution.Attribution_Data) AS INPUT\n",
    "         PARTITION BY cookie\n",
    "         ORDER BY tmstp   \n",
    "         ON ATTRIBUTION_CONVERSION      AS CONVERSION    DIMENSION\n",
    "         ON ATTRIBUTION_MODEL_UNIFORM    AS MODEL1        DIMENSION\n",
    "         USING\n",
    "         EVENTCOLUMN ('interaction') \n",
    "         TimeCOLUMN ('TMSTP')\n",
    "         WINDOWSize('ROWS:20') \n",
    "     ) U,\n",
    "ATTRIBUTION\n",
    "     (\n",
    "         ON (select cookie, tmstp, TRANSLATE(interaction USING UNICODE_TO_LATIN) as interaction, conversion, conversion_value, cost, channel \n",
    "          from DEMO_MultiTouchAttribution.Attribution_Data)  AS INPUT\n",
    "         PARTITION BY cookie\n",
    "         ORDER BY tmstp   \n",
    "         ON ATTRIBUTION_CONVERSION      AS CONVERSION    DIMENSION\n",
    "         ON ATTRIBUTION_MODEL_LASTCLICK    AS MODEL1        DIMENSION\n",
    "         USING\n",
    "         EVENTCOLUMN ('interaction') \n",
    "         TimeCOLUMN ('TMSTP')\n",
    "         WINDOWSize('ROWS:20') \n",
    "     ) L,\n",
    " ATTRIBUTION\n",
    "     (\n",
    "         ON (select cookie, tmstp, TRANSLATE(interaction USING UNICODE_TO_LATIN) as interaction, conversion, conversion_value, cost, channel \n",
    "          from DEMO_MultiTouchAttribution.Attribution_Data) AS INPUT\n",
    "         PARTITION BY cookie\n",
    "         ORDER BY tmstp   \n",
    "         ON ATTRIBUTION_CONVERSION      AS CONVERSION    DIMENSION\n",
    "         ON ATTRIBUTION_MODEL_FIRSTCLICK    AS MODEL1        DIMENSION\n",
    "         USING\n",
    "         EVENTCOLUMN ('interaction') \n",
    "         TimeCOLUMN ('TMSTP')\n",
    "         WINDOWSize('ROWS:20') \n",
    "     ) F,\n",
    " ATTRIBUTION\n",
    "     (\n",
    "         ON (select cookie, tmstp, TRANSLATE(interaction USING UNICODE_TO_LATIN) as interaction, conversion, conversion_value, cost, channel \n",
    "          from DEMO_MultiTouchAttribution.Attribution_Data) AS INPUT\n",
    "         PARTITION BY cookie\n",
    "         ORDER BY tmstp   \n",
    "         ON ATTRIBUTION_CONVERSION      AS CONVERSION    DIMENSION\n",
    "         ON ATTRIBUTION_MODEL_EXPONENTIAL    AS MODEL1        DIMENSION\n",
    "         USING\n",
    "         EVENTCOLUMN ('interaction') \n",
    "         TimeCOLUMN ('TMSTP')\n",
    "         WINDOWSize('ROWS:20')  \n",
    "     ) E\n",
    "     WHERE F.cookie = L.cookie\n",
    "AND   F.cookie = U.cookie\n",
    "AND   F.cookie = E.cookie\n",
    "AND   F.TMSTP = L.TMSTP\n",
    "AND   F.TMSTP = U.TMSTP\n",
    "AND   F.TMSTP = E.TMSTP\n",
    "AND   F.channel     = L.channel\n",
    "AND   F.channel     = U.channel\n",
    "AND   F.channel     = E.channel\n",
    ") WITH DATA;\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b048b4-c338-42bb-a0b9-c0a70341cd11",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>5.4. Calculate attribution weights by channel and rule based model</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17bc0d8-473f-4a37-bb1f-981378ecfa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate attribution weights for all four rule based models\n",
    "qry = '''\n",
    "WITH TOTAL\n",
    "AS\n",
    "(SELECT\n",
    "SUM(UNIFORM_ATTRIBUTION) AS TOT_UNI,\n",
    "SUM(FIRST_CLICK_ATTRIBUTION) AS TOT_FC, \n",
    "SUM(LAST_CLICK_ATTRIBUTION)AS TOT_LC, \n",
    "SUM(EXPONENTIAL_ATTRIBUTION) AS TOT_EXP\n",
    "from \n",
    "ATTRIBUTION_4MODEL_OUTPUT)\n",
    "\n",
    "select \n",
    "CHANNEL, \n",
    "SUM(UNIFORM_ATTRIBUTION)/TOT_UNI AS UNIFORM_ATTRIBUTION,\n",
    "SUM(FIRST_CLICK_ATTRIBUTION)/TOT_FC AS FIRST_CLICK_ATTRIBUTION, \n",
    "SUM(LAST_CLICK_ATTRIBUTION)/TOT_LC AS LAST_CLICK_ATTRIBUTION, \n",
    "SUM(EXPONENTIAL_ATTRIBUTION)/TOT_EXP as EXPONENTIAL_ATTRIBUTION\n",
    "from \n",
    "ATTRIBUTION_4MODEL_OUTPUT, TOTAL\n",
    "GROUP BY CHANNEL;\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)\n",
    "\n",
    "AttribRule=DataFrame.from_query(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbe37ef-6d2e-4f71-ab3b-129514643c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results\n",
    "AttribRule_plot=AttribRule.to_pandas()\n",
    "AttribRule_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81af4231-b658-4914-859c-da2c07d6afba",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above output shows the Attribution values for each type of channel using different models.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019c37a4-a262-452c-a25c-46f4fad3e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Bar(name='Uniform', x=AttribRule_plot[\"CHANNEL\"], y=AttribRule_plot[\"UNIFORM_ATTRIBUTION\"], yaxis='y', offsetgroup=1,marker_color='#76B7B2'),\n",
    "        go.Bar(name='First Click', x=AttribRule_plot[\"CHANNEL\"], y=AttribRule_plot[\"FIRST_CLICK_ATTRIBUTION\"], yaxis='y', offsetgroup=2, marker_color='#F28E2B'),\n",
    "        go.Bar(name='Last Click', x=AttribRule_plot[\"CHANNEL\"], y=AttribRule_plot[\"LAST_CLICK_ATTRIBUTION\"], yaxis='y', offsetgroup=3,marker_color='#E15759'),\n",
    "        go.Bar(name='Exponential', x=AttribRule_plot[\"CHANNEL\"], y=AttribRule_plot[\"EXPONENTIAL_ATTRIBUTION\"], yaxis='y', offsetgroup=4,marker_color='#4E79A7')\n",
    "    ],\n",
    "    layout={\n",
    "        'yaxis': {'title': 'Attribution '},\n",
    "\n",
    "    }\n",
    ")\n",
    " \n",
    "# Change the bar mode\n",
    "fig.update_layout(barmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd5a96f-1159-4b36-8c30-b30453c22c7c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>From the above graph we can see that the Attribution Value for Facebook channel is highest in all the 4 models and that for Online Display is the lowest.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699314f5-4317-4f21-84f5-c539fb87132d",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>5.5. Exploring Uniform Model in more details</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72843900-9c0c-4963-84d7-19dab0fad4ff",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Whatever the model the attribution function will output a score (or attribution weight) and compute the time to conversion.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We can easily put this information in perspective with the cost to measure and visualize channel effectiveness.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The uniform model can serve as a starting point or baseline for attribution analysis. It provides a benchmark against which more advanced attribution models can be compared. By evaluating the performance of other models relative to the uniform model, marketers can gain insights into the additional value or improvement offered by more sophisticated approaches like the Statistics based models or Machine learning models. We have used some of these models below in this notebook.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18feee2f-a880-4941-968e-6af16fa35884",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = '''\n",
    " SELECT ATTRIB.channel,  sum(uniform_attribution) AS total_attribution , sum(cost) as total_cost,\n",
    "AVG(-uniform_ttc)/86400 AS time_to_conversion\n",
    "FROM ATTRIBUTION_4MODEL_OUTPUT As ATTRIB\n",
    "INNER JOIN DEMO_MultiTouchAttribution.CHANNEL_COST AS COST\n",
    "ON ATTRIB.CHANNEL=COST.CHANNEL\n",
    "GROUP BY 1\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)\n",
    "\n",
    "AttribUni=DataFrame.from_query(qry)\n",
    "\n",
    "AttribUni_plot=AttribUni.to_pandas()\n",
    "AttribUni.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5ddd2e-adf2-447a-9ac9-2b32cd7bbea5",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The total attribution , cost and time to conversion are used from the output of the Attribution function used above. Here we are considering only the attribution scores from the UNIFORM attribution model(sum(uniform_attribution)).</p> \n",
    "<p style = 'font-size:16px;font-family:Arial'>All three dimensions - cost, attribution and time to conversion - can be plotted on a bubble chart, the size of the bubbles showing the cost. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dd7bd0-3126-4a62-8b0b-62aa03209976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "ax=px.scatter(AttribUni_plot, x=\"total_attribution\", y=\"time_to_conversion\",\n",
    "              size=\"total_cost\",size_max = 70,color=\"CHANNEL\",hover_data=['CHANNEL'],\n",
    "              width=900, height=400, \n",
    "              color_discrete_map = {'Online Display': '#E15759','Online Video': '#76B7B2','Facebook': '#4E79A7','Instagram': '#F28E2B' ,'Paid Search': '#59A14F'},\n",
    "             labels={\n",
    "                     \"total_attribution\": \"Total  Attribution\",\n",
    "                     \"time_to_conversion\": \"Time to Conversion (Days)\"\n",
    "        }\n",
    "             )\n",
    "ax.update_layout(showlegend=False)\n",
    "ax.update_layout(title_text='Channel Performance - Uniform Model', title_x=0.5)\n",
    "ax.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4ebf95-e5a5-4056-91f8-4b24a6fdcfb6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above graph shows the Channel Performance using the UNIFORM Model. The size of the circle depends on the total cost of the channel. When we move the mouse over the circles we can see channel, it's attribution value, time to conversion and also the cost, in the text. The largest circle is for Online Video followed by Facebook, which indicates that the Online Video channel is less performant than Facebook (higher cost, lower attribution).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d47b9-ef24-4540-a31a-e5a2a5045b9e",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a id=\"stat\"></a>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>6. STATISTICAL BASED MODELS</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ebb9b8-6f19-4e33-a20a-684324da58b7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>6.1 SIMPLE FREQUENCY ANALYSIS</b></p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>A simple frequency analysis (obtained by calculating the occurrences of the channel in the journeys leading to Conversion) can be used as a basic approach to compute marketing attribution.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The NGramSplitter function tokenizes (splits) an input stream of text and outputs n multigrams (called n-grams) based on the specified delimiter and reset parameters. NGramSplitter provides more flexibility than standard tokenization when performing text analysis.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>We just need to tokenize paths in converting journeys and calculate the frequency. </p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Here for path tokenization we use NGramSplitter function which splits the input stream of text (here paths) into \"terms\" (grams) of selected size (1:- which means each event) and count them.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374274b5-baaf-4956-892c-337492e13362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop table if exists\n",
    "qry = 'DROP TABLE cngrams;'\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except Exception as e:\n",
    "    if str(e.args).find('3807') >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Create the table.  \n",
    "qry = '''\n",
    "CREATE MULTISET TABLE cngrams AS(\n",
    "    SEL ngram as channel\n",
    "    ,frequency\n",
    "    ,sum(frequency) OVER(PARTITION BY 1) as tot\n",
    "    ,(1.000 * frequency/tot) as tp\n",
    "    FROM(\n",
    "        SEL TRIM(BOTH FROM ngram) as ngram\n",
    "                , sum(frequency) as frequency\n",
    "            FROM NGramSplitter (\n",
    "    ON  (select * from conv_journeys where event_cnt <=20)\n",
    "    USING\n",
    "    TextColumn ('path')\n",
    "    Delimiter (',')\n",
    "    Grams ('1')\n",
    "    Overlapping ('true')\n",
    "    ToLowerCase ('false')\n",
    "    --Punctuation ('\\[.,?\\!\\]')\n",
    "    --Reset ('\\[.,?\\!\\]')\n",
    "    Reset ('[]')\n",
    "    TotalGramCount ('false')\n",
    "  --  Accumulate ('cookie')\n",
    "  ) AS dt\n",
    "    group by 1\n",
    ")as aa\n",
    ") WITH DATA PRIMARY INDEX (channel);\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e278ca30-2492-4c87-ab2c-8c21362ba920",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqattribution = DataFrame(in_schema('demo_user','cngrams'))\n",
    "freq=freqattribution.to_pandas().reset_index()\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c3ae99-2f86-4e53-9f6a-9e5f5b278568",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'> The output of the NGramSplitter contains ngram, the frequency of the channel, the Total frequency(to) and the percentage of the channel frequency to total frequency(tp). </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991d1db6-3449-4fd5-be09-cd9610ddbf6d",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Visualizing the results in a vertical bar chart.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b69976e-f7f2-4d8c-87bb-9ba4210973d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.bar(freq, y=\"tp\", x=\"channel\", \n",
    "             color='channel', orientation='v',\n",
    "             height=600,width=900,\n",
    "             color_discrete_map = {'Online Display': '#E15759','Online Video': '#76B7B2','Facebook': '#4E79A7','Instagram': '#F28E2B' ,'Paid Search': '#59A14F'},\n",
    "             title='Attribution Summary')\n",
    "fig.update_layout(title_text='Frequency Based Attribution Summary', title_x=0.5)\n",
    "fig.update_xaxes(title='Channel',tickangle=-45)\n",
    "fig.update_yaxes(title='Attribution Weight')\n",
    "fig.update_traces(width=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1371852b-f06a-46ba-86ba-a4ffd87085e8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above graph shows the Frequency based Attribution value for each channel using the ngrams. We can see that the Attribution Value for Facebook channel is highest and that for Online Display is lowest.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c552ba-ed1f-42d3-be17-147d65f3e1d3",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>7. ASSOCIATION ANALYSIS (looking for association of channels driving conversion)</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972dc55d-ec67-4019-ba94-664643f3a8bd",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Association analysis can help identify channels that are frequently used in combination within converting journeys.  This information can guide resource allocation and enable marketers to focus on the most effective channel combinations to lift conversion.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2c7af3-8dda-404b-833a-a7a7bfbf3389",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>7.1. Prepare data</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38077989-e8e3-48ba-a75e-2f67d23ebdc0",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Association analysis can help identify channels that are frequently used in combination with other successful channels. This information can guide resource allocation and enable marketers to focus on the most effective channels.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>We use the nPath function to identify all cookies that are leading to a conversion and use this cookies list as a filter to the original dataset.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a334d8ff-a332-4f3a-a1e1-c558c0cb1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop table if exists\n",
    "qry = 'DROP TABLE ATTRIBUTION_DATA4_ASSO_2;'\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except Exception as e:\n",
    "    if str(e.args).find('3807') >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "\n",
    "qry = '''\n",
    "CREATE TABLE ATTRIBUTION_DATA4_ASSO_2 AS\n",
    "(\n",
    "Select * from DEMO_MultiTouchAttribution.Attribution_Data\n",
    "where cookie in (\n",
    "SELECT cookie FROM nPath (\n",
    "  ON DEMO_MultiTouchAttribution.Attribution_Data PARTITION BY cookie ORDER BY tmstp\n",
    "  USING\n",
    "  Mode (NONOVERLAPPING)\n",
    "  Pattern ('E*.C')\n",
    "  Symbols (conversion='1' as C\n",
    "          ,conversion='0' as E)\n",
    "  Result (ACCUMULATE (case when conversion='1' then 'converted ' else channel end OF ANY(C,E)) AS path\n",
    "          ,COUNT (* of ANY(C,E)) as event_cnt\n",
    "          ,FIRST (cookie OF ANY(C,E)) AS cookie\n",
    "  ) \n",
    ") where event_cnt >1  \n",
    ")\n",
    ") with data;\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbf0337-cc64-40dc-944c-6a20e869c86f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>7.2. Compute Association Analysis</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We calculate the association by passing the function name as 'association' to the td_analyze procedure call. The source data will be the output of the nPath function.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b29423-0beb-4f07-aeac-31a70468644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop table if exists\n",
    "qry = 'DROP TABLE CONVERSION_ASSO_GLOBAL_2;'\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except Exception as e:\n",
    "    if str(e.args).find('3807') >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Run Vantage Analytics Library. An output table is created.  \n",
    "qry = '''\n",
    "call \n",
    "val.td_analyze\n",
    "(\n",
    "'association',\n",
    "'database=demo_user;\n",
    "tablename=ATTRIBUTION_DATA4_ASSO_2;\n",
    "groupcolumn=cookie;\n",
    "itemcolumn=channel;\n",
    "outputdatabase=demo_user;\n",
    "outputtablename=CONVERSION_ASSO_GLOBAL;'\n",
    ");\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695d9da8-3151-4bc7-87ff-ba9ef98b7611",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConvAsso = DataFrame(in_schema('demo_user','CONVERSION_ASSO_GLOBAL'))\n",
    "ConvAsso=ConvAsso.to_pandas().reset_index()\n",
    "ConvAsso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909f2619-c870-451d-b21c-60326dcd16e4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The output of the td_analyze procedure call for the function 'association' has the above columns.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Item1of2 and item2of2 are the channel for which the association is calculated. The measures are defined as follows:</p>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial'>\n",
    "Support is percentage of groups containing the items on the left (left side support), on the right (right side support) or on both sides of a rule (rule support).</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Confidence is percentage of groups containing the left side items that also contain the right side items.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Lift is a measure of how much the probability is raised that the right side items occur in a group given that the left side items occur in the group.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Z Score is a statistical measure of how much the expected and actual values of the number of groups containing all the items in the rule varies.  (Zero means expected and actual are the same.)</li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d555c96-aa8b-47bb-8091-e80313d6f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "marker_text = [f\"{size}\" for size in round(ConvAsso['CONFIDENCE'],2)]\n",
    "hover_text = [f\"Lift: {value}\" for value in round(ConvAsso['LIFT'],2)]\n",
    "\n",
    "fig = go.Figure(data=go.Scatter(x=ConvAsso['ITEM1OF2'],\n",
    "                                y=ConvAsso['ITEM2OF2'],\n",
    "                                mode='markers+text',\n",
    "                               text=marker_text,  # Set the marker size text values\n",
    "    hovertext=hover_text,  # Set the hovertext values\n",
    "    hoverinfo='text',  # Only show hovertext on hover\n",
    "                                #text=hover_text, \n",
    "                                marker=dict(\n",
    "        size=ConvAsso['CONFIDENCE'],\n",
    "        sizemode='area',\n",
    "        sizeref=0.0004,\n",
    "        symbol='square',\n",
    "        color=ConvAsso['LIFT'],\n",
    "        colorscale='GnBu'\n",
    "    )))\n",
    "       # text=toto['LIFT'])) # hover text goes here\n",
    "\n",
    "fig.update_layout(title='Channel Associations in Converting Journeys', title_x=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a913703-54ff-4267-aba4-133dccdd0a76",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The strongest channel associations within conversion journeys are <b>Instagram</b> + <b>Facebook</b> and <b>Paid Search</b> + <b>Online Display</b>. \n",
    "<p style = 'font-size:16px;font-family:Arial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36313ec9-84e8-4d20-a956-d7cdb7bde045",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>8. TERM FREQUENCY (Inverse Document Frequency (TF-IDF))</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>TF-IDF is a technique commonly used in natural language processing and text mining tasks to determine the importance of a term within a document or corpus.</p> \n",
    "\n",
    "<p style = 'font-size:14px;font-family:Arial'>      TF-IDF can be defined as the calculation of how relevant a word in a series or corpus is to a text.\n",
    "<p style = 'font-size:14px;font-family:Arial'>The meaning increases proportionally to the number of times in the text a word appears but is compensated by the word frequency in the corpus.\n",
    "<p style = 'font-size:14px;font-family:Arial'>It's commonly used for ranking word relevance and then compare text documents.\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Considering paths (sequence of events) as text we commute and compare the TF-IDF scores between the two sets of event paths (converting and non-converting). We can then examine the top-ranked terms - in our case, channels - with high TF-IDF scores in each set to identify the channels that are most distinctive or important within each set. Therefore we can compare channel contribution across Converted and Non-Converted journeys and put calculated attribution weights in perspective.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37187c09-6a9c-483f-a5a1-496f8727ae43",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>8.1. Prepare Data</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50d05af-c1d9-4730-b9d2-abdd2b3171c9",
   "metadata": {},
   "source": [
    " <p style = 'font-size:16px;font-family:Arial;'>Tokenize paths for both converting and non-converting journeys and save output into a table. We use NGramSplitter function here for path tokenization which splits the input stream of text (here paths) into \"terms\" (grams) of selected size (1:- which means each event) and count them.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34eb95-aa92-474f-9ad8-bfb5728b6c47",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#E37C4D'><b> Converting journeys.</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b88666-9f2d-4dd1-a7e3-d90c1abd607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop table if exists\n",
    "qry = 'DROP TABLE convgrams;'\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except Exception as e:\n",
    "    if str(e.args).find('3807') >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Create table \n",
    "qry = '''\n",
    " CREATE MULTISET TABLE convgrams AS(\n",
    "    SEL*\n",
    "       \n",
    "            FROM NGramSplitter (\n",
    "    ON  (select * from conv_journeys where event_cnt <=20)\n",
    "    USING\n",
    "    TextColumn ('path')\n",
    "    Delimiter (',')\n",
    "    Grams ('1')\n",
    "    Overlapping ('true')\n",
    "    ToLowerCase ('false')\n",
    "    --Punctuation ('\\[.,?\\!\\]')\n",
    "    --Reset ('\\[.,?\\!\\]')\n",
    "    Reset ('[]')\n",
    "    TotalGramCount ('false')\n",
    "  --  Accumulate ('cookie')\n",
    "  ) AS dt\n",
    ") WITH DATA PRIMARY INDEX (ngram)\n",
    ";\n",
    "''' \n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38acff15-ba53-49d2-b9f0-52540ded08a8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#E37C4D'><b> Non-Converting journeys.</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Similar to the converting journeys we also use the NgramSplitter on the non-converting journeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac13bc2-c8bd-4d98-aa4a-9283f50b23f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop table if exists\n",
    "qry = 'DROP TABLE nonconvgrams;'\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except Exception as e:\n",
    "    if str(e.args).find('3807') >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Create table \n",
    "qry = '''\n",
    " CREATE MULTISET TABLE nonconvgrams AS(\n",
    "    SEL*\n",
    "       \n",
    "            FROM NGramSplitter (\n",
    "    ON  (select * from nonconv_journeys)\n",
    "    USING\n",
    "    TextColumn ('path')\n",
    "    Delimiter (',')\n",
    "    Grams ('1')\n",
    "    Overlapping ('true')\n",
    "    ToLowerCase ('false')\n",
    "    --Punctuation ('\\[.,?\\!\\]')\n",
    "    --Reset ('\\[.,?\\!\\]')\n",
    "    Reset ('[]')\n",
    "    TotalGramCount ('false')\n",
    "  --  Accumulate ('cookie')\n",
    "  ) AS dt\n",
    ") WITH DATA PRIMARY INDEX (ngram)\n",
    ";\n",
    "''' \n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d381fd56-5947-4ad4-a03d-ff647bb7c371",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>8.2. Compute TF-IDF scores</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c969f06c-c734-439e-af74-9e5cf99bb334",
   "metadata": {},
   "source": [
    " <p style = 'font-size:16px;font-family:Arial;'>Calculate the TF-IDF scores for each term in the term-document sets (Converting and Non-Converting). TF-IDF is computed by multiplying the term frequency (TF) of a term in a document by its inverse document frequency (IDF) across the collection of documents. The TF component measures the importance of a term within an individual event path, while the IDF component captures the rarity or distinctiveness of a term across the entire set of event paths.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c9b32f-c458-4547-bd86-b05138a56a49",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#E37C4D'><b> Converting journeys.</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7649c55b-1159-46e9-b664-872c9b16fd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop table if exists\n",
    "qry = 'DROP TABLE CONVTFIDF;'\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except Exception as e:\n",
    "    if str(e.args).find('3807') >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Create table \n",
    "qry = '''\n",
    "CREATE TABLE CONVTFIDF\n",
    "AS(\n",
    "WITH \n",
    "TFCONV AS\n",
    "(SELECT t.\"ngram\", t.cookie, \n",
    "        1.00000 * t.frequency / t.event_cnt as tf\n",
    "from convgrams t)\n",
    ",\n",
    "IDFCONV AS\n",
    "(SELECT \"ngram\", log((SELECT count(cookie) FROM convgrams)/(count(*))) as IDF \n",
    "FROM convgrams \n",
    "group by \"ngram\"\n",
    ")\n",
    "SELECT TFCONV.\"ngram\", sum((tf*idf)) AS tfidf\n",
    "FROM TFCONV JOIN IDFCONV  ON TFCONV.\"ngram\"=IDFCONV.\"ngram\"\n",
    "group by 1) WITH DATA;\n",
    "''' \n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2e7582-9c52-4c9a-8d30-1e241795b1f6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#E37C4D'><b> Non-Converting journeys.</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e2c673-a913-43be-9ec2-3ae503f8fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop table if exists\n",
    "qry = 'DROP TABLE NONCONVTFIDF;'\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except Exception as e:\n",
    "    if str(e.args).find('3807') >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "# Create table \n",
    "qry = '''\n",
    "CREATE TABLE NONCONVTFIDF\n",
    "AS(\n",
    "WITH \n",
    "TFNONCONV AS\n",
    "(SELECT \n",
    "        \"ngram\", cookie, \n",
    "        1.00000 * frequency / event_cnt as tf\n",
    "from nonconvgrams)\n",
    ",\n",
    "IDFNONCONV AS\n",
    "(SELECT \"ngram\", log((SELECT count(cookie) FROM nonconvgrams)/(count(*))) as IDF \n",
    "FROM nonconvgrams\n",
    "group by \"ngram\")\n",
    "\n",
    "SELECT TFNONCONV.\"ngram\", sum((tf*idf)) AS tfidf\n",
    "FROM TFNONCONV JOIN IDFNONCONV  ON TFNONCONV.\"ngram\"=IDFNONCONV.\"ngram\"\n",
    "group by 1) WITH DATA;\n",
    "''' \n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd3b7ae-d330-4324-944c-9f4874389f29",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>8.3. Rank and Compare</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a018546f-f4aa-4f78-bd3d-85b39d8f1005",
   "metadata": {},
   "source": [
    " <p style = 'font-size:16px;font-family:Arial;'>The following SQL query will rank and regroup the channel TF-IDF scores for channels in both Converting and Non-Converting journeys.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ca7a61-5859-4f9a-9de9-bcc3ee7ee60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = '''\n",
    "SELECT\n",
    "conv.channel, converted_rank,nonconverted_rank\n",
    "from\n",
    "(\n",
    "select \n",
    "ngram as channel,\n",
    "rank () over ( order by tfidf desc) as converted_rank\n",
    "from CONVTFIDF) CONV\n",
    "INNER JOIN\n",
    "(\n",
    "select \n",
    "ngram as channel,\n",
    "rank () over ( order by tfidf desc) as nonconverted_rank\n",
    "from nonCONVTFIDF) NONCONV\n",
    "on\n",
    "CONV.channel=nonconv.channel\n",
    ";\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6a73c0-4169-43c7-9753-3bad0f731e2c",
   "metadata": {},
   "source": [
    " <p style = 'font-size:16px;font-family:Arial;'>We will create a Slope Chart to compare the channel significance ranking in both Converting and Non-Converting journeys.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f827af-b41d-4de7-bbf7-07a6a66a3cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slope=DataFrame.from_query(qry)\n",
    "slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4057a460-35b9-4c8a-bbe7-5f36ffd743ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=slope.to_pandas()\n",
    "df.sort_values(by='channel', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7908aa-88d1-42fb-8ae5-c984e97b5e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sort DataFrame by channel\n",
    "df.sort_values(by='channel', inplace=True)\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Set x and y values for the slope chart\n",
    "x = [0, 1]\n",
    "channels = df['channel']\n",
    "y_conv = df['converted_rank']\n",
    "y_nconv = df['nonconverted_rank']\n",
    "\n",
    "# Define custom colors for each channel\n",
    "color_mapping = {\n",
    "    'Instagram': '#F28E2B',\n",
    "    'Facebook': '#4E79A7',\n",
    "    'Online Display': '#E15759',\n",
    "    'Online Video': '#76B7B2',\n",
    "    'Paid Search': '#59A14F',\n",
    "    # Add more channels and corresponding colors as needed\n",
    "}\n",
    "\n",
    "# Plot the slope chart with assigned colors\n",
    "for channel, conv, nconv in zip(channels, y_conv, y_nconv):\n",
    "    color = color_mapping.get(channel, 'black')  # Default color if channel not found in the mapping\n",
    "    ax.plot(x, [conv, nconv], marker='o', markersize=10, color=color, label='_nolegend_')\n",
    "    ax.text(-0.1, conv, channel, ha='right', va='center', fontsize=8, color='black')\n",
    "    ax.text(1.05, nconv, channel, ha='left', va='center', fontsize=8, color='black')\n",
    "\n",
    "# Set x-axis ticks and labels\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['CONVERTING', 'NON CONVERTING'])\n",
    "\n",
    "# Set y-axis label\n",
    "ax.set_ylabel('Rank')\n",
    "\n",
    "# Set title\n",
    "ax.set_title('Comparing Channel in Converting and Non Converting Paths',loc='center', pad=30)\n",
    "\n",
    "# Remove spines (borders) of the plot\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "# Hide ticks and tick labels on the left spine\n",
    "ax.yaxis.set_ticks_position('none')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "# Set the limits of the x-axis\n",
    "ax.set_xlim(-0.4, 1.2)\n",
    "\n",
    "# Format y-axis tick labels to remove decimal values with .5 and invert the scale\n",
    "ax.yaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71621010-0091-401a-bd46-be0cb46b3d51",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'><b>Online Video</b> and <b>Facebook</b> are slightly more significantly appearing in Converting journeys and <b>Paid Search</b> is clearly more distinctive to Non-Converting journeys.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d930a6bd-18cc-42a5-b1d0-acbcac34b6bc",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a id=\"ml\"></a>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>9. MACHINE LEARNING BASED MODELS</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748c3279-480b-4d15-b123-6be52c5537e4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Machine Learning based models allow us to switch from rule-based/heuristic methods to probabilistic ones, moving further up the maturity scale. With a data-driven algorithmic  approach, attribution outputs are predicated based on data and the modelling of that data.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5956ffcc-271f-4d4b-b047-c5bca07dd3de",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>NAIVE BAYES</b></p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Naive Bayes is a machine learning algorithm commonly used for classification tasks, including text classification, spam filtering, and sentiment analysis. While it is not typically used to directly compute marketing attribution, it can be employed as part of a broader marketing attribution framework.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>We will use Naive Bayes for binary text classification of paths in two categories, converted and non converted. Once the Naive Bayes classifier is trained, it can be used to estimate the probability that a specific marketing touchpoint contributed to an outcome.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>By evaluating the likelihood of the observed features associated with conversion, the algorithm can provide a probability score representing the attribution weight.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>To run a Naive Bayes classification model we can leverage Vantage native Naive Bayes text classifier trainer function beside some in-database data preparation.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb3b9f8-559a-42c9-8d76-e2e582fe10eb",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#E37C4D'><b>Prepare Data</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a158dd98-12a9-4fa3-8fa3-c42f04968b71",
   "metadata": {},
   "source": [
    " <p style = 'font-size:16px;font-family:Arial;'>Tokenize paths for both converting and non-converting journeys and save output into a table. We use NGramSplitter function here for path tokenization which splits the input stream of text (here paths) into \"terms\" (grams) of selected size (1:- which means each event) and count them.</p>\n",
    " <p style = 'font-size:16px;font-family:Arial;'>This data preparation step will serve both Naive Bayes and Random Forest models.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687ada25-9a07-46c4-8d54-010b19544de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop table if exists\n",
    "qry = 'DROP TABLE ALLNGRAMS;'\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except Exception as e:\n",
    "    if str(e.args).find('3807') >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "#   \n",
    "qry = '''\n",
    "CREATE MULTISET TABLE ALLNGRAMS AS(\n",
    " SEL \n",
    " cookie,TRIM(BOTH FROM ngram) as ngram, '1' as distcnt, frequency as totcnt, '1' as conv \n",
    "            FROM NGramSplitter (\n",
    "    ON  conv_journeys\n",
    "    USING\n",
    "    TextColumn ('path')\n",
    "    Delimiter (',')\n",
    "    Grams ('1')\n",
    "    Overlapping ('f')\n",
    "    ToLowerCase ('false')\n",
    "    --Punctuation ('\\[.,?\\!\\]')\n",
    "    --Reset ('\\[.,?\\!\\]')\n",
    "    Reset ('[]')\n",
    "    TotalGramCount ('false')\n",
    "   Accumulate ('cookie')\n",
    "  ) AS dt\n",
    " \n",
    "  UNION ALL \n",
    "  \n",
    "SEL \n",
    " cookie,TRIM(BOTH FROM ngram) as ngram, '1' as distcnt, frequency as totcnt, '0' as conv \n",
    "            FROM NGramSplitter (\n",
    "    ON  nonconv_journeys\n",
    "    USING\n",
    "    TextColumn ('path')\n",
    "    Delimiter (',')\n",
    "    Grams ('1')\n",
    "    Overlapping ('true')\n",
    "    ToLowerCase ('false')\n",
    "    --Punctuation ('\\[.,?\\!\\]')\n",
    "    --Reset ('\\[.,?\\!\\]')\n",
    "    Reset ('[]')\n",
    "    TotalGramCount ('false')\n",
    "   Accumulate ('cookie')\n",
    "  ) AS dt\n",
    "  ) with data;\n",
    "  '''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f7d5c8-10a8-4347-a410-4d230d7aedcf",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#E37C4D'><b>Run Naive Bayes Text Classifier model</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>TD_NaiveBayesTextClassifierTrainer function calculates the conditional probabilities for token-category pairs, the prior probabilities, and the missing token probabilities for all categories. The trainer function trains the model with the probability values (and the predict function - not used here - would use the values to classify paths into categories).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0af8ff-5974-49b5-b161-281076309f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop table if exists\n",
    "qry = 'DROP TABLE NBOUTPUT;'\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except Exception as e:\n",
    "    if str(e.args).find('3807') >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Run Naive Bayes Text Classifier and output the result in a table  \n",
    "qry = '''\n",
    "CREATE TABLE NBOUTPUT AS\n",
    "(\n",
    "  SELECT * FROM TD_NaiveBayesTextClassifierTrainer (\n",
    "   ON allngrams AS InputTable\n",
    "   USING\n",
    "   TokenColumn ('ngram')\n",
    "   DocCategoryColumn ('conv')\n",
    "   DocIDColumn ('cookie')\n",
    "   ModelType ('Bernoulli')\n",
    ") AS dt)\n",
    "WITH DATA;\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943c801d-5722-43dd-84f2-16ad05544f04",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#E37C4D'><b>Derive Attribution Weights and visualize</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The output of the Naive Bayes Text Classifier contains: \n",
    "    <li style = 'font-size:16px;font-family:Arial'>token: The classified training tokens (channels from tokenized paths).</li>\n",
    "    <li style = 'font-size:16px;font-family:Arial'>category: The category of the token (converted, non-converted).</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>prob: The probability of the token in the category.</li>\n",
    "</p>    \n",
    "<p style = 'font-size:16px;font-family:Arial'>This output probability is used to calculate the attribution of the channels.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9692a90-9489-4caa-9093-9c673686ccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = '''\n",
    "  WITH TOTAL as\n",
    "  (Select sum(prob) as total_attribution from\n",
    "    NBOUTPUT\n",
    "    where category='1'\n",
    "    and token in ('Online Display', 'Online Video', 'Facebook','Instagram','Paid Search'))\n",
    "    \n",
    "  Select token as channel, prob/total_attribution as nb_attribution from\n",
    "    NBOUTPUT, TOTAL\n",
    "    where category='1'\n",
    "    and token in ('Online Display', 'Online Video', 'Facebook','Instagram','Paid Search');\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404a14b9-b932-4f94-b6d7-2a0404a6f4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbattribution=DataFrame.from_query(qry)\n",
    "nbattribution=nbattribution.to_pandas()\n",
    "nbattribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810e350e-3463-485b-a963-daca21a9d720",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Visualizing the results in a vertical bar chart.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55afa626-f833-45e9-b623-863fc02f9238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.bar(nbattribution, y=\"nb_attribution\", x=\"channel\", \n",
    "             color='channel', orientation='v',\n",
    "             height=600,width=900,\n",
    "             color_discrete_map = {'Online Display': '#E15759','Online Video': '#76B7B2','Facebook': '#4E79A7','Instagram': '#F28E2B' ,'Paid Search': '#59A14F'},\n",
    "             title='Attribution Summary')\n",
    "fig.update_layout(title_text='Naive Bayes Model Attribution Summary', title_x=0.5)\n",
    "fig.update_xaxes(title='Channel',tickangle=-45)\n",
    "fig.update_yaxes(title='Attribution Weight')\n",
    "fig.update_traces(width=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733f8a55-94e6-4bce-98c1-348958d36d13",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above graph shows the Attribution value using the Naive Bayes Model. The Attribution Value for Facebook channel is highest and that for Online Display is the lowest.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589505e2-2363-400e-b82a-84c6a500e756",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>10. MULTITOUCH ATTRIBUTION MODELS SUMMARY</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b251c6-720c-4031-a3ec-958ffb6a5d57",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>To compare the attribution results of all models into a single comparative chart, we will group them together using the below query and create a visualization chart.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e524ac-131b-4cb2-8f71-fc171b3a0bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry= '''\n",
    "SELECT\n",
    "ATTRIB.CHANNEL,\n",
    "ATTRIB.Uniform,\n",
    "ATTRIB.FirstClick,\n",
    "ATTRIB.LastClick,\n",
    "ATTRIB.Exponential,\n",
    "NB.NaiveBayes,\n",
    "--ASSO.Association,\n",
    "FREQ.Frequency\n",
    "FROM\n",
    "(\n",
    "WITH TOTAL\n",
    "AS\n",
    "(SELECT\n",
    "SUM(UNIFORM_ATTRIBUTION) AS TOT_UNI,\n",
    "SUM(FIRST_CLICK_ATTRIBUTION) AS TOT_FC, \n",
    "SUM(LAST_CLICK_ATTRIBUTION)AS TOT_LC, \n",
    "SUM(EXPONENTIAL_ATTRIBUTION) AS TOT_EXP\n",
    "from \n",
    "ATTRIBUTION_4MODEL_OUTPUT)\n",
    "select \n",
    "CHANNEL, \n",
    "SUM(UNIFORM_ATTRIBUTION)/TOT_UNI AS Uniform,\n",
    "SUM(FIRST_CLICK_ATTRIBUTION)/TOT_FC AS FirstClick, \n",
    "SUM(LAST_CLICK_ATTRIBUTION)/TOT_LC AS LastClick, \n",
    "SUM(EXPONENTIAL_ATTRIBUTION)/TOT_EXP as Exponential\n",
    "from \n",
    "ATTRIBUTION_4MODEL_OUTPUT, TOTAL\n",
    "GROUP BY CHANNEL)\n",
    "as ATTRIB\n",
    ",\n",
    "\n",
    "(    \n",
    "      WITH TOTAL as\n",
    "  (Select sum(prob) as total_attribution from\n",
    "    NBOUTPUT\n",
    "    where category='1'\n",
    "    and token in ('Online Display', 'Online Video', 'Facebook','Instagram','Paid Search'))\n",
    "    \n",
    "  Select token as channel, prob/total_attribution as NaiveBayes from\n",
    "    NBOUTPUT, TOTAL\n",
    "    where category='1'\n",
    "    and token in ('Online Display', 'Online Video', 'Facebook','Instagram','Paid Search')\n",
    ")AS NB\n",
    ",\n",
    "(\n",
    "select channel, tp as frequency from cngrams\n",
    " ) AS FREQ   \n",
    " WHERE\n",
    "ATTRIB.channel =NB.channel and\n",
    "--ATTRIB.channel =ASSO.channel and\n",
    "ATTRIB.channel =FREQ.channel\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "eng.execute(qry)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd66a0a-39cf-4c12-9e4b-fe3087dec2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=DataFrame.from_query(qry)\n",
    "summary_plot=summary.to_pandas()\n",
    "summary_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d2ca77-78ec-4322-9b76-ceba1eadd45a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Bar(name='Uniform', x=summary_plot[\"CHANNEL\"], y=summary_plot[\"Uniform\"], yaxis='y', offsetgroup=1,marker_color='#76B7B2'),\n",
    "        go.Bar(name='First Click', x=summary_plot[\"CHANNEL\"], y=summary_plot[\"FirstClick\"], yaxis='y', offsetgroup=2, marker_color='#F28E2B'),\n",
    "        go.Bar(name='Last Click', x=summary_plot[\"CHANNEL\"], y=summary_plot[\"LastClick\"], yaxis='y', offsetgroup=3,marker_color='#E15759'),\n",
    "        go.Bar(name='Exponential', x=summary_plot[\"CHANNEL\"], y=summary_plot[\"Exponential\"], yaxis='y', offsetgroup=4,marker_color='#4E79A7'),\n",
    "        go.Bar(name='Naive Bayes', x=summary_plot[\"CHANNEL\"], y=summary_plot[\"NaiveBayes\"], yaxis='y', offsetgroup=7,marker_color='#EDC948'),\n",
    "        go.Bar(name='Frequency', x=summary_plot[\"CHANNEL\"], y=summary_plot[\"frequency\"], yaxis='y', offsetgroup=9,marker_color='#B07AA1')\n",
    "    ],\n",
    "    layout={\n",
    "        'yaxis': {'title': 'Attribution '},\n",
    "\n",
    "    }\n",
    ")\n",
    " \n",
    "# Change the bar mode\n",
    "fig.update_layout(barmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda4779c-4b2a-4d28-8ed5-39db4980c793",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Statistical based(Simple Frequency, Association and Term Frequency) and Algorithmic based(like Naive Bayes) models tend to produce slightly different attribution scores compared to rule based.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The bar chart above shows how many conversions were attributed to each channel for each model. Analyzing the graph, specifically the statistical/ML based in comparison to the other methods, you can gain insights as to the relative importance of different marketing channels. For the first touch, last touch and linear touch models, Facebook and Paid Search are the most import channels driving conversions while Instagram and Online Display are the least important. However, according to the Statistical/ML based models, Instagram is far more important to our conversions than our simple attribution models suggest - indeed according to the probabilistic model it is infact our third most important channel. Also, according to Associations and Naive Bayes models, Online Video appears less important compared to what other models say.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831e0559-d8fa-40f4-98cb-cc82b33d7380",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>12. Cleanup</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Work Tables</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e36efdb-a867-414d-913d-a6f89af96d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['CONV_JOURNEYS', 'NONCONV_JOURNEYS','cngrams','convgrams','nonconvgrams','ALLNGRAMS','ATTRIBUTION_CONVERSION',\n",
    "          'ATTRIBUTION_MODEL_UNIFORM','ATTRIBUTION_MODEL_FIRSTCLICK','ATTRIBUTION_MODEL_LASTCLICK','ATTRIBUTION_MODEL_EXPONENTIAL',\n",
    "            'ATTRIBUTION_4MODEL_OUTPUT','ATTRIBUTION_DATA4_ASSO_2','CONVTFIDF','NONCONVTFIDF','NBOUTPUT']\n",
    "\n",
    "# Loop through the list of tables and execute the drop table command for each table\n",
    "for table in tables:\n",
    "    db_drop_table(table_name=table, schema_name='demo_user')\n",
    "    # Construct the drop table SQL statement\n",
    "    # drop_table_sql = f\"DROP TABLE {table};\"\n",
    "    # Execute the drop table command\n",
    "    # eng.execute(drop_table_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60443c3-5225-44d7-ad89-8ed8c54102b2",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Databases and Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbfa951-2844-4f79-b7c6-08c6e3c3d5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_MultiTouchAttribution');\" \n",
    "#Takes 40 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e081f5ae-3b5c-40b3-a6af-42e0588f0103",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8527dd62-7c24-4382-8cfd-cd187c90091d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<footer style=\"padding:10px;background:#f9f9f9;border-bottom:3px solid #394851\">Copyright © Teradata Corporation - 2023. All Rights Reserved.</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
