{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<header style=\"padding:1px;background:#f9f9f9;border-top:3px solid #00b2b1\"><img id=\"Teradata-logo\" src=\"https://www.teradata.com/Teradata/Images/Rebrand/Teradata_logo-two_color.png\" alt=\"Teradata\" width=\"220\" align=\"right\" />\n",
    "\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>Text Term Frequency Analysis - Python</b>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Introduction</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "This demo will analyse the text in rows of the table to find the TF-IDF or Term Frequency-Inverse Document Frequency is an indicator of a term's importance in a specific document based on the entire corpus of documents.    \n",
    "This is a demonstration of Vantage capabilities for functional demos e.g.\n",
    "    <li style = 'font-size:16px;font-family:Arial'> NGramSplitter Function - tokenizes (splits) an input stream of text and outputs n multigrams (called n-grams) based on the specified Reset, Punctuation, and Delimiter syntax elements.</li>\n",
    "</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'> This notebook demonstrate how the function is used in Python kernel, there is a similar notebook which shows the same features in sql kernel. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Steps</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "    <li style = 'font-size:16px;font-family:Arial'> Connect to Vantage and read the dataset. </li>\n",
    "    <li style = 'font-size:16px;font-family:Arial'> Use NGramSplitter SQL to create a table of grams of n-size. </li>\n",
    "    <li style = 'font-size:16px;font-family:Arial'> Express SQL to calculate TF-IDF and store the output in a table. </li>\n",
    "    <li style = 'font-size:16px;font-family:Arial'> Retrieve the data as a local dataframe. </li>\n",
    "    <li style = 'font-size:16px;font-family:Arial'> Basic visualization to show top 30 important terms. </li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'> <b> Accessing the Data </b> </p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>These demos will work either with foreign tables accessed from Cloud Storage via NOS or you may import the tables to your machine. If you import data for multiple demos, you may need to use the Data Dictionary \"Manage Your Space\" routine to cleanup tables you no longer need.     \n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial'>Use the link below to access the 2 options for using data from the data dictionary notebook:\n",
    "\n",
    "[Click Here to get data for this notebook](../Data_Dictionary/Data_Dictionary.ipynb#TRNG_RETAILDSE)\n",
    "\n",
    "[Click Here to Manage Your Space](../Data_Dictionary/Data_Dictionary.ipynb#Manage_Your_Space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:28px;font-family:Arial;color:#E37C4D'><b>1. Import python packages, connect to Vantage and explore the dataset</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import getpass\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from teradataml.dataframe.dataframe import DataFrame\n",
    "from teradataml.analytics.sqle import NGramSplitter\n",
    "from teradataml.dataframe.dataframe import in_schema\n",
    "from teradataml.context.context import create_context, remove_context, get_context\n",
    "from teradataml.dataframe.copy_to import copy_to_sql\n",
    "from teradataml.dataframe.fastload import fastload\n",
    "from teradataml.options.display import display\n",
    "\n",
    "from teradatasqlalchemy.types import *\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'> <b> Connect to Vantage </b> </p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Below command will make a connection to the Vantage environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Vantage\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = getpass.getpass())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'> <b> Access data in Vantage  </b> </p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>For this demo, data is already resident in Object Storage which we are accessing via ReadNOS.  Create a reference to the table, and sample the contents.  Data could just as easily reside in permanent tables, another RDBMS, or another Vantage system.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_reviews = DataFrame('\"TRNG_RETAILDSE\".\"WEB_COMMENT\"')\n",
    "tdf_reviews.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:28px;font-family:Arial;color:#E37C4D'><b>2. Use the NGram Splitter SQL Function</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>NGram function will split the corpus of documents into \"terms\" (grams) of selected size.  Specifically, this example will create a table called \"tbl_grams\" that is the result of splitting each \"document\" (review) into two-word chunks (grams).  Each row in this table includes;\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>The two-word chunk (ngram).</li>\n",
    "    <li>The source review id (row_id).</li>\n",
    "     <li>Chunk length (n).</li>\n",
    "     <li>The count of this chunk in the review (frequency).</li>\n",
    "     <li>The count of this chunk in all the reviews (totalcnt)</li>\n",
    "</ol>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "The splitting algorithm can be controlled with delimeters, punctuation indicators, etc.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qry = 'DROP TABLE tbl_grams;'\n",
    "\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except Exception as e:\n",
    "    if str(e.args).find('3807') >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "#how many grams should we split the docs into?\n",
    "grams = 2\n",
    "\n",
    "#Create ngram table\n",
    "qry = f'''\n",
    "CREATE TABLE tbl_grams AS (\n",
    "    SELECT * FROM NGramSplitter ( \n",
    "        ON ( SELECT * FROM \"TRNG_RETAILDSE\".\"WEB_COMMENT\" )   \n",
    "        USING \n",
    "            TextColumn('comment_text') \n",
    "            Accumulate('comment_id') \n",
    "            Grams('{grams}') \n",
    "            OverLapping('TRUE') \n",
    "            ConvertToLowerCase('TRUE') \n",
    "            Delimiter(' ') \n",
    "            Punctuation('[`~#^&*()-]') \n",
    "            OutputTotalGramCount('TRUE') \n",
    "            NGramColName('ngram') \n",
    "            GramLengthColName('n') \n",
    "            FrequencyColName('frequency') \n",
    "            TotalCountColName('totalcnt') \n",
    "    ) as ngram_out\n",
    "    )\n",
    "WITH DATA\n",
    "PRIMARY INDEX (comment_id);\n",
    "'''\n",
    "\n",
    "eng.execute(qry)\n",
    "\n",
    "tdf_grams = DataFrame('tbl_grams')\n",
    "\n",
    "tdf_grams.to_pandas(num_rows = 5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In the table created above we can see the NGram function applied to the web comment column. We can see the frequency and the total number of times the ngram appear in the column.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:28px;font-family:Arial;color:#E37C4D'><b>3. Create the TF-IDF Table</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>TF-IDF</b> or <b>Term Frequency-Inverse Document Frequency</b> is an indicator of a term's <b>importance</b> in a specific document based on the entire corpus of documents.  This value is calculated by taking the Product of:\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Term Frequency = (Number of Terms in the Document)/(Number of Terms in the Corpus)</li>\n",
    "    <li>Inverse Document Frequency = Natural Log((Total Number of Documents)/(Number of Documents with the Term))</li>\n",
    " </ul>   \n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "This can be accomplished in SQL using the results table created using NGgram Splitter function in above step:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = 'DROP TABLE tbl_tf_idf;'\n",
    "\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except Exception as e:\n",
    "    if str(e.args).find('3807') >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "        \n",
    "qry = '''\n",
    "CREATE TABLE tbl_tf_idf AS (\n",
    "SELECT gr.comment_id as comment_id,\n",
    "gr.\"ngram\" as term,\n",
    "CAST (CAST(gr.frequency AS FLOAT) / CAST(gr.totalcnt AS FLOAT) AS DECIMAL(10,6)) as tf,\n",
    "CAST(LN(sel_docs.tot_docs / sel_docs.tot_term) AS DECIMAL(10,6)) as idf,\n",
    "CAST(idf * tf AS DECIMAL(10,6)) as tf_idf\n",
    "FROM tbl_grams as gr\n",
    "--get the number of docs where each term exists\n",
    "LEFT JOIN (select \"ngram\", tot_term , tot_docs from\n",
    "((SELECT \"ngram\",COUNT(*) as tot_term\n",
    "FROM tbl_grams\n",
    "GROUP BY \"ngram\") terms\n",
    "--get the total doc count and join it to the table\n",
    "CROSS JOIN (SELECT COUNT(DISTINCT comment_id) as tot_docs\n",
    "FROM tbl_grams ) as sum_docs\n",
    ")\n",
    ") sel_docs\n",
    "ON gr.\"ngram\" = sel_docs.\"ngram\"\n",
    "WHERE tf_idf > .5\n",
    "    )\n",
    "WITH DATA\n",
    "PRIMARY INDEX (comment_id);\n",
    "'''\n",
    "\n",
    "eng.execute(qry)\n",
    "\n",
    "tdf_tf_idf = DataFrame('tbl_tf_idf')\n",
    "tdf_tf_idf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf_idf = tdf_tf_idf.to_pandas(all_rows = True)\n",
    "df_tf_idf['tf_idf'] = df_tf_idf['tf_idf'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf_idf.sort_values(by = 'tf_idf', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:28px;font-family:Arial;color:#E37C4D'><b>4. Visualize the Results</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Let's use Pandas and Matplotlib to do visualizations of the data:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_tf_idf.sort_values(by = 'tf_idf', ascending = False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot it:\n",
    "df1.sort_values(by = 'term', ascending = False).head(30).set_index('term')[['tf_idf']].plot(kind = 'barh', legend = True, figsize = (12, 9));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "In this plot we are plotting the top 30 terms which are used in the reviews. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:28px;font-family:Arial;color:#E37C4D'><b>5.  Clean up</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.execute('DROP TABLE DEMO_USER.tbl_tf_idf;') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.execute('DROP TABLE DEMO_USER.tbl_grams;') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>Links:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Teradata Python Package User Guide: <a href = 'https://docs.teradata.com/reader/eteIDCTX4O4IMvazRMypxQ/uDjppX7PJInABCckgu~KFg'>https://docs.teradata.com/reader/eteIDCTX4O4IMvazRMypxQ/uDjppX7PJInABCckgu~KFg</a></li>\n",
    "    <li>Teradataml Python Reference: <a href = 'https://docs.teradata.com/reader/GsM0pYRZl5Plqjdf9ixmdA/MzdO1q_t80M47qY5lyImOA'>https://docs.teradata.com/reader/GsM0pYRZl5Plqjdf9ixmdA/MzdO1q_t80M47qY5lyImOA</a></li>\n",
    "    <li>Teradata NGramSplitter Function Reference: <a href = 'https://docs.teradata.com/r/Teradata-VantageTM-Analytics-Database-Analytic-Functions-17.20/Text-Analytic-Functions/NGramSplitter'>https://docs.teradata.com/r/Teradata-VantageTM-Analytics-Database-Analytic-Functions-17.20/Text-Analytic-Functions/NGramSplitter</a></li>\n",
    "  \n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<footer style=\"padding:10px;background:#f9f9f9;border-bottom:3px solid #394851\">Â©2023 Teradata. All Rights Reserved</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
