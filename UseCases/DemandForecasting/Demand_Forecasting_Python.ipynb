{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07c7b2ca-a3a2-4525-aeb3-2276de42e3c2",
   "metadata": {},
   "source": [
    "<header style=\"padding:1px;background:#f9f9f9;border-top:3px solid #00b2b1\"><img id=\"Teradata-logo\" src=\"https://www.teradata.com/Teradata/Images/Rebrand/Teradata_logo-two_color.png\" alt=\"Teradata\" width=\"220\" align=\"right\" />\n",
    "\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>Demand Forecasting with In-Database Time Series </b>\n",
    "</header>\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>Introduction</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Forecasting is a process of making predictions of the future based on past and present data and, most commonly, by analyzing trends.<br>\n",
    " \n",
    "<p style = 'font-size:16px;font-family:Arial'>For businesses, the ability to predict the future and make informed decisions is critical to their survival. The traditional method of generating forecasts from time series data often struggles to generate accurate predictions, especially when dealing with extensive data with irregular trends.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The ability to predict demand accurately is a critical need for retailers. They need to know how many inventory store units to have at hand to be at full stock for each product at a given time. A low inventory level increases the risk of having a stock out, and a too-high inventory level increases the cost related to handling inventory.</p>\n",
    "<br>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Unbounded Array Framework (UAF) is the Teradata framework for building end-to-end time series forecasting pipelines. It also provides functions for digital signal processing and 4D spatial analytics. The series can reside in any Teradata supported or Teradata accessible table or in an analytic result table (ART).</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>UAF provides data scientists with the tools for all phases of forecasting:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Data preparation functions</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Data exploration functions</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Model coefficient estimation functions</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Model validation functions</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Model scoring functions</li>\n",
    "\n",
    "<p></p>    \n",
    "<br>  \n",
    "<p style = 'font-size:16px;font-family:Arial'>Hence as a data science consultant, we are showcasing the complete approach about how we can make prediction for the demand for each store. We are demonstrating how we can train our models and use them for scoring using the ClearScape Analytics platform. The data we are using is a sample dataset and the results and predictions may not be entirely accurate.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034d3da0-34dd-4d23-8401-c2d817268273",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>1. Start by connecting to the Vantage system.</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527135cc-6731-4019-8011-62bd08b18ba1",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In the section, we import the required libraries and set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f6655-e7d8-45ee-8b73-32ea33151f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import teradataml as tdml\n",
    "from teradataml import * \n",
    "\n",
    "import getpass\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tdsense.plot import plotcurves\n",
    "from tdsense.clustering import resample\n",
    "\n",
    "display.max_rows=5\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9c2a75-1ce4-4481-8c62-239cb4154244",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>You will be prompted to provide the password. Enter your password, press the Enter key, then use down arrow to go to next cell. Begin running steps with Shift + Enter keys.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23bc7a6-5b0a-4266-96db-09163ecdfd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)\n",
    "eng.execute('''SET query_band='DEMO=DemandForecasting.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18fd14a-95f7-4a3f-a963-3830cf78f1e7",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#E37C4D'>2. Getting Data for This Demo </b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have provided data for this demo on cloud storage.  You have the option of either running the demo using foreign tables to access the data without using any storage on your environment or downloading the data to local storage which may yield somewhat faster execution, but there could be considerations of available storage.  There are two statements in the following cell, and one is commented out.  You may switch which mode you choose by changing the comment string. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a389d258-6ef6-4b26-8afb-7ee5e7ebecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ../run_procedure.py \"call get_data('DEMO_DemandForecast_cloud');\"\n",
    " # Takes about 45 seconds\n",
    "%run -i ../run_procedure.py \"call get_data('DEMO_DemandForecast_local');\"\n",
    " # Takes about 70 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3c754c-2e1c-40da-8298-b4c89bcebb8f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Next is an optional step – if you want to see status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94903d-62d7-4d32-8d20-52b25c6ac94f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f223fe73-10a0-4d0d-9fdb-cfcc08653c45",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>3. Analyze Raw Data.</b></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d415b0-4606-4d70-888c-d7e2173cb31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(in_schema('DEMO_DemandForecast','Demand_Data'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8714207f-d261-4489-b44e-beb618a3959b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'>The dataset is a retail dataset where we have the timekey , the Product(MODELID), the Store(MARKET) and the column DEMAND which will be used for analysis.</p>\n",
    "<p style = 'font-size:18px;font-family:Arial'>In this demo we will consider data for the 3 Products(ModelIDs) which are mentioned below .</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc84c85-f56f-4b14-b759-8adb61332b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELID_1 = 'MARKET0301261'\n",
    "MODELID_2 = 'MARKET0501264'\n",
    "MODELID_3 = 'MARKET0200798'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa4bb62-f7ab-4476-863f-d8ffa0118db5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'>We will check the Demand for these Products</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d0639b-9a82-4cc5-a8ad-d4c6b447bfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_1 = df.loc[df.MODELID == MODELID_1,['timeKey','DEMAND']].sort('timeKey').to_pandas().set_index('timeKey')\n",
    "df_ts_2 = df.loc[df.MODELID == MODELID_2,['timeKey','DEMAND']].sort('timeKey').to_pandas().set_index('timeKey')\n",
    "df_ts_3 = df.loc[df.MODELID == MODELID_3,['timeKey','DEMAND']].sort('timeKey').to_pandas().set_index('timeKey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b4d1c0-89be-4289-bf14-c0c8a02fc00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(21,5))\n",
    "df_ts_1.plot(ax=ax[0], title=MODELID_1)\n",
    "df_ts_2.plot(ax=ax[1], title=MODELID_2)\n",
    "df_ts_3.plot(ax=ax[2], title=MODELID_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba33309-6036-4256-b921-78a2fae65445",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We will check if the Demand is Zero, and also calculate the duration of the Demand based on the timekey for these Products.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7167a8-9606-4f1f-885d-6e5954c7df6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics = df[['MODELID','timeKey','DEMAND']]. \\\n",
    "                    assign(demand_is_zero=tdml.sqlalchemy.literal_column('CASE WHEN DEMAND=0 THEN 1 ELSE 0 END')). \\\n",
    "                    groupby('MODELID'). \\\n",
    "                    agg({'timeKey' : ['min','max'], 'demand_is_zero':['sum']}). \\\n",
    "                    assign(duration=tdml.sqlalchemy.literal_column('max_timeKey - min_timeKey')). \\\n",
    "                    select(['MODELID','sum_demand_is_zero','duration']). \\\n",
    "                    assign(ratio = tdml.sqlalchemy.literal_column('CAST(sum_demand_is_zero AS FLOAT) / NULLIFZERO(duration)'))\n",
    "\n",
    "dataset_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93225bc0-f9d1-4d55-881e-25e5c6737c7a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We will check only those Series where the duration is greater than 50.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3a165d-9316-4b4f-850d-957c6e048c7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = df.join(other=dataset_metrics, on='MODELID', how='inner', lsuffix='l', rsuffix='r').assign(MODELID=tdml.sqlalchemy.literal_column('l_MODELID')).drop(columns=['l_MODELID','r_MODELID'])\n",
    "dataset = dataset[dataset.duration > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f2e933-69ce-4cea-b5a3-a25222aefa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plotcurves(dataset[dataset.MATERIAL < 300],field='DEMAND',row_axis='timeKey', series_id='MODELID',row_axis_type='sequence',plot_type='line')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6179702f-a003-47d1-b65c-fb3e2cbf85f4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above graph shows the Demand for each Product(MODELID) along the timekey axis</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We use the window function on the timekey column to build a series for the Demands for different ModelIDs.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b7ccaf-672e-4e4f-9b62-5deeffce5642",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_for_counting = dataset.timeKey.window(\n",
    "                            partition_columns   = \"MODELID\",\n",
    "                            order_columns       = 'timeKey'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d4f4f1-c010-4b74-b874-70d00ff62300",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_new = dataset.assign(series_length = window_for_counting.count(),\n",
    "                             nb_zeros = tdml.sqlalchemy.literal_column('SUM(CASE WHEN DEMAND = 1 THEN 1 ELSE 0 END) OVER (PARTITION BY MODELID)'),\n",
    "                             frac_zeros = tdml.sqlalchemy.literal_column('CAST((SUM(CASE WHEN DEMAND = 0 THEN 1 ELSE 0 END) OVER (PARTITION BY MODELID)) AS FLOAT)/series_length'),\n",
    "                             fold = tdml.sqlalchemy.literal_column(\"CASE WHEN timeKey < 0.67*series_length + (min(timeKey) OVER (PARTITION BY MODELID)) THEN 'train' ELSE 'test' END\"),\n",
    "                             time_no_unit = tdml.sqlalchemy.literal_column(\"timeKey-(min(timeKey) OVER (PARTITION BY MODELID))\")\n",
    "                            )\n",
    "dataset_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ee3c58-50a8-4af2-ac21-be995e028ffc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We use the subset of data where the series length is greater than 90 and the ratio od zero demand and series length is less than 0.1.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83d2ba0-a5bb-4818-8bc5-8d3ec8f4814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = dataset_new[(dataset_new.series_length > 90)&(dataset_new.frac_zeros < 0.1)]\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff06e4-85ae-4193-9879-ac54dcd670ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5918b4fb-d432-4732-ac89-55525815d322",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>So the dataset we are using for our analysis has around 46k rows and 21 columns.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ed8e73-e9f2-454d-88b8-5c67ee87aef9",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>4. Checking for Stationarity of Time Series using the Dickey Fuller Test</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf337f98-70d1-4b0e-8ea2-dd3ba147757a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>To be able to model a time series, it needs to be stationary. ARIMA models deal with non-stationary time series by differencing (The \"d' parameter in ARIMA determines the number of differences needed to make a series stationary)</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here we will check for stationarity of all time series using the Dickey-Fuller Test. For more info on the test,  see <a href=\"https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Teradata-VantageTM-Unbounded-Array-Framework-Time-Series-Reference-17.20/Diagnostic-Statistical-Test-Functions/TD_DICKEY_FULLER/TD_DICKEY_FULLER-Example\">here.</a> \n",
    "<p style = 'font-size:16px;font-family:Arial'>The null hypothesis for the test is that the data is non-stationary. We want to REJECT the null hypothesis for this test. So we want a p-value of less that 0.05 (or smaller) and a negative coefficient value for the lag term in our regression model.</p> \n",
    "<p style = 'font-size:16px;font-family:Arial'>The Dickey fuller function needs series data so we use the TDSeries function to create a series and apply DickeyFuller to check the stationarity of the data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098f74d5-a88f-4b9c-81dc-29e6d47bc17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create teradataml TDSeries object.\n",
    "data_series_df = tdml.TDSeries(data=subset,\n",
    "                          id=\"MODELID\",\n",
    "                          row_index=\"time_no_unit\",\n",
    "                          row_index_style=\"SEQUENCE\",\n",
    "                          payload_field=\"DEMAND\",\n",
    "                          payload_content=\"REAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b1994d-006e-4ba6-8a07-6a2cc62b7159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import DickeyFuller\n",
    "df_out = DickeyFuller(   data=data_series_df,\n",
    "                           algorithm='NONE')\n",
    "\n",
    "# Print the result DataFrame.\n",
    "print(df_out.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3b2f94-5022-41a5-b950-2646431cfb52",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In the above output the p-value corresponding to the calculated test statistic is less than 0.05. It means that the series is stationary. The output column NULL_HYP which means NULL HYPOTHESIS can have 2 values \n",
    "    <li style = 'font-size:16px;font-family:Arial'>ACCEPT means the null hypothesis is accepted. No Unit roots are present, and therefore the process is stationary.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>REJECT means the null hypothesis is rejected. Unit roots are present, and the process may or may not be stationary, depending on other factors.</li>\n",
    "</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Since the P_VALUE is less than 0.05 we consider the series and stationary.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80890992-f8a7-47a3-87ec-3b3f399372b8",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>5. Autocorrelation and Partial Autocorrelation of the time series</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>5.1 Check for Autocorrelation of the time series</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>ACF calculates the autocorrelation or autocovariance of a time series. The autocorrelation and autocovariance show how the time series correlates or covaries with itself when delayed by a lag in time or space. Here we check autocorrelation with a maximum lag of 10 time steps.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ce9923-8586-4f3b-9f97-d7585b47b2af",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>First we use the Series created above to get the ACF and PACF.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f8cb5c-bf6b-4a0d-9cbe-c7edbf7440cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import ACF, PACF\n",
    "uaf_out = ACF(data=data_series_df,\n",
    "                  max_lags=10,\n",
    "             ALPHA=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81780e3d-b55d-4667-bbf7-487b76920e43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uaf_out.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a678260-f071-417d-a1e4-ee73328adf38",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#E37C4D'>5.2. Check for partial autocorrelation of the time series</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The PACF function provides insight as to whether the modelled function is stationary. The partial autocorrelations measure the degree of correlation between time series sample points. Here we check partial autocorrelation with a maximum lag of 10 time steps.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e4538-ea17-49fd-81b1-f465ba59417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PACF_out = PACF(data=data_series_df,\n",
    "                    algorithm='LEVINSON_DURBIN',\n",
    "                    max_lags=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86660cda-fdc2-4514-adf4-70a4f950badc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PACF_out.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67515454-0011-4ca2-98c9-f7e56d22a8d4",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#E37C4D'>5.3. Plot graphs for ACF and PACF of the time series</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We plot the ACF and PACF graphs for all the 3 series we are considering in our analysis.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5aeaa0-bcb1-4d7e-bab6-1c2629dec03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_1 = subset.loc[subset.MODELID == MODELID_1,['timeKey','DEMAND']].sort('timeKey').to_pandas().set_index('timeKey')\n",
    "df_ts_2 = subset.loc[subset.MODELID == MODELID_2,['timeKey','DEMAND']].sort('timeKey').to_pandas().set_index('timeKey')\n",
    "df_ts_3 = subset.loc[subset.MODELID == MODELID_3,['timeKey','DEMAND']].sort('timeKey').to_pandas().set_index('timeKey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065e4e7e-4c92-47db-8379-caf9a4389613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "def plot_acf_pacf(df,m=12):\n",
    "    # Create figure\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(20,6))\n",
    "    # Make ACF plot\n",
    "    plot_acf(df, lags=12, zero=False, ax=ax1)\n",
    "    # Make PACF plot\n",
    "    plot_pacf(df, lags=12, zero=False, ax=ax2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bceaee1-ccc7-403d-8556-f0f127d578ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf_pacf(df_ts_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0798849-1614-4cf5-ac49-be4c35e6eeec",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>To get the value of the Moving Average or Q, we need the lag(here, ROW_I is the X axis) where the value from the ACF plot is just outside the significant limit. Looking at the graph, the Auto-Correlation value at ROW_I = 2 is outside the confidence band and much closer to it. Hence it is acceptable to say that the value of the Moving Average or <b>Q = 2</b>.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>To get the value of Auto-Regressive lags or P, we need the lag(here, Row_I) where the value from the PACF plot falls just outside the significant limit. Looking at the graph, the Partial Auto-Correlation value at ROW_I = 1 falls outside the significant limit. Hence we can say that the value of Auto-Regressive lags or <b>P = 1</b>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2e1931-ebbd-4be7-be38-8bacd3064b76",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>6. Using ARIMA (AutoRegressive Integrated Moving Average) model to forecast Demand</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>ARIMA functions on VANTAGE run in the following order:</p>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial'>Run <b>ARIMAESTIMATE</b> function to get the coefficients for the ARIMA model.\n",
    "</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'><i>[Optional]</i> Run <b>ARIMAVALIDATE</b> function to validate the \"goodness of fit\" of the ARIMA model, when FIT_PERCENTAGE is not 100 in ARIMAESTIMATE.\n",
    "</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Run the <b>ARIMAFORECAST</b> function with input from step 1 or step 2 to forecast the future periods beyond the last observed period.</li>\n",
    "</p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>6.1 Estimation step using ARIMAESTIMATE</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The ARIMAESTIMATE function estimates the coefficients corresponding to an ARIMA model and fits a series with an existing ARIMA model. The function can also provide the \"goodness of fit\" and the residuals of the fitting operation. The function generates a model layer used as input for the ARIMAVALIDATE and ARIMAFORECAST functions. This function is for univariate series.</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here, the previously estimated parameters P, d and Q need to be passed in the MODEL_ORDER(P, d, Q), i.e. <b>MODEL_ORDER(1, 1, 2)</b>. The output is stored in a dataframe. The fit percentage is 80, meaning the ARIMA model is being trained on 80% of the data. The remaining 20% of the data will be used to validate the model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e8feba-644e-4db4-9c15-a18da1887658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import ArimaEstimate,ArimaValidate, ArimaForecast, TDAnalyticResult\n",
    "arima_estimate_op = ArimaEstimate(data1=data_series_df,\n",
    "                                       nonseasonal_model_order=[1,1,2],\n",
    "                                       seasonal_period=12,\n",
    "                                       seasonal_model_order=[0,1,0], \n",
    "                                       constant=False,\n",
    "                                       algorithm=\"MLE\",\n",
    "                                       coeff_stats=True,\n",
    "                                       fit_metrics=True,\n",
    "                                       residuals=True,\n",
    "                                       fit_percentage=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc98d38-81f0-4f26-bb3b-e4be7c9af38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_estimate = arima_estimate_op.fitresiduals\n",
    "results_estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c92f98-ed41-4be6-8f47-f5c2305e9201",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>6.2 Validate using ArimaValidate</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The ArimaValidate() function performs an in-sample     forecast for both seasonal and non-seasonal auto-regressive (AR), moving-average (MA), ARIMA models and Box-Jenkins seasonal ARIMA model formula followed by an analysis of the produced residuals. The aim is to provide a collection of metrics useful to select the model and expose the produced residuals such that multiple model validation and statistical tests can be conducted.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The TDAnalyticResult function retrieves auxiliary result sets stored in the output dataframe of the ArimaEstimate. Here we extract the residuals from the previous estimation step. Analytical Result Tables have multiple layers that store different data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f7ca54-d2bf-4cda-b54d-a2aa3e24536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_art_df = tdml.TDAnalyticResult(data=arima_estimate_op.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8409e0e4-7911-4a88-920c-cd4ff98d1e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_validate_op = ArimaValidate(data=data_art_df, fit_metrics=True, residuals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a65cc2-2b50-41c1-8cef-3dfb59b0658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_validate_op.result.sort('AIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0391cf92-d8b0-4c5f-862c-1f7964c079e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_validate = arima_validate_op.fitresiduals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529d7c33-d658-42e0-bb09-fde5a9eb39f4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We plot the actual vs calculated values for the 3 different Products(MODELIDs) we are analyzing.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a7c0d2-3378-4486-bd88-33bdeb3dde43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(MODELID):\n",
    "    res1 = results_validate[results_validate.MODELID == MODELID].sort('ROW_I').to_pandas()\n",
    "    res2 = results_estimate[results_estimate.MODELID == MODELID].sort('ROW_I').to_pandas()\n",
    "    res1['ROW_I'] = res1['ROW_I']-res1['ROW_I'].values[0]+res2['ROW_I'].values[-1]+1\n",
    "    res3 = subset[subset.MODELID == MODELID][['MODELID','time_no_unit','DEMAND']].sort('time_no_unit').to_pandas()\n",
    "    fig, ax = plt.subplots(figsize=(10,4))\n",
    "    res1.plot(x='ROW_I',y=['CALC_VALUE'],ax=ax, marker='o',xlabel='Time',ylabel='Demand',)\n",
    "    res2.plot(x='ROW_I',y=['CALC_VALUE'],ax=ax, marker='s',xlabel='Time',ylabel='Demand')\n",
    "    res3.plot(x='time_no_unit',y='DEMAND',ax=ax,xlabel='Time',ylabel='Demand')\n",
    "    return\n",
    "\n",
    "plot_results(MODELID_1)\n",
    "plot_results(MODELID_2)\n",
    "plot_results(MODELID_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65166abb-9e31-48cc-ab19-751ba47195b5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above graphs show the Actual Demand Values(Green) and the Calculated Values for the Demand using the ArimaEstimate(Orange) and ArimaValidate(Blue). The 3 graphs are for the 3 Products(MODELIDs).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29847e03-39f8-4792-b34a-269197e76e2f",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>6.3 Forecast Demand using ArimaForecast</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The ArimaForecast() function is used to forecast a user-defined number of periods based on\n",
    "    models fitted from the ArimaEstimate() function.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The ArimaForecast() function with input from step 1 or step 2 to forecast the future periods beyond the last observed period. Here we are forecasting for 20 periods.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804bf238-c0d2-45eb-92fe-45f8674a6c19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_art_df = TDAnalyticResult(data=arima_validate_op.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8931335b-23e8-4c9e-bd3e-52086e9f5257",
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_forecast_op = ArimaForecast(data=data_art_df, forecast_periods=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3d84f9-d29f-4c96-aa6d-ad7e0790eecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_forecast = arima_forecast_op.result\n",
    "results_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f3bbff-aad3-41ac-9a95-8d8ac29517fe",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We plot the actual vs forecast values for the 3 different Products(MODELIDs) we are analyzing.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b9fe5e-2c8e-41a6-bcaa-f30919ed31e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(MODELID):\n",
    "    fig, ax = plt.subplots(figsize=(10,4))\n",
    "    # Plot prediction\n",
    "    mean_forecast = results_forecast[results_forecast.MODELID==MODELID].sort('ROW_I').to_pandas()\n",
    "    res3 = subset[subset.MODELID == MODELID][['MODELID','time_no_unit','DEMAND']].sort('time_no_unit').to_pandas()\n",
    "    res3['time_no_unit'] = res3['time_no_unit'] - res3.time_no_unit.values[-1]\n",
    "    res3.plot(x='time_no_unit',y='DEMAND',label='actual',ax=ax)\n",
    "    mean_forecast.plot(x='ROW_I',y='FORECAST_VALUE',label='forecast',color='red',ax=ax)\n",
    "    # Shade uncertainty area\n",
    "    plt.fill_between(mean_forecast.ROW_I, mean_forecast.LO_80, mean_forecast.HI_80, color='pink', alpha=0.5)\n",
    "    plt.fill_between(mean_forecast.ROW_I, mean_forecast.LO_95, mean_forecast.HI_95, color='pink', alpha=0.2)\n",
    "    plt.title(MODELID)\n",
    "    plt.show()\n",
    "    return\n",
    "plot_forecast(MODELID_1)\n",
    "plot_forecast(MODELID_2)\n",
    "plot_forecast(MODELID_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba1d9de-f015-47ab-9298-04b756016db9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The plot in pink color shows the forecasted values for each Product(MODELID) for the 20 periods we have specified in the ArimaForecast.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4342cc-9661-48bf-ad96-b2057f8b359d",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>7. Conclusion:</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have trained and validated the ARIMA model on the Weekly Sales dataset, and the results closely match the actual data. The goodness of fit metrics calculated in the estimate and validate phase also resonate with our understanding that the model is well-trained to forecast. This can be observed in the Estimate and the Validate function graphs. So we can say that the model is well trained to forecast the Weekly Sales.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767b3987-5668-4706-a7a3-5af33cfa1896",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>8. Cleanup</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf292234-0cdb-43a4-a370-f8039cf5f39b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Databases and Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333849a1-b510-404b-ad01-8a2e41defeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_DemandForecast');\" \n",
    "#Takes 45 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418001cb-0540-4836-9a34-35cc910aa2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893f134d-77d6-4a62-be43-51bb64920882",
   "metadata": {},
   "source": [
    "<footer style=\"padding:10px;background:#f9f9f9;border-bottom:3px solid #394851\">Copyright © Teradata Corporation - 2023. All Rights Reserved.</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
