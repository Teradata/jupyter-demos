{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ee96203-f8ae-4648-b550-5844f2fa17f1",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Semantic Similarity using Open Source Language Models in Database\n",
    "  <br>\n",
    "              <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac817186-c9b9-48c5-9150-025e5e752878",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial'><b>Introduction</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Semantic similarity refers to the degree to which two pieces of text, words, or concepts have similar meanings. It measures how much two entities are related based on their meanings rather than just their surface forms or literal text. The similarity can be with synonyms e.g car and automobile, with realted concepts e.g doctor and nurse or with phrases e.g \"she enjoys reading books\" and \"she loves to read\" .\n",
    "</p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Applications of Semantic Similarity:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>There are various applications which use semantic similarity e.g\n",
    "            <li>Natural Language Processing (NLP): Used in tasks like text summarization, question-answering, and machine translation. </li>\n",
    "            <li>Information Retrieval: Helps search engines return results that are conceptually related to the user's query. </li>\n",
    "            <li>Recommendation Systems: Suggests similar items based on their semantic meaning  </li></ul>\n",
    "    </li>\n",
    " </ul>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Why Vantage?</b></p>  \n",
    "<p style = 'font-size:16px;font-family:Arial'>Teradata has Integration with LLMs with Amazon BedRock etc and also emerging Open Analytics Framework in the Cloud Lake where we can host a Language Model etc. For many on-prem customers it is not practical to move the big NLP data out of Teradata such as complaints/emails, score it and put it back even if HF models run outside the DB. Moving huge volume of historical data from Vantage for the NLP models to transform does not provide much advantage as my latency is high. Moreover on-prem customers sometimes may not have even access to Cloud/LLMs and even Open Analytics Framework and can't get any AI going today. By bringing the language models within Vantage we can bridge the gap and enable on-prem customers to run NLP models in database.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b968b80c-57ed-4f61-9b16-4aea1f7457da",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>1. Connect to Vantage</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baca5f27-67cc-4d7c-9e1e-7fa0d429832a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Let's start by importing the libraries needed.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066391b5-367d-4101-8857-b47b6d767a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import getpass\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# Teradata libraries\n",
    "from teradataml import *\n",
    "display.max_rows = 5\n",
    "\n",
    "#other libraries\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236ad4c9-874a-479b-853c-f8e7478605ec",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell. Begin running steps with Shift + Enter keys.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14195ef8-872e-486a-80fa-361f7861ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd85a2e-7076-4594-9c98-bd32d4d393e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql(\"SET query_band='DEMO=Language_Model_Semantic_Similarity_Python.ipynb;' UPDATE FOR SESSION;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe258d2-fefb-4628-92e5-499f85fedd05",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>2. Confirmation for functions</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Before starting let us confirm that the required functions are installed.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b100ee-4de1-468b-8ee0-913518594b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check= DataFrame.from_query('''select count(*) as cnt from dbc.tablesV where databasename = 'ivsm';''')\n",
    "if df_check.get_values()[0][0] >= 10:\n",
    "    print('Functions are installed, please continue.')\n",
    "else:\n",
    "    print('Functions are not installed, please execute the Initialization_and_Model_Load notebook before proceeding further.  When completed, please return and run this cell again.')\n",
    "    display(Markdown(\"[Initialization Notebook](./Initialization_and_Model_Load.ipynb)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5ecf84-6aac-4eda-9f00-95eed92cff82",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'> <b>3. Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have provided data for this demo on cloud storage. Since we are using embeddings stored in Vantage for this demo we will only use the option of creating table locally.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b8ad4f-1174-46b2-b0af-1e64ff24ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call get_data('DEMO_ComplaintAnalysis_local');\"\n",
    "# takes about 30 seconds, estimated space: 3 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9760e3fa-5a74-4e54-96e3-f7b25a0041b6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Optional step – We should execute the below step only if we want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b78c80-32c3-4919-9f5c-521b99b8feb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955427f9-33a5-40de-8952-85bfd7ad5a8f",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>4. Confirmation for Models Loaded in Vantage</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e517834a-e5ef-4ce4-9452-a970c2c0aedd",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The tokenizer.json and the model.onnx is created from a huggingface embedding model and must be uploaded using the \"save_byom\" function earlier from the Initialization_and_Model_Load notebook.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a6e6a4-2639-4070-a346-2d1ea558e1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_token = DataFrame('embeddings_tokenizers')\n",
    "df_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550f86d1-a1d3-4f96-a08d-1970707a5894",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = DataFrame(\"embeddings_models\")\n",
    "df_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4965f0fd-0330-4259-936b-a523dc7f170c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above tables storing the model and tokenizer are replicated table across all the AMPs in the database, so embedding creation will happen in parallel</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13261da-bbfb-499a-be6c-169bd3d82bee",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>5. Creating Embeddings on Source Data</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7d262d-fc93-4434-85be-54bd41e593d9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The data is from Consumers Complaints from <a href = 'https://www.consumerfinance.gov'>CFPB website</a> which we have loaded in table for our demo. Let us see how the data looks like.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5424ce-9d3e-4f33-94b7-b715befa3f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame('\"DEMO_ComplaintAnalysis\".\"Consumer_Complaints\"')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0043a8-ceba-4c36-a423-d1f5049a06b3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'> For the tokenizer function to run we'll need only two columns in the underlying table named <b>id</b> and <b>txt</b>. <br> If the table doesnt have those columns we can either rename them or just create a view with the id and txt columns at a minimum. <b>id</b> holds the unique id of the row and <b>txt</b> has the key text field that we'll create the embeddings and do semantic search on. Ideally, we want to create a two column dataset and after the embeddings run join back to original dataset using id to minimize overheads in IO/memory etc.<br> For our usecase we will rename complaint_id as id and consumer_complaint_narrative as txt in view when we create embeddings.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400682da-6d13-4a66-be6d-89135dff8092",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.1 Creating Tokens</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this first step we will create tokens on the txt column for which we are generating embeddings. We will do this by careting a view calling tokenizer_encode() on the Consumer_Complaints table that uses the tokenizer.json in the embeddings_tokenizers table. For our small system (2nodes 4amps) we are taking 1000 records only for demo.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c441896-b77d-4ea8-8871-43d447549a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = ('''\n",
    "replace view v_complaints_tokenized_for_embeddings as (\n",
    "    select\n",
    "        id,\n",
    "        txt,\n",
    "        IDS as input_ids,\n",
    "        attention_mask\n",
    "    from ivsm.tokenizer_encode(\n",
    "        on (select top 1000 complaint_id as id, consumer_complaint_narrative as txt \n",
    "            from DEMO_ComplaintAnalysis.Consumer_Complaints)\n",
    "        on (select model as tokenizer from embeddings_tokenizers \n",
    "            where model_id = 'bge-small-en-v1.5') DIMENSION\n",
    "        USING\n",
    "            ColumnsToPreserve('id', 'txt')\n",
    "            OutputFields('IDS', 'ATTENTION_MASK')\n",
    "            MaxLength(1024)\n",
    "            PadToMaxLength('True')\n",
    "            TokenDataType('INT64')\n",
    "    ) a\n",
    ")\n",
    "''')\n",
    "try:\n",
    "    execute_sql(qry)\n",
    "    print('View Created')\n",
    "except Exception as e:\n",
    "    print('View creation failed')\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcd3dd7-18a7-43c6-9dde-4ce5a14a8a2a",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.2 Creating Embeddings</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this next step we will create embeddings in a binary form using the tokens created in the view in step 1.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f120b7a-852b-4f29-b682-b7145e9c80b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = ('''\n",
    "replace view complaints_embeddings as (\n",
    "    select \n",
    "            *\n",
    "    from ivsm.IVSM_score(\n",
    "            on v_complaints_tokenized_for_embeddings  -- table with data to be scored\n",
    "            on (select * from embeddings_models where model_id = 'bge-small-en-v1.5') dimension\n",
    "            using\n",
    "                ColumnsToPreserve('id', 'txt') -- columns to be copied from input table\n",
    "                ModelType('ONNX') -- model format\n",
    "                BinaryInputFields('input_ids', 'attention_mask') -- enables binary input vectors\n",
    "                BinaryOutputFields('sentence_embedding')\n",
    "                Caching('inquery') -- tun on model caching within the query\n",
    "        ) a \n",
    ")\n",
    "''')\n",
    "try:\n",
    "    execute_sql(qry)\n",
    "    print('View Created')\n",
    "except Exception as e:\n",
    "    print('View creation failed')\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56da8871-334f-46c1-84a1-19e32e511050",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>5.3 Creating Final Embeddings table</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this last step we will create embeddings table creating a column for each embedding essentially converting an array to separate columns.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0988f95e-5aa9-4fa0-97a6-797d0f872778",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b> Do you want to generate the embeddings?</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial'>Generating embeddings will take around <b>35-40 minutes.</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have already generated embeddings for the Consumer_Complaints and stored them in <b>Vantage</b> table.</p>\n",
    " \n",
    "<center><img src=\"images/decision_emb_gen_1.svg\" alt=\"embeddings_decision\" width=300 height=400/></center>\n",
    " \n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial'><i><b>Note: If you would like to skip the embedding generation step to save the time and move quickly to next step, please enter \"No\" in the next prompt.</b></i></p>\n",
    "</div>\n",
    " \n",
    "<p style = 'font-size:16px;font-family:Arial'>To save time, you can move to the already generated embeddings section. However, if you would like to see how we generate the embeddings, or if you need to generate the embeddings for a different dataset, then continue to the following section.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d4605e-3932-49e5-a54f-c8e9b96024dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request user's input\n",
    "generate = input(\"Do you want to generate embeddings? ('yes'/'no'): \")\n",
    "\n",
    "# Check the user's input\n",
    "if generate.lower() == 'yes':\n",
    "    print(\"\\nGreat! We'll start by generating embeddings.\")\n",
    "\n",
    "    print(\"\\nGenerating embeddings and Saving to the database, please wait...\")\n",
    "    # start = time.time()\n",
    "    qry=''' create multiset table complaints_embeddings_store as (\n",
    "            select \n",
    "            *\n",
    "            from ivsm.vector_to_columns(\n",
    "            on complaints_embeddings\n",
    "            using\n",
    "                ColumnsToPreserve('id', 'txt') \n",
    "                VectorDataType('FLOAT32')\n",
    "                VectorLength(384)\n",
    "                OutputColumnPrefix('emb_')\n",
    "                InputColumnName('sentence_embedding')\n",
    "             ) a \n",
    "             ) with data primary index(id);\n",
    "        '''\n",
    "\n",
    "    try:\n",
    "        print(\"Embedding process started at\",time.ctime())\n",
    "        start = time.time()\n",
    "        execute_sql(qry)\n",
    "        end = time.time()\n",
    "        print('Table Created')\n",
    "        print(\"Total time to run tokenization+embeddings took = \",(end-start)/60, \" min on 2nodes 4Amp VM\")\n",
    "        df_emb = DataFrame('complaints_embeddings_store')\n",
    "        \n",
    "        \n",
    "    except:\n",
    "        db_drop_table('complaints_embeddings_store')\n",
    "        start = time.time()\n",
    "        execute_sql(qry)\n",
    "        end = time.time()\n",
    "        print('Table Created')\n",
    "        print(\"Total time to run tokenization+embeddings took = \",(end-start)/60, \" min on 2nodes 4Amp VM\")\n",
    "        df_emb = DataFrame('complaints_embeddings_store')\n",
    "\n",
    "    print(\"\\nEmbeddings generated and saved successfully!\")\n",
    "\n",
    "elif generate.lower() == 'no':\n",
    "    print(\"\\nLoading embeddings from the Vantage table\")\n",
    "    df_emb = DataFrame('\"DEMO_ComplaintAnalysis\".\"Complaints_Embeddings_Store\"')\n",
    "    \n",
    "else:\n",
    "    print(\"\\nInvalid input. Please enter 'yes' or 'no' to proceed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7afc4a-0c6a-4fc4-ac6b-23d33644039c",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>6. Embeddings Data</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Let us review the Embeddings table we created on the Consumer Complaints dataset earlier.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603201b2-0c9c-4584-9ed8-959a221f9d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate.lower() == 'yes':\n",
    "    df_emb = DataFrame('complaints_embeddings_store')\n",
    "elif generate.lower() == 'no':\n",
    "    df_emb = DataFrame('\"DEMO_ComplaintAnalysis\".\"Complaints_Embeddings_Store\"')\n",
    "    \n",
    "else:\n",
    "    print(\"\\nEmbeddings not created, please run the section 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b257c4ba-951f-4aac-ae35-0f1591d7078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa8ab0f-51a0-445e-a35f-775ee9739370",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'> As we can see from the above, 384 embeddings are created for every txt.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6050c5b4-83df-4e21-b4c8-657197124d00",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>7. Topics Data</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1751c79b-849b-4666-8fa7-e19ee115f490",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'> Now let us create a list of topics for which we will do our search.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d186b0f4-7246-494d-b239-fdedab7c3aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id': [1,2,3,4,5,6],\n",
    "      'txt': ['Fradulent activity with Debit Cards at Wells Fargo',\n",
    "              'Identity theft issues at Citibank',\n",
    "              'Multiple account openings without authorization',\n",
    "              'Irresponsible behavior by customer support',\n",
    "              'App issues when transacting with bank',\n",
    "              'Cant get money out of ATM',\n",
    "              ]})\n",
    "\n",
    "copy_to_sql(df,table_name='topics_of_interest', if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e181d98e-f515-421d-99f7-d0d4c31244db",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>8. Generating Embedding for Topics Data</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We will generate the embeddings for the Topics data in 3 steps as explained earlier in section 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478df7c6-2d4f-4035-a805-e19e82f9f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = ('''\n",
    "replace view v_topics_tokenized_for_embeddings as (\n",
    "    select\n",
    "        id,\n",
    "        txt,\n",
    "        IDS as input_ids,\n",
    "        attention_mask\n",
    "    from ivsm.tokenizer_encode(\n",
    "        on (select * from topics_of_interest)\n",
    "        on (select model as tokenizer from embeddings_tokenizers \n",
    "            where model_id = 'bge-small-en-v1.5') DIMENSION\n",
    "        USING\n",
    "            ColumnsToPreserve('id', 'txt')\n",
    "            OutputFields('IDS', 'ATTENTION_MASK')\n",
    "            MaxLength(1024)\n",
    "            PadToMaxLength('True')\n",
    "            TokenDataType('INT64')\n",
    "    ) a\n",
    ")\n",
    "''')\n",
    "try:\n",
    "    execute_sql(qry)\n",
    "    print('View Created')\n",
    "except Exception as e:\n",
    "    print('View creation failed')\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b11964d-b24e-4ba6-8f85-8383329ad86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = ('''\n",
    "replace view topics_embeddings as (\n",
    "    select \n",
    "            *\n",
    "    from ivsm.IVSM_score(\n",
    "            on v_topics_tokenized_for_embeddings  -- table with data to be scored\n",
    "            on (select * from embeddings_models where model_id = 'bge-small-en-v1.5') dimension\n",
    "            using\n",
    "                ColumnsToPreserve('id', 'txt') -- columns to be copied from input table\n",
    "                ModelType('ONNX') -- model format\n",
    "                BinaryInputFields('input_ids', 'attention_mask') -- enables binary input vectors\n",
    "                BinaryOutputFields('sentence_embedding')\n",
    "                Caching('inquery') -- tun on model caching within the query\n",
    "        ) a \n",
    ")\n",
    "''')\n",
    "try:\n",
    "    execute_sql(qry)\n",
    "    print('View Created')\n",
    "except Exception as e:\n",
    "    print('View creation failed')\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e23225-ee43-4a1b-8be7-4fdd0e52aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = ('''\n",
    "create table topics_embeddings_store as (\n",
    "    select \n",
    "            *\n",
    "    from ivsm.vector_to_columns(\n",
    "            on topics_embeddings\n",
    "            using\n",
    "                ColumnsToPreserve('id', 'txt') \n",
    "                VectorDataType('FLOAT32')\n",
    "                VectorLength(384)\n",
    "                OutputColumnPrefix('emb_')\n",
    "                InputColumnName('sentence_embedding')\n",
    "        ) a \n",
    ") with data\n",
    "''')\n",
    "try:\n",
    "    execute_sql(qry)\n",
    "    print('Table Created')\n",
    "except:\n",
    "    db_drop_table('topics_embeddings_store')\n",
    "    execute_sql(qry)\n",
    "    print('Table Created')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208bd049-3c94-4737-94dd-bd753b9be3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic = DataFrame('topics_embeddings_store')\n",
    "df_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bd7595-b5dd-4fa4-a611-29bba5b4280c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'> As we can see from the above, we have generated embeddings for the topic data.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be16901-a641-4096-af39-69634b70e5cd",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>9. Semantic Similarity</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Now we will run Semantic Similarity of the Topics Embeddings against the Complaints Embeddings table. Vector Distance is a measure of the similarity or dissimilarity between two vectors in multidimensional space. We will use Vantage's TD_VectorDistance function. The <b>TD_VectorDistance</b> function accepts a table of target vectors and a table of reference vectors and returns a table that contains the distance between target-reference pairs. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9823b88-6863-4fd9-a6ed-4b654cab846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the user's input before to generate embeddings\n",
    "qry1= '''\n",
    "create multiset table semantic_search_results\n",
    "as (\n",
    "SELECT \n",
    "    dt.target_id,\n",
    "    dt.reference_id,\n",
    "    e_tgt.consumer_complaint_narrative as target_txt,\n",
    "    e_ref.txt as reference_txt,\n",
    "    (1.0 - dt.distance) as similarity \n",
    "FROM\n",
    "    TD_VECTORDISTANCE (\n",
    "        ON (select * from complaints_embeddings_store a) AS TargetTable\n",
    "        ON topics_embeddings_store AS ReferenceTable DIMENSION\n",
    "        USING\n",
    "            TargetIDColumn('id')\n",
    "            TargetFeatureColumns('[emb_0:emb_383]')\n",
    "            RefIDColumn('id')\n",
    "            RefFeatureColumns('[emb_0:emb_383]')\n",
    "            DistanceMeasure('cosine')\n",
    "            topk(1) -- Only want the best match per complaint. If you want multi-label/multi-class - you can increase it\n",
    "    ) AS dt\n",
    "JOIN DEMO_ComplaintAnalysis.Consumer_Complaints e_tgt on e_tgt.complaint_id = dt.target_id\n",
    "JOIN topics_embeddings_store e_ref on e_ref.id = dt.reference_id\n",
    "WHERE dt.distance < 0.3 -- Cosine Similarity of 0.7 or greater\n",
    ") with data;\n",
    "'''\n",
    "qry2= '''\n",
    "create multiset table semantic_search_results\n",
    "as (\n",
    "SELECT \n",
    "    dt.target_id,\n",
    "    dt.reference_id,\n",
    "    e_tgt.consumer_complaint_narrative as target_txt,\n",
    "    e_ref.txt as reference_txt,\n",
    "    (1.0 - dt.distance) as similarity \n",
    "FROM\n",
    "    TD_VECTORDISTANCE (\n",
    "        ON (select * from DEMO_ComplaintAnalysis.Complaints_Embeddings_Store a) AS TargetTable\n",
    "        ON topics_embeddings_store AS ReferenceTable DIMENSION\n",
    "        USING\n",
    "            TargetIDColumn('id')\n",
    "            TargetFeatureColumns('[emb_0:emb_383]')\n",
    "            RefIDColumn('id')\n",
    "            RefFeatureColumns('[emb_0:emb_383]')\n",
    "            DistanceMeasure('cosine')\n",
    "            topk(1) -- Only want the best match per complaint. If you want multi-label/multi-class - you can increase it\n",
    "    ) AS dt\n",
    "JOIN DEMO_ComplaintAnalysis.Consumer_Complaints e_tgt on e_tgt.complaint_id = dt.target_id\n",
    "JOIN topics_embeddings_store e_ref on e_ref.id = dt.reference_id\n",
    "WHERE dt.distance < 0.3 -- Cosine Similarity of 0.7 or greater\n",
    ") with data;\n",
    "'''\n",
    "\n",
    "if generate.lower() == 'yes':\n",
    "    try:\n",
    "        execute_sql(qry1)\n",
    "        print(\"Semantic Search Results table created\")\n",
    "    except:\n",
    "        db_drop_table('semantic_search_results')\n",
    "        execute_sql(qry1)\n",
    "        print(\"Semantic Search Results table created\")\n",
    "elif generate.lower() == 'no':\n",
    "    try:\n",
    "        execute_sql(qry2)\n",
    "        print(\"Semantic Search Results table created\")\n",
    "    except:\n",
    "        db_drop_table('semantic_search_results')\n",
    "        execute_sql(qry2)\n",
    "        print(\"Semantic Search Results table created\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nError creating the Semantic Search Results\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727e11bd-47a0-4335-bdf5-414b73bdc0a0",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>10. Check Matches</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7903352c-83fe-4e1a-9386-5cb6a9ee55d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = DataFrame('semantic_search_results')\n",
    "\n",
    "#displaying the results with most simialrity first\n",
    "df_results.sort(['similarity'],ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f3d0f3-ff31-4c81-94f5-20d7ca4a3cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying the top 2 records for each reference_id from the similarity result created\n",
    "window = df_results.window(partition_columns=\"reference_id\",\n",
    "                           order_columns=\"similarity\",\n",
    "                           sort_ascending=False)\n",
    "df = window.rank()\n",
    "df[df.col_rank.isin([1,2])].sort(['reference_id','col_rank']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5cbed6-a573-4429-bfbf-d37d1d9e44b6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial'><b>Conclusion</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this demo we have seem that how we can run HuggingFace Embedding Model (BAAI/bge-small-1.5) in ONNX format and run it in database parallelly to create embeddings. We have done Cosine Similarity match using TD_VectorDistance function to find the similar topics.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764fdb44-dec4-4d2c-9479-d90bee60adb4",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>11. Cleanup</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c86fee-041e-412b-b6bf-7773aa8bc55f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'> <b>Work Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following code will clean up tables created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45aaabf-36e2-4301-94d2-06bbda56513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['complaints_embeddings_store', 'topics_embeddings_store','semantic_search_results','topics_of_interest']\n",
    "\n",
    "# Loop through the list of tables and execute the drop table command for each table\n",
    "for table in tables:\n",
    "    try:\n",
    "        db_drop_table(table_name=table)\n",
    "    except:\n",
    "        pass  \n",
    "    \n",
    "views = ['v_complaints_tokenized_for_embeddings','complaints_embeddings','v_topics_tokenized_for_embeddings',\n",
    "         'topics_embeddings']   \n",
    "\n",
    "for view in views:\n",
    "    try:\n",
    "        db_drop_view(view_name=view)\n",
    "    except:\n",
    "        pass "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72802d0-aeee-442e-a920-9d16d9663188",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbac5a13-3658-4932-9491-d93a226a2ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_ComplaintAnalysis');\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fece83-0aac-4e95-99ba-f73aa81e6588",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b33117-fa3a-45ac-bd67-3f6aa76be063",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; border-bottom:3px solid #91A0Ab\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2024. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
