{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df79517-1e4f-420a-b7e3-fbb2bb44009d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Semantic Clustering using Open Source Language Models in Database\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683b88c6-5ced-4e58-9e41-a3c78606ec02",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial'><b>Introduction:</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Semantic Clustering measures the degree to which two pieces of text relate in meaning, regardless of the exact wording. This captures relationships between words, sentences, or documents in ways that traditional keyword-based methods might miss.</p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "            <li><strong>Information Retrieval:</strong> Improves search engines by retrieving documents or results that are semantically related to the user's query.</li>\n",
    "            <li><strong>Text Classification:</strong> Categorizes text into predefined classes based on meaning, useful in spam detection, sentiment analysis, etc.</li>\n",
    "            <li><strong>Question Answering:</strong> Matches questions to relevant answers by understanding their meaning.</li>\n",
    "            <li><strong>Recommendation Systems:</strong> Suggests items (like products or content) based on similarity in user preferences or behaviors.</li>\n",
    "            <li><strong>Plagiarism Detection:</strong> Identifies copied content even if paraphrased</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Why Vantage?</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "    Teradata’s integration with <b>LLMs and hosting capabilities in-DB</b>, along with the Open Analytics Framework, would enable customers to run NLP models at scale. The key challenges noted for on-prem customers—such as data movement latency and lack of access to cloud models—are valid. By bringing language models within Vantage, Teradata can provide a significant advantage to on-prem customers by allowing them to run NLP models without needing to move large amounts of data to and from external services.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a628f056-dbee-4ec4-a5d4-b7a860cbaa80",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Downloading and installing additional software needed</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a325ffa-f4ab-44fb-b729-adeaf9e9df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install wordcloud nltk --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc16152-9448-4b1c-a398-7a3a94bac040",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install --force-reinstall pillow --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5639a5-1b8c-4001-8f20-45221b039f6e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Note: </b><i>The above libraries have to be installed. Restart the kernel after executing these cells to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing <b> 0 0</b></i> (zero zero) and pressing <i>Enter</i>.</p>\n",
    "</div>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18116bca-b8af-4360-bf4a-a420451777b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Data manipluation and Visualization libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# Teradata libraries\n",
    "from teradataml import (\n",
    "    create_context, \n",
    "    delete_byom, \n",
    "    display,\n",
    "    execute_sql,\n",
    "    save_byom,\n",
    "    remove_context,\n",
    "    in_schema,\n",
    "    KMeans,\n",
    "    DataFrame,\n",
    "    db_drop_table,\n",
    "    db_drop_view,\n",
    "    configure,\n",
    "    ONNXEmbeddings,\n",
    "    copy_to_sql\n",
    ")\n",
    "display.max_rows = 5\n",
    "\n",
    "configure.byom_install_location = \"mldb\"\n",
    "\n",
    "# NLP libraries\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "# machine learning libraries\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d689b8-787e-470c-820d-2d794d92ccf1",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>1. Initiate a connection to Vantage</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>You will be prompted to provide the password. Enter your password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e801c-31af-48bc-af16-0f150cec7c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08236876-6758-45ef-b1ea-cfac6f0668fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=Language_Model_SemanticClustering.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039fbd7c-8dc2-4508-8216-492ee83c59d8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded1b2e3-5391-4025-8428-093b4ecfff56",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have provided data for this demo on cloud storage. You can either run the demo using foreign tables to access the data without any storage on your environment or download the data to local storage, which may yield faster execution. Still, there could be considerations of available storage. Two statements are in the following cell, and one is commented out. You may switch which mode you choose by changing the comment string.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16973665-4402-466e-bd51-8b3e279bb866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ../run_procedure.py \"call get_data('DEMO_ComplaintAnalysis_cloud');\"        # Takes 1 minute\n",
    "%run -i ../run_procedure.py \"call get_data('DEMO_ComplaintAnalysis_local');\"        # Takes 2 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05175b33-b1a0-4292-ad58-a155c0892491",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Next is an optional step – if you want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e6f604-ef55-4503-88ac-7dd584fbd601",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39506f3-d7ce-4301-b756-cacebd2621fe",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>2. Confirmation for Model</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Before starting let us confirm that the required model is installed.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ea8251-8d99-4663-a476-a8c47942b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bge-small-en-v1.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f458c7-d659-41d2-b455-8e77244599a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "df_check= DataFrame.from_query(f'''select (select 1 as cnt from embeddings_models where model_id = '{model_name}') +\n",
    "(select 1 as cnt from embeddings_tokenizers where model_id =  '{model_name}') as cnt''')\n",
    "if df_check.get_values()[0][0] == 2:\n",
    "    print('Model is installed, please continue.')\n",
    "else:\n",
    "    print('Model is not installed, please go to Instalization notebook before proceeding further')\n",
    "    display(Markdown(\"[Initialization Notebook](./Initialization_and_Model_Load.ipynb)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d755479-839b-4c36-b6f9-6d3026bd9abb",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>3. Create the Embeddings</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22728822-81f3-412f-b1d8-dd9e20314bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tdf = DataFrame(in_schema('DEMO_ComplaintAnalysis', 'consumer_complaints'))\n",
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c44deb-be42-4f76-a7d0-568e2f2cebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf698007-2da6-4efc-a1f6-46ad9623e24d",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial;'>3.1 Generate Embeddings with ONNXEmbeddings</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca7ec56-2cb4-4bf2-9690-96d7c0b6b417",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "Now it's time to generate the embeddings using <b>ONNXEmbeddings</b>.<br>We run the ONNXEmbeddings function to generate embeddings for a small subset of records. The model is <b>loaded into the cache memory on each node</b>, and Teradata's <b>Massively Parallel Processing (MPP)</b> architecture ensures that embeddings are computed in parallel using <b>ONNX Runtime</b> on each node.  <br>Having said that, generating embeddings for the entire training set can be time-consuming, especially when working on a system with limited resources. In the <b>ClearScape Analytics experience</b>, only a <b>4 AMP system</b> with constrained RAM and CPU power is available. To ensure smooth execution, we test embedding generation on a small sample and use <b>pre-calculated embeddings</b> for the remainder of demo. In a real-life scenario you would tyipically encounter multiple hundred AMPs with much more compute power!<br>Also have a look at the most important input parameters of this <b>ONNXEmbeddings</b> function.\n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "<li><b>InputTable</b>: The source table containing the text to be embedded. </li>\n",
    "<li><b>ModelTable</b>: The table storing the ONNX model.                    </li>\n",
    "<li><b>TokenizerTable</b>: The table storing the tokenizer JSON file.       </li>\n",
    "<li><b>Accumulate</b>: Specifies additional columns to retain in the output </li>  \n",
    "<li><b>OutputFormat</b>: Specifies the data format of the output embeddings (<b>FLOAT32(354)</b>, matching the model's output dimension).</li>\n",
    "</ul>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "Since embedding generation is computationally expensive, we only process <b>100 records for testing</b> and rely on precomputed embeddings for further analysis.  \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee84581-140e-4abc-b299-f1d2eb1d6188",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_sample = tdf.iloc[:100, :]\n",
    "tdf_sample=tdf_sample.assign(drop_columns = True,\n",
    "                             id = tdf_sample.complaint_id,\n",
    "                             txt= tdf_sample.consumer_complaint_narrative)\n",
    "tdf_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2571ff48-11cc-43f4-9c82-e9c6dcc92c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = DataFrame.from_query(f\"select * from embeddings_models where model_id = '{model_name}'\")\n",
    "my_tokenizer = DataFrame.from_query(f\"select model as tokenizer from embeddings_tokenizers where model_id = '{model_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c093349b-daba-4644-bed9-85d5470de003",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_dimensions_output = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a283c90-2a08-49b1-997a-413c48374734",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_embeddings_sample = ONNXEmbeddings(\n",
    "    newdata = tdf_sample,\n",
    "    modeldata = my_model, \n",
    "    tokenizerdata = my_tokenizer, \n",
    "    accumulate = [\"id\", \"txt\"],\n",
    "    model_output_tensor = \"sentence_embedding\",\n",
    "    output_format = f'FLOAT32({number_dimensions_output})',\n",
    "    enable_memory_check = False\n",
    ").result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfb4749-aa31-4086-a322-008f84656d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_embeddings_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89777af1-d6ea-484e-959a-b385a6ff8a8e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'> Here we can see how the embeddings are generated for the consumer_complaint_narrative. For further analysis we will use the precomputed embeddings</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09a3f2e-1896-4076-be0b-93e381732eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_embeddings_store = DataFrame(in_schema('DEMO_ComplaintAnalysis', 'Complaints_Embeddings_Store'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4040471e-6b45-4175-8958-f3dbbbf1222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_embeddings_store.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ac23c0-8ecf-412c-b504-3b7a91a38644",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>4. Run K-Means on the Embeddings Store and then build final table with Cluster ID assignments to rows</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680e433a-ff47-495f-8c97-7601c300851c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The K-means() function groups a set of observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid). This algorithm minimizes the objective function, that is, the total Euclidean distance of all data points from the center of the cluster</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daac7e03-f0c7-4d6b-b6de-a1dfbc862556",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_column_list = [col for col in tdf_embeddings_store.columns if col not in [\"id\", \"txt\"]]\n",
    "\n",
    "num_clusters = 4\n",
    "kmeans_out = KMeans(\n",
    "    id_column=\"id\",\n",
    "    data=tdf_embeddings_store,\n",
    "    target_columns=embedding_column_list,\n",
    "    output_cluster_assignment=True,\n",
    "    num_init=10,\n",
    "    num_clusters=num_clusters,\n",
    "    iter_max=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac0e6a6-8947-40a0-afcc-786d6388e0ed",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The output below shows cluster assignment for each row.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa7f4f1-57f9-4d57-aefe-46eec5c989a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_out.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda2b439-13b2-4894-bd4f-96bd5162cdd7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Let's check how many data points each cluster has.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e985c8d7-92b3-4bdd-9d12-27305978f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_df = kmeans_out.result\n",
    "d2 = kmeans_df.groupby('td_clusterid_kmeans').count()\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c734da84-4a5c-49ac-9245-06f822b81110",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_df = tdf_embeddings_store.join(\n",
    "    other = kmeans_df,\n",
    "    on = [\"id\"],\n",
    "    how = \"inner\",\n",
    "    lprefix=\"l\",\n",
    "    rprefix=\"r\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a7b547-5af5-4898-8e5b-cb301ac307b7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Let's check a sample of data points from cluster number 2.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539d2d74-3e22-4a98-a91a-052dffe40588",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = clustered_df[[\"l_id\",\"txt\",\"td_clusterid_kmeans\"]]\n",
    "final_df[final_df.td_clusterid_kmeans == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935ab7b1-72f7-461f-9535-efa0df784bb2",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>5. Visualization</b>\n",
    "\n",
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial'>5.1 WordCloud Visualization</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c078c8ac-b559-48c0-8ef0-68e7479691de",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Let's visualize all the clusters through wordcloud visualization.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef151e0b-5708-49d9-ad70-11599d0704ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Cloud all those clusters\n",
    "for i in range(0, num_clusters):\n",
    "    filtered_df = final_df[final_df.td_clusterid_kmeans == i]\n",
    "    df = filtered_df.to_pandas()\n",
    "    total_rows = len(df)\n",
    "\n",
    "    sw = ['x','xx','xxx','xxxx','xxxxx','xxxxxx']\n",
    "    es = list(set(stopwords.words('english')))\n",
    "    es.extend(sw)\n",
    "\n",
    "    text_tokens = word_tokenize(' '.join(df['txt']),preserve_line=True)\n",
    "    l_text_tokens = [item.lower() for item in text_tokens]\n",
    "    tokens_without_sw = [word for word in l_text_tokens if word not in es]\n",
    "\n",
    "    all_text = pd.Series(tokens_without_sw)\n",
    "\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,4))\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_text)\n",
    "\n",
    "    col_sum = tfidf_matrix.sum(axis=0).A.squeeze()\n",
    "    k = 5\n",
    "    top_indices = np.argsort(col_sum)[-k:][::-1]\n",
    "\n",
    "    dense = tfidf_matrix.todense()\n",
    "    df = pd.DataFrame(dense, columns=vectorizer.get_feature_names_out())\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    top_terms = feature_names[top_indices]\n",
    "    cluster_name = '_'.join(top_terms).upper()\n",
    "\n",
    "    print(\"Cluster #\" + str(i)+\": \"+cluster_name+\"\\n # of Rows: \"+str(total_rows)+\"\\n\")\n",
    "    # Generate a word cloud\n",
    "    wordcloud = WordCloud(width=800, \\\n",
    "                          height=400, \\\n",
    "                          background_color='white',\\\n",
    "                          collocations=True,\\\n",
    "                          max_words=100,\\\n",
    "                          min_word_length=1, \\\n",
    "                         ).generate_from_frequencies(df.T.sum(axis=1))\n",
    "\n",
    "    # Plot the word cloud\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='gaussian')\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud for Text Data (TF-IDF)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b18331-766e-43b1-baae-f16a782c10fe",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'> \n",
    "\n",
    "<p style='font-size:18px;font-family:Arial'><b>5.2 Visualization of Clusters with Complaints</b></p> \n",
    "\n",
    "<p style='font-size:16px;font-family:Arial'>The graph displays the clustering of complaints into distinct groups. Based on the analysis, the data has been divided into 5 optimal clusters, each representing a unique pattern or category of complaints. This clustering approach helps to identify the key areas or types of complaints that are most prevalent, allowing for more targeted investigation and resolution efforts.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1137fab0-1d7f-4029-a14b-489e5ae5efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb = DataFrame('kmeans_features').to_pandas()\n",
    "clus = clustered_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c63aeb0-ff9a-497f-8622-c67403e474b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=123)\n",
    "tsne_result = tsne.fit_transform(clus.iloc[:, 3:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c7d20-11de-446e-9014-5b7450b65269",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df = pd.DataFrame(tsne_result, columns=['tsne_1', 'tsne_2'])\n",
    "tsne_df['cluster_id'] = clus['td_clusterid_kmeans']\n",
    "tsne_df['complaint_id'] = clus['l_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00109dac-bcf0-4fa7-b228-e076ef4a64ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = 'notebook' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1172672-bf05-4077-ac21-ae1038b81a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame combining t-SNE results with complaint information\n",
    "tsne_complaint_df = pd.DataFrame(tsne_result, columns=['tsne_1', 'tsne_2'])\n",
    "tsne_complaint_df['cluster_id'] = clus['td_clusterid_kmeans']\n",
    "tsne_complaint_df['complaint_id'] = clus['l_id']\n",
    "tsne_complaint_df['complaint'] = clus['txt']\n",
    "\n",
    "# Truncate text for hover data\n",
    "max_chars = 50  # Maximum characters to display\n",
    "tsne_complaint_df['truncted_complaint'] = clus['txt'].apply(lambda x: x[:max_chars] + '...' if len(x) > max_chars else x)\n",
    "\n",
    "# Plot using Plotly Express\n",
    "fig = px.scatter(tsne_complaint_df, x='tsne_1', y='tsne_2', color='cluster_id',\n",
    "                 hover_data=['complaint_id', 'truncted_complaint', 'cluster_id'])\n",
    "\n",
    "fig.update_traces(marker=dict(size=15))\n",
    "fig.update_layout(\n",
    "    title='t-SNE Visualization of Clusters with Complaints',\n",
    "    xaxis_title='dimension-1',\n",
    "    yaxis_title='dimension-2',\n",
    "    xaxis=dict(tickangle=45),\n",
    "    width=1000,\n",
    "    height=800,\n",
    "    hoverlabel=dict(\n",
    "        bgcolor=\"white\",\n",
    "        font_size=16,\n",
    "        font_family=\"Rockwell\"\n",
    "    ),\n",
    "    autosize=False,\n",
    ")\n",
    "\n",
    "# Customize the hovertemplate\n",
    "fig.update_traces(hovertemplate=\"<b>Complaint ID:</b> %{customdata[0]}<br>\"\n",
    "                                 \"<b>Complaint:</b> %{customdata[1]}<br>\"\n",
    "                                 \"<b>Cluster ID:</b> %{customdata[2]}<br><extra></extra>\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cf8020-c8c9-4ff1-85e5-30a467a2e572",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>Conclusion</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this demo we have seem that how we can run HuggingFace Embedding Model (BAAI/bge-small-1.5) in ONNX format and run it in database parallelly to create embeddings. We have done KMeans Clustering to group similar complaints.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c55b0d-6159-4a8c-a3c2-e87df578fbfc",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>6. Cleanup</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c47c2b-7d73-4237-95b9-a2c7c04a4947",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b057f0da-0043-472d-b762-8bcd1b8404bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_ComplaintAnalysis');\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae18ad9-9836-46a0-9810-f42e9ef5c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08206109-4d2a-4a7f-a169-c60709384d05",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; border-bottom:3px solid #91A0Ab\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2024,2025. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
