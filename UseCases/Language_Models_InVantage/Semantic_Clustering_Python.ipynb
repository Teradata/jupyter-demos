{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df79517-1e4f-420a-b7e3-fbb2bb44009d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Semantic Clustering using Open Source Language Models in Database\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683b88c6-5ced-4e58-9e41-a3c78606ec02",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Introduction:</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Semantic Clustering measures the degree to which two pieces of text relate in meaning, regardless of the exact wording. This captures relationships between words, sentences, or documents in ways that traditional keyword-based methods might miss.</p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "            <li><strong>Information Retrieval:</strong> Improves search engines by retrieving documents or results that are semantically related to the user's query.</li>\n",
    "            <li><strong>Text Classification:</strong> Categorizes text into predefined classes based on meaning, useful in spam detection, sentiment analysis, etc.</li>\n",
    "            <li><strong>Question Answering:</strong> Matches questions to relevant answers by understanding their meaning.</li>\n",
    "            <li><strong>Recommendation Systems:</strong> Suggests items (like products or content) based on similarity in user preferences or behaviors.</li>\n",
    "            <li><strong>Plagiarism Detection:</strong> Identifies copied content even if paraphrased</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Why Vantage?</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    Teradata’s integration with <b>LLMs and hosting capabilities in-DB</b>, along with the Open Analytics Framework, would enable customers to run NLP models at scale. The key challenges noted for on-prem customers—such as data movement latency and lack of access to cloud models—are valid. By bringing language models within Vantage, Teradata can provide a significant advantage to on-prem customers by allowing them to run NLP models without needing to move large amounts of data to and from external services.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a628f056-dbee-4ec4-a5d4-b7a860cbaa80",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Downloading and installing additional software needed</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a325ffa-f4ab-44fb-b729-adeaf9e9df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install wordcloud nltk --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc16152-9448-4b1c-a398-7a3a94bac040",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install --force-reinstall pillow --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5639a5-1b8c-4001-8f20-45221b039f6e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note: </b><i>The above libraries have to be installed. Restart the kernel after executing these cells to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing <b> 0 0</b></i> (zero zero) and pressing <i>Enter</i>.</p>\n",
    "</div>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18116bca-b8af-4360-bf4a-a420451777b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Data manipluation and Visualization libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# Teradata libraries\n",
    "from teradataml import (\n",
    "    create_context, \n",
    "    delete_byom, \n",
    "    display,\n",
    "    execute_sql,\n",
    "    save_byom,\n",
    "    remove_context,\n",
    "    in_schema,\n",
    "    KMeans,\n",
    "    DataFrame,\n",
    "    db_drop_table,\n",
    "    db_drop_view\n",
    ")\n",
    "display.max_rows = 5\n",
    "\n",
    "# NLP libraries\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "# machine learning libraries\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d689b8-787e-470c-820d-2d794d92ccf1",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>1. Initiate a connection to Vantage</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>You will be prompted to provide the password. Enter your password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e801c-31af-48bc-af16-0f150cec7c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08236876-6758-45ef-b1ea-cfac6f0668fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=Language_Model_SemanticClustering.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039fbd7c-8dc2-4508-8216-492ee83c59d8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded1b2e3-5391-4025-8428-093b4ecfff56",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We have provided data for this demo on cloud storage. You can either run the demo using foreign tables to access the data without any storage on your environment or download the data to local storage, which may yield faster execution. Still, there could be considerations of available storage. Two statements are in the following cell, and one is commented out. You may switch which mode you choose by changing the comment string.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16973665-4402-466e-bd51-8b3e279bb866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ../run_procedure.py \"call get_data('DEMO_ComplaintAnalysis_cloud');\"        # Takes 1 minute\n",
    "%run -i ../run_procedure.py \"call get_data('DEMO_ComplaintAnalysis_local');\"        # Takes 2 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05175b33-b1a0-4292-ad58-a155c0892491",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Next is an optional step – if you want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e6f604-ef55-4503-88ac-7dd584fbd601",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39506f3-d7ce-4301-b756-cacebd2621fe",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>2. Confirmation for functions</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Before starting let us confirm that the required functions are installed.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f458c7-d659-41d2-b455-8e77244599a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "df_check= DataFrame.from_query('''select count(*) as cnt from dbc.tablesV where databasename = 'ivsm';''')\n",
    "if df_check.get_values()[0][0] >= 10:\n",
    "    print('Functions are installed, please continue.')\n",
    "else:\n",
    "    print('Functions are not installed, please go to Instalization notebook before proceeding further')\n",
    "    display(Markdown(\"[Initialization Notebook](./Initialization_and_Model_Load.ipynb)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d755479-839b-4c36-b6f9-6d3026bd9abb",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>3. Create the Embeddings</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22728822-81f3-412f-b1d8-dd9e20314bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tdf = DataFrame(in_schema('DEMO_ComplaintAnalysis', 'consumer_complaints'))\n",
    "tdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33261854-6678-4d64-86f0-1c9e6ff2b9ac",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>3.1 Creation of the view with tokenized original texts</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555acbe1-e959-4fa5-aff5-f886fc126447",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This code creates a view named <code>v_complaints_tokenized_for_embeddings</code> that contains tokenized consumer complaint data for embedding purposes. It selects the <code>id</code>, <code>txt</code> (complaint text), <code>input_ids</code> (tokenized representations), and <code>attention_mask</code> from a tokenization function <code>ivsm.tokenizer_encode</code>.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11cdbe4-e229-4394-9f78-592f2eba50c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_sql(\"\"\"\n",
    "REPLACE VIEW v_complaints_tokenized_for_embeddings AS (\n",
    "  SELECT \n",
    "    id, \n",
    "    txt, \n",
    "    IDS AS input_ids, \n",
    "    attention_mask \n",
    "  FROM \n",
    "    ivsm.tokenizer_encode(\n",
    "      ON (\n",
    "        SELECT \n",
    "          top 1000 complaint_id AS id, \n",
    "          consumer_complaint_narrative AS txt \n",
    "        FROM \n",
    "          DEMO_ComplaintAnalysis.Consumer_Complaints\n",
    "      ) ON (\n",
    "        SELECT \n",
    "          model AS tokenizer \n",
    "        FROM \n",
    "          embeddings_tokenizers \n",
    "        WHERE \n",
    "          model_id = 'bge-small-en-v1.5'\n",
    "      ) DIMENSION\n",
    "      USING \n",
    "          ColumnsToPreserve('id', 'txt')\n",
    "          OutputFields('IDS', 'ATTENTION_MASK')\n",
    "          MaxLength(1024)\n",
    "          PadToMaxLength('True')\n",
    "          TokenDataType('INT64')\n",
    "    ) a\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc5cafc-c1f8-45c8-8f19-51384411f4e9",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>3.2 Creation of the view with calculated binary embeddings</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba897e85-f7b5-4281-92d5-d24f5c6a1a09",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This code creates a view named <code>complaints_embeddings</code> that stores the computed embeddings (vector representations) of consumer complaint texts. The embeddings are generated using the <code>ivsm.IVSM_score</code> function, which scores/tokenizes input data based on a specific model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c54badc-3660-42fc-9c8f-ca746473a805",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_sql(\"\"\"\n",
    "REPLACE VIEW complaints_embeddings AS (\n",
    "  SELECT \n",
    "    * \n",
    "  FROM \n",
    "    ivsm.IVSM_score(\n",
    "      ON v_complaints_tokenized_for_embeddings ON (\n",
    "        SELECT \n",
    "          * \n",
    "        FROM \n",
    "          embeddings_models \n",
    "        WHERE \n",
    "          model_id = 'bge-small-en-v1.5'\n",
    "      ) dimension\n",
    "      USING \n",
    "          ColumnsToPreserve('id', 'txt')\n",
    "          ModelType('ONNX')\n",
    "          BinaryInputFields('input_ids', 'attention_mask')\n",
    "          BinaryOutputFields('sentence_embedding')\n",
    "          Caching('inquery')\n",
    "    ) a\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ac7184-1e6f-4ac2-a7de-6ea4df50edef",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>3.3 Creating Final Embeddings table</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In this last step we will create embeddings table creating a column for each embedding essentially converting an array to separate columns.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536ae863-e6d5-4412-85bd-b76636a91572",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b> Do you want to generate the embeddings?</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Generating embeddings will take around <b>10-15 minutes.</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We have already generated embeddings for the Consumer_Complaints and stored them in <b>Vantage</b> table.</p>\n",
    " \n",
    "<center><img src=\"images/decision_emb_gen_cmt.svg\" alt=\"embeddings_decision\" width=300 height=400/></center>\n",
    " \n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Note: If you would like to skip the embedding generation step to save the time and move quickly to next step, please enter \"No\" in the next prompt.</b></i></p>\n",
    "</div>\n",
    " \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>To save time, you can move to the already generated embeddings section. However, if you would like to see how we generate the embeddings, or if you need to generate the embeddings for a different dataset, then continue to the following section.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bfa2f9-ecef-4991-82d2-05977ae11e6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Request user's input\n",
    "generate = input(\"Do you want to generate embeddings? ('yes'/'no'): \")\n",
    "\n",
    "# Check the user's input\n",
    "if generate.lower() == 'yes':\n",
    "    print(\"\\nGreat! We'll start by generating embeddings.\")\n",
    "\n",
    "    print(\"\\nGenerating embeddings and Saving to the database, please wait...\")\n",
    "    start = time.time()\n",
    "\n",
    "    qry=(\"\"\"\n",
    "    CREATE multiset TABLE complaints_embeddings_store AS (\n",
    "      SELECT \n",
    "        * \n",
    "      FROM \n",
    "        ivsm.vector_to_columns(\n",
    "          ON complaints_embeddings \n",
    "        USING \n",
    "          ColumnsToPreserve('id', 'txt') \n",
    "          VectorDataType('FLOAT32')\n",
    "          VectorLength(384) \n",
    "          OutputColumnPrefix('emb_')\n",
    "          InputColumnName('sentence_embedding')\n",
    "        ) a\n",
    "    ) WITH DATA PRIMARY index(id)\n",
    "    \"\"\")\n",
    "\n",
    "    try:\n",
    "        start = time.time()\n",
    "        execute_sql(qry)\n",
    "        end = time.time()\n",
    "        print('Table Created')\n",
    "        print(\"Total time to run tokenization+embeddings took = \",(end-start)/60, \" min on 2nodes 4Amp VM\")\n",
    "        tdf_embeddings_store = DataFrame('complaints_embeddings_store')\n",
    "        \n",
    "        \n",
    "    except:\n",
    "        db_drop_table('complaints_embeddings_store')\n",
    "        start = time.time()\n",
    "        execute_sql(qry)\n",
    "        end = time.time()\n",
    "        print('Table Created')\n",
    "        print(\"Total time to run tokenization+embeddings took = \",(end-start)/60, \" min on 2nodes 4Amp VM\")\n",
    "        tdf_embeddings_store = DataFrame('complaints_embeddings_store')\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(f\"Total time to run tokenization+embeddings on {tdf_embeddings_store.shape[0]} rows = \", (end-start)/60, \" min\")\n",
    "\n",
    "elif generate.lower() == 'no':\n",
    "    tdf_embeddings_store = DataFrame('\"DEMO_ComplaintAnalysis\".\"Complaints_Embeddings_Store\"')\n",
    "    print(\"\\nLoaded embeddings from the Vantage table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763261bd-d95b-47b7-ba7c-8a5eb7f3c636",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_embeddings_store.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ac23c0-8ecf-412c-b504-3b7a91a38644",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>4. Run K-Means on the Embeddings Store and then build final table with Cluster ID assignments to rows</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680e433a-ff47-495f-8c97-7601c300851c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The K-means() function groups a set of observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid). This algorithm minimizes the objective function, that is, the total Euclidean distance of all data points from the center of the cluster</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daac7e03-f0c7-4d6b-b6de-a1dfbc862556",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_column_list = [col for col in tdf_embeddings_store.columns if col not in [\"id\", \"txt\"]]\n",
    "\n",
    "num_clusters = 4\n",
    "kmeans_out = KMeans(\n",
    "    id_column=\"id\",\n",
    "    data=tdf_embeddings_store,\n",
    "    target_columns=embedding_column_list,\n",
    "    output_cluster_assignment=True,\n",
    "    num_init=10,\n",
    "    num_clusters=num_clusters,\n",
    "    iter_max=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac0e6a6-8947-40a0-afcc-786d6388e0ed",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The output below shows cluster assignment for each row.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa7f4f1-57f9-4d57-aefe-46eec5c989a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_out.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda2b439-13b2-4894-bd4f-96bd5162cdd7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Let's check how many data points each cluster has.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e985c8d7-92b3-4bdd-9d12-27305978f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_df = kmeans_out.result\n",
    "d2 = kmeans_df.groupby('td_clusterid_kmeans').count()\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c734da84-4a5c-49ac-9245-06f822b81110",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_df = tdf_embeddings_store.join(\n",
    "    other = kmeans_df,\n",
    "    on = [\"id\"],\n",
    "    how = \"inner\",\n",
    "    lprefix=\"l\",\n",
    "    rprefix=\"r\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a7b547-5af5-4898-8e5b-cb301ac307b7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Let's check a sample of data points from cluster number 2.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539d2d74-3e22-4a98-a91a-052dffe40588",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = clustered_df[[\"l_id\",\"txt\",\"td_clusterid_kmeans\"]]\n",
    "final_df[final_df.td_clusterid_kmeans == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935ab7b1-72f7-461f-9535-efa0df784bb2",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>5. Visualization</b>\n",
    "\n",
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>5.1 WordCloud Visualization</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c078c8ac-b559-48c0-8ef0-68e7479691de",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Let's visualize all the clusters through wordcloud visualization.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef151e0b-5708-49d9-ad70-11599d0704ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Cloud all those clusters\n",
    "for i in range(0, num_clusters):\n",
    "    filtered_df = final_df[final_df.td_clusterid_kmeans == i]\n",
    "    df = filtered_df.to_pandas()\n",
    "    total_rows = len(df)\n",
    "\n",
    "    sw = ['x','xx','xxx','xxxx','xxxxx','xxxxxx']\n",
    "    es = list(set(stopwords.words('english')))\n",
    "    es.extend(sw)\n",
    "\n",
    "    text_tokens = word_tokenize(' '.join(df['txt']),preserve_line=True)\n",
    "    l_text_tokens = [item.lower() for item in text_tokens]\n",
    "    tokens_without_sw = [word for word in l_text_tokens if word not in es]\n",
    "\n",
    "    all_text = pd.Series(tokens_without_sw)\n",
    "\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,4))\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_text)\n",
    "\n",
    "    col_sum = tfidf_matrix.sum(axis=0).A.squeeze()\n",
    "    k = 5\n",
    "    top_indices = np.argsort(col_sum)[-k:][::-1]\n",
    "\n",
    "    dense = tfidf_matrix.todense()\n",
    "    df = pd.DataFrame(dense, columns=vectorizer.get_feature_names_out())\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    top_terms = feature_names[top_indices]\n",
    "    cluster_name = '_'.join(top_terms).upper()\n",
    "\n",
    "    print(\"Cluster #\" + str(i)+\": \"+cluster_name+\"\\n # of Rows: \"+str(total_rows)+\"\\n\")\n",
    "    # Generate a word cloud\n",
    "    wordcloud = WordCloud(width=800, \\\n",
    "                          height=400, \\\n",
    "                          background_color='white',\\\n",
    "                          collocations=True,\\\n",
    "                          max_words=100,\\\n",
    "                          min_word_length=1, \\\n",
    "                         ).generate_from_frequencies(df.T.sum(axis=1))\n",
    "\n",
    "    # Plot the word cloud\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='gaussian')\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud for Text Data (TF-IDF)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b18331-766e-43b1-baae-f16a782c10fe",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'> \n",
    "\n",
    "<p style='font-size:18px;font-family:Arial;color:#00233c'><b>5.2 Visualization of Clusters with Complaints</b></p> \n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;color:#00233c'>The graph displays the clustering of complaints into distinct groups. Based on the analysis, the data has been divided into 5 optimal clusters, each representing a unique pattern or category of complaints. This clustering approach helps to identify the key areas or types of complaints that are most prevalent, allowing for more targeted investigation and resolution efforts.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1137fab0-1d7f-4029-a14b-489e5ae5efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb = DataFrame('kmeans_features').to_pandas()\n",
    "clus = clustered_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c63aeb0-ff9a-497f-8622-c67403e474b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=123)\n",
    "tsne_result = tsne.fit_transform(clus.iloc[:, 3:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c7d20-11de-446e-9014-5b7450b65269",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df = pd.DataFrame(tsne_result, columns=['tsne_1', 'tsne_2'])\n",
    "tsne_df['cluster_id'] = clus['td_clusterid_kmeans']\n",
    "tsne_df['complaint_id'] = clus['l_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1172672-bf05-4077-ac21-ae1038b81a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame combining t-SNE results with complaint information\n",
    "tsne_complaint_df = pd.DataFrame(tsne_result, columns=['tsne_1', 'tsne_2'])\n",
    "tsne_complaint_df['cluster_id'] = clus['td_clusterid_kmeans']\n",
    "tsne_complaint_df['complaint_id'] = clus['l_id']\n",
    "tsne_complaint_df['complaint'] = clus['txt']\n",
    "\n",
    "# Truncate text for hover data\n",
    "max_chars = 50  # Maximum characters to display\n",
    "tsne_complaint_df['truncted_complaint'] = clus['txt'].apply(lambda x: x[:max_chars] + '...' if len(x) > max_chars else x)\n",
    "\n",
    "# Plot using Plotly Express\n",
    "fig = px.scatter(tsne_complaint_df, x='tsne_1', y='tsne_2', color='cluster_id',\n",
    "                 hover_data=['complaint_id', 'truncted_complaint', 'cluster_id'])\n",
    "\n",
    "fig.update_traces(marker=dict(size=15))\n",
    "fig.update_layout(\n",
    "    title='t-SNE Visualization of Clusters with Complaints',\n",
    "    xaxis_title='dimension-1',\n",
    "    yaxis_title='dimension-2',\n",
    "    xaxis=dict(tickangle=45),\n",
    "    width=1000,\n",
    "    height=800,\n",
    "    hoverlabel=dict(\n",
    "        bgcolor=\"white\",\n",
    "        font_size=16,\n",
    "        font_family=\"Rockwell\"\n",
    "    ),\n",
    "    autosize=False,\n",
    ")\n",
    "\n",
    "# Customize the hovertemplate\n",
    "fig.update_traces(hovertemplate=\"<b>Complaint ID:</b> %{customdata[0]}<br>\"\n",
    "                                 \"<b>Complaint:</b> %{customdata[1]}<br>\"\n",
    "                                 \"<b>Cluster ID:</b> %{customdata[2]}<br><extra></extra>\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cf8020-c8c9-4ff1-85e5-30a467a2e572",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Conclusion</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In this demo we have seem that how we can run HuggingFace Embedding Model (BAAI/bge-small-1.5) in ONNX format and run it in database parallelly to create embeddings. We have done KMeans Clustering to group similar complaints.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c55b0d-6159-4a8c-a3c2-e87df578fbfc",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>6. Cleanup</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8710e68-dd46-4115-9ec3-928588b803bc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Cleanup work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f170503-df80-49cd-a85e-8417619f54ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['complaints_embeddings_store']\n",
    "\n",
    "# Loop through the list of tables and execute the drop table command for each table\n",
    "for table in tables:\n",
    "    try:\n",
    "        db_drop_table(table_name=table)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "views = ['v_complaints_tokenized_for_embeddings','complaints_embeddings']\n",
    "\n",
    "for view in views:\n",
    "    try:\n",
    "        db_drop_view(view_name=view)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c47c2b-7d73-4237-95b9-a2c7c04a4947",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b057f0da-0043-472d-b762-8bcd1b8404bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_ComplaintAnalysis');\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae18ad9-9836-46a0-9810-f42e9ef5c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08206109-4d2a-4a7f-a169-c60709384d05",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2024. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
