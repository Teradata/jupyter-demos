{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d7b831-249f-4775-9d56-d9d9aec81f54",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       RAG solution with Embedding/Chunking in Vantage and AWS Bedrock integration\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Introduction</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this demo we will explore how to do chunk PDFs, run embedding, try vector db style indexing in Vantage and than query LLM with context/prompts after semantic search</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>We use ONNXEmbeddings function for creating embeddings using the Hugging Face PyTorch models stored inDb using the BYOM functionality.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Teradata has Integration with LLMs with Amazon BedRock etc., and also emerging Open Analytics Framework in the Cloud Lake, where you can host a Language Model etc.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>LLMs are a key artificial intelligence (AI) technology powering intelligent chatbots and other natural language processing (NLP) applications. The goal is to create bots that can answer user questions in various contexts by cross-referencing authoritative knowledge sources. Unfortunately, the nature of LLM technology introduces unpredictability in LLM responses. Additionally, LLM training data is static and introduces a cut-off date on the knowledge it has.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Known challenges of LLMs include:</p>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial'>Presenting false information when it does not have the answer.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Presenting out-of-date or generic information when the user expects a specific, current response.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Creating a response from non-authoritative sources.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Creating inaccurate responses due to terminology confusion, wherein different training sources use the same terminology to talk about different things.</li>\n",
    "</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>RAG is one approach to solving some of these challenges. It redirects the LLM to retrieve relevant information from authoritative, pre-determined knowledge sources. Organizations have greater control over the generated text output, and users gain insights into how the LLM generates the response.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this demo, we will work with some PDF parsing and chunking with a Teradata SEC-10K PDF/LLM to answer prompts.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d10764-d095-45bb-9017-f4d599a74414",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;'>\n",
    "<b style = 'font-size:20px;font-family:Arial'>1. Configuring the environment</b>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>1.1 Install the required libraries</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc66e62d-a6d2-4af8-9802-004bbfb2de7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langchain_community pypdf\n",
    "!pip install boto3 awscli\n",
    "!pip install pyopenssl --upgrade --force-reinstall\n",
    "!pip install -U pandas==2.1.3\n",
    "!pip install langchain\n",
    "!pip install langchain_text_splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b214bd0-c408-48cb-9ec2-b843eafa7207",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Note: </b><i>Please restart the kernel after executing these two lines. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4e6f39-2b02-465a-aa33-b3c2d36bc327",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>1.2 Import the required libraries</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4228628-d8bb-459c-bdfc-4088902a57ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from teradataml import *\n",
    "import getpass\n",
    "\n",
    "configure.byom_install_location = \"mldb\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import display, Markdown\n",
    " \n",
    "display.max_rows=5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539c3596-bc64-45b2-a828-53fd8228177b",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>1.3. Connect to Vantage</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell. Begin running steps with Shift + Enter keys.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01baa577-2526-405a-90f0-a1977a20a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host='host.docker.internal', username='demo_user', password=password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4e462d-9e75-47f5-b281-6c171b0c4345",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql(\"SET query_band='DEMO=Language_Model_RAG_PDF_Python.ipynb;' UPDATE FOR SESSION;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6917041c-b7f7-428e-93de-6a8f16d08ee6",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>2. Confirmation for Model</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Before starting let us confirm that the required functions are installed.</p>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe73ea9a-646e-4cca-80f1-e1aab848e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bge-small-en-v1.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f08f5be-0504-4c2c-9c09-44edd6dfc2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "df_check= DataFrame.from_query(f'''select (select 1 as cnt from embeddings_models where model_id = '{model_name}') +\n",
    "(select 1 as cnt from embeddings_tokenizers where model_id =  '{model_name}') as cnt''')\n",
    "if df_check.get_values()[0][0] == 2:\n",
    "    print('Model is installed, please continue.')\n",
    "else:\n",
    "    print('Model is not installed, please go to Instalization notebook before proceeding further')\n",
    "    display(Markdown(\"[Initialization Notebook](./Initialization_and_Model_Load.ipynb)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4c15a4-a3bd-4bcb-98e7-efced66c3424",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>3. Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have provided data for this demo on cloud storage. Since we are using embeddings stored in Vantage for this demo we are only using the local storage for the demo. We will only use the option of creating table locally.</p>   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6b94e0-bb25-46a2-a6a9-5eedaa1d39a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call get_data('DEMO_SLM_RAG_local');\"\n",
    " # Takes about 2 minutes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad64b842-fd24-44f2-8e20-f35150e56299",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Optional step – We should execute the below step only if we want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2ba64d-11f6-4fb5-a52f-51cb6f379955",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88494f15-4d3b-466e-bde7-9d458032b3e8",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>4. Parse PDF and Create Chunks</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here we will parse the PDF which is available to us in the left pane: <b>Teradata-sec10k.pdf</b>. Then we will use the <b>RecursiveCharacterTextSplitter</b> from langchain package. This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text. The text is split by list of characters and the chunk size is measured by number of characters.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a9d870-dfde-4b37-9e5a-c63ac31c891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC_PATH = \"./Teradata-sec10k.pdf\"\n",
    "\n",
    "# load your pdf doc\n",
    "loader = PyPDFLoader(DOC_PATH)\n",
    "pages = loader.load()\n",
    "\n",
    "\n",
    "# split the doc into smaller chunks i.e. chunk_size=500\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=75)\n",
    "chunks = text_splitter.split_documents(pages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1e741c-f9cd-445c-b42a-645271e1553f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>From the chunks created we will extract the text and create a dataframe from the extracted texts.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a268ad-e48e-4c6f-94ab-38c24edccab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract chunk info to a Dataframe with a column named 'txt'\n",
    "\n",
    "df = pd.DataFrame(chunks)\n",
    "df['junk'], df['txt'] = zip(*df[2])\n",
    "df['txt'] = df['txt'].astype(str)\n",
    "df = df['txt']\n",
    "#df = df.replace(r'\\n',' ', regex=True)\n",
    "df = df.reset_index(drop=True).to_frame(name='txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c5a05-8642-4ccc-8244-f21e2b9d1b63",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We will load these texts in a Vantage table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69143a77-e612-4e7b-aede-0b43566b4f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the chunks to the table called 'pdf_contents'\n",
    "copy_to_sql(df, table_name='pdf_contents', index=True, if_exists='replace')\n",
    "\n",
    "# Fix the id column\n",
    "execute_sql(\"ALTER TABLE pdf_contents rename index_label to id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc26f0d-d66a-4dee-9840-8e72caf61a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame('pdf_contents')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb7dce8-4a9f-4631-8807-0a985eaf4d35",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>5. Generate embeddings from the chunks</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>First we will create embediings from the pdf document, then we will create prompts for different questions that can be answered from the document.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9e18e4-a9da-41e5-9856-052492c4671f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "Now it's time to generate the embeddings using <b>ONNXEmbeddings</b>.<br>We run the ONNXEmbeddings function to generate embeddings for a small subset of records. The model is <b>loaded into the cache memory on each node</b>, and Teradata's <b>Massively Parallel Processing (MPP)</b> architecture ensures that embeddings are computed in parallel using <b>ONNX Runtime</b> on each node.  <br>Having said that, generating embeddings for the entire training set can be time-consuming, especially when working on a system with limited resources. In the <b>ClearScape Analytics experience</b>, only a <b>4 AMP system</b> with constrained RAM and CPU power is available. To ensure smooth execution, we test embedding generation on a small sample and use <b>pre-calculated embeddings</b> for the remainder of demo. In a real-life scenario you would tyipically encounter multiple hundred AMPs with much more compute power!<br>Also have a look at the most important input parameters of this <b>ONNXEmbeddings</b> function.\n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "<li><b>InputTable</b>: The source table containing the text to be embedded. </li>\n",
    "<li><b>ModelTable</b>: The table storing the ONNX model.                    </li>\n",
    "<li><b>TokenizerTable</b>: The table storing the tokenizer JSON file.       </li>\n",
    "<li><b>Accumulate</b>: Specifies additional columns to retain in the output </li>  \n",
    "<li><b>OutputFormat</b>: Specifies the data format of the output embeddings (<b>FLOAT32(354)</b>, matching the model's output dimension).</li>\n",
    "</ul>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "Since embedding generation is computationally expensive, we only process <b>100 records for testing</b> and rely on precomputed embeddings for further analysis.  \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be4d1e4-6d2c-4108-8968-c831f453afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = DataFrame.from_query(f\"select * from embeddings_models where model_id = '{model_name}'\")\n",
    "my_tokenizer = DataFrame.from_query(f\"select model as tokenizer from embeddings_tokenizers where model_id = '{model_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a42a218-4a0e-434a-abff-edeb31feff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.iloc[:100, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246e4c2a-e988-4b36-b575-e6fe6148f76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_dimensions_output = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34820cf-acf4-4d61-aec3-5b985ee426bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_embeddings_sample = ONNXEmbeddings(\n",
    "    newdata = df_sample,\n",
    "    modeldata = my_model, \n",
    "    tokenizerdata = my_tokenizer, \n",
    "    accumulate = [\"id\", \"txt\"],\n",
    "    model_output_tensor = \"sentence_embedding\",\n",
    "    output_format = f'FLOAT32({number_dimensions_output})',\n",
    "    enable_memory_check = False\n",
    ").result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d565401-e672-4686-834f-41af396c72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_embeddings_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507fca86-ae6f-4810-b39a-b75f14e63aa8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'> Here we can see how the embeddings are generated for the chunks of pdf document. For further analysis we will use the precomputed embeddings.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f638047c-f6f7-4e79-9f81-630ec02b3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emb = DataFrame(in_schema(\"DEMO_SLM_RAG\",\"Pdf_Embedding_Data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7ec437-e0ce-4f67-8aad-a7a4f7de9064",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>6. Insert Prompts into a Table</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceade411-5a69-46b3-b2e1-7e50da961d45",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We will create the required table and than we will insert different values for the prompts.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e319d050-6735-4838-b7a9-703c6071c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = '''CREATE MULTISET TABLE pdf_topics_of_interest(\n",
    "      txt VARCHAR(1024) CHARACTER SET UNICODE NOT CASESPECIFIC,\n",
    "      id INT) NO PRIMARY INDEX''' ;\n",
    "try:\n",
    "    execute_sql(qry)\n",
    "except:\n",
    "    db_drop_table('pdf_topics_of_interest')\n",
    "    execute_sql(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e396f9b4-576d-4a62-aae9-86cdbb1520df",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We will create prompts for different questions that can be answered from the document. Below are some sample questions that can be asked.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b50dc0-95e8-443f-87b9-27d538a32388",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\"What is this document about ? Which company is this document for ?\",\n",
    "           \"Where is Teradata HQ located ? Which countries are Teradata has offices ?\",\n",
    "           \"What is the annual revenue of Teradata and when does the fiscal year end ?\",\n",
    "           \"What products does Teradata sell ? What is Teradatas business ?\",\n",
    "           \"How does Teradata think about leveraging Artificial Intelligence into its products ? What about Cloud Strategy ?\\\n",
    "Can you explain this both in Spanish and English ?\",\n",
    "           \"What is the revenue breakdown of products sold across different countries/regions ? \\\n",
    "Which countries/regions performed the best ? Format the output in markdown HTML\",\n",
    "           \"Is Teradata profitable ? How ? Whats the secret ?\"]\n",
    "\n",
    "for idx, prompt in enumerate(prompts, start=1):\n",
    "    execute_sql(f'''INSERT into pdf_topics_of_interest values ('{prompt}', {idx});''')\n",
    "    # print(f'''INSERT into pdf_topics_of_interest values ('{prompt}', {idx});''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd7745f-77c9-46d9-8e74-66c323361c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame('pdf_topics_of_interest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba2e5d7-b520-4d58-ade8-5d2dd31e0aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2def5178-aaaa-4443-896c-4895b4bcb1cb",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>7. Generate Embeddings from the Prompts</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We will create embeddings for the prompts which we have inserted into the table above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de763df8-bf2a-48e5-a694-3d3ca2eb49fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_topic_embeddings = ONNXEmbeddings(\n",
    "    newdata = DataFrame('pdf_topics_of_interest'),\n",
    "    modeldata = my_model, \n",
    "    tokenizerdata = my_tokenizer, \n",
    "    accumulate = [\"id\", \"txt\"],\n",
    "    model_output_tensor = \"sentence_embedding\",\n",
    "    output_format = f'FLOAT32({number_dimensions_output})',\n",
    "    enable_memory_check = False\n",
    ").result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3780d81d-30a4-4602-9c68-98e310677092",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(DF_topic_embeddings,table_name='pdf_topics_embeddings_store', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf60e750-76ab-4d37-8a7d-49de9a3adadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame('pdf_topics_embeddings_store')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c38ea0-3aad-4582-82ce-642ad5c07913",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>8. Find top 10 matching chunks</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We will find the top 10 chunks that match the queries using the TD_VectorDistance. The TD_VectorDistance function accepts a table of target vectors and a table of reference vectors and returns a table that contains the distance between target-reference pairs. The function computes the distance between the target pair and the reference pair from the same table. We must have the same column order in the TargetFeatureColumns argument and the RefFeatureColumns argument. The function ignores the feature values during distance computation if the value is either NULL, NAN, or INF.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df3c5b4-bd88-43f4-958f-290c26f942ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry=\"\"\"create multiset table pdf_semantic_search_results\n",
    "as (\n",
    "SELECT \n",
    "    dt.target_id,\n",
    "    dt.reference_id,\n",
    "    e_tgt.txt as target_txt,\n",
    "    e_ref.txt as reference_txt,\n",
    "    (1.0 - dt.distance) as similarity \n",
    "FROM\n",
    "    TD_VECTORDISTANCE (\n",
    "        ON pdf_topics_embeddings_store AS TargetTable\n",
    "        ON DEMO_SLM_RAG.Pdf_Embedding_Data AS ReferenceTable DIMENSION\n",
    "        USING\n",
    "            TargetIDColumn('id')\n",
    "            TargetFeatureColumns('[emb_0:emb_383]')\n",
    "            RefIDColumn('id')\n",
    "            RefFeatureColumns('[emb_0:emb_383]')\n",
    "            DistanceMeasure('cosine')\n",
    "            topk(10)\n",
    "    ) AS dt\n",
    "JOIN pdf_topics_embeddings_store e_tgt on e_tgt.id = dt.target_id\n",
    "JOIN DEMO_SLM_RAG.Pdf_Embedding_Data e_ref on e_ref.id = dt.reference_id\n",
    ") with data;\"\"\"\n",
    "\n",
    "try:\n",
    "    execute_sql(qry)\n",
    "    print('Table Created')\n",
    "except:\n",
    "    db_drop_table('pdf_semantic_search_results')\n",
    "    execute_sql(qry)\n",
    "    print('Table Created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c344b850-fc45-4d79-aae1-cb42f86862cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame('pdf_semantic_search_results').to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e1d3ba-5d34-4ca7-b0d2-2b421d0bde3b",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<a id=\"rule\"></a>\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>9. Create Context and Prompt for LLM</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We will create context and prepare instructions and prompt to the LLM.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870d938b-9710-4dae-af7c-8f84bf068313",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\"Where is Teradata HQ located ? Which countries are Teradata has offices ?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b264eb-e512-4585-ab9e-17a03c6e1aa6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Below are some options available.</p>\n",
    "<li style = 'font-size:16px;font-family:Arial'> prompt = [\"What is this document about ? Which company is this document for ?\"]</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'> prompt = [\"Where is Teradata HQ located ? Which countries are Teradata has offices ?\"]</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'> prompt = [\"What is the annual revenue of Teradata and when does the fiscal year end ?\"]</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'> prompt = [\"What products does Teradata sell ? What is Teradata's business ?\"]</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'> prompt = [\"How does Teradata think about leveraging Artificial Intelligence into its products ? What about Cloud Strategy ? Can you explain this both in Spanish and English ?\"]</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'> prompt = [\"What is the revenue breakdown of products sold across different countries/regions ? \\\n",
    "Which countries/regions performed the best ? Format the output in markdown HTML\"]</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'> prompt = [\"Is Teradata profitable ? How ? Whats the secret ?\"]</li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6770bca6-732f-4302-98ee-9f83a05bfd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = str.join('\\n',df['reference_txt'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082ea00b-e539-466e-b729-1f25e338114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_query = \"Answer the question based only on the following context: \" + context + \\\n",
    "\"Answer the question based on the above context: \" + prompt[0] + \\\n",
    "\"\"\" \n",
    "Provide a detailed answer.\n",
    "Don’t justify your answers.\n",
    "Don’t give information not mentioned in the CONTEXT INFORMATION.\n",
    "Do not say \"according to the context\" or \"mentioned in the context\" or similar.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2104d119-7169-485e-8bf1-d3212ed75ff6",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>10. Configuring AWS CLI and Initialize Bedrock Model</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following cell will prompt us for the following information:</p>\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "<li><b>aws_access_key_id</b>: Enter your AWS access key ID</li>\n",
    "<li><b>aws_secret_access_key</b>: Enter your AWS secret access key</li>\n",
    "<li><b>region name</b>: Enter the AWS region you want to configure (e.g., us-east-1)</li>\n",
    "<ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962a2b83-352f-419c-bc1d-25ce005dbf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Prompt for credentials securely\n",
    "aws_access_key_id = getpass.getpass(\"Enter AWS Access Key ID: \")\n",
    "aws_secret_access_key = getpass.getpass(\"Enter AWS Secret Access Key: \")\n",
    "region_name = getpass.getpass(\"Enter AWS Region (e.g., us-east-1): \")\n",
    "aws_session_token = getpass.getpass(\"Enter AWS Session Token (if any, else leave blank): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d841ce98-844c-4467-8831-2e244f193f19",
   "metadata": {},
   "source": [
    "<b style = 'font-size:18px;font-family:Arial'>Initialize the Bedrock Model</b>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "<li>The code below initializes a Boto3 client for the “bedrock-runtime” service.</li>\n",
    "<li>We provide the model to be used.</li>\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eacd8c-e774-40a0-a9e7-25b4a80a1303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Bedrock Runtime client with user-provided credentials\n",
    "client = boto3.client(\n",
    "    \"bedrock-runtime\",\n",
    "    region_name=region_name,\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    aws_session_token=aws_session_token\n",
    ")\n",
    "\n",
    "\n",
    "# Set the model ID\n",
    "model_id = \"mistral.mistral-7b-instruct-v0:2\"\n",
    "\n",
    "print(\"Bedrock client successfully created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4019d1ba-cdde-4a5b-b1c3-532a551e878d",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>11. Pass the question and get Answer from the PDF</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following cell will pass the question to the llm model and get the answer using the embeddings created from the pdf and the prompts.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e192d77-88a4-49ef-96bb-f5c71dddfc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Prepare the message for the model ----\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [{\"text\": llm_query}]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d481f075-4564-41ed-b2b8-875931210900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Call the model ----\n",
    "try:\n",
    "    response = client.converse(\n",
    "        modelId=model_id,\n",
    "        messages=messages,\n",
    "        inferenceConfig={\"maxTokens\": 100, \"temperature\": 0.2}\n",
    "    )\n",
    "\n",
    "    # ---- Extract and print model response ----\n",
    "    output_text = response['output']['message']['content'][0]['text']\n",
    "    print(\"✅ Model response:\")\n",
    "    print(output_text)\n",
    "\n",
    "except ClientError as e:\n",
    "    print(f\"❌ Error testing client: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9fb1e1-8cec-4b99-919f-88854490fc1a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In case you want to check answer for some other question please enter the question again <a href='#rule'>here</a> and run the following steps again.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd537d9-cfa0-40e5-8f14-5e8806a083c0",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>12. Cleanup</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aabf96-bde5-4d40-9ab3-bb525bfb4ee7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'> <b>Work Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following code will clean up tables created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612fd68c-0db2-40d3-b3ba-5b80ff300355",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['pdf_contents', 'pdf_topics_of_interest','pdf_topics_embeddings_store',\n",
    "          'pdf_semantic_search_results']\n",
    "\n",
    "# Loop through the list of tables and execute the drop table command for each table\n",
    "for table in tables:\n",
    "    try:\n",
    "        db_drop_table(table_name=table)\n",
    "    except:\n",
    "        pass      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775caa6c-3067-4de5-8857-3c38aaa4a97a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1155d0af-0d3a-4247-a97d-13b5f9101267",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_SLM_RAG');\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222c9505-635f-44bf-a379-d6862488a1b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e53bf1c-cbd3-4aca-a174-7f4edbf13c9d",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; border-bottom:3px solid #91A0Ab\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2024. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
