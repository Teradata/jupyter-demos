{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38bc532d-c78c-4c89-b191-242da0733f39",
   "metadata": {},
   "source": [
    "<header style=\"padding:1px;background:#f9f9f9;border-top:3px solid #00b2b1\"><img id=\"Teradata-logo\" src=\"https://www.teradata.com/Teradata/Images/Rebrand/Teradata_logo-two_color.png\" alt=\"Teradata\" width=\"220\" align=\"right\" />\n",
    "\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>Generative Question Answering using Generative AI with Vantage</b>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff71661-19b4-423a-867a-7c815b064c81",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Introduction:</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In the Question-Answering system using Generative AI demo, the combination of <b>RAG, Langchain, and LLM models</b> allows users to ask queries in layman's terms, retrieve relevant information from the Vantage tables, and generate accurate and concise answers based on the retrieved data. This integration of retrieval-based and generative-based approaches provides a powerful tool for extracting knowledge from structured sources and delivering user-friendly responses.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this demo we will build Generative Question-Answering using LangChain, a powerful library for working with LLMs like GPT-3.5, GPT-4, Bloom, etc. and JumpStart in ClearScape notebooks, a system is built where users can ask business questions in natural English and receive answers with data drawn from the relevant databases.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following diagram illustrates the architecture.</p>\n",
    "\n",
    "<center><img src=\"images/vantage_qa_gen.png\" alt=\"Generative_QA_architecture\"  width=800 height=800/></center>\n",
    "\n",
    "<br>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Before going any farther, let's get a better understanding of RAG, LangChain, and LLM.</p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial'><li> <b>Retrieval-Augmented Generation (RAG):</b></li></ul>\n",
    "<p style = 'font-size:16px;font-family:Arial'> &emsp;  &emsp;RAG is a framework that combines the strengths of retrieval-based and generative-based approaches in question-answering systems.It utilizes both a retrieval model and a generative model to generate high-quality answers to user queries. The retrieval model is responsible for retrieving relevant information from a knowledge source, such as a database or documents. The generative model then takes the retrieved information as input and generates concise and accurate answers in natural language.</p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial'><li> <b>Langchain:</b></li></ul>\n",
    "<p style = 'font-size:16px;font-family:Arial'> &emsp;  &emsp; LangChain is a framework that facilitates the integration and chaining of large language models to other tools and sources to build more sophisticated AI applications. Langchain provides a standard way of communicating with a variety of LLM’s including OpenAI and HuggingFace. Langchain leverages state-of-the-art deep learning techniques to comprehend the semantics and context of user queries. It helps process various types of queries, ranging from simple factual questions to complex and nuanced queries.</p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial'><li> <b>LLM Models (Large Language Models):</b></li></ul>\n",
    "<p style = 'font-size:16px;font-family:Arial'> &emsp;  &emsp; LLM models refer to the large-scale language models that are trained on vast amounts of text data.\n",
    "These models, such as GPT-3 (Generative Pre-trained Transformer 3),  GPT-3.5, GPT-4, HuggingFace BLOOM, LLaMA, Google's FLAN-T5, etc. are capable of generating human-like text responses. LLM models have been pre-trained on diverse sources of text data, enabling them to learn patterns, grammar, and context from a wide range of topics. They can be fine-tuned for specific tasks, such as question-answering, natural language understanding, and text generation.\n",
    "LLM models have achieved impressive results in various natural language processing tasks and are widely used in AI applications for generating human-like text responses.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca49b9d-df0b-400a-acf8-0252ab8a2618",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#E37C4D'><b>Steps in the analysis:</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Configuring the environment</li>\n",
    "    <li>Connect to Vantage</li>\n",
    "    <li>Data Exploration</li>\n",
    "    <li>LLM</li>\n",
    "    <li>Run the query function</li>\n",
    "    <li>Cleanup</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833b5bf-74af-42be-8543-3782e1da95dc",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>1. Configuring the environment</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6027a7-888d-441f-abc7-a6ea1c45f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# '%%capture' suppresses the display of installation steps of the following packages\n",
    "\n",
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca97cdce-0d5e-4e54-b404-da7bae24ef51",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "    <i>The above statements will install the required libraries to run this demo. To gain access to installed libraries after running this, restart the kernel.</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b160ce-5ace-4116-86b6-394d6502553b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>To restart the kernel, press the escape key first, then type 0 0.</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61067c88-2e9a-4c92-985b-34dc4ab74a13",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>1.1 Import the required libraries</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50a4aa-1211-44fc-8166-317c35253207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# teradata lib\n",
    "from teradataml import *\n",
    "\n",
    "# LLM\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from langchain import PromptTemplate, SQLDatabase, LLMChain\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "display.max_rows = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59718f8-7af4-4d1a-abc7-a860eb7cbae3",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>2. Connection to Vantage and OpenAI</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4153b889-0924-4e0f-acc8-6b0d440c77b3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>2.1 Get the OpenAI API key</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e10add-4b3c-4fc5-9359-0b44737bba0f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In order to utilize this demo, you will need an OpenAI API key. If you do not have one, please refer to the instructions provided in this guide to obtain your OpenAI API key: </p>\n",
    "\n",
    "[Openai_setup_api_key_guide](..//Openai_setup_api_key/Openai_setup_api_key.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd64269-9393-434a-ac26-0b8386fc0a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your openai api key\n",
    "api_key = input(prompt = '\\n Please Enter Openai api key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60e4d23-3f17-4d43-b9b9-7e125f59b8c7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>2.2 Connect to Vantage</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>You will be prompted to provide the password. Enter your password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164cfc91-93ed-45b9-98ba-73b91a50c28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)\n",
    "eng.execute('''SET query_band='DEMO= Generative_Question_Answering_Python.ipynb;' UPDATE FOR SESSION;''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22db506-84a7-406b-be9f-9fe69d268ba4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beec557-411b-4418-acf3-2f28d3c6beac",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>2.3 Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have provided data for this demo on cloud storage. You can either run the demo using foreign tables to access the data without any storage on your environment or download the data to local storage, which may yield faster execution. Still, there could be considerations of available storage. Two statements are in the following cell, and one is commented out. You may switch which mode you choose by changing the comment string.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e26ca7c-fa9e-4200-8e9e-27f5886aa5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call get_data('DEMO_MarketingCamp_cloud');\"        # Takes 1 minute\n",
    "# %run -i ../run_procedure.py \"call get_data('DEMO_MarketingCamp_local');\"        # Takes 2 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99a16b5-da34-4326-b66b-5f7d5a9d9b04",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Next is an optional step – if you want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79252a5e-b2c1-404a-ae22-6c3d698510c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f3fe2-ed63-4838-bb19-4c0d0157453d",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>3. Data Exploration</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The goal of the Marketing Campaign Effectiveness prediction is to reduce marketing resources by identifying customers who would purchase the product and thereby directing marketing efforts to them.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The data is from the last marketing campaign, with thousands of rows of customer data like age, job, marital status, education, etc.<p/>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Each row is a snapshot of data taken during the last marketing campaign, and each column is a different variable. The input dataset can be divided into three categories, as below:</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'> \n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>customer data i.e. age, profession, eduction, monthly income, etc.</li>\n",
    "    <li>attributes related with the last contact of the current campaign i.e. contact, month, day, etc.</li>\n",
    "    <li>other attributes i.e. campaign, previous outcome, payment methods, etc.</li>\n",
    "   <li>target attribute - purchased.</li>\n",
    "\n",
    "</ol>\n",
    "</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The source data from <a href=\"https://www.kaggle.com/datasets/janiobachmann/bank-marketing-dataset\">kaggle</a> is loaded in Vantage and supplemented with information about city, monthly income, family members, etc. The data is loaded into vantage table named <i>Retail_Marketing</i>.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><b><i>*Please scroll down to the end of the notebook for detailed column descriptions of the dataset.</i></b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda8e565-b58b-4cc6-8d9c-50790ca3dcab",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>3.1 Examine the Retail Marketing Campaign table</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial'>Let's look at the sample data in the Retail_Marketing table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9951cf-e2b0-40d7-9a8f-a01c7f48ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = DataFrame(in_schema('DEMO_MarketingCamp', 'Retail_Marketing'))\n",
    "df = tdf.to_pandas()\n",
    "print(\"Data information: \\n\",tdf.shape)\n",
    "tdf.sort('customer_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d6d954-b72f-41c3-9f8c-bc15cf74d672",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>There are 11K records in all, and there are 23 variables. Purchased is the target variable. We shall classify the purchased variable in accordance with the remaining features.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89367d27-22ca-4a0e-b299-0f8e1a669157",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>4. LLM </b>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>4.1 Connect to databases using SQL Alchemy</b></p>    \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Under the hood, LangChain uses SQLAlchemy to connect to SQL databases. The SQLDatabaseChain can therefore be used with any SQL dialect supported by SQLAlchemy, such as Teradata Vantage, MS SQL, MySQL, MariaDB, PostgreSQL, Oracle SQL, and SQLite. Please refer to the <a href=\"https://docs.sqlalchemy.org/en/20/\"> SQLAlchemy documentation</a> for more information about requirements for connecting to your database.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Important: The code below establishes a database connection for data sources and Large Language Models. Please note that the solution will only work if the database connection for your sources is defined in the cell below</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Build a consolidated view of Table Data Catalog by combining metadata stored for the database and table in pipe delimited format.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995a2df6-8095-4688-be4c-0b850afd420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create the vantage  SQLAlchemy engine\n",
    "db_vantage = SQLDatabase(eng)\n",
    "\n",
    "def parse_catalog(source, source_dataset):\n",
    "    columns_str = ''\n",
    "   \n",
    "    for c in tdf.columns:\n",
    "        columns_str = columns_str + f\"\\n{source}|{source_dataset}|{c}\"\n",
    "\n",
    "    return columns_str, \",\".join(tdf.columns)\n",
    "\n",
    "source = 'DEMO_MarketingCamp'\n",
    "source_dataset = 'Retail_Marketing'\n",
    "catalog, columns = parse_catalog(source, source_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4781b83c-0907-4bbd-8fe1-1067e587512b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b> 4.2 Format the answer and Display</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>To view the answer in proper format with markdown</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c27d29-1bde-4908-b7f1-309dcfd89eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def response_template(query, response):\n",
    "    if \"result\" in response:\n",
    "        return f\"<p style = 'font-size:16px;font-family:Arial'>SQL and response from user query {query}  <br> <b>{response['result']}<b>\"\n",
    "    else:\n",
    "        return f\"<p style = 'font-size:16px;font-family:Arial'>SQL and response from user query {query}  <br> <b>{response}<b>\"\n",
    "\n",
    "def error_template():\n",
    "    return f\"<p style = 'font-size:16px;font-family:Arial'>Sorry, there was an error while generating the SQL query. The GenAI may have made a mistake in the syntax of the query.  <br>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680228a2-3bfa-44f4-8a02-b73fa8bf8e95",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>4.3 Define LLM model</b></p>  \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In OpenAI's language models, the <b>temperature</b> parameter controls the randomness of the generated text. It affects the diversity and creativity of the model's responses.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>A higher temperature value, such as 1.0 or above, increases the randomness and diversity of the generated output. This can lead to more varied and surprising responses, but it may also result in less coherence and occasional nonsensical outputs.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>On the other hand, a lower temperature value, such as 0.2 or below, reduces randomness and makes the model's output more focused and deterministic. The generated text is likely to be more conservative, sticking closely to patterns observed in the training data.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Choosing an appropriate temperature value depends on the desired output. Higher temperatures can be useful for creative tasks or brainstorming, while lower temperatures are preferred when you need more control over the output, such as when generating specific responses or following a particular style.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbceafb4-793b-4d62-ab22-c9d49ac9a759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# OpenAI API\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    \n",
    "# call open AI model - api\n",
    "llm = OpenAI(temperature=0.2, model=\"gpt-3.5-turbo-instruct\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60be3888-a03d-430f-a2c0-7ae78d161e18",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b> 4.4 Define the function to get the best data channel to answer the user query</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>To find the channel, we are taking the following steps:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial'> \n",
    "    <li>In order to establish the prompts that LangChain will utilise, we must first create the prompt template by pasting the consolidated Data Catalog into it. </li>\n",
    "    <li>Next, We pass the prompt template generated in the previous step to the prompt, along with the user query to the LangChain model, to find the best data source to answer the question. LangChain uses the LLM model of our choice to detect source metadata.</li>\n",
    "    <li>Return the name of the data source and the channel from this function as the final step.</li>\n",
    "</ol>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Because many LLMs are trained on code, it can be helpful to separate different parts of the prompt using XML tags as below:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e025d0d0-1b22-45e9-bff3-23f49fc820b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that infers the channel/database/table and sets the database for querying\n",
    "def identify_channel(query):\n",
    "    \n",
    "    # Prompt 1 'Infer Channel'\n",
    "    # set prompt template. It instructs the llm on how to evaluate and respond to the llm. \n",
    "    # It is referred to as dynamic since glue data catalog is first getting generated and appended to the prompt.\n",
    "    infer_channel_template = (\"\"\"\n",
    " From the table below, find the database (in column database) which will contain the data (in corresponding column_names) \\\n",
    " to answer the question {query}\n",
    "\n",
    "<catalog>\n",
    "  {catalog}\n",
    "</catalog>\n",
    "\n",
    " Give your answer as database == \n",
    " Also,give your answer as database.table == \n",
    "     \"\"\"\n",
    "    )\n",
    "\n",
    "    #define prompt 1\n",
    "    PROMPT_channel = PromptTemplate.from_template(infer_channel_template)\n",
    "\n",
    "    # define a chain with pipe syntax\n",
    "    chain = PROMPT_channel | llm | StrOutputParser()\n",
    "    generated_texts = chain.invoke({\"query\": query, \"catalog\": catalog})\n",
    "    \n",
    "    # set the channel from where the query can be answered\n",
    "    if source in generated_texts:\n",
    "        channel = \"db\"\n",
    "        db = db_vantage\n",
    "    else:\n",
    "        raise Exception(\n",
    "            \"User question cannot be answered by any of the channels mentioned in the catalog\"\n",
    "        )\n",
    "    \n",
    "    return channel, db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43426d21-bc09-4574-b58a-8d1fcc87bf83",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The resulting text includes details such as the names of the database and tables used to execute the user query.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>For instance, if the user query is <b>How many male customers have purchased the product?</b> The generated_text will contain the information <b> database == DEMO_MarketingCamp</b> and <b>database.table == DEMO_MarketingCamp.Retail_Marketing</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5753a719-44da-460e-91c4-a17b665b25b2",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b> 4.5 Define the function to generate response to user query</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Next, we run LangChain’s SQL database chain to convert text to SQL and implicitly run the generated SQL against the database to retrieve the database results in a simple readable language. we are taking the following steps:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial'> \n",
    "    <li>Let's begin by establishing a prompt template that guides the Language Model (LLM) to generate SQL statements in a dialect that adheres to correct syntax. Subsequently, we execute these generated statements against the corresponding database.</li>\n",
    "    <li>Finally, we pass the LLM, database connection, and prompt to the SQL database chain if channel is db and run the SQL query:</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbe3f75-c7ff-4142-9848-7aa89530a6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that infers the channel/database/table and sets the database for querying\n",
    "def run_query(query):\n",
    "\n",
    "    # call the identify channel function first    \n",
    "    channel, db = identify_channel(query)\n",
    "\n",
    "    #Prompt 2 'Run Query'\n",
    "    prompt_template_query = \"\"\"Given an input question, first create a syntactically correct {dialect} Teradata-style query to run, then look at the results of the query and return the answer.\n",
    "    \n",
    "    Do not append 'Query:' to SQLQuery.\n",
    "    \n",
    "    Do not remove dashes from the Query\n",
    "\n",
    "    Display SQLResult after the query is run in plain english that users can understand. \n",
    "\n",
    "    Provide answer in simple english statement.\n",
    "\n",
    "    Only use the following tables:\n",
    "\n",
    "    <table_info>\n",
    "        {table_info}\n",
    "    </table_info>\n",
    "    \n",
    "    Only use the following Column names:\n",
    "    \n",
    "    <columns>\n",
    "        {columns}\n",
    "    </columns>\n",
    "    \n",
    "    If someone asks about marketing, they really mean the DEMO_MarketingCamp.Retail_Marketing table.\n",
    "    Use default DEMO_MarketingCamp as database\n",
    "    Use default Retail_Marketing as table\n",
    "    purchased column have only 2 values: yes or no\n",
    "    \n",
    "    Do not use below restricted words in SQL query:\n",
    "    1. LIMIT\n",
    "    2. FETCH\n",
    "    3. FIRST\n",
    "    \n",
    "    Do not use 'count' or 'COUNT' as alias keyword instead of count_\n",
    "    \n",
    "    To select top 3 results, use TOP keyword instead of LIMIT or FETCH. \n",
    "    \n",
    "    Examples of question and expected SQLQuery\n",
    "    \n",
    "    Question: Which city has the highest average income?\n",
    "    SQLQuery: SELECT TOP 1 city, AVG(monthly_income_in_thousand) AS avg_income\n",
    "    FROM DEMO_MarketingCamp.Retail_Marketing\n",
    "    WHERE monthly_income_in_thousand IS NOT NULL\n",
    "    GROUP BY city\n",
    "    ORDER BY avg_income DESC; \n",
    "    \n",
    "    Question: count total number of records in table?\n",
    "    SQLQuery: SELECT count(*) as total_count FROM DEMO_MarketingCamp.Retail_Marketing\n",
    "    \n",
    "    Write a Teradata SQL query for Question: {input}\"\"\"\n",
    "\n",
    "    PROMPT_sql = PromptTemplate.from_template(prompt_template_query)\n",
    "    PROMPT_sql = PROMPT_sql.partial(columns=columns)\n",
    "\n",
    "    if channel == \"db\":\n",
    "        db_chain = SQLDatabaseChain.from_llm(\n",
    "            llm, db, prompt=PROMPT_sql, verbose=True, return_intermediate_steps=False, use_query_checker=True\n",
    "        )\n",
    "        response = db_chain.invoke({\n",
    "            \"query\": query,\n",
    "        })\n",
    "    else:\n",
    "        raise Exception(\"Unlisted channel. Check your unified catalog\")\n",
    "\n",
    "    return response "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fe1c6a-191a-4dc7-9b3f-7c282ec94541",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>5. Run the query function</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Run the run_query function that in turn calls the Langchain SQL Database chain to convert 'text to sql' and runs the query against the source data channel</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f938e3-acab-4799-bb0e-b550fa035bc3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>5.1 Query 1</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>For example, for the user query <b>How many married customers have purchased the product?</b> the answer is as follows:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3a21be-1038-4796-b2b7-b50579d39b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Enter the query\n",
    "    query = \"\"\"How many married customers have purchased the product?\"\"\" \n",
    "\n",
    "    #Response from Langchain\n",
    "    response = run_query(query)\n",
    "    \n",
    "    display(Markdown(response_template(query, response)))\n",
    "except Exception as e:\n",
    "     print(e)\n",
    "     display(Markdown(error_template()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f1659e-e1e0-49bc-91d7-66f1904764c6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>5.2 Query 2</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>For example, another user query <b>What is the number of purchases made by customers who are in management professions?</b> the answer is as follows:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b9098a-921b-4363-92f4-3c49c4d48283",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Enter the query\n",
    "    query = \"\"\"What is the number of purchases made by customers who are in management professions?\"\"\"  \n",
    "\n",
    "    #Response from Langchain\n",
    "    response =  run_query(query)\n",
    "    \n",
    "    display(Markdown(response_template(query, response)))\n",
    "except: \n",
    "     display(Markdown(error_template()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc58553-78d9-4b94-8409-b1e66aff9518",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>5.3 Query 3</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>For example, for little bit complex user query <b>Which are the most common purchasing behaviours of customers?</b> the answer is as follows:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c57a87-ab22-4655-91c9-61fe36502759",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    # Enter the query\n",
    "    query = \"\"\"Which are the most common purchasing behaviours of customers?\"\"\" \n",
    "\n",
    "    #Response from Langchain\n",
    "    response =  run_query(query)\n",
    "\n",
    "    display(Markdown(response_template(query, response)))\n",
    "except: \n",
    "     display(Markdown(error_template()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbc93f6-fd54-4dea-bbcd-f367c8237923",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>5.4 You can try your own question</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here are some sample questions that you can try out:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>What is the average income for Phoenix?</li>\n",
    "    <li>Which city has the highest average income?</li>\n",
    "    <li>What is the average age of married people?</li>\n",
    "    <li>Which profession has the most married people in Phoenix?</li>\n",
    "    <li>What is the month with the lowest sales?</li>\n",
    "    <li>What is the month with the highest number of marketing engagements?</li>\n",
    "    <li>What is the number of purchases made by customers who are in management professions?</li>\n",
    "    <li>What is the average number of days between a customer's last contact and their next purchase?</li>\n",
    "    <li>What is the relationship between marital status and purchase frequency?</li>\n",
    "    <li>What is the most effective communication method for reaching customers who have not purchased from our company in the past 6 months?</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161c0567-f2e0-45c7-94f1-2324ccc1fc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    query = input(prompt = '\\n Enter your natural language query: ')\n",
    "    response = run_query(query)\n",
    "    display(Markdown(response_template(query, response)))\n",
    "except: \n",
    "     display(Markdown(error_template()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b8b817-c0ff-42b3-a651-c8268ac40942",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>5. Cleanup</b>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Cleanup work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aacb87c-0d81-40f0-8754-608d47e602cc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b398148-9486-4535-8c06-d3f77669bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_MarketingCamp');\"        # Takes 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef4cbe-1beb-4c65-ac60-ffd6250668a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae971f90-bef1-4228-bcbf-c333e9843284",
   "metadata": {},
   "source": [
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>Dataset:</b>\n",
    "\n",
    "- `customer_id`: Unique row customer id\n",
    "- `age`: customer age (numeric)\n",
    "- `profession` : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\",\"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\")\n",
    "- `marital` : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" meansdivorced or widowed)\n",
    "- `education` customer eduction (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\n",
    "- `city`: city of customer (categorical: 'New York','Los Angeles','Chicago','Houston','Phoenix','Philadelphia','San Antonio','San Diego','Dallas','San Jose')\n",
    "- `monthly_income_in_thousand`: customer's monthly income, in dollar (numeric)\n",
    "- `family_members`: number of family members (numeric)\n",
    "- `communication_type`: communication type (categorical: \"unknown\",\"telephone\",\"cellular\")\n",
    "- `last_contact_day`: last contact day of the month (numeric)\n",
    "- `last_contact_month`: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n",
    "- `credit_card`: does customer have a credit card? (binary: 'yes','no')\n",
    "- `num_of_cars`: number of cars (numeric)\n",
    "- `last_contact_duration`: last contact duration, in seconds (numeric)\n",
    "- `campaign`: number of contacts performed during this campaign and for this client (categorical,includes last contact)\n",
    "- `days_from_last_contact`: number of days that passed by after the client was last contacted from a previouscampaign (numeric, -1 means client was not previously contacted)\n",
    "- `prev_contacts_performed`: number of contacts performed before this campaign and for this client (numeric)\n",
    "- `prev_campaign_outcome`: outcome of the previous marketing campaign (categorical:\"unknown\",\"other\",\"failure\",\"success\")\n",
    "- `payment_method`: payment method use by customer (categorical: 'cash','credit_card','debit_card','ewallets', 'payment_links', 'QRcodes')\n",
    "- `purchase_frequency`: how frequently customer is purchasing (categorical: 'daily','weekly','biweekly','monthly','quarterly','yearly')\n",
    "- `gender`: gender of customer? (binary: 'male','female')\n",
    "- `recency`: number of days since the last purchase (numeric)\n",
    "\n",
    "\n",
    "Output variable (desired target):\n",
    "- `purchased`: does customer did a purchase - target column (binary: 'yes','no')\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#E37C4D'><b>Links:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Teradataml Python reference: <a href = 'https://docs.teradata.com/search/all?query=Python+Package+User+Guide&content-lang=en-US'>here</a></li>\n",
    "    <li>Langchain Python reference: <a href='https://python.langchain.com/docs/get_started/introduction.html'>here</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5463848-592f-4321-b852-287e133872dd",
   "metadata": {},
   "source": [
    "<footer style=\"padding:10px;background:#f9f9f9;border-bottom:3px solid #394851\">Copyright © Teradata Corporation - 2023. All Rights Reserved.</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
