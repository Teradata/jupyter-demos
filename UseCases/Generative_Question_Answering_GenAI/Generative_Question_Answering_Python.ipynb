{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38bc532d-c78c-4c89-b191-242da0733f39",
   "metadata": {},
   "source": [
    "<header style=\"padding:1px;background:#f9f9f9;border-top:3px solid #00b2b1\"><img id=\"Teradata-logo\" src=\"https://www.teradata.com/Teradata/Images/Rebrand/Teradata_logo-two_color.png\" alt=\"Teradata\" width=\"220\" align=\"right\" />\n",
    "\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>Generative Question Answering using Generative AI with Vantage</b>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff71661-19b4-423a-867a-7c815b064c81",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Introduction:</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In the Question-Answering system using Generative AI demo, the combination of <b>RAG, Langchain, and LLM models</b> allows users to ask queries in layman's terms, retrieve relevant information from the Vantage tables, and generate accurate and concise answers based on the retrieved data. This integration of retrieval-based and generative-based approaches provides a powerful tool for extracting knowledge from structured sources and delivering user-friendly responses.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this demo we will build Generative Question-Answering using LangChain, a powerful library for working with LLMs like GPT-3.5, GPT-4, Bloom, etc. and JumpStart in ClearScape notebooks, a system is built where users can ask business questions in natural English and receive answers with data drawn from the relevant databases.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following diagram illustrates the architecture.</p>\n",
    "\n",
    "<center><img src=\"images/vantage_qa_gen.png\" alt=\"Generative_QA_architecture\"  width=800 height=800/></center>\n",
    "\n",
    "<br>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Before going any farther, let's get a better understanding of RAG, LangChain, and LLM.</p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial'><li> <b>Retrieval-Augmented Generation (RAG):</b></li></ul>\n",
    "<p style = 'font-size:16px;font-family:Arial'> &emsp;  &emsp;RAG is a framework that combines the strengths of retrieval-based and generative-based approaches in question-answering systems.It utilizes both a retrieval model and a generative model to generate high-quality answers to user queries. The retrieval model is responsible for retrieving relevant information from a knowledge source, such as a database or documents. The generative model then takes the retrieved information as input and generates concise and accurate answers in natural language.</p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial'><li> <b>Langchain:</b></li></ul>\n",
    "<p style = 'font-size:16px;font-family:Arial'> &emsp;  &emsp; Langchain is a language model developed for understanding and generating human-like text. It is designed to handle queries and requests expressed in everyday language, enabling users to ask questions in layman's terms. Langchain leverages state-of-the-art deep learning techniques to comprehend the semantics and context of user queries. It can process various types of queries, ranging from simple factual questions to complex and nuanced queries.</p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial'><li> <b>LLM Models (Large Language Models):</b></li></ul>\n",
    "<p style = 'font-size:16px;font-family:Arial'> &emsp;  &emsp; LLM models refer to the large-scale language models that are trained on vast amounts of text data.\n",
    "These models, such as GPT-3 (Generative Pre-trained Transformer 3),  GPT-3.5, GPT-4, HuggingFace BLOOM, LLaMA, Google's FLAN-T5, etc. are capable of generating human-like text responses. LLM models have been pre-trained on diverse sources of text data, enabling them to learn patterns, grammar, and context from a wide range of topics. They can be fine-tuned for specific tasks, such as question-answering, natural language understanding, and text generation.\n",
    "LLM models have achieved impressive results in various natural language processing tasks and are widely used in AI applications for generating human-like text responses.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca49b9d-df0b-400a-acf8-0252ab8a2618",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#E37C4D'><b>Steps in the analysis:</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Configuring the environment</li>\n",
    "    <li>Connect to Vantage</li>\n",
    "    <li>Data Exploration</li>\n",
    "    <li>LLM Setup</li>\n",
    "    <li>Run the query function</li>\n",
    "    <li>Cleanup</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833b5bf-74af-42be-8543-3782e1da95dc",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>1. Configuring the environment</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bea4ff-4ad8-4e66-9c9b-2550ed795a1d",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In order to utilize this demo, you will need an OpenAI API key. If you do not have one, please refer to the instructions provided in this guide to obtain your OpenAI API key: </p>\n",
    "\n",
    "[Openai_setup_api_key_guide](..//Openai_setup_api_key/Openai_setup_api_key.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6027a7-888d-441f-abc7-a6ea1c45f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# '%%capture' suppresses the display of installation steps of the following packages\n",
    "\n",
    "# !pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca97cdce-0d5e-4e54-b404-da7bae24ef51",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "    <i>The above statements may need to be uncommented if you run the notebooks on a platform that does not have the libraries installed.  If you uncomment those installs, be sure to restart the kernel after executing those lines.</i>\n",
    "</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50a4aa-1211-44fc-8166-317c35253207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# teradata lib\n",
    "from teradataml import *\n",
    "\n",
    "# LLM\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from langchain import PromptTemplate,SQLDatabase, SQLDatabaseChain, LLMChain\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "display.max_rows = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59718f8-7af4-4d1a-abc7-a860eb7cbae3",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>2. Initiate a connection to Vantage</b>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'> <b>Let's start by connecting to the Teradata system </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>You will be prompted to provide the password. Enter your password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164cfc91-93ed-45b9-98ba-73b91a50c28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)\n",
    "eng.execute('''SET query_band='DEMO= Generative_Question_Answering_Python.ipynb;' UPDATE FOR SESSION;''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22db506-84a7-406b-be9f-9fe69d268ba4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beec557-411b-4418-acf3-2f28d3c6beac",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have provided data for this demo on cloud storage. You can either run the demo using foreign tables to access the data without any storage on your environment or download the data to local storage, which may yield faster execution. Still, there could be considerations of available storage. Two statements are in the following cell, and one is commented out. You may switch which mode you choose by changing the comment string.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e26ca7c-fa9e-4200-8e9e-27f5886aa5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call get_data('DEMO_MarketingCamp_cloud');\"        # Takes 1 minute\n",
    "# %run -i ../run_procedure.py \"call get_data('DEMO_MarketingCamp_local');\"        # Takes 2 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99a16b5-da34-4326-b66b-5f7d5a9d9b04",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Next is an optional step – if you want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79252a5e-b2c1-404a-ae22-6c3d698510c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f3fe2-ed63-4838-bb19-4c0d0157453d",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>3. Data Exploration</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The goal of the Marketing Campaign Effectiveness prediction is to reduce marketing resources by identifying customers who would purchase the product and thereby directing marketing efforts to them.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The data is from the last marketing campaign, with thousands of rows of customer data like age, job, marital status, education, etc.<p/>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Each row is a snapshot of data taken during the last marketing campaign, and each column is a different variable. The input dataset can be divided into three categories, as below:</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'> \n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>customer data i.e. age, profession, eduction, monthly income, etc.</li>\n",
    "    <li>attributes related with the last contact of the current campaign i.e. contact, month, day, etc.</li>\n",
    "    <li>other attributes i.e. campaign, previous outcome, payment methods, etc.</li>\n",
    "   <li>target attribute - purchased.</li>\n",
    "\n",
    "</ol>\n",
    "</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The source data from <a href=\"https://www.kaggle.com/datasets/janiobachmann/bank-marketing-dataset\">kaggle</a> is loaded in Vantage and supplemented with information about city, monthly income, family members, etc. The data is loaded into vantage table named <i>Retail_Marketing</i>.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><b><i>*Please scroll down to the end of the notebook for detailed column descriptions of the dataset.</i></b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda8e565-b58b-4cc6-8d9c-50790ca3dcab",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>3.1 Examine the Retail Marketing Campaign table</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial'>Let's look at the sample data in the Retail_Marketing table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9951cf-e2b0-40d7-9a8f-a01c7f48ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = DataFrame(in_schema('DEMO_MarketingCamp', 'Retail_Marketing'))\n",
    "df = tdf.to_pandas()\n",
    "print(\"Data information: \\n\",tdf.shape)\n",
    "tdf.sort('customer_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d6d954-b72f-41c3-9f8c-bc15cf74d672",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>There are 11K records in all, and there are 23 variables. Purchased is the target variable. We shall classify the purchased variable in accordance with the remaining features.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89367d27-22ca-4a0e-b299-0f8e1a669157",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>4. LLM setup</b>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>4.1 Connect to databases using SQL Alchemy</b></p>    \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Under the hood, LangChain uses SQLAlchemy to connect to SQL databases. The SQLDatabaseChain can therefore be used with any SQL dialect supported by SQLAlchemy, such as Teradata Vantage, MS SQL, MySQL, MariaDB, PostgreSQL, Oracle SQL, and SQLite. Please refer to the <a href=\"https://docs.sqlalchemy.org/en/20/\"> SQLAlchemy documentation</a> for more information about requirements for connecting to your database.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Important: The code below establishes a database connection for data sources and Large Language Models. Please note that the solution will only work if the database connection for your sources is defined in the cell below</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Build a consolidated view of Table Data Catalog by combining metadata stored for the database and table in pipe delimited format.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995a2df6-8095-4688-be4c-0b850afd420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create the vantage  SQLAlchemy engine\n",
    "db_vantage = SQLDatabase(eng)\n",
    "\n",
    "def parse_catalog(source, source_dataset):\n",
    "    columns_str = ''\n",
    "   \n",
    "    for c in tdf.columns:\n",
    "        columns_str = columns_str + f\"\\n{source}|{source_dataset}|{c}\"\n",
    "\n",
    "    return columns_str, \",\".join(tdf.columns)\n",
    "\n",
    "catalog, columns = parse_catalog(source = 'DEMO_MarketingCamp', source_dataset = 'Retail_Marketing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680228a2-3bfa-44f4-8a02-b73fa8bf8e95",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>4.2 Define LLM model</b></p>  \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>define large language model here. Make sure to set api keys for the variable YOUR_API_KEY</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In OpenAI's language models, the <b>temperature</b> parameter controls the randomness of the generated text. It affects the diversity and creativity of the model's responses.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>A higher temperature value, such as 1.0 or above, increases the randomness and diversity of the generated output. This can lead to more varied and surprising responses, but it may also result in less coherence and occasional nonsensical outputs.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>On the other hand, a lower temperature value, such as 0.2 or below, reduces randomness and makes the model's output more focused and deterministic. The generated text is likely to be more conservative, sticking closely to patterns observed in the training data.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Choosing an appropriate temperature value depends on the desired output. Higher temperatures can be useful for creative tasks or brainstorming, while lower temperatures are preferred when you need more control over the output, such as when generating specific responses or following a particular style.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbceafb4-793b-4d62-ab22-c9d49ac9a759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# OpenAI API\n",
    "# To authenticate your requests with the OpenAI API, you need to set the API key. Replace 'YOUR_API_KEY' in the code below with your actual API key:\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-XXXX\"  \n",
    "\n",
    "llm = OpenAI(temperature=0.9) # call open AI model - api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60be3888-a03d-430f-a2c0-7ae78d161e18",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b> 4.3 Determine the best data channel to answer the user query</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>To find the channel, we are taking the following steps:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial'> \n",
    "    <li>In order to establish the prompts that LangChain will utilise, we must first create the prompt template by pasting the consolidated Data Catalog into it. </li>\n",
    "    <li>Next, We pass the prompt template generated in the previous step to the prompt, along with the user query to the LangChain model, to find the best data source to answer the question. LangChain uses the LLM model of our choice to detect source metadata.</li>\n",
    "    <li>Return the name of the data source and the channel from this function as the final step.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e025d0d0-1b22-45e9-bff3-23f49fc820b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that infers the channel/database/table and sets the database for querying\n",
    "def identify_channel(query):\n",
    "    \n",
    "    # Prompt 1 'Infer Channel'\n",
    "    #set prompt template. It instructs the llm on how to evaluate and respond to the llm. \n",
    "    # It is referred to as dynamic since glue data catalog is first getting generated and appended to the prompt.\n",
    "    prompt_template = (\n",
    "        \"\"\"\n",
    "     From the table below, find the database (in column database) which will contain the data (in corresponding column_names) to answer the question \n",
    "     {query} \\n\n",
    "     \"\"\"\n",
    "        + catalog\n",
    "        + \"\"\" \n",
    "     Give your answer as database == \n",
    "     Also,give your answer as database.table == \n",
    "     \"\"\"\n",
    "    )\n",
    "    \n",
    "    #define prompt 1\n",
    "    PROMPT_channel = PromptTemplate(template=prompt_template, input_variables=[\"query\"])\n",
    "   \n",
    "    # define llm chain\n",
    "    llm_chain = LLMChain(prompt=PROMPT_channel, llm=llm)\n",
    "    generated_texts = llm_chain.run(query)    \n",
    "\n",
    "    # set the channel from where the query can be answered\n",
    "    if source in generated_texts:\n",
    "        channel = \"db\"\n",
    "        db = db_vantage\n",
    "    else:\n",
    "        raise Exception(\n",
    "            \"User question cannot be answered by any of the channels mentioned in the catalog\"\n",
    "        )\n",
    "    \n",
    "    return channel, db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43426d21-bc09-4574-b58a-8d1fcc87bf83",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The resulting text includes details such as the names of the database and tables used to execute the user query.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>For instance, if the user query is <b>How many male customers have purchased the product?</b> The generated_text will contain the information <b> database == DEMO_MarketingCamp</b> and <b>database.table == DEMO_MarketingCamp.Retail_Marketing</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5753a719-44da-460e-91c4-a17b665b25b2",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b> 4.4 Generate response to user query</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Next, we run LangChain’s SQL database chain to convert text to SQL and implicitly run the generated SQL against the database to retrieve the database results in a simple readable language. we are taking the following steps:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial'> \n",
    "    <li>Let's begin by establishing a prompt template that guides the Language Model (LLM) to generate SQL statements in a dialect that adheres to correct syntax. Subsequently, we execute these generated statements against the corresponding database.</li>\n",
    "    <li>Finally, we pass the LLM, database connection, and prompt to the SQL database chain if channel is db and run the SQL query:</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20804c89-5d12-43d3-8855-771dba935d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that infers the channel/database/table and sets the database for querying\n",
    "def run_query(query):\n",
    "\n",
    "    # call the identify channel function first    \n",
    "    channel, db = identify_channel(query)\n",
    "\n",
    "    #Prompt 2 'Run Query'\n",
    "    prompt_template_query = \"\"\"Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\n",
    "\n",
    "    Do not append 'Query:' to SQLQuery.\n",
    "    \n",
    "    Do not remove dashes from the Query\n",
    "\n",
    "    Display SQLResult after the query is run in plain english that users can understand. \n",
    "\n",
    "    Provide answer in simple english statement.\n",
    "\n",
    "    Only use the following tables:\n",
    "\n",
    "    {table_info}\n",
    "    \n",
    "    Only use the following Column names: \\n\n",
    "     \"\"\"+columns +\"\"\" \n",
    "    \n",
    "    If someone asks for the marketing, they really mean the DEMO_MarketingCamp.Retail_Marketing table.\n",
    "    Use default DEMO_MarketingCamp as database\n",
    "    Use default Retail_Marketing as table\n",
    "\n",
    "    Question: {input}\"\"\"\n",
    "\n",
    "    PROMPT_sql = PromptTemplate(\n",
    "        input_variables=[\"input\", \"table_info\", \"dialect\"], template=prompt_template_query\n",
    "    )\n",
    "    \n",
    "    if channel == \"db\":\n",
    "        db_chain = SQLDatabaseChain.from_llm(\n",
    "            llm, db, prompt=PROMPT_sql, verbose=False, return_intermediate_steps=False,\n",
    "        )\n",
    "        response = db_chain.run(query)\n",
    "    else:\n",
    "        raise Exception(\"Unlisted channel. Check your unified catalog\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debff6ef-0e51-435c-aed8-377f76efffd3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b> 4.5 Format the answer and Display</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>To view the answer in proper format with markdown</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44563666-7d6a-417d-b84b-d0ce70b5a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def markdown_template(query, response):\n",
    "    return f\"<p style = 'font-size:16px;font-family:Arial'>SQL and response from user query {query}  <br> <b>{response}<b>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fe1c6a-191a-4dc7-9b3f-7c282ec94541",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>5. Run the query function</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Run the run_query function that in turn calls the Langchain SQL Database chain to convert 'text to sql' and runs the query against the source data channel</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f938e3-acab-4799-bb0e-b550fa035bc3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>5.1 Query 1</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>For example, for the user query How many married customers have purchased the product? the answer is as follows:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3a21be-1038-4796-b2b7-b50579d39b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the query\n",
    "\n",
    "query = \"\"\"How many married customers have purchased the product?\"\"\" \n",
    "\n",
    "#Response from Langchain\n",
    "response =  run_query(query)\n",
    "\n",
    "display(Markdown(markdown_template(query, response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f1659e-e1e0-49bc-91d7-66f1904764c6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>5.2 Query 2</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>For example, for the user query What is the number of purchases made by customers who are in management professions? the answer is as follows:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70a7200-92bb-4ce7-a7cf-b9a19d95b87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the query\n",
    "\n",
    "query = \"\"\"What is the number of purchases made by customers who are in management professions?\"\"\" \n",
    "\n",
    "#Response from Langchain\n",
    "response =  run_query(query)\n",
    "\n",
    "display(Markdown(markdown_template(query, response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc58553-78d9-4b94-8409-b1e66aff9518",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>5.3 Query 3</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>For example, for the user query Which are the most common purchasing behaviours of customers? the answer is as follows:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c57a87-ab22-4655-91c9-61fe36502759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the query\n",
    "\n",
    "query = \"\"\"Which are the most common purchasing behaviours of customers?\"\"\" \n",
    "\n",
    "#Response from Langchain\n",
    "response =  run_query(query)\n",
    "\n",
    "display(Markdown(markdown_template(query, response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b8b817-c0ff-42b3-a651-c8268ac40942",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>5. Cleanup</b>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Cleanup work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aacb87c-0d81-40f0-8754-608d47e602cc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b398148-9486-4535-8c06-d3f77669bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_MarketingCamp');\"        # Takes 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef4cbe-1beb-4c65-ac60-ffd6250668a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae971f90-bef1-4228-bcbf-c333e9843284",
   "metadata": {},
   "source": [
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>Dataset:</b>\n",
    "\n",
    "- `customer_id`: Unique row customer id\n",
    "- `age`: customer age (numeric)\n",
    "- `profession` : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\",\"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\")\n",
    "- `marital` : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" meansdivorced or widowed)\n",
    "- `education` customer eduction (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\n",
    "- `city`: city of customer (categorical: 'New York','Los Angeles','Chicago','Houston','Phoenix','Philadelphia','San Antonio','San Diego','Dallas','San Jose')\n",
    "- `monthly_income_in_thousand`: customer's monthly income, in dollar (numeric)\n",
    "- `family_members`: number of family members (numeric)\n",
    "- `communication_type`: communication type (categorical: \"unknown\",\"telephone\",\"cellular\")\n",
    "- `last_contact_day`: last contact day of the month (numeric)\n",
    "- `last_contact_month`: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n",
    "- `credit_card`: does customer have a credit card? (binary: 'yes','no')\n",
    "- `num_of_cars`: number of cars (numeric)\n",
    "- `last_contact_duration`: last contact duration, in seconds (numeric)\n",
    "- `campaign`: number of contacts performed during this campaign and for this client (categorical,includes last contact)\n",
    "- `days_from_last_contact`: number of days that passed by after the client was last contacted from a previouscampaign (numeric, -1 means client was not previously contacted)\n",
    "- `prev_contacts_performed`: number of contacts performed before this campaign and for this client (numeric)\n",
    "- `prev_campaign_outcome`: outcome of the previous marketing campaign (categorical:\"unknown\",\"other\",\"failure\",\"success\")\n",
    "- `payment_method`: payment method use by customer (categorical: 'cash','credit_card','debit_card','ewallets', 'payment_links', 'QRcodes')\n",
    "- `purchase_frequency`: how frequently customer is purchasing (categorical: 'daily','weekly','biweekly','monthly','quarterly','yearly')\n",
    "- `gender`: gender of customer? (binary: 'male','female')\n",
    "- `recency`: number of days since the last purchase (numeric)\n",
    "\n",
    "\n",
    "Output variable (desired target):\n",
    "- `purchased`: does customer did a purchase - target column (binary: 'yes','no')\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#E37C4D'><b>Links:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Teradataml Python reference: <a href = 'https://docs.teradata.com/search/all?query=Python+Package+User+Guide&content-lang=en-US'>here</a></li>\n",
    "    <li>Langchain Python reference: <a href='https://python.langchain.com/docs/get_started/introduction.html'>here</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5463848-592f-4321-b852-287e133872dd",
   "metadata": {},
   "source": [
    "<footer style=\"padding:10px;background:#f9f9f9;border-bottom:3px solid #394851\">Copyright © Teradata Corporation - 2023. All Rights Reserved.</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
