{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df79517-1e4f-420a-b7e3-fbb2bb44009d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       From Complaints to Clarity:<br> Uncovering Hidden Trends in Telco Customer Feedback\n",
    " <br>       \n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 150px; height: auto; margin-top: 20pt;\">\n",
    "  <br>\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e1b65b-2d1a-4122-82fb-24c90b84ed0a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial'><b>Introduction:</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "    In this notebook, we will demonstrate how <b>Teradata helps Telcos turn customer complaints into valuable insights.</b><br>\n",
    "By analyzing customer feedback, we’ll reveal hidden trends and patterns, allowing companies to understand and address customer experience challenges more effectively.\n",
    "<br><br>\n",
    "This demo will build an interactive dashboard that provides a clear, real-time view of these trends, helping decision-makers improve customer satisfaction.\n",
    "<br><br>\n",
    "Discover how Teradata's unique <code>GenAI</code> based approach ensures reliable and consistent results, making it an essential tool for the telecommunications industry.\n",
    "<br><br>\n",
    "Tracking the evolution of topics over time is essential for understanding patterns, behaviors, and emerging trends in large datasets of text. In industries such as customer support, social media monitoring, and market research, identifying how topics shift over time can provide valuable insights for decision-making and strategy development. Traditional manual analysis methods, however, can be labor-intensive and prone to human bias.<br>\n",
    "In this demo, we explore a dynamic approach to topic trend analysis by combining message embeddings with topic embeddings, leveraging vector distance calculations to measure similarity between the two.\n",
    "<br><br>\n",
    "While the specific example can be applied across many sectors, we’ll focus on a use case using a synthetic dataset of fictitious telco-related complaints. This dataset contains complaints about various telecommunications services, providing valuable insights into customer sentiment and trends. By categorizing these complaints by topic, businesses can gain a deeper understanding of customer concerns in the telecommunications sector and adjust their strategies to address emerging issues more effectively.<br>\n",
    "To achieve this, we will:\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Generate embeddings for both customer messages and inferred/predefined topics</li>\n",
    "    <li>Calculate vector distances between message and topic embeddings to assess similarity</li>\n",
    "    <li>Feed the results into a dashboard to display topic trends over time, with configurable similarity thresholds and message counts</li>\n",
    "</ul>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "<center><img src=\"images/workflow_topictrend.png\" alt=\"workflow_topictrend\" style=\"border: 4px solid #404040; border-radius: 10px;\"/></center>\n",
    "<p style = 'font-size:16px;font-family:Arial'>This method provides an efficient way to not only categorize messages by topic but also track how these topics evolve over time, offering actionable insights into changing customer concerns, emerging issues, and overall trends.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a628f056-dbee-4ec4-a5d4-b7a860cbaa80",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>Downloading and installing additional software needed</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a325ffa-f4ab-44fb-b729-adeaf9e9df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install wordcloud nltk --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc16152-9448-4b1c-a398-7a3a94bac040",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#!pip install --force-reinstall pillow --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669afc49-343d-4bf1-96f4-b49ed7a75261",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5639a5-1b8c-4001-8f20-45221b039f6e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;'><b>Note: </b><i>The above libraries have to be installed. Restart the kernel after executing these cells to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing <b> 0 0</b></i> (zero zero) and pressing <i>Enter</i>.</p>\n",
    "</div>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18116bca-b8af-4360-bf4a-a420451777b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Data manipluation and Visualization libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# Teradata libraries\n",
    "from teradataml import (\n",
    "    create_context, \n",
    "    delete_byom, \n",
    "    display,\n",
    "    execute_sql,\n",
    "    save_byom,\n",
    "    configure,\n",
    "    ONNXEmbeddings,\n",
    "    copy_to_sql,\n",
    "    remove_context,\n",
    "    in_schema,\n",
    "    KMeans,\n",
    "    KMeansPredict,\n",
    "    VectorDistance,\n",
    "    DataFrame,\n",
    "    DATE,\n",
    "    db_drop_table,\n",
    "    db_drop_view,\n",
    ")\n",
    "display.max_rows = 5\n",
    "from sqlalchemy.sql import literal_column as col\n",
    "\n",
    "# NLP libraries\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "# machine learning libraries\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d689b8-787e-470c-820d-2d794d92ccf1",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>1. Initiate a connection to Vantage</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>You will be prompted to provide the password. Enter your password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e801c-31af-48bc-af16-0f150cec7c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1916ffa0-c72c-4980-a100-d13904fc3f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=Telco_Complaints_Analysis_Onnx.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039fbd7c-8dc2-4508-8216-492ee83c59d8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded1b2e3-5391-4025-8428-093b4ecfff56",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;'><b>Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>We have provided data for this demo on cloud storage. You can either run the demo using foreign tables to access the data without any storage on your environment or download the data to local storage, which may yield faster execution. Still, there could be considerations of available storage. Two statements are in the following cell, and one is commented out. You may switch which mode you choose by changing the comment string.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16973665-4402-466e-bd51-8b3e279bb866",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call get_data('DEMO_Telco_Complaints_Onnx_local');\" # Takes 2 minutes\n",
    "#%run -i ../run_procedure.py \"call get_data('DEMO_Telco_Complaints_Onnx_cloud');\" # Takes 2 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05175b33-b1a0-4292-ad58-a155c0892491",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Next is an optional step – if you want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e6f604-ef55-4503-88ac-7dd584fbd601",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39506f3-d7ce-4301-b756-cacebd2621fe",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>2. Load HuggingFace Model</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>To generate embeddings, we need an ONNX model capable of transforming text into vector representations. We use a pretrained model from [Teradata's Hugging Face repository](https://huggingface.co/Teradata/gte-base-en-v1.5), such as gte-base-en-v1.5. The model and its tokenizer are downloaded and stored in Vantage tables as BLOBs using the save_byom function.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f683bb-5d43-45e0-ae46-f176c270e6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce45a0-b693-4e1c-9aa2-36b7399d40bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "model_name = \"gte-base-en-v1.5\"\n",
    "number_dimensions_output = 768\n",
    "model_file_name = \"model.onnx\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c738f5-bcde-4acf-9d97-c8e425dece0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Download Model from Teradata HuggingFace Page\n",
    "\n",
    "hf_hub_download(repo_id=f\"Teradata/{model_name}\", filename=f\"onnx/{model_file_name}\", local_dir=\"./\")\n",
    "hf_hub_download(repo_id=f\"Teradata/{model_name}\", filename=f\"tokenizer.json\", local_dir=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b627f152-e28c-40f5-aa84-ae147ed13c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    db_drop_table(\"embeddings_models\")\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    db_drop_table(\"embeddings_tokenizers\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3a74fe-4373-4121-9886-01d3a8ef1fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load Models into Vantage\n",
    "# a) Embedding model\n",
    "save_byom(model_id = model_name, # must be unique in the models table\n",
    "               model_file = f\"onnx/{model_file_name}\",\n",
    "               table_name = 'embeddings_models' )\n",
    "# b) Tokenizer\n",
    "save_byom(model_id = model_name, # must be unique in the models table\n",
    "              model_file = 'tokenizer.json',\n",
    "              table_name = 'embeddings_tokenizers') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9742dd4-15e0-4154-8d9f-46bf29867871",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Recheck the installed model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2f8a2b-4f6d-4a36-a3d1-781cb7cd6852",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = DataFrame('embeddings_models')\n",
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec29f26-b532-4257-9c15-d201e9ceccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_token = DataFrame('embeddings_tokenizers')\n",
    "df_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d755479-839b-4c36-b6f9-6d3026bd9abb",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>3. Create the Embeddings</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a4fcab-3bc1-44fb-acb8-76dfa09c70f4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'> Let us take a look at our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22728822-81f3-412f-b1d8-dd9e20314bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DF_complaints = DataFrame(in_schema('DEMO_Telco_Complaints_Onnx', 'telco_consumer_complaints'))\n",
    "DF_complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435fcd99-141c-44a9-9f58-2133122aceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_complaints.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33261854-6678-4d64-86f0-1c9e6ff2b9ac",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial;'>3.1 Generate Embeddings with ONNXEmbeddings</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555acbe1-e959-4fa5-aff5-f886fc126447",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "Now it's time to generate the embeddings using <b>ONNXEmbeddings</b>.<br>We run the ONNXEmbeddings function to generate embeddings for a small subset of records. The model is <b>loaded into the cache memory on each node</b>, and Teradata's <b>Massively Parallel Processing (MPP)</b> architecture ensures that embeddings are computed in parallel using <b>ONNX Runtime</b> on each node.  <br>Having said that, generating embeddings for the entire training set can be time-consuming, especially when working on a system with limited resources. In the <b>ClearScape Analytics experience</b>, only a <b>4 AMP system</b> with constrained RAM and CPU power is available. To ensure smooth execution, we test embedding generation on a small sample and use <b>pre-calculated embeddings</b> for the remainder of demo. In a real-life scenario you would tyipically encounter multiple hundred AMPs with much more compute power!<br>Also have a look at the most important input parameters of this <b>ONNXEmbeddings</b> function.\n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "<li><b>InputTable</b>: The source table containing the text to be embedded. </li>\n",
    "<li><b>ModelTable</b>: The table storing the ONNX model.                    </li>\n",
    "<li><b>TokenizerTable</b>: The table storing the tokenizer JSON file.       </li>\n",
    "<li><b>Accumulate</b>: Specifies additional columns to retain in the output </li>  \n",
    "<li><b>OutputFormat</b>: Specifies the data format of the output embeddings (<b>FLOAT32(768)</b>, matching the model's output dimension).</li>\n",
    "</ul>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "Since embedding generation is computationally expensive, we only process <b>10 records for testing</b> and rely on precomputed embeddings for further analysis.  \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d3a1d8-23c9-44b0-9d81-90ff9bb8e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "configure.byom_install_location = \"mldb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fa709f-a234-426c-99c3-54a0c60acfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_sample10 = DataFrame.from_query(\"SELECT TOP 10 t.row_id, t.txt  FROM DEMO_Telco_Complaints_Onnx.telco_consumer_complaints t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49f538a-043f-4b95-9c2b-018d9de60774",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = DataFrame.from_query(f\"select * from embeddings_models where model_id = '{model_name}'\")\n",
    "my_tokenizer = DataFrame.from_query(f\"select model as tokenizer from embeddings_tokenizers where model_id = '{model_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8680328-fa4e-46b0-89a4-c18643f9da43",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_embeddings_sample = ONNXEmbeddings(\n",
    "    newdata = DF_sample10,\n",
    "    modeldata = my_model, \n",
    "    tokenizerdata = my_tokenizer, \n",
    "    accumulate = [\"row_id\", \"txt\"],\n",
    "    model_output_tensor = \"sentence_embedding\",\n",
    "    output_format = f'FLOAT32({number_dimensions_output})',\n",
    "    enable_memory_check = False\n",
    ").result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c241af98-b0ae-442f-acf0-4a2d8fc90b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_embeddings_sample.show_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814c04d9-1136-47b1-ab17-23f37e2869c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_embeddings_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de20fdc-917e-42e8-b666-ed753e503626",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'> Here we can see how the embeddings are generated for the compalint text we have given.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ac23c0-8ecf-412c-b504-3b7a91a38644",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>4. Topic Generation</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680e433a-ff47-495f-8c97-7601c300851c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>When identifying topics from or for textual data, there are generally two approaches:  \n",
    "<ol style = 'font-size:16px;font-family:Arial;'><li>\n",
    "    <b>Domain Knowledge-Driven Approach:</b> Topics are predefined based on expert knowledge or business rules.  </li>\n",
    "    <li><b>Data-Driven Approach:</b>Topics emerge organically from the data itself using unsupervised learning techniques. </li>\n",
    "    </ol>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "    For this analysis, we adopt the <b>data-driven approach</b>, allowing the structure of the dataset to define the topics rather than imposing predefined categories.  For this, we leverage the <b>semantic similarity</b> between text embeddings to group similar complaints. Instead of manually defining topics, we let a clustering algorithm <b>TD_KMEANS</b> discover natural groupings within the data.  \n",
    "<br>\n",
    "To ensure manageability, we limit our analysis to 5 clusters. After applying K-Means clustering to the complaint embeddings, we identify the centroids of these clusters, which represent the most central points of each topic group. To understand the nature of each cluster, we extract the 20 distinct complaints closest to each centroid, as these provide the most representative examples of the topic. Instead of manually assigning labels, we leverage a powerful large language model (LLM) to analyze these representative complaints and generate meaningful topic names.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb308fea-8601-448e-b28e-c8371aaa996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_embeddings = DataFrame(in_schema('DEMO_Telco_Complaints_Onnx', 'telco_consumer_embeddings'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0de756d-145e-4a63-bff9-8db780bd4fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_column_list = [col for col in DF_embeddings.columns if col not in [\"row_id\", \"txt\"]]\n",
    "\n",
    "num_clusters = 5\n",
    "kmeans_out = KMeans(\n",
    "    id_column=\"row_id\",\n",
    "    data=DF_embeddings,\n",
    "    target_columns=embedding_column_list,\n",
    "    output_cluster_assignment=True,\n",
    "    num_init=10,\n",
    "    num_clusters=num_clusters,\n",
    "    iter_max=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62616030-117d-477d-9851-a9a4fab16aff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(kmeans_out.show_query())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac0e6a6-8947-40a0-afcc-786d6388e0ed",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>The output below shows cluster assignment for each row.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa7f4f1-57f9-4d57-aefe-46eec5c989a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_out.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda2b439-13b2-4894-bd4f-96bd5162cdd7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Let's check how many data points each cluster has.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e985c8d7-92b3-4bdd-9d12-27305978f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_df = kmeans_out.result\n",
    "d2 = kmeans_df.groupby('td_clusterid_kmeans').count()\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8123bd8d-aec8-4102-a27a-cbfbb02688aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(kmeans_out.model_data, \"complaints_clustermodel\", if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81bc022-49ae-4746-98e2-fb77fdae70a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the distance of each message to their cluster centroid. We pick the 20 closest messages\n",
    "DF_clusterdistance = KMeansPredict(\n",
    "    data = DF_embeddings,\n",
    "    object = DataFrame(\"complaints_clustermodel\"),\n",
    "    output_distance = True   \n",
    ").result\n",
    "\n",
    "\n",
    "DF_clusterdistance = DF_clusterdistance.assign(\n",
    "    rank_distance = DF_clusterdistance.td_distance_kmeans.window(\n",
    "            partition_columns=DF_clusterdistance.td_clusterid_kmeans,\n",
    "            order_columns=DF_clusterdistance.td_distance_kmeans\n",
    "        ).dense_rank()\n",
    "    )\n",
    "\n",
    "DF_clusterdistance_top = DF_clusterdistance.loc[DF_clusterdistance.rank_distance<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a56c37-2ef3-4cad-a4ed-ed570b6abe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_clusterdistance_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4afa86-8fac-4b4e-89ec-cccf75cf8cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_topmesages = DF_clusterdistance_top.join(\n",
    "    DF_complaints.select([\"row_id\",\"txt\"]),\n",
    "    how = \"inner\",\n",
    "    on =  [\"row_id = row_id\"],\n",
    "    lsuffix= \"a\"\n",
    ").select([\"td_clusterid_kmeans\", \"txt\"]).drop_duplicate()\n",
    "DF_topmesages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935ab7b1-72f7-461f-9535-efa0df784bb2",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>5. Visualization</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.1 WordCloud Visualization</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c078c8ac-b559-48c0-8ef0-68e7479691de",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Let's visualize all the clusters through wordcloud visualization.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef151e0b-5708-49d9-ad70-11599d0704ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Cloud all those clusters\n",
    "for i in range(0, num_clusters):\n",
    "    filtered_df = DF_topmesages[DF_topmesages.td_clusterid_kmeans == i]\n",
    "    df = filtered_df.to_pandas()\n",
    "    total_rows = len(df)\n",
    "\n",
    "    sw = ['x','xx','xxx','xxxx','xxxxx','xxxxxx']\n",
    "    es = list(set(stopwords.words('english')))\n",
    "    es.extend(sw)\n",
    "\n",
    "    text_tokens = word_tokenize(' '.join(df['txt']),preserve_line=True)\n",
    "    l_text_tokens = [item.lower() for item in text_tokens]\n",
    "    tokens_without_sw = [word for word in l_text_tokens if word not in es]\n",
    "\n",
    "    all_text = pd.Series(tokens_without_sw)\n",
    "\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,4))\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_text)\n",
    "\n",
    "    col_sum = tfidf_matrix.sum(axis=0).A.squeeze()\n",
    "    k = 5\n",
    "    top_indices = np.argsort(col_sum)[-k:][::-1]\n",
    "\n",
    "    dense = tfidf_matrix.todense()\n",
    "    df = pd.DataFrame(dense, columns=vectorizer.get_feature_names_out())\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    top_terms = feature_names[top_indices]\n",
    "    cluster_name = '_'.join(top_terms).upper()\n",
    "\n",
    "    print(\"Cluster #\" + str(i)+\": \"+cluster_name+\"\\n # of Rows: \"+str(total_rows)+\"\\n\")\n",
    "    # Generate a word cloud\n",
    "    wordcloud = WordCloud(width=800, \\\n",
    "                          height=400, \\\n",
    "                          background_color='white',\\\n",
    "                          collocations=True,\\\n",
    "                          max_words=100,\\\n",
    "                          min_word_length=1, \\\n",
    "                         ).generate_from_frequencies(df.T.sum(axis=1))\n",
    "\n",
    "    # Plot the word cloud\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='gaussian')\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud for Text Data (TF-IDF)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b18331-766e-43b1-baae-f16a782c10fe",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;'> \n",
    "\n",
    "<p style='font-size:18px;font-family:Arial;'><b>5.2 Visualization of Clusters with Complaints</b></p> \n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>The graph displays the clustering of complaints into distinct groups. Based on the analysis, the data has been divided into 5 optimal clusters, each representing a unique pattern or category of complaints. This clustering approach helps to identify the key areas or types of complaints that are most prevalent, allowing for more targeted investigation and resolution efforts.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f845f1-cf03-46b2-a734-073835053871",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_df = DF_embeddings.join(\n",
    "    other = kmeans_df,\n",
    "    on = [\"row_id\"],\n",
    "    how = \"inner\",\n",
    "    lprefix=\"l\",\n",
    "    rprefix=\"r\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bc1aa2-f160-4f42-ad75-a2532d21605b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#adding complaint txt\n",
    "clustered_df_txt = clustered_df.join(\n",
    "    DF_complaints.select([\"row_id\",\"txt\"]),\n",
    "    how = \"inner\",\n",
    "    on =  [\"l_row_id = row_id\"],\n",
    "    lsuffix= \"a\"\n",
    ").drop_duplicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653f1398-e497-48bf-93e8-cd0e1bf495d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb = DataFrame('kmeans_features').to_pandas()\n",
    "clus = clustered_df_txt.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c63aeb0-ff9a-497f-8622-c67403e474b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=123)\n",
    "tsne_result = tsne.fit_transform(clus.iloc[:, 2:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c7d20-11de-446e-9014-5b7450b65269",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df = pd.DataFrame(tsne_result, columns=['tsne_1', 'tsne_2'])\n",
    "tsne_df['cluster_id'] = clus['td_clusterid_kmeans']\n",
    "tsne_df['complaint_id'] = clus['l_row_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba2ad3c-4ccd-4c57-906d-54e69e4094c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = 'notebook' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1172672-bf05-4077-ac21-ae1038b81a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame combining t-SNE results with complaint information\n",
    "tsne_complaint_df = pd.DataFrame(tsne_result, columns=['tsne_1', 'tsne_2'])\n",
    "tsne_complaint_df['cluster_id'] = clus['td_clusterid_kmeans']\n",
    "tsne_complaint_df['complaint_id'] = clus['l_row_id']\n",
    "tsne_complaint_df['complaint'] = clus['txt']\n",
    "\n",
    "# Truncate text for hover data\n",
    "max_chars = 50  # Maximum characters to display\n",
    "tsne_complaint_df['truncted_complaint'] = clus['txt'].apply(lambda x: x[:max_chars] + '...' if len(x) > max_chars else x)\n",
    "\n",
    "# Plot using Plotly Express\n",
    "fig = px.scatter(tsne_complaint_df, x='tsne_1', y='tsne_2', color='cluster_id',\n",
    "                 hover_data=['complaint_id', 'truncted_complaint', 'cluster_id'])\n",
    "\n",
    "fig.update_traces(marker=dict(size=15))\n",
    "fig.update_layout(\n",
    "    title='t-SNE Visualization of Clusters with Complaints',\n",
    "    xaxis_title='dimension-1',\n",
    "    yaxis_title='dimension-2',\n",
    "    xaxis=dict(tickangle=45),\n",
    "    width=1000,\n",
    "    height=800,\n",
    "    hoverlabel=dict(\n",
    "        bgcolor=\"white\",\n",
    "        font_size=16,\n",
    "        font_family=\"Rockwell\"\n",
    "    ),\n",
    "    autosize=False,\n",
    ")\n",
    "\n",
    "# Customize the hovertemplate\n",
    "fig.update_traces(hovertemplate=\"<b>Complaint ID:</b> %{customdata[0]}<br>\"\n",
    "                                 \"<b>Complaint:</b> %{customdata[1]}<br>\"\n",
    "                                 \"<b>Cluster ID:</b> %{customdata[2]}<br><extra></extra>\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fda723e-4617-4fbf-bbe9-f85cd392b5ac",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>6. Get Topic Names by asking a LLM</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "To leverage the summarization capabilities of large-scale language models, we use a multi-billion parameter model to generate meaningful topic names based on representative complaints from each cluster. This step requires an OpenAI API key, as the model runs through an external API. If you don't have an OpenAI API key, use the pre-generated topic names below.<br>Also, feel free to play around with the prompt and see how this changes the cluster names.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20238b6e-e61e-4e83-9e4c-c56dcac1e6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to True, if you have an OpenAI key\n",
    "I_Have_an_OpenAI_API_Key = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f198d7d-85e7-4138-a4e3-36e146fabae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if I_Have_an_OpenAI_API_Key:\n",
    "    import os, getpass\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OPENAI API KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd07538-6c74-4e27-adcf-7ef8a507c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if I_Have_an_OpenAI_API_Key:\n",
    "    prompt_template = \"\"\"Your task is to identify a common topic of 10 messages that have shown similar vector embeddings. \n",
    "    Your answer should be exactly one sentence, maximal 10 words long, summarising the topic. You can skip unneccary filler words.\n",
    "    The answer should not be starting with \"The common topic of the messages is\", or \"the topic is\", or \"Customers are complaining\" etc.\n",
    "    \n",
    "    Here are the 10 messages:\n",
    "    \n",
    "    {messages}\n",
    "    \n",
    "    ====\n",
    "    Topic:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba2679b-0e0b-42d9-a65f-15d3a69f483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topmessages=DF_topmesages.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cc953c-6c0a-484c-8476-596294286743",
   "metadata": {},
   "outputs": [],
   "source": [
    "if I_Have_an_OpenAI_API_Key:\n",
    "    from openai import OpenAI\n",
    "    results =  {}\n",
    "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    for i in range (5):\n",
    "        cluster_feedback = '\\n\\n'.join(df_topmessages[df_topmessages['td_clusterid_kmeans'] == i]['txt'])\n",
    "        this_prompt = prompt_template.format(messages = cluster_feedback)\n",
    "        try:\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": this_prompt,\n",
    "                    }\n",
    "                ],\n",
    "                model=\"gpt-4o\",\n",
    "                temperature=0,\n",
    "                max_tokens=4096\n",
    "            )\n",
    "            results[i] = chat_completion.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Failed to call OpenAI API: {str(e)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73709a1-d5e8-4a41-a916-c2a9b74ff2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not I_Have_an_OpenAI_API_Key :\n",
    "    #pre-defined topics\n",
    "    results = {\n",
    "            0: 'Network Coverage',\n",
    "            1: 'Call Drops',\n",
    "            2: 'Internet Speed',\n",
    "            3: 'Billing Errors',\n",
    "            4: 'Overcharging'\n",
    "}\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e89db58-aa11-4ca1-a590-ee7b0a18cc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dict → DataFrame with 2 columns\n",
    "df = pd.DataFrame(list(results.items()), columns=[\"id\", \"txt\"])\n",
    "copy_to_sql(df,table_name='telco_topics_of_interest', if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a47e0c-349f-422b-a7b4-0f2d5e3a2049",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>7. Generate Embeddings for Topics and  get Similarity</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efce204-74d7-4d2c-93a9-1a096f8b9eab",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "Now that we have abstracted topics from the data, we need to generate embeddings for them. This step is crucial because, in the next phase, we will calculate the <b>pairwise similarity</b> between complaints and topics, effectively computing a <b>Cartesian product</b> of all complaint-topic pairs.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b139738-a57f-46d2-99ee-96ab8eedee2c",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>7.1 Generating Embedding for Topics Data</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>We will generate the embeddings for the Topics data in 3 steps as explained earlier in section 3.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167c4db7-60ef-434c-a65f-cb30a5dd9ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic = ONNXEmbeddings(\n",
    "    newdata = DataFrame('telco_topics_of_interest'),\n",
    "    modeldata = my_model, \n",
    "    tokenizerdata = my_tokenizer, \n",
    "    accumulate = [\"id\", \"txt\"],\n",
    "    model_output_tensor = \"sentence_embedding\",\n",
    "    output_format = f'FLOAT32({number_dimensions_output})',\n",
    "    enable_memory_check = False\n",
    ").result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f80201-c285-41cd-ba6e-94b17aa65944",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd6f085-630f-401b-8139-3f2840ca81c9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'> As we can see from the above, we have generated embeddings for the topic data.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a357ab-11f9-4a6c-9901-18289189bbc0",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>7.2 Semantic Similarity</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Now we will run Semantic Similarity of the Topics Embeddings against the Complaints Embeddings table. Vector Distance is a measure of the similarity or dissimilarity between two vectors in multidimensional space. We will use Vantage's TD_VectorDistance function. The <b>TD_VectorDistance</b> function accepts a table of target vectors and a table of reference vectors and returns a table that contains the distance between target-reference pairs. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2059155f-33df-4fe8-89eb-fb98bbeb0fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_new_vectdist = VectorDistance(\n",
    "        target_data = DF_embeddings,\n",
    "        target_id_column = \"row_id\",\n",
    "        reference_data = df_topic,\n",
    "        ref_id_column = \"id\",\n",
    "        distance_measure= \"COSINE\",    \n",
    "        target_feature_columns=\"emb_0:emb_767\",\n",
    "        ref_feature_columns=\"emb_0:emb_767\",\n",
    "        volatile = True\n",
    "    ).result.join(\n",
    "         DF_complaints,\n",
    "        on = [\"target_id = row_id\"],\n",
    "        how = \"left\").join(\n",
    "         df_topic.select([\"id\",\"txt\"]),\n",
    "         on = [\"reference_id = id\"],\n",
    "         how = \"left\",rsuffix = 'topic')\n",
    "DF_new_vectdist=DF_new_vectdist.assign(similarity = 1.0-DF_new_vectdist.distance)\n",
    "DF_new_vectdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc886c8-cd35-4fdd-914c-251d4fddfa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying the top 2 records for each reference_id from the similarity result created\n",
    "window = DF_new_vectdist.window(partition_columns=\"reference_id\",\n",
    "                           order_columns=\"similarity\",\n",
    "                           sort_ascending=False)\n",
    "df = window.rank()\n",
    "df[df.col_rank.isin([1,2])].sort(['reference_id','col_rank']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c201c57-879f-4a5d-92b1-839bb594f106",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>7.3 Interactive Dashboard for BI reporting</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>As a final step, we build a dashboard designed to serve as a <b>business intelligence (BI) reporting tool</b>, allowing us to analyze how topic prevalence changes over time. This interactive dashboard provides a structured way to explore complaint trends and refine topic detection dynamically.\n",
    "<ul style = 'font-size:16px;font-family:Arial;'>Dashboard Requirements\n",
    "    <li><b>Visualizing topic trends:</b> Display the number of complaints per topic per month using a <b>multi-line chart</b>, filtering only those complaints with a similarity score above a defined threshold (default: <b>0.6</b>).</li>  \n",
    "<li><b>Dynamic threshold adjustment:</b> Allow users to modify the similarity threshold, automatically updating the visualization in real time.  \n",
    "    </li></ul>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "The dashboard logic is encapsulated in the <code>`topics_widget.py`</code> module.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847dfbbf-e660-4bd9-85d1-945e750ce493",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_new_vectdist.assign(\n",
    "             topic_id = DF_new_vectdist.reference_id,\n",
    "             topic = DF_new_vectdist.txt_topic,\n",
    "             year_month = col(\"td_month_begin(complaint_date)\")\n",
    "            ).select([\"row_id\", \"topic_id\",\"topic\",\"similarity\", \"year_month\"  ]).to_sql(\"consumer_complaint_topic_similarity\", if_exists = \"replace\",\n",
    "            primary_index = [\"year_month\", \"topic_id\"], \n",
    "            types= {\"year_month\":DATE},\n",
    "            temporary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ba98cc-b333-4b95-95cf-123c34fb112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_new_similarity = DataFrame(\"consumer_complaint_topic_similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1386784-1e18-430c-867b-968b3bc2adcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils/topics_distance.py\n",
    "%run utils/topics_widget.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23793d3e-559f-4c24-98da-06ae89a26342",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_complaints_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cf8020-c8c9-4ff1-85e5-30a467a2e572",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>Conclusion</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>In this demo we have seen that how a <b>fully data-driven approach</b> can help analyze large volumes of text data, automatically identifying topics and tracking their trends over time. Instead of relying on <b>prompt engineering</b> to classify messages—which can be inconsistent, expensive, and hard to scale—we used <b>embeddings, clustering and Vector Distance</b> to get a <b>deterministic and repeatable</b> solution.  <br>\n",
    "By applying <b>K-Means clustering</b> on complaint embeddings, we discovered topics without predefining them. A <b>large language model (LLM)</b> then helped generate human-readable names for these clusters, but only once—keeping costs low while still benefiting from its summarization power. From there, we converted topic names into embeddings and calculated <b>vector similarities</b>, allowing us to efficiently map messages to topics in a <b>scalable and automated</b> way.<br>The final step was building an <b>interactive BI dashboard</b> that lets users explore topic trends over time and tweak similarity thresholds. <br>\n",
    "With this approach, we get the <b>best of both worlds</b>: the flexibility of unsupervised learning, the power of embeddings, and the practicality of real-time reporting—all while keeping things <b>scalable, cost-efficient, and environmentally friendly</b>.    \n",
    "</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c55b0d-6159-4a8c-a3c2-e87df578fbfc",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>6. Cleanup</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8710e68-dd46-4115-9ec3-928588b803bc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;'><b>Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Cleanup work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f170503-df80-49cd-a85e-8417619f54ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['embeddings_models','embeddings_tokenizers','complaints_clustermodel','telco_topics_of_interest','consumer_complaint_topic_similarity']\n",
    "\n",
    "# Loop through the list of tables and execute the drop table command for each table\n",
    "for table in tables:\n",
    "    try:\n",
    "        db_drop_table(table_name=table)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c47c2b-7d73-4237-95b9-a2c7c04a4947",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b057f0da-0043-472d-b762-8bcd1b8404bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_Telco_Complaints_Onnx');\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae18ad9-9836-46a0-9810-f42e9ef5c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08206109-4d2a-4a7f-a169-c60709384d05",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2025. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
