{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38bc532d-c78c-4c89-b191-242da0733f39",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Predictive Maintenance using Vantage\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff71661-19b4-423a-867a-7c815b064c81",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Introduction</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Y-Machine</b> is a manufacturing company that operates a large fleet of machines across multiple locations. They have been experiencing frequent machine breakdowns, which has been causing significant losses in production time and maintenance costs. To address this issue, <b>Y-Machine</b> is looking for a predictive maintenance solution that can help them identify potential machine failures before they occur, allowing them to proactively schedule maintenance and minimize downtime.</p>\n",
    "\n",
    "<center><img src=\"./images/giphy.gif\" alt=\"Machine GIF\"/></center>\n",
    "<p><a href=\"https://giphy.com/gifs/Ykga9Kp0xT4GswQAbh\">via GIPHY</a></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>To achieve the goal of predictive maintenance, Y-Machine will be leveraging the power of <b>Teradata Vantage</b>, an advanced analytics platform. With Teradata Vantage, we can deploy machine learning algorithms through teradataml python library, which enable us to identify and mitigate potential machine failures before they even occur.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Teradata Vantage provides us with the necessary capabilities to analyze the vast amounts of data generated by Y-Machine's machines, such as temperature, rotational speed, and torque. By processing this data and detecting anomalies or patterns, we can take proactive measures to address potential issues, preventing costly downtimes and ensuring the longevity of the machines.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>With Teradata Vantage, we can help Y-Machine stay ahead of the curve, providing them with cutting-edge analytics capabilities to improve the reliability and efficiency of their machines.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833b5bf-74af-42be-8543-3782e1da95dc",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50a4aa-1211-44fc-8166-317c35253207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import warnings\n",
    "\n",
    "# Data Manipulation and Analysis Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Teradata Libraries\n",
    "from teradataml import *\n",
    "configure.val_install_location = 'val'\n",
    "\n",
    "# Configuration\n",
    "display.max_rows = 5\n",
    "\n",
    "# Suppress Warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59718f8-7af4-4d1a-abc7-a860eb7cbae3",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>1. Connect to Vantage</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>You will be prompted to provide the password. Enter your password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e079584d-0767-42a0-a254-f9623b51cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username = 'demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e69ecb-f5f5-49da-9ce8-d93b4599bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=Predictive_Maintenance_Python.ipynb;' UPDATE FOR SESSION;''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22db506-84a7-406b-be9f-9fe69d268ba4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a90d5e-2e0a-4701-9368-adb97f7c9590",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We have provided data for this demo on cloud storage. You can either run the demo using foreign tables to access the data without any storage on your environment or download the data to local storage, which may yield faster execution. Still, there could be considerations of available storage. Two statements are in the following cell, and one is commented out. You may switch which mode you choose by changing the comment string.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf2b3c2-f90e-428d-a949-c16294016e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call get_data('DEMO_PredictiveMaintenance_cloud');\"        # Takes about 1 minute\n",
    "# %run -i ../run_procedure.py \"call get_data('DEMO_PredictiveMaintenance_local');\"        # Takes about 2 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1670345f-dfd2-440b-919a-ff824c65c2c9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Next is an optional step – if you want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce328a8-e2bf-4b64-98aa-5f8007f86815",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f3fe2-ed63-4838-bb19-4c0d0157453d",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>2. Read the data from Vantage as a teradataml Dataframe</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9951cf-e2b0-40d7-9a8f-a01c7f48ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(in_schema('DEMO_PredictiveMaintenance', 'Machine_Data'))\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ac6f90-11f3-4522-a72a-405479290d08",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The dataset mentioned above consists of ten columns, and among them, the 'Target' and 'Failure_Type' columns are dependent variables. The 'Target' column contains binary values, with 1(failure) and 0(no failure) indicating binary classification scenario. On the other hand, the 'Failure_Type' column comprises multiple types of failures, indicating a multi-class classification scenario.\n",
    "</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b><i>*Please scroll down to the end of the notebook for detailed column descriptions of the dataset.</i></b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a852763-cd2b-4034-8ed5-cfcd0484e2b9",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>3. Data Exploration</b>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Removing nulls and redundant columns</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the next cell, we'll check for null values.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30069b9e-b3f6-425e-a704-b7c630077d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(null_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0a8901-891f-4c90-a8f1-3cc8cb8d87bd",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>From the above results, we see no null values in the dataset as all the columns have 10,000 rows.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the next cell, we'll remove the Product_ID column as we already have a UID column as a unique identifier.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955720ad-0801-45b0-bb55-27d90726c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column Product_ID\n",
    "df = df.drop(columns=['Product_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16608f3f-8cf0-4d32-905f-f250acc0af4d",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Checking target variable distribution</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the next cell, we'll check the distribution of target variables, i.e., Target and Failure_Type.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f21d79-24e0-4a02-ab21-13230183cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of Failure_Type by Target and create a Pandas DataFrame\n",
    "tdf = df.groupby('Target').assign(count = df.Failure_Type.count()).sort('count', ascending = False).to_pandas()\n",
    "\n",
    "# Create a figure with a larger size\n",
    "fig, ax = plt.subplots(figsize = (8, 6))\n",
    "\n",
    "# Sort the DataFrame by count in descending order\n",
    "tdf = tdf.sort_values(by = 'count', ascending = False)\n",
    "\n",
    "# Create a bar chart of the counts by Target\n",
    "ax = tdf.plot.bar(x = \"Target\", y = \"count\", rot = 45, colormap = 'summer', ax = ax)\n",
    "\n",
    "# Add the count to the top of each bar\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i, label_type = 'edge', fontsize = 10)\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "ax.set_title(\"Failure Distribution\")\n",
    "ax.set_xlabel(\"Failure?\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "\n",
    "# Add a grid to the plot\n",
    "ax.grid(axis = 'y', linestyle = '--', alpha = 0.7)\n",
    "\n",
    "# Add a legend to the plot\n",
    "ax.legend(['Count'], loc = 'best', fontsize = 12)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dd09a1-25b7-41ed-9487-e67b308c0225",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The distribution here shows that the majority of the products have no failure, and a tiny number of products have some failure.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Let's check further w.r.t. Failure_Type</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c595311-78fb-431c-a1b1-d67ff055f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of Failure_Type and create a Pandas DataFrame\n",
    "tdf = df.groupby('Failure_Type').assign(count = df.Failure_Type.count()).sort('count', ascending = False).to_pandas()\n",
    "\n",
    "# Create a figure with a larger size\n",
    "fig, ax = plt.subplots(figsize = (8, 6))\n",
    "\n",
    "# Sort the DataFrame by count in descending order\n",
    "tdf = tdf.sort_values(by = 'count', ascending = False)\n",
    "\n",
    "# Create a bar chart of the counts by Failure_Type\n",
    "ax = tdf.plot.bar(x = \"Failure_Type\", y = \"count\", rot = 45, colormap = 'summer', ax = ax)\n",
    "\n",
    "# Add the count to the top of each bar\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i, label_type = 'edge', fontsize = 10)\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "ax.set_title(\"Type of Failure Distribution\")\n",
    "ax.set_xlabel(\"Type of Failure\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "\n",
    "# Add a grid to the plot\n",
    "ax.grid(axis = 'y', linestyle = '--', alpha = 0.7)\n",
    "\n",
    "# Add a legend to the plot\n",
    "ax.legend(['Count'], loc = 'best', fontsize = 12)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fdc1d6-c2fc-4b31-b216-5bb4e7b5c84b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The distribution here shows that the majority of the products have no failure, and a tiny number of products have different failures.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>There are two target variables: 'Target' and 'Failure_Type'. Let's check if everything is ok.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b08bbf9-af9b-4caf-a1d8-b9b32385c8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failure = df[df['Target'] == 1]\n",
    "df_failure.groupby('Failure_Type').assign(count = df.Failure_Type.count()).sort('count', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1046e30-22f7-4691-b445-4360edd22a40",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note:</b> 9 values are classified as failure in the 'Target' variable but as No Failure in the 'Failure_Type' variable. Let's check the dataset:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0000f65c-cd38-4b7c-b02d-193b0318433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failure[df_failure['Failure_Type'] == 'No Failure']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e3ac79-bff3-48c3-80e5-b7dc274ec5c5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>It could go both ways, either failure or no failure. It makes sense to remove those instances since we do not know the real target here.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e4bd2a-5219-463c-a4c6-15b3c3e8faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_possible_failure = list(df_failure[df_failure['Failure_Type'] == 'No Failure'].get_values()[:, 0])\n",
    "df = df.drop(labels = index_possible_failure, axis = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77cd57d-6b16-47f8-b072-6e1f6cff3e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failure = df[df['Target'] == 0]\n",
    "df_failure.groupby('Failure_Type').assign(count = df.Failure_Type.count()).sort('count', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec86430-029f-444d-af15-d1ea6a52f7ec",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note:</b> 18 instances are classified as Random Failures by 'Failure_Type', whereas they are classified as No failure by the 'Target'. These 18 instances are, in fact, all instances of 'Random Failures'. Let's check and remove those instances, as we do not know if they belong to the Failure class. Hence, we will end up with four types of failures since 'Random Failures' will be removed altogether.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c85191-6d18-4964-9f1e-29f584c0d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failure[df_failure['Failure_Type'] == 'Random Failures']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cfda96-55cb-4cac-ba8d-cfdc61641602",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_possible_failure = list(df_failure[df_failure['Failure_Type'] == 'Random Failures'].get_values()[:, 0])\n",
    "df = df.drop(labels = index_possible_failure, axis = 'index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f78548-c68b-44a8-8c1b-f7e204ad6bbe",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Checking the correlation</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here, we'll check the distribution of target variables w.r.t features like torque, rotational speed, air temperature and process temperature.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858f9346-0631-4cc6-b748-32f378796a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.to_pandas()\n",
    "\n",
    "# Set the figure size\n",
    "fig, ax = plt.subplots(1, 2, figsize = (22, 8))\n",
    "\n",
    "# Set the titles for each subplot\n",
    "ax[0].set_title('Rot. Speed vs Torque wrt Failure Type (Including class no failure)')\n",
    "ax[1].set_title('Rot. Speed vs Torque wrt Failure Type (Excluding class no failure)')\n",
    "\n",
    "# Set the color palette for the plots\n",
    "palette = ['#E9C0CB', '#39A692', '#976EBD', '#ACBF5C', '#DF8B4E']\n",
    "\n",
    "# Plot the scatterplots\n",
    "sns.scatterplot(data = df1, x = 'Rotational_speed', y = 'Torque', hue = 'Failure_Type', palette = palette, ax = ax[0])\n",
    "sns.scatterplot(data = df1[df1['Target'] == 1], x = 'Rotational_speed', y = 'Torque', hue = 'Failure_Type',\n",
    "                palette = palette[1:], ax = ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eb5a4e-9847-4ca0-bb83-2a2dc766f08f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Some insights:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Power failure happens both for lower and higher rotational speed/torque. It is the type of failure with the highest rotational speed (over 2500rpm) and lowest torque (below around 15Nm). In other words, only power failures occur above and below these thresholds.</li>    \n",
    "    <li>Between torques 16Nm and 41Nm, all failures are tool wear.</li>\n",
    "    <li>Overstrain failures occur with torques ranging from around (47 and 68Nm) and rotational speeds from 1200 to 1500rpm approximately.</li>\n",
    "    <li>The torque range is smaller for heat dissipation failures, and the rotational speed range is higher than for overstrain failures </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e24ec1e-3224-4ced-a3ac-f4497ec6247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "fig, ax = plt.subplots(1, 2, figsize = (22, 8))\n",
    "\n",
    "# Set the titles for each subplot\n",
    "ax[0].set_title('Process Temperature vs Air Temperature wrt Failure Type (Including class no failure)')\n",
    "ax[1].set_title('Process Temperature vs Air Temperature wrt Failure Type (Excluding class no failure)')\n",
    "\n",
    "# Set the color palette for the plots\n",
    "palette = ['#E9C0CB', '#39A692', '#976EBD', '#ACBF5C', '#DF8B4E']\n",
    "\n",
    "# Plot the scatterplots\n",
    "sns.scatterplot(data = df1, x = 'Process_temperature', y = 'Air_temperature', hue = 'Failure_Type', palette = palette, ax = ax[0])\n",
    "sns.scatterplot(data = df1[df1['Target'] == 1], x = 'Process_temperature', y = 'Air_temperature', hue = 'Failure_Type',\n",
    "                palette = palette[1:], ax = ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908421a3-fb22-4281-a947-0385e9d84c29",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Some insights:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Heat Dissipation Failure happens when Process Temperature and Air Temperature exceed 300 K.</li>\n",
    "    <li>Other failures have no meaningful insights.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3ff7fc-3cce-4281-82b8-2acf12f11225",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>4. Data Transformation</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the next step, we'll use Label Encoder to convert a categorical variable to integer and numerical columns will be scaled using the ZScore function.\n",
    "<br>\n",
    "<br>\n",
    "ZScore will allows rescaling of continuous numeric data in a more sophisticated way than a Rescaling transformation. In a Z-Score transformation, a numeric column is transformed into its Z-score based on the mean value and standard deviation of the data in the column. Z-Score transforms each column value into the number of standard deviations from the mean value of the column. This non-linear transformation is useful in data mining rather than in a linear Rescaling transformation.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d22bd7c-3b93-4517-8b70-76ac6b749632",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739bf137-d90f-471c-9f42-e8d70d9cc5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the label encoders\n",
    "type_encoder = LabelEncoder(values = {\"L\": 1, \"M\": 2, \"H\": 3}, columns = \"Type\", datatype = 'integer')\n",
    "failure_type_encoder = LabelEncoder(values = {\n",
    "                            \"No Failure\": 1,\n",
    "                            \"Heat Dissipation Failure\": 2,\n",
    "                            \"Power Failure\": 3,\n",
    "                            \"Overstrain Failure\": 4,\n",
    "                            \"Tool Wear Failure\": 5\n",
    "                            }, \n",
    "                    columns = ['Failure_Type'],\n",
    "                    datatype = 'integer'\n",
    "                  )\n",
    "\n",
    "# Define the standard scaler\n",
    "z_scaler = ZScore(columns = ['Air_temperature', 'Process_temperature',\n",
    "                      'Rotational_speed', 'Torque', 'Tool_wear'],\n",
    "            out_columns = ['Air_temperature', 'Process_temperature',\n",
    "                      'Rotational_speed', 'Torque', 'Tool_wear'])\n",
    "\n",
    "# Define the retain object\n",
    "retain = Retain(columns = \"Target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974a9726-80fc-4267-a5e8-4f617f7f15a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = valib.Transform(data = df,\n",
    "                      label_encode = [type_encoder, failure_type_encoder],\n",
    "                      zscore = z_scaler,\n",
    "                      retain = retain,\n",
    "                      index_columns = 'UID')\n",
    "df_trans = obj.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2c61d7-4c3d-4404-94f6-0701d227101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9421ea-c89c-4204-8dd2-b36259a364c1",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>As \"Type\" is a reserved keyword, we'll rename the column \"Machine_type.\"<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fe1302-49c9-4b19-bd69-d9b5b5e5f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_td_reserved_keywords('type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde6e179-1b74-41f4-9bd6-ff7b518cd8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans = df_trans.assign(Machine_type = df_trans.Type)\n",
    "df_trans = df_trans.drop(columns=['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c892747b-b280-423a-8699-5221485f66b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d805fbf-7d7f-47e8-a010-9be1a3da83bd",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>5. Train-Test Split</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the next step, we'll split the transformed dataset into training and testing datasets in the ratio 80:20, and we will save the datasets into Vantage.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934a5223-29e4-4959-9ce5-cac8f085b470",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTestSplit_out = TrainTestSplit(\n",
    "                                    data = df_trans,\n",
    "                                    id_column = \"UID\",\n",
    "                                    train_size = 0.80,\n",
    "                                    test_size = 0.20,\n",
    "                                    seed = 42\n",
    ")\n",
    "\n",
    "df_train = TrainTestSplit_out.result[TrainTestSplit_out.result['TD_IsTrainRow'] == 1].drop(['TD_IsTrainRow'], axis = 1)\n",
    "df_test = TrainTestSplit_out.result[TrainTestSplit_out.result['TD_IsTrainRow'] == 0].drop(['TD_IsTrainRow'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4279af-ee91-4c18-9386-a109b9414760",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(df_train,\n",
    "            table_name = 'df_train',\n",
    "            if_exists = 'replace')\n",
    "\n",
    "copy_to_sql(df_test,\n",
    "            table_name = 'df_test',\n",
    "            if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346840f5-df98-46b8-8ee8-4820ac8a0c86",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>6. In Database Model Training (Binary Classification)</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the next step, we'll use the XGBOOST function to train an xgboost model using the 'Target' column as the target variable for binary classification. XGBoost's tree-based ensemble approach, regularization techniques, handling of missing values, scalability, and feature importance capabilities make it a powerful and effective choice for modeling tabular data, often leading to superior performance compared to other machine learning algorithms.\n",
    "<br>\n",
    "<br>\n",
    "The XGBoost function, eXtreme Gradient Boosting, implements the gradient-boosted decision tree designed for speed and performance. It has recently been dominating applied machine learning.\n",
    "<br>\n",
    "<br>\n",
    "In gradient boosting, each iteration fits a model to the residuals (errors) of the previous iteration to correct the errors made by existing models. The predicted residual is multiplied by this learning rate and then added to the previous prediction. Models are added sequentially until no further improvements can be made. It is called gradient boosting because it uses a gradient descent algorithm to minimize the loss when adding new models.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34cd6cf-d819-49b8-bb8f-04c3fc411947",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost_out_1 = XGBoost(\n",
    "                            data = df_train,\n",
    "                            input_columns = '3:8',\n",
    "                            response_column = 'Target',\n",
    "                            max_depth = 7,\n",
    "                            num_boosted_trees = 10,\n",
    "                            model_type = 'CLASSIFICATION',\n",
    "                            seed = 2,\n",
    "                            lambda1 = 100000.0,\n",
    "                            shrinkage_factor = 1.0,\n",
    "                            iter_num = 10,\n",
    "                            column_sampling = 1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdf90da-89ba-4b99-9a9f-0c8fa80b7917",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>7. In Database Model Scoring</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "In the next step, we'll use the XGBoostPredict function to score the xgboost model trained in the previous step.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df5d491-1f88-472f-8e8c-5ecac4ae869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoostPredict_out_1 = XGBoostPredict(\n",
    "                                        newdata = df_test,\n",
    "                                        object = XGBoost_out_1.result,\n",
    "                                        id_column = 'UID',\n",
    "                                        accumulate = 'Target',\n",
    "                                        model_type = 'CLASSIFICATION',\n",
    "                                        object_order_column = ['task_index', 'tree_num', 'iter', 'class_num', 'tree_order'],\n",
    "                                        output_responses = ['0', '1'],\n",
    "                                        output_prob = True\n",
    ")\n",
    "\n",
    "out = XGBoostPredict_out_1.result.assign(Prediction = XGBoostPredict_out_1.result.Prediction.cast(type_ = BYTEINT))\n",
    "out = out.assign(Prediction = out.Prediction.cast(type_ = VARCHAR(2)))\n",
    "out = out.assign(Target = out.Target.cast(type_ = VARCHAR(2)))\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b928d6-568d-42ca-9106-4cde60fe87a4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Next, we'll use the ClassificationEvaluator function to evaluate the trained xgboost model on test data. This will let us know how well our model has performed on unseen data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928adf04-5675-4d35-a238-9c93dea47502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ClassificationEvaluator_obj = ClassificationEvaluator(\n",
    "                                                        data = out,\n",
    "                                                        observation_column = 'Target',\n",
    "                                                        prediction_column = 'Prediction',\n",
    "                                                        labels = ['0', '1']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c46f6c-4cdf-470a-bd59-ab9d140cefc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassificationEvaluator_obj.output_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355e7227-8a18-4c63-b071-13b940703d96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data and compute confusion matrix\n",
    "\n",
    "xgb_result = out.to_pandas()\n",
    "cm = confusion_matrix(xgb_result['Prediction'], xgb_result['Target'])\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = ['No Failure', 'Failure'])\n",
    "fig, ax = plt.subplots(figsize = (8, 8))\n",
    "disp.plot(ax = ax, cmap = 'Blues', colorbar = True)\n",
    "\n",
    "# Add labels and annotations\n",
    "plt.title('XGBoost Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.xticks(ticks = [0, 1], labels = ['No Failure', 'Failure'])\n",
    "plt.yticks(ticks = [0, 1], labels = ['No Failure', 'Failure'])\n",
    "\n",
    "# Add text to the plot to show the actual values of the confusion matrix\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, f'{cm[i, j]}', ha = 'center', va = 'center', color = 'white' if cm[i, j] > cm.max()/2 else 'black')\n",
    "        \n",
    "print(f'''This means that out of all the actual no-failure cases ({cm[0][0] + cm[0][1]}),\n",
    "{round(cm[0][0]/(cm[0][0] + cm[0][1])*100, 2)}% were correctly classified as no-failure, while\n",
    "{round(cm[0][1]/(cm[0][0] + cm[0][1])*100, 2)}% were incorrectly classified as failure.\n",
    "Similarly, out of all the actual failure cases ({cm[1][0] + cm[1][1]}),\n",
    "{round(cm[1][1]/(cm[1][0] + cm[1][1])*100, 2)}% were correctly classified as failure, while\n",
    "{round(cm[1][0]/(cm[1][0] + cm[1][1])*100, 2)}% were incorrectly classified as no-failure.''')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc3273f-5848-4819-8d7d-1054e9be0816",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_result['Target'] = xgb_result['Target'].astype(int)\n",
    "AUC_xgb = roc_auc_score(xgb_result['Target'], xgb_result['Prob_1'])\n",
    "fpr_xgb, tpr_xgb, thresholds_xgb = roc_curve(xgb_result['Target'], xgb_result['Prob_1'])\n",
    "plt.plot(fpr_xgb, tpr_xgb, color = 'green', label = 'XGB ROC. AUC = {}'.format(str(round(AUC_xgb, 4))))\n",
    "\n",
    "# Plot the diagonal dashed line\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8ed8a2-6a6f-4ed5-aaeb-f6d5cf0fc31a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The above metrics show that our model performs well on the binary classification test dataset.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c32ff2-c021-468b-98a9-43af77318e0f",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>8. In Database Model Training (Multi-Class Classification)</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the next step, we'll use the XGBOOST function to train an xgboost model using Failure_Type as the target variable for multi-class classification.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93577fdd-0eee-4506-a3d9-7a125c00610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost_out_1 = XGBoost(\n",
    "                            data = df_train,\n",
    "                            input_columns = '3:8',\n",
    "                            response_column = 'Failure_Type',\n",
    "                            max_depth = 7,\n",
    "                            num_boosted_trees = 10,\n",
    "                            model_type = 'CLASSIFICATION',\n",
    "                            seed = 2,\n",
    "                            lambda1 = 100000.0,\n",
    "                            shrinkage_factor = 0.9,\n",
    "                            iter_num = 10,\n",
    "                            column_sampling = 1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e69e89-62c6-4173-9cfe-d322fe0a58a3",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>9. In Database Model Scoring</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the next step, we'll use the TD_XGBoostPredict function to score the xgboost model trained in the previous step.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1fa98b-ac2d-4bb2-b943-b2fd2555b064",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoostPredict_out_1 = XGBoostPredict(\n",
    "                                        newdata = df_test,\n",
    "                                        object = XGBoost_out_1.result,\n",
    "                                        id_column = 'UID',\n",
    "                                        accumulate = 'Failure_Type',\n",
    "                                        model_type = 'CLASSIFICATION',\n",
    "                                        object_order_column = ['task_index', 'tree_num', 'iter', 'class_num', 'tree_order'],\n",
    "                                        output_responses = ['1', '2', '3', '4', '5'],\n",
    "                                        output_prob = True\n",
    ")\n",
    "\n",
    "out = XGBoostPredict_out_1.result.assign(Prediction = XGBoostPredict_out_1.result.Prediction.cast(type_ = BYTEINT))\n",
    "out = out.assign(Prediction = out.Prediction.cast(type_ = VARCHAR(2)))\n",
    "out = out.assign(Failure_Type = out.Failure_Type.cast(type_ = VARCHAR(2)))\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d094762-61a7-4034-a2c0-a5a7182d69aa",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Next, we'll use the ClassificationEvaluator function to evaluate the trained xgboost model on test data. This will let us know how well our model has performed on unseen data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae3cc39-9ebf-4f15-8291-27d308e4acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassificationEvaluator_obj = ClassificationEvaluator(\n",
    "                                                        data = out,\n",
    "                                                        observation_column = 'Failure_Type',\n",
    "                                                        prediction_column = 'Prediction',\n",
    "                                                        labels = ['1', '2', '3', '4', '5']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6a94b5-518f-4626-a405-9ff18110556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassificationEvaluator_obj.output_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5f42ba-0532-4db3-9088-4535c3c3a6ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load prediction results into a pandas dataframe\n",
    "xgb_result = out.to_pandas()\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(xgb_result['Prediction'], xgb_result['Failure_Type'])\n",
    "\n",
    "# Plot confusion matrix using ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "# Create figure and axes objects\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
    "\n",
    "# Set title and axis labels\n",
    "plt.title('XGBoost Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "\n",
    "# Set x and y ticks with labels and rotation\n",
    "plt.xticks(ticks=[0, 1, 2, 3, 4], labels=['No Failure', 'Heat Dissipation Failure', 'Power Failure', 'Overstrain Failure', 'Tool Wear Failure'], rotation=45)\n",
    "plt.yticks(ticks=[0, 1, 2, 3, 4], labels=['No Failure', 'Heat Dissipation Failure', 'Power Failure', 'Overstrain Failure', 'Tool Wear Failure'])\n",
    "\n",
    "# Add text to the plot to show the actual values of the confusion matrix\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, f'{cm[i, j]}', ha='center', va='center', color='white' if cm[i, j] > cm.max()/2 else 'black')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "print(f'''As an example, consider total power failure cases: ({cm[2][0] + cm[2][1], cm[2][2] + cm[2][3], cm[2][4]}),\n",
    "{cm[2][2]} were correctly classified as power failure,\n",
    "{cm[2][0]} were incorretcly classified as no failure,\n",
    "{cm[2][1]} were incorretcly classified as heat dissipation failure,\n",
    "{cm[2][3]} were incorretcly classified as overstrain failure,\n",
    "{cm[2][4]} were incorretcly classified as tool wear failure\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a174f15-eae8-4962-8476-1e7222440524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your dataframe with the columns described above\n",
    "# Extract the relevant columns\n",
    "y_true = xgb_result['Failure_Type'].values  # True labels (ground truth)\n",
    "y_pred = xgb_result['Prediction'].values  # Predicted labels\n",
    "y_probs = xgb_result[['Prob_1', 'Prob_2', 'Prob_3', 'Prob_4', 'Prob_5']].values  # Predicted probabilities for each class\n",
    "\n",
    "# Binarize the true labels\n",
    "y_true_binary = label_binarize(y_true, classes=np.unique(y_true))\n",
    "\n",
    "# Compute ROC curve and ROC-AUC for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(y_probs.shape[1]):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_binary[:, i], y_probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure()\n",
    "colors = ['b', 'g', 'r', 'c', 'm']\n",
    "for i in range(y_probs.shape[1]):\n",
    "    plt.plot(fpr[i], tpr[i], color=colors[i], lw=2,\n",
    "             label='Class {0} (AUC = {1:0.2f})'\n",
    "             ''.format(i+1, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-AUC Curve for 5-Class Prediction')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402b7ab3-a5db-4392-a67a-36b1f016c887",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The above metrics show that our model performs well on the multi-class classification test dataset.</p><hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Conclusion:</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In conclusion, the implementation of a predictive maintenance solution can greatly benefit Y-Machine by reducing machine downtime and maintenance costs, improving production efficiency, and increasing overall productivity. Proactive scheduling of maintenance based on real-time data and analytics can help prevent costly breakdowns and emergency repairs, leading to improved machine reliability.\n",
    "    <br>\n",
    "    <br>\n",
    "Additionally, setting limits and alarms on key parameters can enable early detection of potential failures, allowing for timely maintenance interventions. The ability to predict the type of failure can also help reduce diagnosis time, further optimizing maintenance efforts. By leveraging predictive maintenance, Y-Machine can make data-driven decisions to improve their maintenance strategy, leading to tangible benefits to the company's bottom line, including increased operational efficiency, reduced costs, and improved overall performance.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ebb8c3-cb01-46f7-84b1-33e5a54507b5",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>10. Cleanup</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ff078f-2f59-4e09-8ea6-5b9a2fc0bda0",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Cleanup work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fd8f89-67ed-4f8e-9942-ed37fbd30098",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['df_train', 'df_test']\n",
    "\n",
    "# Loop through the list of tables and execute the drop table command for each table\n",
    "for table in tables:\n",
    "    try:\n",
    "        db_drop_table(table_name = table)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aacb87c-0d81-40f0-8754-608d47e602cc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b398148-9486-4535-8c06-d3f77669bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_PredictiveMaintenance');\"        # Takes 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef4cbe-1beb-4c65-ac60-ffd6250668a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae971f90-bef1-4228-bcbf-c333e9843284",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>Dataset:</b>\n",
    "\n",
    "- `UID`: Unique identifier ranging from 1 to 10000\n",
    "- `Product_ID`: Unique Product ID consisting of a letter L, M, or H for low (50% of all products), medium (30%) and high (20%) as product quality variants and a variant-specific serial number\n",
    "- `Type`: Consisting of a letter L, M, or H for low (50% of all products), medium (30%) and high (20%) as product quality variants and a variant-specific serial number\n",
    "- `Air_temperature`: Generated using a random walk process later normalized to a standard deviation of 2 K around 300 K\n",
    "- `Process_temperature`: Generated using a random walk process normalized to a standard deviation of 1 K, added to the air temperature plus 10 K\n",
    "- `Rotational_speed`: Calculated from a power of 2860 W, overlaid with a normally distributed noise\n",
    "- `Torque`: Torque values are normally distributed around 40 Nm with a Ïƒ = 10 Nm and no negative values\n",
    "- `Tool_wear`: The quality variants H/M/L add 5/3/2 minutes of tool wear to the used tool in the process\n",
    "- `Target`: If the machine failed or not (boolean)\n",
    "- `Failure_Type`: Type of failure -\n",
    "                            No Failure,\n",
    "                            Heat Dissipation Failure,\n",
    "                            Power Failure,\n",
    "                            Overstrain Failure,\n",
    "                            Tool Wear Failure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5463848-592f-4321-b852-287e133872dd",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2023. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
