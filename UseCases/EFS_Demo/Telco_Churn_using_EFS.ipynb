{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f2f3523-c5f5-42c1-8e78-eb8a818fd487",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial;color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Telco Churn using Enterprise Feature Store in Vantage\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff89c2c-c21b-40c0-b60f-24dedde6270b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial'><b>Introduction</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Customer churn is a concern for all companies, but the complexity makes it difficult to track. Customers may leave due to various reasons such dissatisfaction with service quality, pricing, customer service, or finding better alternatives from competitors. Although some churn may be expected, companies aim to retain their customers to avoid using additional resources to find new customers. Thus, with the help of Teradata Vantage, companies can attain their goal of identifying the factors contributing to the churn, so they can take appropriate measures to retain customers. Vantage’s capabilities allow companies to analyze large amounts of customer data, such as usage patterns, billing information, demographics, and interactions, to find patterns that may indicate customers who are at risk of churning. Plus, Teradata’s machine learning and predictive analytics can be used to build models to predict customers which are likely to churn in the future. This information will give companies the chance to intervene, including sending targeted marketing campaigns, personalized offers, improved customer service, or addressing customer concern.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Successful AI/ML implementations face three main challenges:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial'><b>The Data Problem:</b> Quality data and feature engineering consume 80% of the implementation time. Even when different use cases share the same source data and features, organizations often handle data preparation separately.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'><b>The Scale Problem:</b> Real-world use cases often require multiple models. In production, these models require fresh features engineered in the same way as during training. Ensuring the auditability of these features behind model decisions is crucial.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'><b>The Deployment Problem:</b> Transitioning prototypes to production, especially operationalizing data prep pipelines, is often problematic.</li></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Addressing these challenges requires strategic planning, skilled talent, and integration with existing systems. Oraganizations with a history in Data Management recognize the benefits of reusable Data Products, making Enterprise Feature Stores a valuable investment.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>A Feature Store is a curated repository of pre-calculated features, simplifying the journey from data to actionable insights. An Enterprise Feature Store extends across domains/teams, incorporating a Governance Framework for predictable feature delivery. </p>\n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial'><b>While most features are reusable, some need model-specific calculations before integration into a unified dataset.</b></p>\n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial'>The key difference between Feature Store (FS) and Enterprise Feature Store (EFS) is the scope across multiple domains/teams along with the Governance Framework (that gives an assurance that features are delivered under predictable SLAs and it also defines the operating model how the EFS is used across different teams/domains and how features lifecycle is managed). Although most Features are considered as re-usable, there is still some minor part of Features that must be calculated as model-specific (e.g., scaled variables, principal components, etc.) and then combined with the rest of the pre-calculated Features into a single data set (ADS). The figure below describes this co-existence of model-specific ADS(es) and model-independent EFS.</p>\n",
    "\n",
    "<img src='images/EFS.png'>\n",
    "\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Business Values</b></p>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial'>Rapid model creation and deployment through enterprise feature reuse.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Flexible creation and usage of new features without extensive engineering support.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Consistent definitions ensure accuracy and quick deployment.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Collaboration and sharing of features among teams.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Maintained feature lifecycle for compliance and auditability.</li>\n",
    "</p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Why Vantage?</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>There are several reasons why EFS naturally fits to Teradata Vantage:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Utilizes Teradata Vantage with its powerful Analytical Library and SQL Engine.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Primary Index enables efficient single-row access for online feature use.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Single platform for both online and offline feature stores.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Macros reduce parsing overhead from API access.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>R and Python code execution within SQL Engine.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Bi-temporal querying capability.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Scalable MPP power for feature computation.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Industry-specific Logical Data Model as a feature source.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Connectivity to Object Storage via NOS for feature data sourcing.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Query Grid facilitates access to multiple data sources.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Close-to-real-time feature delivery using Query Services and Teradata Intelligent Memory.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Workload management prioritizes tasks effectively.</li></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The unique massively-parallel architecture of Teradata Vantage allows users to prepare data, train, evaluate, and deploy models at unprecedented scale.</p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Methodology</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this demo we have used a methodology which involves analyzing a time series of data, where each data point represents the outstanding amount at the end of each month. To detect anomalies, we use the following steps:</p>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial'><b>Model the Distribution:</b> We assume that the historical data of monthly balances follow a normal distribution. This distribution is characterized by two parameters: the mean (μ) and the standard deviation (σ). These are the features of the Entity </li>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial'><b>Compute the Z-Score:</b> For the most recent monthly balance (the latest data point in the time series), we compute its Z-score. The Z-score is a statistical measure that describes a value's relationship to the mean of a group of values. It is calculated using the formula: </li>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><div><code>Z = (X - μ) / σ</code></div></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>where X is the value in question, μ is the mean, and σ is the standard deviation.</p>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial'><b>Threshold for Anomaly Detection:</b> We set a threshold for the Z-score. If the absolute value of the Z-score for the latest monthly balance exceeds this threshold, it is flagged as an anomaly.</li></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>It's important to note that the computation of the Z-score and the anomaly flag is dependent on the values of the mean and standard deviation. These dependent features are not computed at the same time as the static features but are derived later, once the latest outstanding amount (the new data point) becomes available.</p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Feature Engineering</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Feature engineering is a crucial step in the entity-feature paradigm, as it involves creating and transforming features to better represent the underlying problem for predictive modeling. In our case, the feature engineering process is twofold, each with its specific inputs and outputs. Below are the processes that are a part of this feature engineering</p>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial'><b>Process 1:</b> Computing Mean and Standard Deviation</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'><b>Process 2:</b> Computing Z-Score and Anomaly Flag</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'><b>Roll Out:</b> Feature Engineering rollout\n",
    "    <ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Addressing Circular Dependency</li>\n",
    "    <li>Roll out after adjusting circular dependency</li></ul>\n",
    "<li style = 'font-size:16px;font-family:Arial'><b>Validation:</b> Feature Store Validation</li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab6f86e-5e58-435a-a8f2-a4eb3176aa3d",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>1. Connect to Vantage, Import python packages and explore the dataset</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe80ce62-d761-4ffe-b171-93b036739e92",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In the section, we import the required libraries and set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d409c76-27ef-4940-98c0-c541aa9cb1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# '%%capture' suppresses the display of installation steps of the following packages\n",
    "!pip install --upgrade teradataml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0df2d7-7b1c-413c-bd59-5f87035f9a90",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Note: </b><i>Please execute the above pip install to get the latest version of the required library. Be sure to restart the kernel after executing those lines to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fb9b4e-8690-4de6-ab49-211f6413cfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Teradata libraries\n",
    "from teradataml import *\n",
    "display.max_rows = 5\n",
    "\n",
    "# Data manipulation and visualization libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcca830-84d7-452b-9a4a-21853933afd4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557f0bcc-56ad-4513-bdab-abae45f09a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdaaddd-c5f8-4699-9c54-72a3dcc711f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=PP_Telco_Customer_Churn_using_EFS.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4794150-a65b-4c3f-8d24-d42f34b6167b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>Setup a Feature Store</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0776e2ee-bdb8-4927-9d14-5cff5583b6ee",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We can now set-up the feature store using the FeatureStore.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e72cc2f-2e36-47cd-a2da-19da50f892d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = FeatureStore(repo='demo_user')\n",
    "fs.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7f40c3-8efe-4042-9ede-a767681f0fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List whether FeatureStore is setup or not.\n",
    "fs.list_repos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80e18e4-d009-4d88-8340-72636ca8f0dd",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>2. Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have provided data for this demo on cloud storage. We have the option of either running the demo using foreign tables to access the data without using any storage on our environment or downloading the data to local storage, which may yield somewhat faster execution. However, we need to consider available storage. There are two statements in the following cell, and one is commented out. We may switch which mode we choose by changing the comment string.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9ef52-74ad-4c33-b978-0d5d8a68f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ../run_procedure.py \"call get_data('DEMO_Telco_cloud');\"\n",
    " # takes about 30 seconds, estimated space: 0 MB\n",
    "%run -i ../run_procedure.py \"call get_data('DEMO_Telco_local');\" \n",
    "# takes about 1 minute 30 seconds, estimated space: 4 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe942be5-f0b5-4ed4-b8a5-58d4821f3f3a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Optional step – We should execute the below step only if we want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf32774-d606-48a8-9d04-0f3e87f2d09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8540286-8309-47c6-9aff-fe153700ee9d",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>3. Feature Engineering</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4992424-3837-4a9f-b532-2e8d188d8c02",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The code creates a DataFrame named <code>df</code> using the DataFrame function. The <code>in_schema</code> function specifies the schema, which in this case is \"DEMO_Telco\", and the table name \"Customer_Churn\". Let us now start with feature engineering.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b6d33-7792-442d-8c46-7e4d659e5920",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(in_schema(\"DEMO_Telco\", \"Customer_Churn\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1d8130-0f2a-409f-be7e-6b9c32649208",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>This code performs the following operations:</p>\n",
    "    <ol style = 'font-size:16px;font-family:Arial'>\n",
    "        <li><strong>Assigning New Values:</strong> The <code>df.assign()</code> function is used to create new columns or modify existing ones in the DataFrame <code>df</code>.</li>\n",
    "        <li><strong>Replacing Values:</strong>\n",
    "            <ul>\n",
    "                <li><span class=\"highlight\">MultipleLines</span>: Replaces \"No phone service\" with \"No\".</li>\n",
    "                <li><span class=\"highlight\">OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport, StreamingTV, StreamingMovies</span>: Replaces \"No internet service\" with \"No\" for each of these columns.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><strong>Converting Churn Values:</strong>\n",
    "            <ul>\n",
    "                <li><span class=\"highlight\">Churn</span>: Uses the <code>case</code> function to convert \"Yes\" to 1 and \"No\" to 0. If the value is neither \"Yes\" nor \"No\", it defaults to 0.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><strong>Displaying the DataFrame:</strong> The final <code>df</code> statement displays the modified DataFrame.</li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb4956-2260-4c65-a6fa-b91ec4048cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    MultipleLines = df.MultipleLines.replace(\"No phone service\",\"No\"),\n",
    "    OnlineSecurity = df.OnlineSecurity.replace(\"No internet service\",\"No\"),\n",
    "    OnlineBackup = df.OnlineBackup.replace(\"No internet service\",\"No\"),\n",
    "    DeviceProtection = df.DeviceProtection.replace(\"No internet service\",\"No\"),\n",
    "    TechSupport = df.TechSupport.replace(\"No internet service\",\"No\"),\n",
    "    StreamingTV = df.StreamingTV.replace(\"No internet service\",\"No\"),\n",
    "    StreamingMovies = df.StreamingMovies.replace(\"No internet service\",\"No\"),\n",
    "    Churn = case({ \"Yes\" : 1, \"No\" : 0}, value=df.Churn,else_=0)\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b383aab-7165-4858-9e21-df0a9297b146",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.show_query())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83827624-1f49-4b05-898f-13aa03b346c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ConvertTo(\n",
    "    data=df,\n",
    "    target_columns=['CustomerID', 'Gender', 'Partner', 'Dependents', 'PhoneService',\n",
    "                    'MultipleLines', 'InternetService','OnlineSecurity', 'OnlineBackup',\n",
    "                    'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
    "                    'Contract', 'PaperlessBilling', 'PaymentMethod'],\n",
    "    target_datatype=[\"VARCHAR(charlen=10,charset=UNICODE,casespecific=NO)\"]\n",
    ").result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f2207c-e7e9-4ffa-ac7a-37a78b129eb5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Let's store the transformed data to table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df39f7d9-37b5-445f-bb29-4f4883c0d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(\n",
    "    df=df,\n",
    "    table_name='transformed_data',\n",
    "    if_exists='replace'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf33828-2e9e-42e5-883b-469cb47dd515",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>4. Save feature and feature processing to Feature Store</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec83605-4d29-47d5-93c3-7c05791d1782",
   "metadata": {},
   "source": [
    "<img src='images/EFS_process.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98794d87-4d1e-4e58-ac39-1337beeace57",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Now we will proceed to save the features as well as the feature processing logic in feature store.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>This will allow us to re-use the features and processing later-on, avoiding to re-write the processing logic.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19557186-c5be-4be6-a452-1ff6869865e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame('transformed_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbe4e7e-0b44-4624-9657-da2f5b7aff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FeatureGroup for this DataFrame.\n",
    "fg = FeatureGroup.from_DataFrame(name='telcom', df=df, entity_columns='CustomerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0565b334-f84e-4843-92b2-7e784494ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at Features\n",
    "fg.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb9c82f-8e99-4cca-bd7a-5d77c7764bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at Entity.\n",
    "fg.entity.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191c113e-08af-4eca-bf7c-fcab24be71ec",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Here we will saving the features and processing with additional metadata such as project names as churn</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c15a2-ddca-4af5-919b-bc7cfd5fd11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the features in the physical feature store\n",
    "fs.apply(fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37931c07-6843-4835-9b33-edd8b8fbc131",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.list_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a60da1-b8ea-4461-a953-2da276a11d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.list_feature_groups()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beda7104-0cc0-48f9-b98f-ad573be558ea",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>5. Re-using features for machine learning</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57de3efb-2956-4a2a-9fc9-9c9ddd7bc155",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'> Now that our features have been stores in feature store, let us re-use them to train a machine learning model</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'> We now need to just specify the feature name, we do not need to specify the processing logic</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce440d3-7c72-4400-82b0-2ff09e8fc914",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = fs.get_dataset('telcom')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaca5d6-2e5a-400f-a653-cbf70c1564c8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'> We have our training dataset which is created, with all the feature engineering</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'> We can see from that the column Multiple lines has only two values yes and no. The same features can also be re-used accross multiple use-cases and models without any data preperation</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f6bf8f-b9e1-441a-b089-c1ceebdbc059",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We split the dataset in to training and testing dataset with 80:20 split ratio.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f3a51-60a2-4b80-8f82-a77d8adcc322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Performing sampling to get 80% for trainning and 20% for testing\n",
    "tdf_sample = df.sample(frac = [0.8, 0.2])\n",
    "\n",
    "# Fetching train and test data\n",
    "tdf_train= tdf_sample[tdf_sample['sampleid'] == 1].drop('sampleid', axis=1)\n",
    "tdf_test = tdf_sample[tdf_sample['sampleid'] == 2].drop('sampleid', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86ae3c5-c44c-4c1d-bf08-c8e8d3d83d58",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>3. AutoML Training</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337e3e67-6a98-4f1f-8479-45a637ca0bb5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>AutoML (Automated Machine Learning) is an approach that automates the process of building, training, and validating machine learning models. It involves various algorithms to automate various aspects of the machine learning workflow, such as data preparation, feature engineering, model selection, hyperparameter tuning, and model deployment. It aims to simplify the process of building machine learning models, by automating some of the more time-consuming and labor-intensive tasks involved in the process.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>We create a <code>AutoClassifier</code> instance which is a special purpose AutoML feature to run classification specific tasks. We use the <code>exclude</code> parameter to specify model algorithms to be excluded from model training phase. Here we exclude the 'knn' model. The <code>max_runtime_secs</code> specifies the time limit in seconds for model training.\n",
    "<br><br>\n",
    "<code>verbose</code>: specifies the detailed execution steps based on verbose level as follows:\n",
    "</p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><b>0</b>: prints the progress bar and leaderboard</li>\n",
    "    <li><b>1</b>: prints the execution steps of AutoML.</li>\n",
    "    <li><b>2</b>: prints the intermediate data between the execution of each step of AutoML.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddce4f43-4035-44af-ba24-4944f7705a9c",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>4. AutoML Training</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b86886-ba91-4e36-9d0f-b0415dd59ccd",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>AutoML (Automated Machine Learning) is an approach that automates the process of building, training, and validating machine learning models. It involves various algorithms to automate various aspects of the machine learning workflow, such as data preparation, feature engineering, model selection, hyperparameter tuning, and model deployment. It aims to simplify the process of building machine learning models, by automating some of the more time-consuming and labor-intensive tasks involved in the process.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>We create a <code>AutoClassifier</code> instance which is a special purpose AutoML feature to run classification specific tasks. We use the <code>exclude</code> parameter to specify model algorithms to be excluded from model training phase. Here we exclude the 'knn' model. The <code>max_runtime_secs</code> specifies the time limit in seconds for model training.\n",
    "<br><br>\n",
    "<code>verbose</code>: specifies the detailed execution steps based on verbose level as follows:\n",
    "</p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><b>0</b>: prints the progress bar and leaderboard</li>\n",
    "    <li><b>1</b>: prints the execution steps of AutoML.</li>\n",
    "    <li><b>2</b>: prints the intermediate data between the execution of each step of AutoML.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8137fc-7250-427f-92c7-6070a8ffddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating AutoClassifier Instance\n",
    "# Selecting 'Auto' mode for AutoML training\n",
    "# Excluding knn,glm and svm model from default model list for training\n",
    "# Used early stopping timer criteria with value 600 sec\n",
    "\n",
    "aml = AutoClassifier(\n",
    "    exclude          = ['knn','svm','glm'],\n",
    "    verbose          = 2,\n",
    "    max_runtime_secs = 600\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e64a2e-648d-4321-8bd6-5bdd8051cbb6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b><i>Note: Since the AutoML functionality does a lot of steps like Feature exploration and Data Preparation along with Model Training and Evaluating to select the Best model the below step may take anywhere between 12-15 minutes</i></b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378743d2-daae-4a91-af06-fbd566072902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fitting train data \n",
    "aml.fit(data = tdf_train, target_column = 'Churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea7b521-d7c1-4994-b380-b0308c85743d",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>5. Model Leaderboard Generation</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4223d717-dd65-449f-8c2b-c415e1471ac3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Here, we generate model leaderboard and leader for a given dataset. Leaderboard is a ranked table with a list of models with all their evaluation metrics.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d69751-fe5e-46dd-9c24-3322a5bd1487",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fetching leaderboard\n",
    "\n",
    "aml.leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a330d76-3671-42f0-a2e3-e0b7f2138048",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>6. Best Performing Model</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cbeea7-d5d8-4333-b25a-8a02aa4b4cff",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The following function displays the best performing model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2054141f-3c2e-47be-b9db-aef8b4c3424d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fetching best performing model\n",
    "aml.leader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a1096f-7c8b-4e2f-b028-aa7f89c22f15",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>7. Prediction</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a2ffe3-91f5-4da0-ac6c-6276323e4eb3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The predict function generates predictions using either the default test data or any specified dataset, based on the model's rank in the leaderboard, and displays the performance metrics of the chosen model. If the test data contains a target column, both predictions and performance metrics are displayed; otherwise, only the predictions are shown.\n",
    "<br><br>\n",
    "You can also use the <code>rank</code> parameter in the predict function. The <code>rank</code> parameter specifies the model's rank in the leaderboard to be used for prediction. By default, the rank is set to 1, meaning the best-performing model is used.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2ea7e4-e02b-47d9-a4eb-18493f90d104",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial'>7.1 Generating prediction on external test data</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff63293-7104-4308-ab81-a6527e9e1a4f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Here, we specify the <code>tdf_test</code> dataset for prediction. When using external data instead of the default test data, the predict function applies all the data transformation steps performed during the training phase on the external data before passing the data to the model for prediction.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dd9ecd-0b1c-4428-8911-61e4f5719d81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fetching prediction and metrics on test data\n",
    "prediction = aml.predict(tdf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f563395c-b381-4fe4-ab20-7b1a7a4882bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printing prediction\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d841fcd4-df97-4d31-bd25-28cce37c1a47",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>Conclusion</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74e6e4a-ae3a-4249-a6ca-8d644f592db9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We used feature store to store features as well as its processing. We re-used it in model training. The features and processing can be re-used accross multiple machine leanring models and use-case , helping to improve data science productivity</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Teradata's AutoML functionality plays a crucial role in this context by automating the complex process of building and deploying machine learning models. AutoML ensures the most optimal preparation and training of models, delivering high-quality machine learning models in minutes. Through hyperparameter tuning (HPT), Teradata's AutoML can automatically select the best parameters for machine learning algorithms using grid search and random search techniques, significantly enhancing model performance.\n",
    "<br><br>\n",
    "By leveraging Teradata's AutoML, companies can save time and reduce costs associated with manual model building and tuning. The technology not only improves the accuracy of predictive models but also democratizes the power of machine learning, allowing customers to utilize advanced analytics without requiring extensive coding or data science expertise. This capability enables companies to swiftly and effectively analyze customer churn data, develop predictive models, and implement proactive strategies to retain customers and enhance their satisfaction.\n",
    "<br><br>\n",
    "In conclusion, Teradata's AutoML functionality is a vital tool for banks aiming to reduce customer churn. By automating and optimizing the machine learning process, Teradata empowers various industries to make data-driven decisions that improve customer retention and drive long-term profitability.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fafdffb-2cde-4d99-8682-9ae64c74497d",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>8. Cleanup</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial'> <b>Work Tables </b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff3fb9b-4d13-4628-988d-f82463d96537",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['transformed_data']\n",
    "\n",
    "# Loop through the list of tables and execute the drop table command for each table\n",
    "for table in tables:\n",
    "    try:\n",
    "        db_drop_table(table_name=table)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc238d9-0d01-4ca0-b34a-f802621cb165",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457f9970-b97d-46bc-8be6-cb969da3ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_Telco');\" \n",
    "#Takes 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fac6bb-3e3a-488c-848b-41473d6156e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bfa61c-3daa-4d47-b0d7-0a69ef13dc1a",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff7e25c-dc4e-45d7-a67f-8c70e2c517f4",
   "metadata": {},
   "source": [
    "<b style = 'font-size:20px;font-family:Arial'>Required Materials</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Let’s look at the elements we have available for reference for this notebook:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4938d2-5ce6-412e-a665-5d62a3b1a1b5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>Filters:</b></p>\n",
    "    <ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><b>Industry:</b> Telco</li>\n",
    "    <li><b>Functionality:</b> Feature Store and AutoML</li>\n",
    "    <li><b>Use Case:</b> Customer Retention</li>\n",
    "    </ul>\n",
    "    <p style = 'font-size:18px;font-family:Arial'><b>Related Resources:</b></p>\n",
    "    <ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><a href = 'https://www.teradata.com/Blogs/NPS-is-a-metric-not-the-goal'>·In the fight to improve customer experience, NPS is a metric, not the goal</a></li>\n",
    "    <li><a href = 'https://www.teradata.com/Blogs/Hyper-scale-time-series-forecasting-done-right'>·Hyper-scale time series forecasting done right</a></li>\n",
    "    <li><a href = 'https://www.teradata.com/Resources/Datasheets/Digital-Identity-Management-and-Great-CX?utm_campaign=i_coremedia-AMS&utm_source=google&utm_medium=paidsearch&utm_content=GS_CoreMedia_NA-US_BKW&utm_creative=Brand-Vantage&utm_term=teradata%20analytic%20platform&gclid=Cj0KCQjwnMWkBhDLARIsAHBOftrWZxDktHkKMsaWjMmNRnQ6Ys-bZBAUhXjWTo1Xa02fsci-IHWBV_waAppkEALw_wcB'>·Close the Gap Between Digital Identity Management and Great Customer Experiences</a></li>\n",
    "        </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fd5272-ceb7-4d47-bd5c-c3aea31e471a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>Reference Links:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'> \n",
    "       <li>Teradata Vantage™ - Analytics Database Analytic Functions - 17.20: <a href = 'https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Teradata-VantageTM-Analytics-Database-Analytic-Functions-17.20/Introduction-to-Analytics-Database-Analytic-Functions '>https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Teradata-VantageTM-Analytics-Database-Analytic-Functions-17.20/Introduction-to-Analytics-Database-Analytic-Functions </a></li>    \n",
    "  <li>Teradata® Package for Python User Guide - 17.20: <a href = 'https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Teradata-Package-for-Python-User-Guide-17.20/Introduction-to-Teradata-Package-for-Python'>https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Teradata-Package-for-Python-User-Guide-17.20/Introduction-to-Teradata-Package-for-Python</a></li>\n",
    "  <li>Teradata® Package for Python Function Reference - 17.20: <a href = 'https://docs.teradata.com/r/Enterprise/Teradata-Package-for-Python-Function-Reference-17.20/Teradata-Package-for-Python-Function-Reference'>https://docs.teradata.com/r/Enterprise/Teradata-Package-for-Python-Function-Reference-17.20/Teradata-Package-for-Python-Function-Reference</a></li>      \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6b60cb-d919-4daf-bc2a-35d7bf17eec7",
   "metadata": {},
   "source": [
    "<b style = 'font-size:18px;font-family:Arial'>Dataset:</b>\n",
    "\n",
    "- `CustomerID`: unique id of customer\n",
    "- `Gender`: Whether the customer is a male or a female\n",
    "- `SeniorCitizen`:Whether the customer is a senior citizen or not (1, 0)\n",
    "- `Partner`:Whether the customer has a partner or not (Yes, No)\n",
    "- `Dependents`:Whether the customer has dependents or not (Yes, No)\n",
    "- `Tenure`:Number of months the customer has stayed with the company\n",
    "- `PhoneService`:Whether the customer has a phone service or not (Yes, No)\n",
    "- `MultipleLines`:Whether the customer has multiple lines or not (Yes, No, No phone service)\n",
    "- `InternetService`:Customer’s internet service provider (DSL, Fiber optic, No)\n",
    "- `OnlineSecurity`:Whether the customer has online security or not (Yes, No, No internet service)\n",
    "- `OnlineBackup`:Whether the customer has online backup or not (Yes, No, No internet service)\n",
    "- `DeviceProtection`:Whether the customer has device protection or not (Yes, No, No internet service)\n",
    "- `TechSupport`:Whether the customer has tech support or not (Yes, No, No internet service)\n",
    "- `StreamingTV`:Whether the customer has streaming TV or not (Yes, No, No internet service)\n",
    "- `StreamingMovies`:Whether the customer has streaming movies or not (Yes, No, No internet service)\n",
    "- `Contract`:The contract term of the customer (Month-to-month, One year, Two year)\n",
    "- `PaperlessBilling`:Whether the customer has paperless billing or not (Yes, No)\n",
    "- `PaymentMethod`:The customer’s payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))\n",
    "- `MonthlyCharges`:The amount charged to the customer monthly\n",
    "- `TotalCharges`:The total amount charged to the customer\n",
    "- `Churn`:Whether the customer churned or not (Yes or No)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e28609-20ff-47e0-a640-48db6a7fa523",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; border-bottom:3px solid #91A0Ab\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2024. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
