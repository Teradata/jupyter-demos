{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Advertising Sales Prediction using teradataml OpenSourceML in Vantage\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Introduction</b></p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the realm of business advertising, the objective is to create a predictive model that forecasts sales figures based on advertising expenditures across different mediums like TV, Radio, and Newspaper. By employing machine learning techniques in teradata, businesses can analyze past data to inform decisions on advertising strategies, optimizing resource allocation and maximizing sales potential.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The Teradata Package for Python introduces teradataml open-source machine learning functions, referred as teradataml OpenSourceML, which exposes most of the functionality of open-source packages like scikit-learn, and so on. With teradataml open-source machine learning functions, you can run these open-source packages without needing to pull the data to your client. It offers a simple interface object for the open-source packages, allowing them to be used with the same syntax and arguments as the actual open-source packages' functions and classes.</p>\n",
    "\n",
    "    \n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Business Value</b></p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>Predict sales for each channel.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>Plan for historic increase and decrease in sales unrelated to the calendar year.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>Increase customer satisfaction.</li>  \n",
    "</p>    \n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Why Vantage?</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Teradata Open-Source Machine Learning Functions dynamically exposes open-source package through Teradata Vantage.</p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>Data movement is not needed and functions can be executed where data resides.</li> \n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>Rapid data exploration, preparation, and testing functions that can analyze massive amounts of data across an unlimited number of forecasts in parallel; drastically reducing the development and testing times.</li> \n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>The creation of a nearly unlimited number of forecasts in parallel, based on individualized models.</li> \n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>The ability to deploy the preparation and forecasting functions into automated pipelines that can run in near-real-time, eliminating the gaps between preparation, development, and deployment. \n",
    "</li></p> \n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Data</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This data expresses sales according to the type of advertisement and the size of the cost. The dataset contains 200 rows of 3 features [ TV , Radio , Newspaper] and target variable [Sales].</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The dataset provides details on advertising spending across various mediums (TV, Radio, Newspaper) alongside corresponding sales figures. Here's a summary:</p>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>TV:</b> Expenditure on TV advertising.</li>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Radio:</b> Expenditure on radio advertising.</li>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Newspaper:</b> Expenditure on newspaper advertising.</li>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Sales:</b> Recorded sales figures (in thousands).</li></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The advertising dataset captures the sales revenue generated with respect to advertisement costs across multiple channels like radio, tv, and newspapers. It is required to understand the impact of ad budgets on the overall sales.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>1. Connect to Vantage.</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the section, we import install the necessary versions of the below libraries.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install teradataml==20.0.0.3\n",
    "!pip install teradatasqlalchemy==20.0.0.3\n",
    "!pip install scikit-learn==1.1.3\n",
    "!pip install pandas==1.5.2\n",
    "!pip install numpy==1.23.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note: </b><i>Please verify that the version for the above libraries are installed in the environment. After the installs, be sure to restart the kernel after executing those lines to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the section, we import the required libraries and set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Importing required libraries.\n",
    "import getpass\n",
    "from teradataml import (create_context, remove_context, DataFrame, load_example_data, \n",
    "ColumnSummary, UnivariateStatistics, TrainTestSplit, execute_sql, in_schema)\n",
    "from teradataml import configure, display\n",
    "from teradataml import td_sklearn as osml\n",
    "import getpass\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "display.suppress_vantage_runtime_warnings = True\n",
    "display.max_rows=5\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell. Begin running steps with Shift + Enter keys.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=Advertising_Sales_Prediction_Python.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>2. Getting Data for This Demo </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We have provided data for this demo on cloud storage. We have the option of either running the demo using foreign tables to access the data without using any storage on our environment or downloading the data to local storage, which may yield somewhat faster execution. However, we need to consider available storage. There are two statements in the following cell, and one is commented out. We may switch which mode we choose by changing the comment string.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ../run_procedure.py \"call get_data('DEMO_Advertising_cloud');\"\n",
    " # Takes about 20 seconds\n",
    "%run -i ../run_procedure.py \"call get_data('DEMO_Advertising_local');\"\n",
    " # Takes about 30 seconds\n",
    "# Loading dataset from example data collection.\n",
    "# load_example_data('teradataml','advertising')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Optional step – We should execute the below step only if we want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>3. Prepare data to do some basic Analysis of the Sales data.</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Let us start by creating a \"Virtual DataFrame\" that points directly to the dataset in Vantage. We begin our analysis by obtaining the necessary data types for columns and extract values such as Sales_week, Sales_year, etc., from the Sales_date column. These extracted values will be used in our subsequent analysis.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching in teradata dataframe.\n",
    "advertising_df = DataFrame(in_schema(\"DEMO_Advertising\",\"Advertising_Data\")) #DataFrame(\"advertising\")\n",
    "advertising_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>describe(): Generates statistics for numeric columns. It computes the count, mean, std, min, percentiles, and max for numeric columns.\n",
    "Default statistics include: \"count\", \"mean\", \"std\", \"min\", \"percentile\", \"max\"</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advertising_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Now let us apply some Data Exploration Functions avaiable in Clearscape Analytics. First let us start by ColumnSummary.<br><b>ColumnSummary </b>function  displays Column name, datatype and other demographics like count of NULLs etc for each specified input table column</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsum = ColumnSummary(\n",
    "    data = advertising_df,\n",
    "    target_columns = [':']\n",
    ")\n",
    "colsum.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We can see that there are no NULLs in each specified input table.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Next we gather statistics using <b>UnivariateStatistics</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Univariate analysis is the simplest form of analyzing data. <b>UnivariateStatistics</b> displays descriptive statistics for each specified numeric input table column.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats analysis\n",
    "obj = UnivariateStatistics(\n",
    "    newdata = advertising_df,\n",
    "    target_columns = ['radio','TV','newspaper','sales'],\n",
    "    stats = ['MEAN','MEDIAN','MODE','KURTOSIS','SKEWNESS','STANDARD DEVIATION',\n",
    "            'SUM','PERCENTILES','MINIMUM','MAXIMUM']\n",
    ")\n",
    "\n",
    "# Print the result DataFrame.\n",
    "obj.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Let us pivot the result of UnivariateStatistics for better readability.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot the result for more readbility\n",
    "p = obj.result\n",
    "p2 = p.pivot(columns = p.ATTRIBUTE, aggfuncs = p.StatValue.max())\n",
    "p2 = p2.assign(\n",
    "    drop_columns = True,\n",
    "    StatName = p2.StatName,\n",
    "    Sales = p2.max_statvalue_sales,\n",
    "    Newspaper = p2.max_statvalue_newspaper,\n",
    "    TV = p2.max_statvalue_tv,\n",
    "    Radio = p2.max_statvalue_radio\n",
    ")\n",
    "p2.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> We will check the histogram for each of the channels.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=advertising_df.to_pandas()\n",
    "\n",
    "plt.figure(figsize = (30,28))\n",
    "for i, col in enumerate( ['newspaper', 'radio','TV']):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    sns.histplot(data = df1, x = col, kde = True, bins = 20, color = 'green')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> We will now check the correlation between the cost of channels and its impact on sales.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df1.corr(), annot=True )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> The above plot shows the correlation of each attribute with each other. We can see that there is a strong correlation between TV advertising and sales. 1 unit cost of TV advertising causes 0.9 units of sales.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>4. Train-Test split the dataset for model training and scoring using sample.</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> We will use sample() function to sample few rows from dataframe directly or based on conditions. Creates a new column 'sampleid' which has a unique id for each sample sampled, it helps to uniquely identify each sample.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing sampling to get 80% for training and 20% for testing.\n",
    "advertising_df_sample = advertising_df.sample(frac = [0.8, 0.2])\n",
    "\n",
    "# Fetching train and test data.\n",
    "df_train = advertising_df_sample[advertising_df_sample['sampleid'] == 1].drop('sampleid', axis=1)\n",
    "df_test = advertising_df_sample[advertising_df_sample['sampleid'] == 2].drop('sampleid', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data shape.\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The train dataset contains 160 rows.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data shape.\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The test dataset contains 40 rows. We than copy the train and test datasets to the database.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persisting test data to be used in another session.\n",
    "df_train.to_sql(table_name='advertising_train', if_exists='replace')\n",
    "df_test.to_sql(table_name='advertising_test', if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>5. Train RandomizedSearchCV on SGDRegressor estimator</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Use <code>SGDRegressor</code> as estimator for <code>RandomizedSearchCV</code> to get best model from the set of training parameters.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Linear model fitted by minimizing a regularized empirical loss with SGD. SGD stands for Stochastic Gradient Descent: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate).</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The regularizer is a penalty added to the loss function that shrinks model parameters towards the zero vector using either the squared euclidean norm L2 or the absolute norm L1 or a combination of both (Elastic Net). If the parameter update crosses the 0.0 value because of the regularizer, the update is truncated to 0.0 to allow for learning sparse models and achieve online feature selection.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdg_regressor = osml.SGDRegressor(max_iter=1000, tol=1e-4)\n",
    "sdg_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RandomizedSearchCV object.\n",
    "from scipy.stats import uniform\n",
    "distributions = dict(alpha=uniform(loc=0, scale=4),\n",
    "                     penalty=['l2', 'l1'],\n",
    "                     loss=['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'])\n",
    "clf = osml.RandomizedSearchCV(sdg_regressor, distributions, random_state=0)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the RandomizedSearchCV model to get the best model out of given distributed parameters.\n",
    "clf.fit(df_train.select(df_train.columns[:-1]), df_train.select([\"sales\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>5.1. Access attributes of the trained model</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the best_params_ property to return a dictionary of the the parameters used for the model with best score.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the best_estimator_ property to return the best estimator with the best arguments .</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_est = clf.best_estimator_\n",
    "best_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the best_score_ to returns the best score of the model out of all generated models.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the cv_results_ to return A dict with keys as column headers and values as columns, that can be imported into a DataFrame.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>6. Deploy the best model</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the deploy method to deploy the model held by interface object to Vantage. The model will be saved to the database.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the value passed to the argument `model`, which is the best estimator of the trained model.\n",
    "deployed_model = best_est.deploy(model_name=\"sgd_regressor_model\", replace_if_exists=True)\n",
    "deployed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(deployed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training score.\n",
    "deployed_model.score(X=df_train.select(df_train.columns[:-1]), y=df_train.select([\"sales\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will remove the context of the current sessions and create another session to load the saved model and use it for scoring.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>7. Load the saved models in another session</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will create the context again for another session</p>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection again to the same host.\n",
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>7.1. Load the saved best model</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will load the model from Vantage based on the interface object on which this function is called.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model.\n",
    "loaded_model = osml.load(model_name=\"sgd_regressor_model\")\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the test dataset which was saved to Vantage. The model which is loaded from the database will be used on the test dataset to do the scoring.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict sales on test data.\n",
    "df_test = DataFrame(\"advertising_test\")\n",
    "predict_df = loaded_model.predict(df_test.select(df_test.columns[:-1]))\n",
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(predict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = df_test.merge(right=predict_df, how =\"inner\", on=[\"TV\",\"radio\",\"newspaper\"], lsuffix =\"l\", rsuffix=\"r\")\n",
    "merge_df = merge_df.assign(drop_columns=True,\n",
    "                           TV = merge_df.TV_l,\n",
    "                           radio = merge_df.radio_l,\n",
    "                           newspaper = merge_df.newspaper_l,\n",
    "                           sales =  merge_df.sales,\n",
    "                           prediction = merge_df.sgdregressor_predict_1)\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot series data\n",
    "from teradataml import plot, subplots\n",
    "fig, axes = subplots(nrows=3, ncols=1)\n",
    "fig.height,fig.width = 800,1000\n",
    "plot = merge_df.plot(\n",
    "                x=merge_df.TV,\n",
    "                y=[merge_df.sales,merge_df.prediction],\n",
    "                ax=axes[0],\n",
    "                figure=fig,\n",
    "                color=['blue','orange'],\n",
    "                xlabel='TV advertising costs',\n",
    "                ylabel='Sales',\n",
    "                grid_linestyle='--',\n",
    "                grid_linewidth=0.5\n",
    ")\n",
    "\n",
    "plot = merge_df.plot(\n",
    "                x=merge_df.radio,\n",
    "                y=[merge_df.sales,merge_df.prediction],\n",
    "                ax=axes[1],\n",
    "                figure=fig,\n",
    "                color=['blue','orange'],\n",
    "                xlabel='Radio advertising costs',\n",
    "                ylabel='Sales',\n",
    "                grid_linestyle='--',\n",
    "                grid_linewidth=0.5\n",
    ")\n",
    "\n",
    "plot = merge_df.plot(\n",
    "                x=merge_df.newspaper,\n",
    "                y=[merge_df.sales,merge_df.prediction],\n",
    "                ax=axes[2],\n",
    "                figure=fig,\n",
    "                color=['blue','orange'],\n",
    "                xlabel='Newspaper advertising costs',\n",
    "                ylabel='Sales',\n",
    "                grid_linestyle='--',\n",
    "                grid_linewidth=0.5\n",
    ")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_value = osml.mean_squared_error(y_true=merge_df.select([\"sales\"]), y_pred=merge_df.select([\"prediction\"]), squared=False)\n",
    "mse_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The MSE is a measure of the quality of an estimator. As it is derived from the square of Euclidean distance, it is always a positive value that decreases as the error approaches zero.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>7.2. Access attributes of saved model</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>coef_ gives you an array of weights estimated by the model. It is of shape (n_targets, n_features).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The intercept in a model is the mean value of the response variable when all the predictor variables in the model are equal to zero. It is the point where the regression line crosses the y-axis.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loaded_model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>n_iter_ determines how many runs in total your randomized search will try.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The t-value is calculated by dividing the estimated regression coefficient by its standard error. The t-statistic measures how many standard errors the coefficient is away from zero.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.t_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>8. Cleanup</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:##00233C'><b>Work Tables</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['advertising_train', 'advertising_test']\n",
    "\n",
    "# Loop through the list of tables and execute the drop table command for each table\n",
    "for table in tables:\n",
    "    try:\n",
    "        db_drop_table(table_name=table)\n",
    "    except:\n",
    "        pass    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Databases and Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_Advertising');\" \n",
    "#Takes 45 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>Required Materials</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Let’s look at the elements we have available for reference for this notebook:</p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Dataset</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This data expresses sales according to the type of advertisement and the size of the cost.The dataset contains 200 rows of 3 features [ TV , Radio , Newspaper] and target variable [Sales]. The dataset was referred from <a href= \"https://www.kaggle.com/datasets/ashydv/advertising-dataset\">kaggle</a></p>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>TV:</b> Expenditure on TV advertising.</li>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Radio:</b> Expenditure on radio advertising.</li>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Newspaper:</b> Expenditure on newspaper advertising.</li>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Sales:</b> Recorded sales figures (in thousands).</li></p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Filters:</b></p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Industry:</b> Advertising</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Functionality:</b> Forecasting using teradataml OpenSource ML functions</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Use Case:</b> Sales Forecasting</li>\n",
    "</p>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Related Resources:</b></p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><a href = 'https://www.teradata.com/blogs/nps-is-a-metric-not-the-goal'>In the fight to improve customer experience, NPS is a metric, not the goal</a></li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><a href = 'https://www.teradata.com/Blogs/Hyper-scale-time-series-forecasting-done-right'>Hyper-scale time series forecasting done right </a></li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><a href = 'https://www.teradata.com/Blogs/Crystal-Ball-or-Black-Box-in-Retail-and-CPG'>Crystal Ball, Black Box or Advanced Forecasting and Demand Planning in Retail and CPG</a></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            © 2024 Teradata. All rights reserved.\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
