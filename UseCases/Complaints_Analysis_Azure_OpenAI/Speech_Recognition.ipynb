{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c49e3cf-e89a-40b0-8e6a-414d8ec337a6",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Complaints Analysis using Vantage and Azure OpenAI\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26752df7-32dc-42f9-b2a4-6db953108237",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#00233c'><b>Introduction:</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Analyzing consumer complaints using audio files conversations involves leveraging advanced technologies like large language models (LLM) and Azure OpenAI to extract insights from unstructured data. This process can be applied to various sectors, including financial services, telecommunications, and e-commerce, to improve customer experience and protect consumer rights.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233c'><b>Steps in the analysis:</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Configuring the environment</li>\n",
    "    <li>Configuring Azure OpenAI Model</li>\n",
    "    <li>Speech Analysis</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13877c9-b0cd-4005-82db-e79a90e3fcf5",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233C;'>\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233c'>1. Configuring the environment</b>\n",
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>1.1 Downloading and installing additional software needed</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f231b3-7dbf-4379-b9d3-9f09be350c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements.txt --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54d7c1c-10d7-407a-ba2a-a4550615f9ea",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note: </b><i>Please restart the kernel after executing these two lines. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c2c5ac-a59a-4c94-b366-ce22b46dd0fe",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>1.2 Import the required libraries</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e495ff-d24d-4f26-84d3-9192ae149dc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# User input\n",
    "import getpass\n",
    "\n",
    "# Teradata utilities\n",
    "from teradataml import *\n",
    "\n",
    "# OpenAI API\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Requests\n",
    "import requests\n",
    "\n",
    "# Display settings\n",
    "display.max_rows = 5\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896aa4ca-6932-461b-875d-654232df4f70",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style='font-size:20px;font-family:Arial;color:#00233C'>2. Configuring Azure OpenAI</b>\n",
    "<p style='font-size:16px;font-family:Arial;color:#00233C'>Before proceeding, you need to provide the following information:</p>\n",
    "<ul style='font-size:16px;font-family:Arial;color:#00233C'>\n",
    "<li><b>Endpoint</b>: Enter your Azure OpenAI deployment endpoint.</li>\n",
    "<li><b>Whisper Endpoint</b>: Enter your Azure OpenAI deployment endpoint for Whisper model (Speech to Text)</li>\n",
    "<li><b>Azure OpenAI API Key</b>: Enter your Azure OpenAI API Key.</li>\n",
    "</ul>\n",
    "<p style='font-size:16px;font-family:Arial;color:#00233C'>If you haven't retrieved your API Key and Endpoint yet, follow the instructions <a href=\"https://learn.microsoft.com/en-us/azure/ai-services/openai/quickstart?tabs=command-line%2Cpython-new&pivots=programming-language-python\" target=\"_blank\" style=\"color:#0066CC;text-decoration:none;\"><b>here</b></a>.</p>\n",
    "<p style='font-size:16px;font-family:Arial;color:#00233C'>Don't have an Azure OpenAI resource yet? Follow this guide:</p>\n",
    "<a href=\"./Azure-OpenAI.ipynb\" style=\"text-decoration:none;\" target=\"_blank\">\n",
    "    <button style=\"font-size:16px;font-family:Arial;color:#fff;background-color:#00233C;border:none;border-radius:5px;cursor:pointer;height:50px;line-height:50px;display:flex;align-items:center;\">\n",
    "        Azure OpenAI Guide <span style=\"margin-left:10px;\">&#8658;</span>\n",
    "    </button>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea9bfcb-df41-4472-bafc-7fd130c471c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prompt user for Azure OpenAI endpoint securely\n",
    "os.environ[\"ENDPOINT\"] = getpass.getpass(prompt=\"\\nPlease enter your Azure OpenAI endpoint(gpt-4o-mini): \")\n",
    "\n",
    "# Prompt user for Azure OpenAI whisper model endpoint securely\n",
    "os.environ[\"WHISPER_ENDPOINT\"] = getpass.getpass(prompt=\"\\nPlease enter your Azure OpenAI endpoint(Whisper model): \")\n",
    "\n",
    "# Prompt user for Azure OpenAI API key securely\n",
    "os.environ[\"API_KEY\"] = getpass.getpass(prompt=\"\\nPlease enter your Azure OpenAI API key(gpt-4o-mini Model): \")\n",
    "os.environ[\"WHISPER_API_KEY\"] = getpass.getpass(prompt=\"\\nPlease enter your Azure OpenAI API key(Whisper Model): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6c5897-e08b-4b37-aaac-07e84bfe917a",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>2.1 Initialize the Azure OpenAI API request</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11cebc1-5ce6-40c9-9ae8-b90288f022e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": os.environ[\"API_KEY\"],\n",
    "}\n",
    "\n",
    "def get_payload(prompt):\n",
    "    \n",
    "    # Payload for the request\n",
    "    payload = {\n",
    "      \"messages\": [\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": \"You are an assistant that categorizes text and gives reasoning for the categorization as well.\\n\"\n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": prompt\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      \"temperature\": 0.7,\n",
    "      \"top_p\": 1,\n",
    "      \"max_tokens\": 512\n",
    "    }\n",
    "\n",
    "    return(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bbf63f-b3b7-4668-b48f-fc5513c7f19d",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>3. Speech Analysis</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following cell defines a prompt that instructs the LLM on steps to be performed.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cbc048-f369-4c8a-b1d4-9826743bd34f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "    review: “{}”\n",
    "    Analyze the given review to extract relevant information and categorize it accordingly. Follow these steps, providing reasoning for each task:\n",
    "\n",
    "    Complaint Categorization: Determine whether the review is a complaint or a non-complaint. A complaint is typically a statement expressing dissatisfaction or grievance, while a non-complaint does not contain such elements. Explain why you categorized it this way.\n",
    "\n",
    "    Topic Classification: If the review is a complaint, identify the most appropriate topic from the following list:\n",
    "        Mortgage Application\n",
    "        Payment Trouble\n",
    "        Mortgage Closing\n",
    "        Report Inaccuracy\n",
    "        Payment Struggle\n",
    "        Select only one topic based on the central issue or subject of the complaint. Explain the reasoning behind your choice of topic.\n",
    "\n",
    "    Sentiment Analysis: Determine the sentiment of the review, which can be:\n",
    "        Positive\n",
    "        Negative\n",
    "        Neutral\n",
    "        Sentiment refers to the emotional tone or attitude conveyed in the review. Describe the reasoning behind the sentiment you identified.\n",
    "\n",
    "    Summarization: Summarize the review in one sentence. A good summary should capture the essence of the review, highlighting the main point or issue. Explain the key elements that formed the basis of your summary.\n",
    "\n",
    "    Return your results in the following format. Only keep the headings in bold:\n",
    "\n",
    "    #### Complaint:\n",
    "    - [Provide the raw complaint from the input.]\n",
    "\n",
    "    #### Classification:\n",
    "    - [Specify whether it's a Complaint or Non-Complaint]\n",
    "      - **Reasoning with Chain-of-Thought**: [Explain the reasoning behind the classification.]\n",
    "\n",
    "    #### Topic:\n",
    "    - [Specify the relevant topic]\n",
    "      - **Reasoning with Chain-of-Thought**: [Provide additional context or reasoning related to the topic.]\n",
    "\n",
    "    #### Sentiment:\n",
    "    - [Specify the sentiment (e.g., Positive, Negative, Neutral)]\n",
    "      - **Reasoning with Chain-of-Thought**: [Explain the rationale for the sentiment.]\n",
    "\n",
    "    #### Summary:\n",
    "    - [Summarize the complaint in a concise sentence]\n",
    "      - **Reasoning with Chain-of-Thought**: [Include any relevant reasoning or context for the summary.]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ad4bf2-f81b-43cb-a4cc-5e6670ff6c3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-12T10:55:31.779304Z",
     "iopub.status.busy": "2024-08-12T10:55:31.778974Z",
     "iopub.status.idle": "2024-08-12T10:55:31.785980Z",
     "shell.execute_reply": "2024-08-12T10:55:31.784985Z",
     "shell.execute_reply.started": "2024-08-12T10:55:31.779270Z"
    },
    "tags": []
   },
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following cell will transcribe the audio files using OpenAI <b>whisper-1</b> LLM model and call then call OpenAI <b>gpt-4o-mini</b> LLM to perform Complaint Analysis on it.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The Whisper model is a speech to text model from OpenAI that you can use to transcribe audio files. The model is trained on a large dataset of English audio and text. The model is optimized for transcribing audio files that contain speech in English. The model can also be used to transcribe audio files that contain speech in other languages. The output of the model is English text.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3209a7e5-7511-4695-90ab-3ba2ad047bde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Audio, HTML\n",
    "\n",
    "for file_name in sorted(os.listdir('./audio_files/')):\n",
    "    audio_file = open(f\"./audio_files/{file_name}\", \"rb\")\n",
    "\n",
    "    client = AzureOpenAI(\n",
    "        api_key = os.environ[\"WHISPER_API_KEY\"],\n",
    "        api_version = \"2024-02-01\",\n",
    "        azure_endpoint = os.environ[\"WHISPER_ENDPOINT\"]\n",
    "    )\n",
    "\n",
    "    deployment_id = \"whisper\"\n",
    "\n",
    "    result = client.audio.transcriptions.create(\n",
    "        file = open(audio_file.name, \"rb\"),\n",
    "        model = deployment_id\n",
    "    )\n",
    "    transcription = result.text\n",
    "    \n",
    "    # Send request\n",
    "    try:\n",
    "        response = requests.post(os.environ[\"ENDPOINT\"], headers = headers, json = get_payload(prompt.format(transcription)))\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        raise SystemExit(f\"Failed to make the request. Error: {e}\")\n",
    "\n",
    "    output = response.json()['choices'][0]['message']['content']\n",
    "\n",
    "    # Description HTML content\n",
    "    desc = f'''<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "               <p style='font-size:18px;font-family:Arial;color:#00233C'><b>For file: {file_name}</b></p>'''\n",
    "\n",
    "    # Create the HTML, audio, and markdown objects\n",
    "    desc_display = HTML(desc)\n",
    "    audio_display = Audio(f\"./audio_files/{file_name}\")\n",
    "    markdown_display = Markdown(output)\n",
    "\n",
    "    # Display all elements in a single output\n",
    "    display(desc_display, audio_display, markdown_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c05788-5048-42fd-8327-ae8e1c52e114",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2024. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
