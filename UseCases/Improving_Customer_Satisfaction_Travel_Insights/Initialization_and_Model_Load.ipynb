{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "601d9a90-f9e1-4d0e-8136-5b89bd7e5dcc",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Language Models<br>\n",
    "   <span style=\"font-size: 24px;\">An Introduction to Parallel CPU Inferencing of HuggingFace Models in Vantage</span>\n",
    "       \n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b738d7d9-c96f-4816-ba0d-c480ba1560e2",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;'><b>Introduction</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "Hugging Face is a French-American company based in New York City that develops computation tools for building applications using machine learning. They are known for their <b>Transformers Library</b> which provides open-source implementations of transformer models for text, image, video, audio tasks including time-series. These models include well-known architectures like BERT and GPT. The library is compatible with PyTorch, TensorFlow, and JAX deep learning libraries. <br>\n",
    "    Deep Learning Models in HuggingFace are pre-trained by users/open source outfits/companies on various types of data – NLP, Audio, Images, Videos etc. Most popular tool of choice by users is PyTorch (open source python library) which helps create a Deep Learning model from scratch or take an existing model, retrain/fine-tune (Transfer Learning) on new set of data to be published in HF. Models can be inference with CPUs and GPUs with slight performance improvement for smaller models.<br>\n",
    "</p>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>Why Vantage?</b></p>  \n",
    "<p style = 'font-size:16px;font-family:Arial;'>As many Hugging Face models are available in <b>ONNX Runtime</b>, we can load them using the <b>BYOM</b> feature of Vantage and run them in Vantage. Because of <b>Graph Optimizations</b> on ONNX Runtime, there are proven benchmarks that show that inference with <b>ONNX Runtime will be 20% faster than a native PyTorch model on a CPU</b>. </p>\n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial;'><b>Vantage Parallelism</b> on top of boosted ONNX Runtime inference can turn a Vantage system as effective as inference on GPUs. If we have a <b>Vantage box with 72 AMPs</b>, assuming the table is perfectly distributed, it will <b>closely match the performance of a dedicated GPU and data never moves across the network saving time and I/O operations</b>. As parallelism increases with number of AMPs, the model inference will complete faster in Teradata Vantage with the same amount of text data vs a GPU. We can of course quantize the model (change float8 weights to int8/int4) for inference on CPU to go even faster with some tradeoff with accuracy. However, If Model size goes up GPU advantage will widen – example LLM like LLama3 and costs will be disproportionate with GPU but for smaller models we can get comparable performance. \n",
    "</p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>Overall flow:</b></p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a30786-eb41-4518-9abb-dd8bbaa7a640",
   "metadata": {},
   "source": [
    "<center><img src=\"images/pat1.png\" alt=\"Design pattern 1\" width=1200 height=900 style=\"border: 4px solid #404040; border-radius: 10px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9101f149-3076-4bab-aec5-5f1a638cfa44",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;'>\n",
    "<b style = 'font-size:20px;font-family:Arial;'>1. Configuring the environment</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce275db-9aa2-424f-88bd-edc91f2dcf84",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678dd728-e926-41c8-8c95-1f9a371ed873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "# Teradata libraries\n",
    "from teradataml import (\n",
    "    create_context,\n",
    "    delete_byom,\n",
    "    display,\n",
    "    execute_sql,\n",
    "    save_byom,\n",
    "    remove_context,\n",
    "    DataFrame\n",
    ")\n",
    "\n",
    "display.max_rows = 5\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action=\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b218aee-06db-4377-b170-8b1423029bce",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>2. Connect to Vantage</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell. Begin running steps with Shift + Enter keys.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd4855-ac57-4241-9d12-024b0d2cbae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host='host.docker.internal', username='demo_user', password=password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ccda78-2923-49ed-873d-58183d725c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql(\"SET query_band='DEMO=Language_Model_Init_Python.ipynb;' UPDATE FOR SESSION;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b464041-461c-46dd-a18e-681878df2987",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Optional step – We should execute the below step only if we want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49645f4-2888-41f9-a03b-6a9628d1a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65e1d32-6c9d-4076-97a3-e7742ed7c579",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>3. HuggingFace Model installation</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>In the below steps we will download and install the HuggingFace Model in Vantage.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcd268a-92d9-440d-b5a4-8a85ea0bfdf7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>To generate embeddings, we need an ONNX model capable of transforming text into vector representations. We will use a pretrained model from [Teradata's Hugging Face repository]  <a href = 'https://huggingface.co/Teradata/bge-small-en-v1.5'>bge-small-en-v1.5</a>. The bge-small-en model is a small-scale English text embedding model developed by BAAI (Beijing Academy of Artificial Intelligence) as part of their FlagEmbedding project.The model and its tokenizer are downloaded and stored in Vantage tables as BLOBs using the save_byom function.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9392255-cbe8-4357-81da-e8a9584e53dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae4d23c-42ba-44d2-98fa-e3edf2b14926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "model_name = \"bge-small-en-v1.5\"\n",
    "number_dimensions_output = 384\n",
    "model_file_name = \"model.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5145bd82-8bfb-42f1-833b-272de8bbfba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Download Model from Teradata HuggingFace Page\n",
    "\n",
    "hf_hub_download(repo_id=f\"Teradata/{model_name}\", filename=f\"onnx/{model_file_name}\", local_dir=\"./\")\n",
    "hf_hub_download(repo_id=f\"Teradata/{model_name}\", filename=f\"tokenizer.json\", local_dir=\"./\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f8e53-abbb-4661-a55e-71bf11df25f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    db_drop_table(\"embeddings_models\")\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    db_drop_table(\"embeddings_tokenizers\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0d3fc0-8869-4dda-8960-569a7b43c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load Models into Vantage\n",
    "# a) Embedding model\n",
    "save_byom(model_id = model_name, # must be unique in the models table\n",
    "               model_file = f\"onnx/{model_file_name}\",\n",
    "               table_name = 'embeddings_models' )\n",
    "# b) Tokenizer\n",
    "save_byom(model_id = model_name, # must be unique in the models table\n",
    "              model_file = 'tokenizer.json',\n",
    "              table_name = 'embeddings_tokenizers') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa02608-608e-4997-be01-29320b16cefe",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Recheck the installed model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682b81da-8bc9-4a61-8b91-088636ef47c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = DataFrame('embeddings_models')\n",
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da1848-2e26-447b-991d-012645ab44da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_token = DataFrame('embeddings_tokenizers')\n",
    "df_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fda5b4d-772e-448c-9467-6f52bb8acd1c",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>5. Next Steps</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'> Now we have initialized and loaded the model into Vantage, we can proceed further with the business usecase.      \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12180f1-5743-4091-a91a-04b605f66062",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;'> <b>Clean up </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The following code will remove the context.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cdfd16-aa93-4d29-a094-bab58c3c083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49407083-7481-463c-8a1f-2762702b78b2",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2025. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
