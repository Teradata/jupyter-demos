{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90fc4bf5-b263-41a3-bb8c-4ef8ba700eed",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       ServiceNow Multipath Pattern Analysis\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dfbbc8-3f81-42e0-ac8c-757c92527fbb",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>Introduction</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>ServiceNow is a widely-used platform for managing IT service requests and incidents. While it effectively captures case-level data and status transitions, it lacks native capabilities to perform deep-dive pattern analysis across the lifecycle of a case — especially in terms of how cases move through different support groups, how long they stay in each state, and what behaviors lead to resolutions or escalations. Due to limitations in ServiceNow's native analytics capabilities, answering questions like below are extremely difficult :<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>How many cases moved from L1 to L2 multiple times?</li>\n",
    "    <li>Which cases were resolved in a single touch by L2 teams?</li>\n",
    "    <li>Which assignment groups handled the highest severity incidents before resolution?</li>\n",
    "    </ul>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Business Value</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>By integrating ServiceNow case audit data with Vantage's nPath® functionality we can unlock critical insights from the case history:<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li style = 'font-size:16px;font-family:Arial'><b>Operational Insights </b>like Understand common and rare resolution paths, identify escalation trends from L1 to L2 or other teams, discover patterns in delayed resolutions or reassignment loops</li>\n",
    "    <li style = 'font-size:16px;font-family:Arial'><b>Improved Efficiency and SLA Management</b> like Highlight cases that violate SLAs due to excessive handoffs, spot 'one-touch' resolution patterns for knowledge reuse, enable proactive case routing strategies.</li>\n",
    "    <li style = 'font-size:16px;font-family:Arial'><b>Enhanced Reporting and Decision-Making </b>like Weekly trend analysis for leadership using dashboards, support data-driven staffing decisions by understanding group-wise workloads.</li>\n",
    "    </ul>\n",
    "</p>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Why Vantage?</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Vantage has unique analytic capabilities for  looking for pattern. nPath® enables sequence mining and event pattern detection across logs or audit trails using syntax similar to regex, making it ideal for modeling complex case journeys. Teradata can handle large volumes of ServiceNow audit logs efficiently, enabling transformation of raw audit data into enriched analytic tables without compromising performance.</p> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007209d7-6171-41c4-937f-0c076c3ab4a3",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>1. Connect to Vantage,  import python packages and explore the dataset</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a256f832-3f00-42a6-ba1e-38d60d0043e5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Let us start with importing the required libraries, set environment variables and connect to Vantage.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54ed496-8c52-4702-be0a-2f4f7bb1b37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import getpass\n",
    "import warnings\n",
    "\n",
    "from teradataml import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "display.max_rows = 5\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64deb4bb-78b5-49d7-aa99-6d09b6e1d5f6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell. Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f38726-fdeb-4619-b467-4d4f19c47cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30898957-c27d-450d-95f4-03e5c169396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=FF_ServiceNow_Multipath_PatternAnalysis_Python.ipynb;' UPDATE FOR SESSION;''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70120eeb-6fe6-4b91-a3f7-ce35b9c9c2bf",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Begin running steps with Shift + Enter keys.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677f1a49-7fb5-4df0-88e0-9a7b954efbe0",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>2. Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have provided data for this demo on cloud storage. We have the option of either running the demo using foreign tables to access the data without using any storage on our environment or downloading the data to local storage, which may yield somewhat faster execution. However, we need to consider available storage. There are two statements in the following cell, and one is commented out. We may switch which mode we choose by changing the comment string.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab82270-16d0-4748-b762-3043821ccc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call get_data('DEMO_ServiceNow_cloud');\"\n",
    "# takes about 20sec minute, estimated space: 0 MB\n",
    "# %run -i ../run_procedure.py \"call get_data('DEMO_ServiceNow_local');\"\n",
    "# takes about 1 minute, estimated space: 20 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ecaf78-ab7b-4ef4-9f72-115d6ef66c0c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Optional step – We should execute the below step only if we want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0d6459-b032-4f87-b216-f92b78885abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac07923-6e89-4322-9c98-51a622081698",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>3. Analyze the raw data set</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'> Sys audit table in ServiceNow stores the assignment groups and states and all the updates that happened on the ticket. We have joined this data with other tables to build a raw data table. It's a mix of different tables (sys_audit, sys_user etc) in ServiceNow that allows us to identify what we think are the most important parts for that we need for the analysis of a journey.<br>One of the column of interest is the audit time stamp. This is the time stamp of when an event occurred. There are two very different dates in the table, the date of when a case was created and then the date of when something happened. We also have column for how long it has happened since the since the case or incident was created (hrs_elapsed). Table also captures the highest severity of the tickets. Let us take a look at the data in the table.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197b2de3-057a-49b7-893c-1559bd6d34a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf= DataFrame(in_schema('DEMO_ServiceNow', 'Audit_Raw_Data'))\n",
    "tdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061fb1b7-a215-4b65-a44a-7a6acb146957",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We can check data for one of the tickets.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b305b4a5-e5ff-4037-beed-7c0dfa6cde44",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tdf = tdf[tdf['sn_ticket'] == 'INC0342089']\n",
    "filtered_tdf.sort('sn_audit_TS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72968b4-0d75-40e0-8ed2-be4a012d86cc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>If we look at the ticket data above we can see that the assignment group when the ticket was created was 'Cloud BaaS Operator' and later it was reassigned to 'GSO L1 Cloud Support'. There can be other tickets where this type of reassignment is done or there may be tickets where there is multiple reassignments. If we want to see the pattern or number of tickets where this happens we can easily do that using Vantage's nPath function.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The nPath function scans a set of rows, looking for patterns that you specify. For each set of input rows that matches the pattern, nPath produces a single output row. The function provides a flexible pattern-matching capability that lets you specify complex patterns in the input data and define the values that are output for each matched input set.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21df957c-2554-4032-8165-78e969798355",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>First let us check the values in the sn_ag column which holds the values for the assigment groups. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997c55d3-79d1-48ac-a3b7-51b98b66dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "catsum = CategoricalSummary(data=tdf,\n",
    "                             target_columns=['sn_ag']\n",
    "                            )\n",
    " \n",
    "catsum.result.sort('DistinctValue').head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaaea5a-152d-4f7c-be22-7f35cfeccf9f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We have also observed that if there is any reassigmnet on the ticket the column fieldname = 'assignment_group' is set and the value is updated in the sn_ag column but if there is no reassigment of service group then this value is not set i.e the Audit_Raw_Data captures the changes on the ticket but not the initial assigment group. Hence we will first create a view by doing union on  all the initial values of assigment groups on the ticket and the subsequent reassignments; and then use this in our Npath query.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c15ca1-5564-4442-9889-bfeeb99eada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query='''\n",
    "Replace view tickets_assignment_groups as\n",
    "select \n",
    "    tablename,\n",
    "    sn_ticket,\n",
    "    sn_audit_converted AS sn_audit_ts,\n",
    "    sn_audit_week_start_date,\n",
    "    t1,\n",
    "    hrs_elapsed,\n",
    "    'assignment_group' AS fieldname,\n",
    "    sn_ag AS fieldname_value\n",
    "    FROM DEMO_ServiceNow.Audit_Raw_Data\n",
    "    WHERE fieldname = 'assignment_group'\n",
    "union\n",
    "select \n",
    "    tablename,\n",
    "    sn_ticket,\n",
    "    sn_created_on AS sn_audit_ts,\n",
    "    sn_audit_week_start_date,\n",
    "    t1,\n",
    "    hrs_elapsed,\n",
    "    'assignment_group' AS fieldname,\n",
    "    sn_ag AS fieldname_value\n",
    "    FROM DEMO_ServiceNow.Audit_Raw_Data\n",
    "    QUALIFY Row_number() OVER( PARTITION BY sn_ticket\n",
    "        ORDER BY sn_audit_ts ASC) = 1\n",
    " ;'''\n",
    "execute_sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0e4b47-5c5d-4ae3-af89-cd3d761877aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf2=DataFrame('tickets_assignment_groups')\n",
    "tdf2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcbe35f-4134-4a86-b802-eeb00ad645ce",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>As a first example we want to build the metric <b>l2_cloudl3_bounces</b> that counts the number of times a ticket has been bounced between L2 and L3 using Teradata's <b>nPath</b> function.<br>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>We do this first defining two main symbols:\n",
    "    <li>L2: This symbol represents the assignment groups that are considered L2 support groups.</li>\n",
    "    <li>Cloud_L3: This symbol represents the assignment groups that are considered L3 support groups.</li>\n",
    "    <li>OTHER: This symbol represents all rows as shown in the npath documentation.</li>\n",
    "</ul>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "We then define our pattern as follows:\n",
    "<br>The pattern <b>'(OTHER?.L2.Cloud_L3.OTHER?)+'</b>  means that we are looking for sequences where there is at least one occurrence of <b>L2</b>, followed by at least one occurrence of <b>Cloud_L3</b>, and then followed by any number of <b>OTHER</b> rows.<br>\n",
    "        The <b>+</b> at the end indicates that this pattern can repeat one or more times.\n",
    "<br>\n",
    "Finally, we use the RESULT clause to extract the following information:    \n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "<li><b>sn_ticket</b>: The ticket number.</li>\n",
    "<li><b>first_l2_to_cloudl3_ts</b>: The timestamp of the first occurrence of the L2 to Cloud L3 transition.</li>\n",
    "<li><b>sn_ags</b>: The total number of assignment groups involved in the ticket's journey.</li>\n",
    "<li><b>l2_cloudl3_bounces</b>: The count of how many times the ticket bounced between L2 and Cloud L3.</li>\n",
    "<li><b>path</b>: An accumulated list of assignment groups involved in the ticket's journey.</li>\n",
    "<li><b>path_sn_audit_week</b>: An accumulated list of the week start dates for each assignment group in the ticket's journey.</li>\n",
    "</ul></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd292f9c-75bc-4044-bdec-1c15b5cedfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "npath_l2_l3 = NPath(data1 = tdf2, \n",
    "                      data1_partition_column = ['sn_ticket'], \n",
    "                      data1_order_column = 'sn_audit_ts', \n",
    "                      mode = 'OVERLAPPING', \n",
    "                      symbols = ['fieldname = \\'assignment_group\\' AND fieldname_value IN (\\'Cloud EU Azure System Operator\\', \\'Cloud EU BaaS Operator\\', \\'Cloud EU Ops Lead\\', \\'Cloud EU UPaaS System Operator\\', \\'Cloud EU VaaS Network Operator\\',\\'Cloud Ops AWS Super Users\\',\\'Cloud Antares AWS System Operator\\',\\'Cloud AWS Change Operator\\',\\'Cloud AWS System Operator\\',\\'Cloud AZURE Change Operator\\',\\'Cloud Azure System Operator\\',\\'Cloud BaaS Operator\\',\\'Cloud DRaaS Operator\\',\\'Cloud GCP Change Operator\\',\\'Cloud GCP System Operator\\',\\'Cloud UPaaS System Operator\\',\\'Cloud VaaS Deployment Operator\\',\\'Cloud VaaS Network Operator\\') AS L2',\n",
    "                                 'fieldname = \\'assignment_group\\' AND (fieldname_value IN (\\'Cloud BaaS L3 Operator\\', \\'Cloud DRaaS L3 Operator\\', \\'Cloud L3 Security Applications Administrator\\', \\'Cloud Data Protection Operator\\')) AS Cloud_L3',\n",
    "                                 'TRUE as OTHER'],\n",
    "                      pattern = '(OTHER?.L2.Cloud_L3.OTHER?)+', \n",
    "                      result = ['FIRST (sn_ticket of L2) as sn_ticket', \n",
    "                                'FIRST (sn_audit_ts of Cloud_L3) as first_l2_to_cloudl3_ts',\n",
    "                                'COUNT (fieldname_value of ANY(L2,Cloud_L3) ) as sn_ags', \n",
    "                                'COUNT (fieldname_value of ANY(Cloud_L3) ) as l2_cloudl3_bounces',\n",
    "                                'ACCUMULATE(10000,TRUE) (CAST(fieldname_value AS VARCHAR(20)) OF ANY(L2,Cloud_L3)) AS path,'\n",
    "                                'ACCUMULATE(10000,TRUE) (CAST(sn_audit_week_start_date AS VARCHAR(100)) OF ANY(L2,Cloud_L3)) AS path_sn_audit_week'\n",
    "                               ])\n",
    "npath_l2_l3.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7a13b2-1540-4737-8cb9-61ce2c8a9624",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>For the distinct values we can use row_number() window function.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d0abf7-4fd8-488c-a76c-e4ad11d988b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=npath_l2_l3.result\n",
    "window=d.window(partition_columns=\"sn_ticket\",order_columns=\"sn_ags\",sort_ascending=False)\n",
    "df1=window.row_number()\n",
    "tdf_l2_l3=df1[(df1.col_row_number==1)].assign(drop_columns = True,\n",
    "                                        sn_ticket=df1.sn_ticket,\n",
    "                                        first_l2_to_cloudl3_ts=df1.first_l2_to_cloudl3_ts,\n",
    "                                        sn_ags=df1.sn_ags,\n",
    "                                        l2_cloudl3_bounces=df1.l2_cloudl3_bounces,\n",
    "                                        path=df1.path,\n",
    "                                        path_sn_audit_week=df1.path_sn_audit_week\n",
    "                                       )\n",
    "tdf_l2_l3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c8785d-3e17-49b7-842a-3e61b04a0a72",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We can take another example where we want to find out the tickets that were touched by any L2 group.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137f9c6b-ff00-4cd4-a9fa-11ba62dacb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "npath_l2 = NPath(data1 = tdf2, \n",
    "                      data1_partition_column = ['sn_ticket'], \n",
    "                      data1_order_column = 'sn_audit_ts', \n",
    "                      mode = 'NONOVERLAPPING', \n",
    "                      symbols = ['fieldname = \\'assignment_group\\' AND fieldname_value IN (\\'Cloud EU Azure System Operator\\', \\'Cloud EU BaaS Operator\\', \\'Cloud EU Ops Lead\\', \\'Cloud EU UPaaS System Operator\\', \\'Cloud EU VaaS Network Operator\\',\\'Cloud Ops AWS Super Users\\',\\'Cloud Antares AWS System Operator\\',\\'Cloud AWS Change Operator\\',\\'Cloud AWS System Operator\\',\\'Cloud AZURE Change Operator\\',\\'Cloud Azure System Operator\\',\\'Cloud BaaS Operator\\',\\'Cloud DRaaS Operator\\',\\'Cloud GCP Change Operator\\',\\'Cloud GCP System Oprator\\',\\'Cloud UPaaS System Operator\\',\\'Cloud VaaS Deployment Operator\\',\\'Cloud VaaS Network Operator\\') AS L2',\n",
    "                                 'TRUE as OTHER'],\n",
    "                      pattern = 'L2*', \n",
    "                      result = ['FIRST (sn_ticket of L2) as sn_ticket', \n",
    "                                'FIRST (sn_audit_ts of L2) as first_l2_touched_ts',\n",
    "                                'COUNT (fieldname_value of ANY(L2) ) as sn_ags', \n",
    "                                'ACCUMULATE(10000,TRUE) (CAST(fieldname_value AS VARCHAR(20)) OF ANY(L2)) AS path,'\n",
    "                                'ACCUMULATE(10000,TRUE) (CAST(sn_audit_week_start_date AS VARCHAR(10)) OF ANY(L2)) AS l2_path_sn_audit_ts'\n",
    "                               ])\n",
    "\n",
    "d=npath_l2.result\n",
    "window=d.window(partition_columns=\"sn_ticket\",order_columns=\"sn_ags\",sort_ascending=False)\n",
    "df1=window.row_number()\n",
    "tdf_l2=df1[(df1.col_row_number==1)].assign(drop_columns = True,\n",
    "                                        sn_ticket=df1.sn_ticket,\n",
    "                                        first_l2_touched_ts=df1.first_l2_touched_ts,\n",
    "                                        sn_ags=df1.sn_ags,\n",
    "                                        path=df1.path,\n",
    "                                        l2_path_sn_audit_ts=df1.l2_path_sn_audit_ts\n",
    "                                       )\n",
    "tdf_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8925174b-306b-4888-a178-eb729dcf9c06",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We can take another example where we want to find out the tickets that were resolved by a particular assignment group for example GSO L1 team and we also want to check all the reassignments that were done before the resolution.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0701fb0-73a4-4443-a31b-131a629ba64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "npath_gso_l1 = NPath(data1 = tdf, \n",
    "                      data1_partition_column = ['sn_ticket'], \n",
    "                      data1_order_column = 'sn_audit_TS', \n",
    "                      mode = 'NONOVERLAPPING', \n",
    "                      symbols = ['fieldname = \\'resolved_by\\' and sn_ag IN (\\'GSO L1 Cloud Support\\',\\'GSO L1 EU Restricted\\') AND sn_state IN (\\'Resolved\\') AS resolved_gso_l1',\n",
    "                                 'TRUE as OTHER'], \n",
    "                      pattern = 'OTHER?*.resolved_gso_l1', \n",
    "                      result = ['FIRST (sn_ticket of resolved_gso_l1) as sn_ticket', \n",
    "                                'FIRST (sn_audit_TS of resolved_gso_l1) as resolved_gso_l1_ts',\n",
    "                                'COUNT (DISTINCT  sn_ag of ANY(other,resolved_gso_l1) ) as sn_ags', \n",
    "                                'ACCUMULATE (DISTINCT  cast(sn_ag as VARCHAR(20)) of ANY(other,resolved_gso_l1)) as path' \n",
    "                               ])\n",
    "\n",
    "tdf_gso_l1=npath_gso_l1.result\n",
    "tdf_gso_l1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03807d71-7149-49a2-99ab-00a4178808d7",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>4. Analysis and Visualization</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'> We can perform analysis on the data in-database and visualize the results by plotting the graphs and paths.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b38478-c817-4c41-944f-de3b0e90c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = tdf_gso_l1.groupby(['path']).count()\n",
    "d1= d1.assign(drop_columns = True,\n",
    "              path = d1.path,\n",
    "              ticket_count = d1.count_sn_ticket)\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f08f3da-49c3-4019-aa80-be667d1c257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_ags_plot = tdf_gso_l1.groupby(['sn_ags']).count().sort(['count_sn_ticket'], ascending = False)\n",
    "sn_ags_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dc7be7-8e49-4bba-b651-fa9001f19c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot =  sn_ags_plot.plot(x=sn_ags_plot.sn_ags, y=sn_ags_plot.count_path,\n",
    "                                 kind='bar',xlabel = 'Number of Reassignments', yabel = 'Count of tickets', \n",
    "                                 heading=\"Reassignments done before ticket resolved by GSO L1\", figsize=(600, 400))\n",
    " \n",
    "# Display the plot.\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f36bde-3f2b-4451-a126-3325a2ccfcad",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>4.1  Sankey Charts</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'> In order to visualize the distribution of the different path of events, we typically use Sankey diagram of the aggregated over the paths reported by the NPATH command.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548135a9-5ce9-488b-888e-5b170ed78ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdnpathviz.visualizations import plot_first_main_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2625e2ac-468f-4c22-a587-160c16c4a5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_first_main_paths(tdf_gso_l1,path_column='path',id_column='sn_ticket')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1b7784-40e2-4a6f-92c4-6b29dd67f80b",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>5. Json Export </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Once we got our patterns from the nPath function, we can also create a combined json table/file from that to be used in any of the BI tools for visualization if needed.<br>We will combine all our nPath results in a single dataframe to get all the kpis in one place.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b86cb7-8396-4f18-9b6e-804a1635fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf3=tdf.drop_duplicate([\"sn_ticket\",\"Site_id\",\"sn_created_on\",\"sn_created_on_DT\"])\n",
    "tdf3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef186686-ca48-48b9-bc27-17b21904c025",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_json = tdf3.join(other = tdf_l2_l3,on = \"sn_ticket\", how = \"left\", rprefix =\"l2_l3\")\\\n",
    "               .join(other = tdf_l2,on = \"sn_ticket\", how = \"left\", rprefix =\"l2\")\\\n",
    "               .join(other = tdf_gso_l1,on = \"sn_ticket\", how = \"left\", rprefix =\"gso_l1\")\n",
    "out_json  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d424ee-b618-4fc4-8fd1-dd713355ca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_json_df = out_json.assign(drop_columns = True,\n",
    "                              sn_ticket = out_json.sn_ticket,\n",
    "                              site_id =out_json.Site_id,\n",
    "                              sn_created_on_ts = out_json.sn_created_on,\n",
    "                              sn_created_on_dt = out_json.sn_created_on_DT,\n",
    "                              gso_l1_path = out_json.gso_l1_path,\n",
    "                              gso_l1_week = out_json.resolved_gso_l1_ts,\n",
    "                              l2_touched_path = out_json.l2_path,\n",
    "                              l2_touched_week= out_json.l2_path_sn_audit_ts,\n",
    "                              l2_cloudl3_bounces_path=out_json.path,\n",
    "                              l2_cloudl3_bounces_week=out_json.path_sn_audit_week)\n",
    "out_json_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4772b2bb-8c45-43aa-891e-e0b05b25803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(out_json_df, table_name = 'out_json', if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97255703-427a-4574-be88-a191c40fb4a1",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Next we will expand all our paths in an intermediate table so that we can get the kpi values as a single row per value.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b43f58e-621b-4ba8-b419-57f3d675cf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "query='''\n",
    "create table demo_user.expanded_kpi_table as (\n",
    " select\n",
    "    events_table.outkey as sn_ticket,\n",
    "    out_df.site_id,\n",
    "    out_df.sn_created_on_ts,\n",
    "    out_df.sn_created_on_dt,\n",
    "    'l2_touched' as kpi,\n",
    "    events_table.tokennum,\n",
    "    events_table.event,\n",
    "    week_table.week\n",
    "\n",
    "from (\n",
    "    select\n",
    "        events.outkey,\n",
    "        events.tokennum,\n",
    "        trim(regexp_replace(events.token, '\\[|\\]', '')) as event\n",
    "    from table(\n",
    "        strtok_split_to_table(DEMO_USER.out_json.sn_ticket, DEMO_USER.out_json.l2_touched_path, ',')\n",
    "        returns(outkey VARCHAR(20), tokennum INTEGER, token VARCHAR(20))\n",
    "        ) as events\n",
    "    ) events_table\n",
    "\n",
    "    inner join (\n",
    "    select\n",
    "        wk.outkey,\n",
    "        wk.tokennum,\n",
    "        trim(regexp_replace(wk.wk, '\\[|\\]', '')) as week\n",
    "    from table(\n",
    "        strtok_split_to_table(DEMO_USER.out_json.sn_ticket, DEMO_USER.out_json.l2_touched_week, ',')\n",
    "        returns(outkey VARCHAR(20), tokennum INTEGER, wk VARCHAR(20))\n",
    "        ) as wk\n",
    "    ) week_table\n",
    "    on week_table.outkey = events_table.outkey\n",
    "    and week_table.tokennum = events_table.tokennum\n",
    "    inner join DEMO_USER.out_json out_df\n",
    "    on events_table.outkey = out_df.sn_ticket\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "select\n",
    "    events_table.outkey as sn_ticket,\n",
    "    out_df.site_id,\n",
    "    out_df.sn_created_on_ts,\n",
    "    out_df.sn_created_on_dt,\n",
    "    'gso_resolved_l1' as kpi,\n",
    "    events_table.tokennum,\n",
    "    events_table.event,\n",
    "    week_table.week\n",
    "\n",
    "from (\n",
    "    select\n",
    "        events.outkey,\n",
    "        events.tokennum,\n",
    "        trim(regexp_replace(events.token, '\\[|\\]', '')) as event\n",
    "    from table(\n",
    "        strtok_split_to_table(DEMO_USER.out_json.sn_ticket,DEMO_USER.out_json.gso_l1_path, ',')\n",
    "        returns(outkey VARCHAR(20), tokennum INTEGER, token VARCHAR(20))\n",
    "        ) as events\n",
    "    ) events_table\n",
    "\n",
    "left join (\n",
    "    select\n",
    "        sn_ticket,\n",
    "        cast(cast(gso_l1_week as date) as varchar(20))week\n",
    "    from DEMO_USER.out_json \n",
    "    ) week_table\n",
    "    on week_table.sn_ticket = events_table.outkey\n",
    "  \n",
    "inner join DEMO_USER.out_json out_df\n",
    "    on events_table.outkey = out_df.sn_ticket\n",
    "     where events_table.tokennum is not null\n",
    "    \n",
    "UNION ALL\n",
    "\n",
    "select\n",
    "    events_table.outkey as sn_ticket,\n",
    "    out_df.site_id,\n",
    "    out_df.sn_created_on_ts,\n",
    "    out_df.sn_created_on_dt,\n",
    "    'l2_cloudl3_bounces' as kpi,\n",
    "    events_table.tokennum,\n",
    "    events_table.event,\n",
    "    week_table.week\n",
    "\n",
    "from (\n",
    "    select\n",
    "        events.outkey,\n",
    "        events.tokennum,\n",
    "        trim(regexp_replace(events.token, '\\[|\\]', '')) as event\n",
    "    from table(\n",
    "        strtok_split_to_table(DEMO_USER.out_json.sn_ticket,DEMO_USER.out_json.l2_cloudl3_bounces_path, ',')\n",
    "        returns(outkey VARCHAR(20), tokennum INTEGER, token VARCHAR(20))\n",
    "        ) as events\n",
    "    ) events_table\n",
    "\n",
    "   left join (\n",
    "    select\n",
    "        wk.outkey,\n",
    "        wk.tokennum,\n",
    "        trim(regexp_replace(wk.wk, '\\[|\\]', '')) as week\n",
    "    from table(\n",
    "        strtok_split_to_table(DEMO_USER.out_json.sn_ticket, DEMO_USER.out_json.l2_cloudl3_bounces_week, ',')\n",
    "        returns(outkey VARCHAR(20), tokennum INTEGER, wk VARCHAR(20))\n",
    "        ) as wk\n",
    "    ) week_table\n",
    "    on week_table.outkey = events_table.outkey\n",
    "    and week_table.tokennum = events_table.tokennum\n",
    "    inner join DEMO_USER.out_json out_df\n",
    "    on events_table.outkey = out_df.sn_ticket\n",
    ")\n",
    "with data;\n",
    "'''\n",
    "execute_sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688cba51-ea8d-4fe1-acfc-d31a46a564e1",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>For output json, let us first create a table with json datatype.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20238bb-163c-41a1-87e9-77831bdfccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query='''\n",
    "create table demo_user.json_kpi_metrics \n",
    "\n",
    "(\n",
    "    sn_ticket VARCHAR(20) CHARACTER SET LATIN NOT CASESPECIFIC,\n",
    "    combined_kpis json(10000)\n",
    "    )\n",
    "primary index(sn_ticket)\n",
    ";\n",
    "'''\n",
    "execute_sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b1dac1-c287-4d3d-a2a8-47b6c63ec67f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Now we will insert the kpi values from the intermediate table in json format.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4463ae17-4cf0-4c9a-8667-2b00c559a3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query='''\n",
    "insert into demo_user.json_kpi_metrics \n",
    "select\n",
    "    sn_ticket,\n",
    "    json_compose (t2.sn_ticket,t2.site_id,\n",
    "                t2.sn_created_on_ts,\n",
    "                t2.sn_created_on_dt, t2.kpis)\n",
    "from\n",
    "    (\n",
    "        select\n",
    "            sn_ticket,\n",
    "            site_id,\n",
    "            sn_created_on_ts,\n",
    "            sn_created_on_dt,\n",
    "            json_agg(kpi,vals) as kpis\n",
    "        from (\n",
    "            select\n",
    "                sn_ticket,\n",
    "                site_id,\n",
    "                sn_created_on_ts,\n",
    "                sn_created_on_dt,\n",
    "                kpi,\n",
    "                json_agg(tokennum, event, week) as vals\n",
    "            from demo_user.expanded_kpi_table\n",
    "            group by 1,2,3,4,5\n",
    "             ) as t1\n",
    "        group by 1,2,3,4\n",
    "    ) as t2;\n",
    "'''\n",
    "execute_sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6b1328-bae8-4271-a853-546852cf2b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame('json_kpi_metrics')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ccf403-9fbc-4456-8a3b-089892cdbc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tdtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ed0e4d-64eb-46ba-8c0f-4012a9e57349",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>Conclusion</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here in this notebook we have seen that with Teradata Vantage and ClearScape Analytics we can find patterns inside ServiceNow data. We can find common paths in our data and improve efficiency and quality of service we provide to ServiceNow customers. We have also seen how we can create a json from the data if we need an export in that format.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a36ffb-11e7-4d01-a187-183b4f0eee6d",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>6. Cleanup </b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We need to clean up our work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0697e579-c578-4129-af12-974ccc4ff63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_drop_view('tickets_assignment_groups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e97b48a-3644-442a-b157-5ac4f5ed12e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['out_json', 'expanded_kpi_table', 'json_kpi_metrics']\n",
    "\n",
    "# Loop through the list of tables and execute the drop table command for each table\n",
    "for table in tables:\n",
    "    try:\n",
    "        db_drop_table(table_name = table)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca773c61-7598-4e88-b1da-3e789f6af3e0",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We will use the following code to clean up tables and databases created for this demonstration.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d231454-9d45-47c3-99dd-4efba55fc6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_ServiceNow');\"   # Takes about 10 seconds, optional if you want to use the data later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9983437c-d035-4322-a3fd-3ccecbde408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4f5df2-2edf-47e2-942e-0b9cf9f769b4",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial'>Dataset Information</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Dataset used here is simulated data based on the actual ServiceNow audit data.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4fc08a-deba-4943-8827-ff547ea8fcd1",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; border-bottom:3px solid #91A0Ab\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            © 2025 Teradata. All rights reserved.\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
