{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Store Sales Forecasting with Prophet using Script Table Operator\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>Introduction</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied.<br>\n",
    "<br>  \n",
    "Our Main Objective is to predict sales of store in a week. We are using the python Prophet model and using the <b><u>S</u></b>cript <b><u>T</u></b>able <b><u>O</u></b>perator<b>(STO)</b> of Vantage for forecasting the Store Sales.\n",
    "<br>\n",
    " <img src=\"./images/STO.png\" width=\"800\" align=\"right\" style=\"padding: 40px; border: 4px solid; border-color:#404040; border-radius: 10px;\"> \n",
    "    \n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial'>STO allows you to leverage the parallelism of Vantage by installing external routines into each unit of parallelism. During the execution of the analysis, data is piped to and from those external routines in dozens, hundreds or thousands units of parallelism depending on the size of the production platform. This allows you the flexibility and power to extend the analytic power of Vantage with routines written in languages such as Python or R to process data in parallel without exporting to another platform.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The SCRIPT function enables invoking the external language interpreters to execute your script files. It does so by running the interpreter in a shell environment invoked upon executing an STO query. Script execution takes place in protected mode, that is, outside the Advanced SQL Engine Database.\n",
    "Pipelines the database I/O to R or Python scripts executed via Linux command line through STO</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Processing steps</b>\n",
    "<li style = 'font-size:14px;font-family:Arial'>User “installs” their script file on Vantage </li>\n",
    "    <li style = 'font-size:14px;font-family:Arial'>User executes a SQL query with STO</li>\n",
    "<li style = 'font-size:14px;font-family:Arial'>STO invokes R or Python, passing the installed script</li>\n",
    "<li style = 'font-size:14px;font-family:Arial'>Script executes in a Linux “forked” child process</li>\n",
    "    <li style = 'font-size:14px;font-family:Arial'>Script reads from STDIN and writes to STDOUT</li>\n",
    "    <li style = 'font-size:14px;font-family:Arial'>Script runs on each unit of parallelism</li>\n",
    "<li style = 'font-size:14px;font-family:Arial'>Each unit of parallelism returns its own results independently</li>\n",
    "</p>\n",
    "\n",
    "<p></p>    \n",
    "<br>  \n",
    "<p style = 'font-size:16px;font-family:Arial'>Hence as a data science consultant, we are showcasing the complete approach about how we can make prediction of sales for different stores in advance. We are demonstrating how we can train our models and use them for scoring using the ClearScape Analytics platform. The data we are using is a sample dataset and the results and predictions may not be entirely accurate.\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>Data</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The dataset contains historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set. Note that some stores in the dataset were temporarily closed for refurbishment.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Most of the fields are self-explanatory. The following are descriptions for those that aren't.</p>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial'>Store - a unique Id for each store</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Sales - the turnover for any given day (this is what you are predicting)</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Customers - the number of customers on a given day</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Open - an indicator for whether the store was open: 0 = closed, 1 = open</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>StateHoliday - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>SchoolHoliday - indicates if the (Store, Date) was affected by the closure of public schools</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>StoreType - differentiates between 4 different store models: a, b, c, d</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Assortment - describes an assortment level: a = basic, b = extra, c = extended</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>CompetitionDistance - distance in meters to the nearest competitor store</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>CompetitionOpenSince[Month/Year] - gives the approximate year and month of the time the nearest competitor was opened</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Promo - indicates whether a store is running a promo on that day</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Promo2 - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Promo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>PromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g., \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store.</li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>1. Connect to Vantage.</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In the section, we import the required libraries and set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install statsmodels\n",
    "# !pip install prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Note: </b><i>The above statements may need to be uncommented if you run the notebooks on a platform other than ClearScape Analytics Experience that does not have the libraries installed. If you uncomment those installs, be sure to restart the kernel after executing those lines to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b> and then clicking <b>Restart</b></i>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import getpass\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import os\n",
    "from prophet import Prophet\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "import pickle\n",
    "import base64\n",
    "\n",
    "from teradataml import *\n",
    "\n",
    "display.max_rows=5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>You will be prompted to provide the password. Enter your password, press the Enter key, then use down arrow to go to next cell. Begin running steps with Shift + Enter keys.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=Store_Sales_Forecasting_Prophet_STO_PY_SQL.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>2. Getting Data for This Demo </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have provided data for this demo on cloud storage.  You have the option of either running the demo using foreign tables to access the data without using any storage on your environment or downloading the data to local storage which may yield somewhat faster execution, but there could be considerations of available storage.  There are two statements in the following cell, and one is commented out.  You may switch which mode you choose by changing the comment string. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ../run_procedure.py \"call get_data('DEMO_ProphetSTO_cloud');\"\n",
    " # Takes about 25 seconds\n",
    "%run -i ../run_procedure.py \"call get_data('DEMO_ProphetSTO_local');\"\n",
    " # Takes about 70 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Next is an optional step – if you want to see status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>3. Prepare data to do some basic Analysis of the Sales data.</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>We create dataframe for the Stores and the Sales Data using tables from Vantage. To gain insights into the data's characteristics, we display a sample of 5 rows each.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store=DataFrame(in_schema('DEMO_ProphetSTO','Store'))\n",
    "store  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The Store dataset contains description of the Stores like, StoreType, distance from the Competition Store and also various Promotion codes and Details.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales=DataFrame(in_schema('DEMO_ProphetSTO','Sales_Data'))\n",
    "sales  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The Store Sales dataset contains the Store, DayofWeek, Date of Sales , Sales done, Customer involved, SalesOpen is a flag mentioning if the Store is Open or Closed and Promotion Code applied for the Sales.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>4. Data Analysis and Transformation </b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial'>In this first section we go through the Sales and store data, handle missing values and create new features for further analysis.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We check the missing values for the CompetitionDistance column and replace it with the median values.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import SimpleImputeFit, SimpleImputeTransform\n",
    "fit_obj = SimpleImputeFit(data=store,\n",
    "                              stats_columns=\"CompetitionDistance\",\n",
    "                              stats=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj =  SimpleImputeTransform(data=store,\n",
    "                                 object=fit_obj.output)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store=obj.result\n",
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We join the Store and Sales dataset to get the required columns for our analysis.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_store = sales.merge(right = store, how = \"inner\", on = \"store=store\",lsuffix='l', rsuffix='r')\n",
    "sales_store=sales_store.assign(Store=sales_store.Store_l)\n",
    "sales_store=sales_store.drop(['Store_l', 'Store_r'], axis=1)\n",
    "sales_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_store.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The final dataset used for analysis contains 18 columns and 91,256 rows.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Based on the data available we do some transformations on the data and create various features. From the SalesDate we, generate columns like , Year, Month, DayOfWeek , WeekofYear etc. Using the columns related to Competition like CompetionOpenSinceYear and CompetitionOpenSinceMonth we calculate if the Competition Store is Open or not(CompetitionOpen). Similarly, we do the processing for Promotions and create a flag(PromoOpen)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_store = sales_store.assign(CompetitionOpenSinceYear = \n",
    "                                     case([(sales_store.CompetitionOpenSinceYear.isnull() == True, '0')], else_ = sales_store.CompetitionOpenSinceYear),\n",
    "                                CompetitionOpenSinceMonth = \n",
    "                                     case([(sales_store.CompetitionOpenSinceMonth.isnull() == True, '0')], else_ = sales_store.CompetitionOpenSinceMonth),\n",
    "                                Promo2SinceYear = \n",
    "                                     case([(sales_store.Promo2SinceYear.isnull() == True, '0')], else_ = sales_store.Promo2SinceYear),\n",
    "                                Promo2SinceWeek = \n",
    "                                     case([(sales_store.Promo2SinceWeek.isnull() == True, '0')], else_ = sales_store.Promo2SinceWeek)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_store = sales_store.assign(Year = sales_store.SalesDate.year(),\n",
    "                                 Month = sales_store.SalesDate.month(),\n",
    "                                 Day = sales_store.SalesDate.day_of_month(),\n",
    "                                 DayOfWeek = sales_store.SalesDate.day_of_week(),\n",
    "                                 WeekOfYear = sales_store.SalesDate.week_of_year())\n",
    "\n",
    "sales_store = sales_store.assign(CompetitionOpen = 12 * (sales_store.Year - sales_store.CompetitionOpenSinceYear)+\n",
    "                                                     (sales_store.Month - sales_store.CompetitionOpenSinceMonth),\n",
    "                                PromoOpen = 12 * (sales_store.Year - sales_store.Promo2SinceYear)+\n",
    "                                                 (sales_store.WeekOfYear - sales_store.Promo2SinceWeek) / 4.0)\n",
    "\n",
    "\n",
    "sales_store = sales_store.assign(CompetitionOpen = case([(sales_store.CompetitionOpen > 0, sales_store.CompetitionOpen)], else_ = 0),\n",
    "                                PromoOpen = case([(sales_store.PromoOpen > 0, sales_store.PromoOpen)], else_ = 0))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_store = sales_store.assign(StoreType = case([(sales_store.StoreType == '0', 0),(sales_store.StoreType == 'a', 1),\n",
    "                                                  (sales_store.StoreType == 'b', 2),(sales_store.StoreType == 'c', 3),\n",
    "                                                  (sales_store.StoreType == 'd', 4)]),\n",
    "                                Assortment = case([(sales_store.Assortment == '0', 0),(sales_store.Assortment == 'a', 1),\n",
    "                                                  (sales_store.Assortment == 'b', 2),(sales_store.Assortment == 'c', 3),\n",
    "                                                  (sales_store.Assortment == 'd', 4)]),\n",
    "                                StateHoliday = case([(sales_store.StateHoliday == '0', 0),(sales_store.StateHoliday == 'a', 1),\n",
    "                                                  (sales_store.StateHoliday == 'b', 2),(sales_store.StateHoliday == 'c', 3),\n",
    "                                                  (sales_store.StateHoliday == 'd', 4)])\n",
    "                                \n",
    "                                )  \n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_store = sales_store.assign(monthStr = case([(sales_store.Month == 1, 'Jan'),(sales_store.Month == 2, 'Feb'),\n",
    "                                                  (sales_store.Month == 3, 'Mar'),(sales_store.Month == 4, 'Apr'),\n",
    "                                                  (sales_store.Month == 5, 'May'),(sales_store.Month == 6, 'Jun'),\n",
    "                                                  (sales_store.Month == 7, 'Jul'),(sales_store.Month == 8, 'Aug'),\n",
    "                                                  (sales_store.Month == 9, 'Sep'),(sales_store.Month == 10, 'Oct'),\n",
    "                                                  (sales_store.Month == 11,' Nov'),(sales_store.Month == 12, 'Dec')]),\n",
    "                                IsPromoMonth = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sales = sales_store.select(['Month','Sales']).groupby('Month').mean()\n",
    "plot =  plot_sales.plot(x=plot_sales.Month, y=plot_sales.mean_Sales,\n",
    "                           kind='bar', xlabel='Month', ylabel='Sales', color=\"orange\")\n",
    " \n",
    "# Display the plot.\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above graph shows the total sales across months for all stores. We can see that the sales are highest in December which is the Holiday Season.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Now we will see the same metrics across different Store types and also based on whether there was any Promotion available(Promo=1) or not (Promo=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Catplot month Vs Sales\n",
    "features_df = sales_store.to_pandas(all_rows=True)\n",
    "sns.catplot(data = features_df, x = 'Month', y = \"Sales\", \n",
    "               col = 'StoreType', # per store type in cols\n",
    "               palette = 'plasma',\n",
    "               # hue = 'StoreType',\n",
    "               row = 'Promo' # per promo in the store in rows\n",
    "               # color ='Year'\n",
    "           ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above graph shows the Sales per Month for each of the 4 StoreTypes(a,b,c,d) for all the 1,115 Stores. The Top row shows the sales for Promo=0 and the bottom row is for Promo=1. Each dot represents the sum of sales for a particular store in a month depending on the Store Type and Promo Code. We can see that there are peaks mainly during the Year end period.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>All store types follow the same trend but at different scales depending on the presence of the promotion `Promo` and `StoreType` except for the StoreType = b.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Next we try to get four stores from store types to represent their group:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial'> Store number 2 for `StoreType` A</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Store number 85 for `StoreType` B</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Store number 1 for `StoreType` C</li> \n",
    "<li style = 'font-size:16px;font-family:Arial'>Store number 15 for `StoreType` D</li>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>It also makes sense to down sample the data from days to weeks using the `resample` method to see the present trends more clearly.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = sales_store.select(['Store','SalesDate','Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_a = train_df[train_df.Store == 2].select(['SalesDate','Sales']).groupby('SalesDate').mean()\n",
    "sales_b = train_df[train_df.Store == 85].select(['SalesDate','Sales']).groupby('SalesDate').sum()\n",
    "# .sort_index(ascending = True) # solve the reverse order\n",
    "sales_c = train_df[train_df.Store == 1].select(['SalesDate','Sales']).groupby('SalesDate').sum()\n",
    "sales_d = train_df[train_df.Store == 15].select(['SalesDate','Sales']).groupby('SalesDate').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = subplots(nrows=4, ncols=1)\n",
    " \n",
    "plot = sales_a.plot(x=sales_a.SalesDate, y=sales_a.mean_Sales,\n",
    "                          ax=axes[0], figure=fig, kind=\"line\",xlabel='Sales Date', ylabel='Sales',\n",
    "                          title=\"Sales for Store 2\", color=\"blue\",figsize=(1200, 1600))\n",
    " \n",
    "plot = sales_b.plot(x=sales_b.SalesDate, y=sales_b.sum_Sales,\n",
    "                          ax=axes[1],figure=fig, kind=\"line\",xlabel='Sales Date', ylabel='Sales',\n",
    "                          title=\"Sales for Store 85\", color=\"blue\")\n",
    " \n",
    "plot = sales_c.plot(x=sales_c.SalesDate, y=sales_c.sum_Sales,\n",
    "                          ax=axes[2],figure=fig, kind=\"line\",xlabel='Sales Date', ylabel='Sales',\n",
    "                          title=\"Sales for Store 1\", color=\"blue\")\n",
    "\n",
    "plot = sales_d.plot(x=sales_d.SalesDate, y=sales_d.sum_Sales,\n",
    "                          ax=axes[3],figure=fig, kind=\"line\",xlabel='Sales Date', ylabel='Sales',\n",
    "                          title=\"Sales for Store 15\", color=\"blue\")\n",
    " \n",
    "# Display the plot.\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Retail sales for all store types tend to peak for the Christmas season and then decline after the holidays.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Next we check the Yearly trend for these Store Types thing to check the presence of a trend in series. Time series decomposition is the process of separating time series data into its core components. These components include a potential trend (overall rise or fall in the mean), seasonality (a recurring cycle), and the remaining random residual. Python’s statsmodels library has a method for time series decomposition called seasonal_decompose(). The model type parameter can either be additive or multiplicative, here we consider additive as If the seasonality’s amplitude is independent of the level then you should use the additive model. The \"period\" parameter is the number of observations in a seasonal cycle. For example, if you have daily observations, the period is 1. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting with 'date'\n",
    "pd_sales_store = features_df\n",
    "train_df = pd_sales_store.set_index('SalesDate')\n",
    "# Sales datacheck\n",
    "train_df['Sales'] = train_df['Sales'] * 1.0\n",
    "# storewise sales data\n",
    "sales_a = train_df[train_df.Store == 2]['Sales'].sort_index(ascending = True)\n",
    "sales_b = train_df[train_df.Store == 85]['Sales'].sort_index(ascending = True) # solve the reverse order\n",
    "sales_c = train_df[train_df.Store == 1]['Sales'].sort_index(ascending = True)\n",
    "sales_d = train_df[train_df.Store == 15]['Sales'].sort_index(ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal decompose\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(4, figsize = (15, 15))\n",
    "\n",
    "# monthly\n",
    "decomposition_a = seasonal_decompose(sales_a, model = 'additive', extrapolate_trend='freq', period=1)\n",
    "decomposition_a.trend.plot(ax = ax1)\n",
    "\n",
    "decomposition_b = seasonal_decompose(sales_b, model = 'additive', extrapolate_trend='freq', period=1)\n",
    "decomposition_b.trend.plot( ax = ax2)\n",
    "\n",
    "decomposition_c = seasonal_decompose(sales_c, model = 'additive', extrapolate_trend='freq', period=1)\n",
    "decomposition_c.trend.plot( ax = ax3)\n",
    "\n",
    "decomposition_d = seasonal_decompose(sales_d, model = 'additive', extrapolate_trend='freq', period=1)\n",
    "decomposition_d.trend.plot( ax = ax4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Overall sales follow similar Trend for all StoreTypes as seen above. There are spikes around the year end which indicate higher sales over the year end holiday season.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>5. Creating the model and forecasting using Prophet in python (stoSalesForecastnew.py).</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Prophet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Prophet follows the sklearn model API. We create an instance of the Prophet class and then call its fit and predict methods.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>All the below steps which include the Prophet model are executed in the python in the file <a href=\"./stoSalesForecastnew.py\">stoSalesForecastnew.py</a> file. We then use this py file in the Script command and get the forecasted values.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The input to Prophet is always a dataframe with two columns: ds and y. The ds (datestamp) column should be of a format expected by Pandas, ideally YYYY-MM-DD for a date or YYYY-MM-DD HH:MM:SS for a timestamp. The y column must be numeric and represents the measurement we wish to forecast.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The below code shows the creation of the Sales DataFrame and the holidays Dataframe which are used in the model creation and model fit.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>Create Sales data dataframe using data from Vantage</b></p>\n",
    "\n",
    "```python \n",
    "# create Sales data \n",
    "sales = pd_sales_store.rename(columns = {'SalesDate': 'ds','Sales': 'y'})\n",
    "```  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>Create holidays dataframe</b></p>\n",
    "\n",
    "```python\n",
    "#create holidays dataframe\n",
    "     \n",
    "\n",
    "school_dates = df[df.SchoolHoliday == 1].loc[:, 'Date'].values\n",
    "\n",
    "school = pd.DataFrame({'holiday': 'school_holiday',\n",
    "                      'ds': pd.to_datetime(school_dates)})\n",
    "\n",
    "holidays = school      \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We fit the model by instantiating a new Prophet object. Any settings to the forecasting procedure are passed into the constructor. Then you call its fit method and pass in the historical dataframe(sales).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>Instantiate and fit model using Prophet</b></p>\n",
    "\n",
    "```python\n",
    "\n",
    "# Prophet implementation \n",
    "my_model = Prophet(interval_width = 0.95, \n",
    "                   holidays = holidays.head(50000))\n",
    "my_model.fit(sales)                   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Predictions are then made on a dataframe with a column ds containing the dates for which a prediction is to be made. You can get a suitable dataframe that extends into the future a specified number of days using the helper method Prophet.make_future_dataframe. By default, it will also include the dates from the history, so we will see the model fit as well.<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>Create future dates for forecasting</b></p>\n",
    "\n",
    "```python\n",
    "dt = min(sales['ds'].values)\n",
    "date1 = datetime.datetime.strptime(dt, \"%y/%m/%d\").date()\n",
    "\n",
    "\n",
    "\n",
    "#  # Subtract one month\n",
    "start_date = date1 - relativedelta(months=1)\n",
    "\n",
    "# Get man date and then get future dates for 1 month\n",
    "dt1 = max(sales['ds'].values)\n",
    "date2 = datetime.datetime.strptime(dt1, \"%y/%m/%d\").date()\n",
    "# date2 = datetime.datetime.strptime(datetime_str, \"%Y/%m/%dT%H:%M:%S.%f\").date()\n",
    "end_date = date2 + relativedelta(months=1)\n",
    "# end_date= str(end_value)\n",
    "\n",
    "\n",
    "# # date_range = pd.date_range(start_date, periods=num_days)\n",
    "date_range = pd.date_range(str(start_date), str(end_date))\n",
    "\n",
    "future_dates = pd.DataFrame({'ds': date_range})               \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The predict method will assign each row in future a predicted value which it names yhat. If you pass in historical dates, it will provide an in-sample fit. The forecast object here is a new dataframe that includes the \"yhat\" column, which is the forecast values for sales, as well as columns for components and uncertainty intervals.<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>Create dataframe with forecast values</b></p>\n",
    "\n",
    "```python\n",
    "# forecast\n",
    "forecast = my_model.predict(future_dates.head(10000))               \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The forecasted values will be sent back to Vantage using the Returns clause of the Script function as seen in the section below.<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>6. Using Script Command to get the forecasted values back to Vantage.</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The SCRIPT COMMAND requires the below elements \n",
    "<li style = 'font-size:16px;font-family:Arial'><b>ON clause: </b> The SCRIPT function can have only one ON clause (single input). The ON clause can be specified with no options or with: HASH BY, PARTITION BY, PARTITION BY ANY, an optional ORDER BY or LOCAL ORDER BY clause</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'><b>SCRIPT_COMMAND: </b>\n",
    "The script to be executed. The SCRIPT_COMMAND is a required keyword.\n",
    "    <li style = 'font-size:16px;font-family:Arial'><b>runtime_literal_command: </b>The parameters to SCRIPT_COMMAND can be an executable name followed by the script name and other inputs, or any valid LINUX command.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'><b>RETURNS: </b>\n",
    "    The names and types of the output columns returned by the script. <b>* </b>Specifies that all columns of the input table should be returned by the SCRIPT function.</li>\n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial'>First we will create a dataset which can be passed to the Script function.</p>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry='''CREATE SET TABLE Store_Sales_ID \n",
    "     (\n",
    "      SlsID INTEGER,\n",
    "      Store INTEGER,\n",
    "      DayOfWeek INTEGER,\n",
    "      SalesDate DATE FORMAT 'yyyy/mm/dd',\n",
    "      Sales INTEGER,\n",
    "      Customers INTEGER,\n",
    "      SalesOpen INTEGER,\n",
    "      Promo INTEGER,\n",
    "      StateHoliday CHAR(1) CHARACTER SET LATIN NOT CASESPECIFIC,\n",
    "      SchoolHoliday INTEGER)\n",
    "      PRIMARY INDEX ( SlsID ); '''\n",
    "qry1='''insert into DEMO_USER.Store_Sales_ID select 1,  Store ,\n",
    "      DayOfWeek ,\n",
    "      SalesDate ,\n",
    "      Sales ,\n",
    "      Customers ,\n",
    "      SalesOpen ,\n",
    "      Promo ,\n",
    "      StateHoliday,\n",
    "      SchoolHoliday  from DEMO_prophetSTO.Sales_Data where Store <= 5;'''\n",
    "try:\n",
    "    execute_sql(qry)\n",
    "    execute_sql(qry1) \n",
    "except:\n",
    "    db_drop_table('Store_Sales_ID')\n",
    "    execute_sql(qry)\n",
    "    execute_sql(qry1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table_df2 = DataFrame('Store_Sales_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>First we set the Database for execution to the user database: demo_user in this case</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = 'demo_user'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Set the search path to the database where the file is installed</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execute_sql(f\"SET SESSION SEARCHUIFDBPATH = {database_name};\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Install the user script file on Vantage. In case of rerun if the file already exists we first remove it and then install again.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sto = Script(data = final_table_df2, script_name='stoSalesForecastnew.py',\n",
    "             files_local_path= r\".\",\n",
    "             script_command= f'tdpython3 ./{database_name}/stoSalesForecastnew.py', \n",
    "                         delimiter = \"\\t\", nulls_first = False,\n",
    "                         returns={\"ds\":TIMESTAMP(0), \"yhat\": FLOAT(), \"yhat_lower\": FLOAT(), \"yhat_upper\": FLOAT() , \n",
    "                                  \"trend\": FLOAT(), \"weekly\": FLOAT(), \"yearly\": FLOAT()} # }, #,  \"Variable\":VARCHAR(50)\n",
    "                        #  data_order_column = \"pkg_id\", #charset='latin',\n",
    "                        # data_partition_column=\"v_id\",\n",
    "                        #  is_local_order = False, sort_ascending=False\n",
    "            )\n",
    "\n",
    "try:\n",
    "    sto.install_file(file_identifier='stoSalesForecastnew', file_name='stoSalesForecastnew.py', is_binary=False)\n",
    "except:\n",
    "    sto.remove_file(file_identifier='stoSalesForecastnew', force_remove=False)\n",
    "    sto.install_file(file_identifier='stoSalesForecastnew', file_name='stoSalesForecastnew.py', is_binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Execute the script in SQL using SCRIPT command with the following SQL code:</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Since the entire process of model training , fitting and scoring takes place in the .py file when used in the script command the below query make take some time approximately 50-60 seconds.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STO_DF = sto.execute_script()\n",
    "STO_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STO_DF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The output contains 1004 rows(1 for each date) and 7 columns.\n",
    "<p style = 'font-size:16px;font-family:Arial'>The forecasting output contains information for:\n",
    "</p>\n",
    "<li style = 'font-size:16px;font-family:Arial'>The forecasted value (yhat)</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Range for the forecasted values (yhat_lower and yhat_upper)</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>The overall trend for a given date (also incorporates seasonality)</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Additive terms to adjust the trend to get the forecasted value</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>To plot the forecast Values we select only the required columns and convert the teradataml dataframe to pandas dataframe.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_output = STO_DF.to_pandas(all_rows=True).reset_index()\n",
    "plot_output[\"ds\"] = pd.to_datetime(plot_output['ds']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_output_forecast = plot_output[['ds','yhat','yhat_lower','yhat_upper']].sort_values('ds', ascending=True)\n",
    "# .tail(300)\n",
    "plot_output_forecast = plot_output_forecast.reset_index()\n",
    "plot_output_forecast.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>To plot the forecast Values and the confidence level we set the lower and upper bounds of the confidence interval to yhat_lower and yhat_upper.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Create the data for the line graph, including the x-values and the corresponding upper and lower bounds\n",
    "x_values = plot_output_forecast['ds'].values\n",
    "y_values = plot_output_forecast['yhat'].values\n",
    "lower_bounds = plot_output_forecast['yhat_lower'].values\n",
    "upper_bounds = plot_output_forecast['yhat_upper'].values\n",
    "\n",
    " \n",
    "plt.figure(figsize=(12, 8))\n",
    "# Plot the line graph\n",
    "plt.plot(x_values, y_values, color='black', label='Forecast Values')\n",
    "plt.fill_between(x_values, lower_bounds, upper_bounds, color='lightblue', alpha=0.3, label='Confidence Interval')\n",
    "\n",
    " \n",
    "\n",
    "# Customize the plot\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Forecast Values')\n",
    "plt.title('Forecast Sales Values with Confidence Interval')\n",
    "plt.legend()\n",
    "\n",
    " \n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above graph contains the Forecast values(black line) and the light blue area is the range of the lower(yhat_lower) and upper(yhat_upper) limits of the forecasted values.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Below we will check the general trend , the Weekly trend and the yearly trend of the forecasted values</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trend = STO_DF[['ds','trend','weekly','yearly']].sort('ds', ascending=True)\n",
    "plot_trend = plot_trend.assign(day_week = plot_trend.ds.cast(type_=TIMESTAMP).day_of_week())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = subplots(nrows=3, ncols=1)\n",
    " \n",
    "plot = plot_trend.plot(x=plot_trend.ds, y=plot_trend.trend,\n",
    "                          ax=axes[0], figure=fig, kind=\"line\",xlabel='Sales Date', ylabel='Sales', \n",
    "                          xtick_format='YYYY-MM',title=\"Sales Trend\", color=\"blue\",figsize=(1200, 1200))\n",
    " \n",
    "plot = plot_trend.plot(x=plot_trend.day_week, y=plot_trend.weekly,\n",
    "                          ax=axes[1],figure=fig, kind=\"scatter\",xlabel='Sales Date', ylabel='Sales',\n",
    "                          title=\"Weekly Sales\", color=\"blue\")\n",
    " \n",
    "plot = plot_trend.plot(x=plot_trend.ds, y=plot_trend.yearly,\n",
    "                          ax=axes[2],figure=fig, kind=\"line\",xlabel='Sales Date', ylabel='Sales',\n",
    "                          xtick_format='YYYY-MM',title=\"Yearly Sales\", color=\"blue\")\n",
    "\n",
    "# Display the plot.\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li style = 'font-size:16px;font-family:Arial'>The first plot illustrates a gradual decline in sales over time. Although the decrease may not seem significant on the graph, it is worth noting that the sales range from a minimum of 4723 to a maximum of 4729.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>The second plot highlights the volume of sales on a particular Day of the week.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>The third plot highlights distinct peaks in sales activity during the winter holidays and summer holidays. These periods are the busiest seasons, indicating an increase in sales volume during those times.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>7. Conclusion:</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have trained and validated the Prophet model using the python script and used the Script Table Operator(STO) using data from Vantage. We get the forecasted data in Vantage using the python script.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>8. Cleanup</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Work Tables</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_drop_table(table_name='Store_Sales_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>Databases and Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_ProphetSTO');\" \n",
    "#Takes 20 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2023, 2024. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
