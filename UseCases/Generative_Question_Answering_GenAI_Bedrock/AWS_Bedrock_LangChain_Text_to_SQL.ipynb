{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c04cefa",
   "metadata": {},
   "source": [
    "<header style=\"background-color: #00233C; color: #F0F0F0; padding: 20pt;\">\n",
    "    <h1 style=\"font-size: 36px; font-family: Arial; margin: 0;\">\n",
    "        Building Text-to-Teradata SQL Agents with LangChain and Amazon Bedrock\n",
    "    </h1>\n",
    "    <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "</header>\n",
    "\n",
    "<section style=\"margin-top: 20px;\">\n",
    "    <p style=\"font-size: 18px; font-family: Arial;\"><b>Introduction</b></p>\n",
    "    <p style=\"font-size: 16px; font-family: Arial;\">\n",
    "        Data scientists, data engineers, and SQL experts are frequently tasked with querying enterprise databases to answer critical business questions, such as “What was our churn this month?” or “Which product led sales in the Americas?” The answers often trigger further follow-up questions, requiring engineers to spend significant time responding to data requests. \n",
    "        <br><br>\n",
    "        By integrating Amazon Bedrock’s secure foundation models, LangChain’s open-source framework, and the powerful capabilities of Teradata Vantage™, we can develop text-to-SQL autonomous agents that enable business teams to independently retrieve insights. Leveraging teradataml, teams can analyze data stored in Vantage and external object stores, such as Amazon S3, Google Cloud, Azure Blob, and OTF, without needing to ingest it. This reduces data transfer costs and offers flexible exploration using text-to-SQL generative AI applications.\n",
    "    </p>\n",
    "</section>\n",
    "\n",
    "<section style=\"margin-top: 20px;\">\n",
    "    <p style=\"font-size: 18px; font-family: Arial;\"><b>Text-to-Teradata SQL Agent Architecture</b></p>\n",
    "        <p style=\"font-size: 16px; font-family: Arial;\">\n",
    "            We will build a LangChain implementation of a text-to-SQL agent to generate and execute advanced SQL queries compatible with any LLM available via Amazon Bedrock. Users can ask business questions in natural English and receive answers with data drawn from the relevant databases. This agent will connect to a Vantage database to analyze data stored in Vantage and Amazon S3. You may add additional foreign tables to load data from Google Cloud, and Azure Blob.\n",
    "        </p>\n",
    "        <img src=\"LangChain-and-Amazon-Bedrock_Jupyter-NB_ImgCover.jpg\" alt=\"Architecture for Text-2-TeradataSQL Agents with LangChain and Amazon Bedrock\" style=\"width: 90%; height: auto; margin-top: 20px;\">\n",
    "    </div>\n",
    "</section>\n",
    "\n",
    "<section style=\"margin-top: 20px;\">\n",
    "    <ul style=\"font-size: 16px; font-family: Arial; list-style-type: none; padding: 0;\">\n",
    "        <li style=\"margin-bottom: 20px;\">\n",
    "            <b>Tools:</b>\n",
    "            <div style=\"padding: 10px; margin-left: 40px; border-left: 4px solid #00BFA5;\">\n",
    "                <b>Amazon Bedrock</b> is a managed platform that allows developers to select, manage, and customize Foudation Models (FMs) with data from a single API. Amazon Bedrock ensures that all proprietary data fed to the selected LLM is managed and protected by AWS, with no data shared with model providers or used to improve base models. This provides a secure way for developing generative AI applications without compromising sensitive data. For this example, we will build our GenAI text-to-TeradataSQL with Anthropic Claude-3 offered via Bedrock.\n",
    "            </div>\n",
    "        </li>\n",
    "        <li style=\"margin-bottom: 20px;\">\n",
    "            <div style=\"padding: 10px; margin-left: 40px; border-left: 4px solid #00BFA5;\">\n",
    "                <b>LangChain</b> provides an easy-to-use open-source framework with components, integaration and tools optimized for querying SQL databases, which speeds up the development process. When coupled with Amazon Bedrock's single API, which interfaces with a variety of chat models, LangChain accelerates the creation of POCs and the deployment of GenAI applications. These two tools together reduce the complexity and time involved in model selection and integration. With Bedrock, we can experiment with models from Anthropic, Cohere, Meta, Mistral AI, and Stability AI via one interface.\n",
    "            </div>\n",
    "        </li>\n",
    "        <li>\n",
    "            <div style=\"padding: 10px; margin-left: 40px; border-left: 4px solid #00BFA5;\">\n",
    "                <b>Teradata Vantage</b> facilitates the analysis of data stored externally in object storage. We can leverage the Teradataml library and its native object storage to read data inside Google Cloud, Azure Blob, Amazon S3, and OTFs (Open Table Formats). This minimizes costly data transfer and allows developers to work within Vantage using foreign tables, without needing to transfer data into Vantage or use additional storage in their Vantage environment.\n",
    "            </div>\n",
    "        </li>\n",
    "    </ul>\n",
    "</section>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20af9b23",
   "metadata": {},
   "source": [
    "<b style = 'font-size:20px;font-family:Arial'>Prerequisite</b>\n",
    "- Must have access to AWS Console and Amazon Bedrock\n",
    "- Ensure you have requested and been granted access to the <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html\">foundation model you want to use</a>. In this example, we are using Anthropic Claude 3 Sonnet. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c410975",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;'>\n",
    "<b style = 'font-size:20px;font-family:Arial'>1. Configuring the environment</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7866a50d",
   "metadata": {},
   "source": [
    "\n",
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "We begin by installing our dependencies. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae5be67",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# '%%capture' suppresses the display of installation steps of the following packages\n",
    "\n",
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b604f5b-c27f-4ce7-b8ab-13fed31e295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pyOpenSSL cryptography --force-reinstall --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bc1aeb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial'><b>Note: </b><i>The above statements will install the required libraries to run this demo. Be sure to restart the kernel after executing the above lines to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i></p>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b3fba",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style=\"font-size: 18px; font-family: Arial;\"><b>1.1 Import the required libraries and set up environment</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac4f409",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "    We will use the following libraries and tools:\n",
    "</p>\n",
    "\n",
    "<ul style=\"font-size: 16px; font-family: Arial; list-style-type: disc; padding-left: 20px;\">\n",
    "    <li>\n",
    "        <b>boto3</b>: The AWS SDK for Python allows us to interact with AWS services, including the Amazon Bedrock API.\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>teradataml</b>: Enables enables us to establish a connection to our database using the <code>create_context()</code> function and allows us to create virtual DataFrames, which serve as references to database objects, allowing exploration of object storage data and enabling operations directly on Vantage without transferring entire datasets to the client, except when needed. For this demo, we will be exploring a dataset in S3 via a foreign table on Vantage.\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>LangChain’s SQLDatabase class </b>: A wrapper around the SQLAlchemy engine to facilitate interactions with databases using SQLAlchemy’s Python SQL toolkit and ORM capabilities.\n",
    "    </li>\n",
    "    <li>\n",
    "        <b> LangChain’s create_sql_agent function</b>: A LangChain function to build a SQL agent by providing a language model and a database connection.\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>LangChain’s ChatBedrockConverse class</b>: A common interface for working with Amazons Bedrock's FM's that support chat functionalities.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d6588f-b6d6-4736-9f40-ac289c31a8a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import getpass\n",
    "import warnings\n",
    "import boto3 \n",
    "\n",
    "from langchain_community.utilities import SQLDatabase \n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from teradataml import *\n",
    " \n",
    "from langchain_aws import ChatBedrockConverse\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912c3093",
   "metadata": {},
   "source": [
    "<hr style=\"height: 1px; border: none;\">\n",
    "\n",
    "<p style=\"font-size: 20px; font-family: Arial;\"><b>2. Connect to Vantage</b></p>\n",
    "\n",
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "    You will be prompted to enter the password. Once you enter the password, press the Enter key, and use the down arrow to move to the next cell.\n",
    "    <br><br>\n",
    "    Here, we use the <a href=\"https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Teradata-Package-for-Python-User-Guide-17.20/Context-to-Teradata-Vantage\" target=\"_blank\">create_context()</a> function to connect to the Vantage system using the teradatasql and teradatasqlalchemy DBAPI and dialect combination. This connection allows us to use the teradataml <a href=\"https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Teradata-Package-for-Python-User-Guide-17.20/DataFrames-for-Tables-and-Views/DataFrames-from-Teradata-Vantage-Data-Sources/DataFrame-Constructor\" target=\"_blank\">DataFrame()</a> constructor to build foreign tables for reading data from Object Storage - in this example from Amazon s3.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57719ca5-c6b9-49fe-97b5-8c4e41e2cbb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "password=getpass.getpass(prompt='Enter your ClearScape Analytics Environment password: ')\n",
    "\n",
    "eng = create_context(host = 'host.docker.internal', username = 'demo_user', password = password, database = 'demo_user')\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd56b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO= AWS_Bedrock_LangChain_Text_to_SQL.ipynb;' UPDATE FOR SESSION;''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfc7c31",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>2.1 Loading Data for This Demo</b></p>\n",
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "    When working with Teradata Vantage for data analysis, you have two options:\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size: 16px; font-family: Arial; margin-left: 20px;\">\n",
    "    <b>Analyze data stored externally in object storage.</b> This method uses native object storage integration to create <code>foreign tables</code> inside the database; point this virtual table to an external object storage location like Google Cloud, Azure Blob, and Amazon S3; and use SQL to analyze the data. The advantage here is that it minimizes data transfer and allows you to work within Vantage using foreign tables, without needing additional storage in your Vantage environment.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size: 16px; font-family: Arial; margin-left: 20px;\">\n",
    "    <b>Download data into your local Vantage environment.</b> Alternatively, you can use native object storage integration to ingest data at scale into Vantage using one SQL request. Downloading data can result in faster execution of some steps that perform the initial access to the source data.\n",
    "</p>\n",
    "<p style=\"font-size: 16px; font-family: Arial; margin-left: 20px;\">\n",
    "Let’s explore the data where it resides in Amazon S3 by creating a foreign table inside our <code> demo_user</code> with the following code:  \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70e7eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = \"\"\" CREATE FOREIGN TABLE demo_user.retail_marketing \n",
    "USING ( \n",
    "location('/s3/dev-rel-demos.s3.amazonaws.com/bedrock-demo/Retail_Marketing.csv') \n",
    "); \"\"\" \n",
    "\n",
    "try:\n",
    "    execute_sql(load_data)\n",
    "    print('Table Loaded')\n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e): \n",
    "        print(\"Table already exists, skipping creation.\")\n",
    "    else:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef60fc7",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;'>\n",
    "<b style = 'font-size:28px;font-family:Arial'>3. Data Exploration</b>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial'>We are working with data from a marketing campaign, which includes thousands of rows of customer data such as age, job, marital status, education, and more.</p>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial'> We can categorize the input dataset into three main categories:</p>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial'>\n",
    "    <ol style='font-size:16px;font-family:Arial'>\n",
    "        <li>Customer data, including age, profession, education, monthly income, and more.</li>\n",
    "        <li>Attributes related to the last contact of the current campaign, such as contact, month, day, and so on.</li>\n",
    "        <li>Other attributes, including campaign, previous outcome, payment methods, and more.</li>\n",
    "        <li>The target attribute - whether the customer purchased the product.</li>\n",
    "    </ol>\n",
    "</p>\n",
    "<p style='font-size:16px;font-family:Arial'>We have loaded the source data from <a href=\"https://www.kaggle.com/datasets/janiobachmann/bank-marketing-dataset\">Kaggle</a> into S3 and supplemented it with additional information such as city, monthly income, family members, and more. The data is then loaded into a Vantage foreign table named <i>Retail_Marketing</i>.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5df83e",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>3.1 Examine the Retail Marketing Campaign table</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial'>Let's look at the data in the Retail_Marketing foreign table. This data resides in Object Storage, Amazon S3, and has not been ingested into our Vantage enviroment. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642d9313",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(in_schema('demo_user', 'retail_marketing'))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e927ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec78a9de",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>4. Create engine using SQLAlchemy </b><p>\n",
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    " We create our engine using LangChain's SQLAlchemy wrapper <a href=\"https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.sql_database.SQLDatabase.html\" target=\"_blank\">SQLDatabase</a>. <br><br>The <code>db.get_usable_table_names()</code> method retrieves and prints the names of tables in the connected database. For this demonstration, we're using our default <code>demo_user</code> database. If there are no tables in your database, this method will return an empty array.\n",
    "</p>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907294cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQLDatabase(eng)\n",
    "\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a873453",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;'>\n",
    "<b style = 'font-size:20px;font-family:Arial'>4. Set up the Bedrock client</b>\n",
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "    Next, initialize the <code>bedrock-runtime</code> client. Because we are executing this demo outside of SageMaker we will pass in or <a/ href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html\"> Amazon credentials<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ceb08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If executing from sagemaker you do not need to define aws_access_key_id, aws_secret_access_key, or aws_session_token. Simply define client as 'bedrock-runtime'.\n",
    "# boto3_bedrock = boto3.client('bedrock-runtime')\n",
    "\n",
    "boto3_bedrock = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=getpass.getpass(prompt='Enter your AWS region: '),\n",
    "    aws_access_key_id=getpass.getpass(prompt='Enter your AWS Access Key ID: '),\n",
    "    aws_secret_access_key=getpass.getpass(prompt='Enter your AWS Secret Access Key: '),\n",
    "    aws_session_token=getpass.getpass(prompt='Enter your AWS Session Token: ')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9490e25e",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>4.1 Define LLM</b></p>\n",
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "     First ensure you have requested and been granted access to the <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html\">foundation model you want to use</a>. In this example, we are using Anthropic Claude 3 Sonnet. \n",
    "</p>   \n",
    "<img src=\"bedrock-claude-3.png\" alt=\"Bedrock Claude 3\" style=\"width: 90%; height: auto;\">\n",
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "    Define the LLM using the <code>ChatBedrockConverse</code> interface. When defining <code>ChatBedrockConverse</code>, set the <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html#model-ids-arns\">Amazon Bedrock base model ID</a>, the client as <code>boto3_bedrock</code>, and the common inference parameters.\n",
    "</p> \n",
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "    We use the optional parameter <b>temperature</b> to make our Teradata SQL outputs more predictable.\n",
    "</p>\n",
    "\n",
    "<div style=\"margin-left: 16px; font-size: 16px; font-family: Arial;\">\n",
    "    <b>- Temperature:</b> which can range from 0.0 to 2 and controls how creative our results will be, Setting it to 0.1 ensures the model favors higher-probability (more predictable) words, resulting in more consistent and less varied outputs.<br>\n",
    "</div>\n",
    "\n",
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "    For a complete list of optional parameters for base models provided by Amazon Bedrock, visit the <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html\"> AWS docs</a>.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d240240-6b6f-4b78-938d-00582fb5e375",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatBedrockConverse(\n",
    "    model=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    temperature=0.1,\n",
    "    client=boto3_bedrock,\n",
    "    max_tokens=None\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e671599",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>4.2 Create and Invoke the SQL agent</b></p>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c0ec1c",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "    With the connection to Teradata Vantage established and our database (<code>db</code>) and Large Language Model (<code>LLM</code>) defined, we are ready to create and invoke our SQL Agent using the <code>create_sql_agent()</code> function. \n",
    "    </p>\n",
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "    We pass in our <code>llm</code> and <code>db</code> as required parameters and set <code>agent_type</code> to \"zero-shot-react-description\" to instruct the agent to perform a reasoning step before acting.  \n",
    "    </p>\n",
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "    We set <code>verbose</code> to true so that the agent can output detailed information of intermediate steps. Additionally, we set <code>handle_parsing_errors</code> to <code>True</code>, ensuring that errors are sent back to the LLM as observations, for the LLM to attempt handling the errors.\n",
    "    </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f4886c-17ac-411a-976d-691297ad8fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent=create_sql_agent(\n",
    "    llm=llm,\n",
    "    db=db,\n",
    "    agent_type=\"zero-shot-react-description\",\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708e7112",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;'>\n",
    "<b style = 'font-size:20px;font-family:Arial'>5. Set optional observability with LangSmith</b>\n",
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "    We add optional additional observability with LangSmith. You can create a <a href=\"https://docs.smith.langchain.com/#2-create-an-api-key\"> LangSmith free account with limited traces here.</a>\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "     To enhance observability in our application, we can configure environment variables for LangSmith. LangSmith comes pre-installed with the LangChain library, so all you need to do is generate a LangSmith API key and set up the following environment variables to start monitoring your applications. Uncomment the LangSmith variables if you want to use the LangSmith tracing functionalities to log and view executions of your LLM application. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd224e2f-fe7e-4009-bf37-318693181b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass() \n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = \"text-to-teradata-sql\"\n",
    "# os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4345b42",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;'>\n",
    "<b style = 'font-size:20px;font-family:Arial'>6. Invoke the SQL Agent to explore the data</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa02c321",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "    Invoke the agent with an exploratory command or question and observe each step. For example, you can ask it to describe the retail marketing table.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "    As soon as we invoke the agent, it begins performing a sequence of thought and action. Notice how this behavior is very similar to how a Data Scientist would approach interacting with a database. \n",
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "Data scientists and data analysts usually start with a trial query to understand the table schema and look at initial rows. This exploration helps in constructing queries. If errors happen, they edit their queries until they are successful. Similarly, LangChain agents ensure LLMs are firmly rooted in real data by describing the database, including its table structure, data samples of the top few columns, and sample SELECT queries. This reduces hallucinations and ensures more reliable and accurate SQL query generation.  \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af91e80-52c7-45f2-8a27-66f48829f2d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    question = \"Describe the retail marketing table\"\n",
    "    response = agent.invoke(question)\n",
    "    if isinstance(response, dict) and 'output' in response:\n",
    "        answer = response['output']\n",
    "    else:\n",
    "        answer = \"No valid response received.\"\n",
    "    print(f\"Query: {question}\\nResponse: {answer}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac86782",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "If we inspect our application using LangSmith we can see all inputs and outputs in every step of the chain. You can view a public run of this example question\n",
    " <a href=\"https://smith.langchain.com/public/cc66a546-acf3-4e51-8044-cc1c194ed386/r\">here</a>.  Note that the first call to Anthropic Claude 3 is the third step in our chain. In this third step, the input includes additional instructions for the agent to use supplementary tools such as sql_db_query, sql_db_list_tables, sql_db_query_checker, and sql_db_query, along with a specified format for thought and action sequences. This SQLDatabase agent has been engineered with prompts to emulate the approach taken by data scientists when exploring and analyzing data. </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6232b246",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;'>\n",
    "<b style = 'font-size:20px;font-family:Arial'>7. Optimizing our SQL Agent with Prompt Engineering</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf279b79",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>7.1 Invoking the SQL Agent with a complex query</b></p>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211d04e",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "   Now let's ask our agent a slightly more involved question. You may notice that the queries generated by the LLM sometimes return syntax errors. However, the LLM might be able to recover from these errors and still provide the correct answer. In some cases, though, the LLM may arrive to the answer and the agent is stumped by a parsing error.\n",
    " \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d4f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    question = \"What is the month with the highest number of marketing engagements?\"\n",
    "    response = agent.invoke(question)\n",
    "    if isinstance(response, dict) and 'output' in response:\n",
    "        answer = response['output']\n",
    "    else:\n",
    "        answer = \"No valid response received.\"\n",
    "    print(f\"Query: {question}\\nResponse: {answer}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a575dc5d",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "The agent can answer various questions about our data using only table names, schemas, sample rows, and the LLM’s knowledge of Teradata SQL. Although it can recover from mistakes as noted in the previous query, there's significant room for improvement. The last query resulted in our agent using 23,913 tokens and taking 49.56 seconds to provide the correct answer. You can view a public view of this execution via this <a href=\"https://smith.langchain.com/public/878e5908-abaa-49fc-8157-781a44adc0a5/r\" >LangSmith trace </a>. </p>\n",
    "<hr style='height:2px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>7.2 Adding a custom prompt to the SQL Agent </b></p>    \n",
    "\n",
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    " We can optimize the agents performance with additional prompt engineering. \n",
    "</p>\n",
    "\n",
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "We import a <code>ChatPromptTemplate</code> class to build flexible reusable prompts in our agent. Here we define a prefix, format instructions, and a suffix and join them to create a custom prompt. The prefix has unique rules that apply to Teradata. The format guides it's Question, thought, observation behavior and the suffix cues it to begin. \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052f9af8-e4b8-48ad-b199-a8707c1bd082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate    \n",
    "\n",
    "prefix = \"\"\"You are an helpful and expert TeradataSQL database admin. TeradataSQL shares many similarities to SQL, with a few key differences.\n",
    "Given an input question, first create a syntactically correct TeradataSQL query to run, then look at the results of the query and return the answer.\n",
    "\n",
    "IMPORTANT: Unless the user specifies an exact number of rows they wish to obtain, you must always limit your query to at most {top_k} results by using \"SELECT TOP {top_k}\".\n",
    "\n",
    "The following keywords do not exist in TeradataSQL: \n",
    "1. LIMIT \n",
    "2. FETCH\n",
    "3. FIRST\n",
    "Instead of LIMIT or FETCH, use the TOP keyword. The TOP keyword should immediately follow a \"SELECT\" statement.\n",
    "For example, to select the top 3 results, use \"SELECT TOP 3 FROM <table_name>\"\n",
    "Enclose all value identifiers in quotes to prevent errors from restricted keywords. Append an underscore to all alias keywords (e.g., AS count_).\n",
    "Always use double quotation marks (\" \") for column names in SQL queries to avoid syntax errors.\n",
    "NOT make any DML statements (INSERT, UPDATE, DELETE, DROP, etc.) to the database. \n",
    "If the question does not seem related to the database, just return \"I don't know\" as the answer\n",
    "\n",
    "You have access to the following tools:\"\"\"\n",
    "\n",
    "format_instructions = \"\"\"You must always the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Don't forget to prefix your final answer with the string, \"Final Answer:\"!\"\"\"\n",
    "\n",
    "suffix = \"\"\"Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\"\"\"\n",
    "\n",
    "custom_prompt = ChatPromptTemplate.from_template(\"\\n\\n\".join([\n",
    "    prefix,\n",
    "    \"{tools}\",\n",
    "    format_instructions,\n",
    "    suffix,\n",
    "]))\n",
    "\n",
    "\n",
    "agent=create_sql_agent(\n",
    "    llm=llm,\n",
    "    db=db,\n",
    "    agent_type=\"zero-shot-react-description\",\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    prompt=custom_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed03836",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>7.3 Test and Compare Results </b></p>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7208e4e0",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "To test and compare our results let's invoke the agent using the same question as the previous step. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdae59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    question = \"What is the month with the highest number of marketing engagements?\"\n",
    "    response = agent.invoke(question)\n",
    "    if isinstance(response, dict) and 'output' in response:\n",
    "        answer = response['output']\n",
    "    else:\n",
    "        answer = \"No valid response received.\"\n",
    "    print(f\"Query: {question}\\nResponse: {answer}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39fc410-8bbf-4992-b904-224718e1ad34",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px; font-family: Arial;\">\n",
    "This time our response was returned within 19.30 seconds and required 5,692 tokens! Inspect this public run on <a href=\"https://smith.langchain.com/public/e5cff28b-9bfe-48ba-a990-b87b0c3e2e06/r\">LangSmith</a>. This time the LLM did not generate the query using the restricted `LIMIT` keyword. This additional prompting enables it to produce the final answer with fewer iterations. \n",
    "Final answer: The month with the highest number of marketing engagements is May. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3585f974",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>7.4 You can try your own question</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here are some sample questions that you can try out:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>What is the average income for Phoenix?</li>\n",
    "    <li>Which city has the highest average income?</li>\n",
    "    <li>What is the average age of married people?</li>\n",
    "    <li>Which profession has the most married people in Phoenix?</li>\n",
    "    <li>What is the month with the lowest sales?</li>\n",
    "    <li>What is the month with the highest number of marketing engagements?</li>\n",
    "    <li>What is the payment method distribution?</li>\n",
    "    <li>What is the average number of days between a customer's last contact and their next purchase?</li>\n",
    "    <li>What is the relationship between marital status and purchase frequency?</li>\n",
    "    <li>What is the most effective communication method for reaching customers who have not purchased from our company in the past 6 months?</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc1eac4-5667-4b7a-862d-7ec4a401c547",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    question = input(\"\\nEnter your natural language query: \")\n",
    "    response = agent.invoke(question)\n",
    "    if isinstance(response, dict) and 'output' in response:\n",
    "        answer = response['output']\n",
    "    else:\n",
    "        answer = \"No valid response received.\"\n",
    "    print(f\"Query: {question}\\nResponse: {answer}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246b13da",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style='height:2px;border:none;'>\n",
    "<b style = 'font-size:20px;font-family:Arial'>8. Cleanup</b>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Cleanup work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfd0669",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_drop_table(table_name='retail_marketing') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0ef2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73399b62-2126-4c4a-8380-d83379dd9c4b",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; border-bottom:3px solid #91A0Ab\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2024. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
