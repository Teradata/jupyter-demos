{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccb0e42b-1d06-4ae0-91ec-e06fd55d6d3d",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Green Manufacturing for vehicles\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>Introduction</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Since the first automobile, the Real Wheel Motor Company has stood for important automotive innovations. These include, for example, the passenger safety cell with crumple zone, the airbag and intelligent assistance systems. Real Wheel Motor Company applies for nearly 2000 patents per year, making the brand the European leader among premium car makers. These cars are leaders in the premium car industry. With a huge selection of features and options, customers can choose the customized models of their dreams.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>To ensure the safety and reliability of each and every unique car configuration before they hit the road, the engineers have developed a robust testing system. But, optimizing the speed of their testing system for so many possible feature combinations is complex and time-consuming without a powerful algorithmic approach. As one of the world’s biggest manufacturers of premium cars, safety and efficiency are paramount on their production lines. ClearScape Analytics can help integrate, standardize, use, and reuse all the automotive data — from customers, vehicles, supply chains, production, and R&D — to digitally transform operations.</p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Business Values</b></p>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Improve accuracy in the production and manufacturing process.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Optimize production and back-end processes.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Decrease additional costs and time wasted due to undetected defects.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Stabilize yield, improve quality control, and predict maintenance issues.</li>\n",
    "</p>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Why Vantage?</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Many organizations fail to realize value from their ML and AI investments due to a lack of scale. It is estimated that for broad adoption across many industries, the number of models and model deployments needs to scale 100-1000x larger than their organizations currently support. The unique massively-parallel architecture of Teradata Vantage allows users to prepare data, train, evaluate, and deploy models at unprecedented scale.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this particular use case, the goal is to work with a dataset representing different permutations of Real Wheel Motor Company car features to predict the time it takes to pass testing. This will contribute to speedier testing, resulting in lower carbon dioxide emissions without reducing the standards of the company cars. Vantage helps maximize efficiency across the entire machine learning lifecycle. ClearScape Analytics’ comprehensive in-database functions and machine learning pipeline seamlessly apply algorithms to large-scale data, with minimal data movement.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>This dataset contains an anonymized set of variables, each representing a custom feature in a car. For example, a variable could be 4WD, added air suspension, or a head-up display. The ground truth is labelled ‘y’ and represents the time (in seconds) that the car took to pass testing for each variable.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66c9b40-011f-4903-a3ce-3621f83470f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>1. Connect to Vantage</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6694c3-bc4b-4ff5-9960-8d564783e888",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In the section, we import the required libraries and set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707f0705-e1cd-4089-8823-c15404f1445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# # '%%capture' suppresses the display of installation steps of the following packages\n",
    "# !pip install xgboost==1.7.3\n",
    "# !pip install colorlover\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22e76b4-c312-4281-a52e-d5eb91674e09",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Note: </b><i>The above statements may need to be uncommented if you run the notebooks on a platform other than ClearScape Analytics Experience that does not have the libraries installed. If you uncomment those installs, be sure to restart the kernel after executing those lines to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a393e50b-2226-436e-8dee-4a320a84aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import json\n",
    "import getpass\n",
    "import pandas as pd\n",
    "\n",
    "from teradataml.dataframe.dataframe import DataFrame\n",
    "from teradataml import *\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "color = sns.color_palette()\n",
    "import xgboost as xgb\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from collections import defaultdict\n",
    "import plotly.offline as offline\n",
    "import colorlover as cl\n",
    "offline.init_notebook_mode()\n",
    "\n",
    "display.max_rows=5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250f03f1-65de-4a7b-b5bc-87efaed7f11d",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell. Begin running steps with Shift + Enter keys.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f417e8-a4ea-4ce1-bced-6142a250d62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7459cd2a-d152-46a9-b2cd-7746febe992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=Green_Manufacturing_PY_SQL.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9746e656-3028-4abd-9278-af179bdd2963",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>2. Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have provided data for this demo on cloud storage. We have the option of either running the demo using foreign tables to access the data without using any storage on our environment or downloading the data to local storage, which may yield somewhat faster execution. However, we need to consider available storage. There are two statements in the following cell, and one is commented out. We may switch which mode we choose by changing the comment string.</p>    \n",
    "<p style = 'font-size:16px;font-family:Arial'><b>** Note : Due to the large number of columns the initial table creation and data loading make take more time.</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000f88a3-c62c-45e5-a083-81f1931df590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ../run_procedure.py \"call get_data('DEMO_GreenManufacturing_cloud');\"\n",
    " # Takes about 50 seconds\n",
    "%run -i ../run_procedure.py \"call get_data('DEMO_GreenManufacturing_local');\"\n",
    " # Takes about 3 minutes 30 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4122e51-c891-4c48-bec9-4f364e178f46",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Optional step – We should execute the below step only if we want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a295649-45ea-4cb1-ace9-ecc1c1f8cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3479e16-ac99-48ba-9aec-6d5eda6c4d96",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>3. Analyze the raw data set</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Let us start by creating a \"Virtual DataFrame\" that points directly to the dataset in Vantage. We then begin our analysis by checking the shape of the DataFrame and examining the data types of all its columns.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'><b><i>** Note : There may be a warning message due to a large number of columns in the dataframe. It's a Warning and not an error. Please ignore the warning</i></b></p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bfab48-052f-4d10-9547-47e321ac2274",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf = DataFrame(in_schema('DEMO_GreenManufacturing', 'Manufacturing_Data'))\n",
    "datadf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b4a74-0383-41fa-a884-00fd703c193c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The ID column is the ID of the cars, 'y' is the time in seconds which the car took to pass testing for each variable. The variables X0-X8 are categorical variables and the remaining are numerical variables having values of 0 and 1. These are the variables which impact the value of 'y'.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ac4d49-3b81-421b-8b7d-a9a7d3c5f553",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>4. Check the impact of Categorical variables on target variable 'y'</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>We can see that the aggregated data is available to us in teradataml dataframe. Let's visualize this data to better understand the categorical variables. Vantage's Clearscape Analytics can easily integrate with 3rd party visualization tools like Tableau, PowerBI or many python modules available like plotly, seaborn etc. We can do all the calculations and pre-processing on Vantage and pass only the necessary information to visualization tools, this will not only make the calculation faster but also reduce the time due to less data movement between tools.</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9d8382-ad00-49c2-a52c-c37501a8f276",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=datadf.to_pandas().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1de150-7f1b-4958-b23e-7fa109fa2e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "var_name = \"X0\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "# sns.stripplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "sns.countplot(x=var_name, data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5860bcda-0c83-48bd-a747-80d8417e5884",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot_x0 = datadf.assign(drop_columns=True,\n",
    "                           X0=datadf.X0,\n",
    "                           X0_cnt = datadf.X0)\n",
    "\n",
    "df_plot_x0 = df_plot_x0.groupby('X0').count()\n",
    "df_plot_x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ab88ef-9a91-4d4d-8d47-fb4494861621",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "var_name = \"X1\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.stripplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47da1621-cc48-4885-92d6-32d3f7a9c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "var_name = \"X2\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abadca04-df20-47e2-9f3c-8ee7f20429b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "var_name = \"X3\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.violinplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bddc45c-d32f-44b7-aac4-b82817fc4e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "var_name = \"X4\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.violinplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7868ab3-06f2-4f32-99b1-5355341b4fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "var_name = \"X5\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f019de-1bb0-4095-90b3-b875741be1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "var_name = \"X6\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac4a66-bee1-4b1c-8146-6cf2447c66df",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "var_name = \"X8\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729b69f2-d98e-4a87-8012-5166f72b9c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = \"ID\"\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.regplot(x=var_name, y='y', data=train_df, scatter_kws={'alpha':0.5, 's':30})\n",
    "# sns.barplot(x=var_name, y='y', data=train_df)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e11993c-bad6-4f3f-956a-d46bd70a02e4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>After the initial analysis done on the variables and the value of y based on these variables, let's go ahead and try to predict the value of Y using these variables. Below are some steps that should be done before using any prediction model.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7a9ed0-0571-451e-a095-271f8bc14bf0",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>5. Check the importance of various features on target variable 'y'</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>We are using the python xgboost model to check the feature importance.</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0631e179-e487-44c2-a2e5-a03897fc8a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "for f in [\"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"]:\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train_df[f].values)) \n",
    "        train_df[f] = lbl.transform(list(train_df[f].values))\n",
    "        \n",
    "train_y = train_df['y'].values\n",
    "train_X = train_df.drop([\"ID\", \"y\"], axis=1)\n",
    "\n",
    "\n",
    "def xgb_r2_score(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'r2', r2_score(labels, preds)\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'silent': 1\n",
    "}\n",
    "dtrain = xgb.DMatrix(train_X, train_y, feature_names=train_X.columns.values)\n",
    "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=100, feval=xgb_r2_score, maximize=True)\n",
    "\n",
    "# plot the important features #\n",
    "fig, ax = plt.subplots(figsize=(12,18))\n",
    "xgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034b2900-451f-4bf7-96ef-9079c2d49095",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>6. OrdinalEncoding of the categorical variables</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Machine learning models require all input and output variables to be numeric.\n",
    "This means that if your data contains categorical data, you must encode it to numbers before you can fit and evaluate a model.\n",
    "The two most popular techniques are an Ordinal Encoding and a One-Hot Encoding.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Ordinal encoding, which turns each label into an integer value and depicts the sequence of labels in the encoded data, is employed when the variables in the data are ordinal. Ordinal encoding converts each label into integer values and the encoded data represents the sequence of labels.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Since the variables X0-X8 are categorical, we will need to convert them into numerical to use them in different models. We are using the OrdinalEncoding for this conversion. The <b>OrdinalEncodingFit()</b>  function identifies distinct categorical values from the input data or a user-defined list and generates the distinct categorical values along with the ordinal value for each category.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The Ordinal encoding will be done for both the Train and Test Datasets.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c777985a-5592-49df-81d3-2effffde339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ordinal_fit_output = OrdinalEncodingFit(target_column=['X0','X1','X2','X3','X4','X5','X6','X8'],\n",
    "                                                   data=datadf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1cb130-a672-4225-9878-4134af5105e7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Ordinal encoding transform is used on the ordinal encoding fit data to get the numerical values for the categorical values.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The <b>OrdinalEncodingTransform()</b> function maps the categorical value to a specified ordinal value using the OrdinalEncodingFit() function output.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dcf8a0-f330-4cfd-a635-09f2427e24f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoding_transform_out = OrdinalEncodingTransform(data = datadf,\n",
    "                                                                object = Ordinal_fit_output.result,\n",
    "                                                                accumulate=['ID','y']\n",
    "                                                                )\n",
    "df = ordinal_encoding_transform_out.result\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63539398-6d2d-4a04-b279-8f024bc4d407",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>7. Preparation of Data</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In the below steps we are preparing the data by joining the converted categorical features and some other important features to be used in Model Training, Scoring and Evaluation</p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>We join the converted dataframe and the important numerical features to get the final dataset which will be used for the model.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Get the output of OrdinalTransform into dataframe.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fe79f2-a52e-4d74-a4f7-5365f09187db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OrdTransdf = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e700ab-f096-4044-b68d-171daa1112ea",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We join the converted dataframe and the original data to get important numerical features.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82c362d-95fa-444f-8688-4fe91e8ccad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "datadf=datadf.drop(columns=[\"X0\", \"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X8\"])\n",
    "datadf_join = OrdTransdf.join(other = datadf, on = [\"ID\"], how = \"left\",lprefix='t1',rprefix='t2')\n",
    "datadf_join=datadf_join.drop(columns=[\"t2_ID\", \"t2_y\"])\n",
    "datadf_join = datadf_join.assign(ID=datadf_join.t1_ID, y=datadf_join.t1_y)\n",
    "datadf_join = datadf_join.drop(columns=[\"t1_ID\", \"t1_y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5658c178-ae52-4e75-874e-a4dbc0d97ed8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Create a final dataframe with only the required important features along with the ID and the response column.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a6431-c94a-477a-8a9e-5cb191c2e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_df = datadf_join[[\"ID\",\n",
    "\"y\",\n",
    "\"X0\",\n",
    "\"X1\",\n",
    "\"X2\",\n",
    "\"X3\",\n",
    "\"X4\",\n",
    "\"X5\",                          \n",
    "\"X6\",\n",
    "\"X8\",\n",
    "\"X47\",\n",
    "\"X314\",\n",
    "\"X118\",\n",
    "\"X315\",\n",
    "\"X127\",\n",
    "\"X29\",\n",
    "\"X115\",\n",
    "\"X351\",                           \n",
    "\"X151\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f3e40a-03f7-4c1c-8010-d11e81c814c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(df = data_new_df, table_name = 'final_data',if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a1d49-a066-41d9-bbc0-af0e4c05e468",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We split the data into Train and Test data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7837b27a-a457-4251-8a11-cb353e06d96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_df = DataFrame('final_data')\n",
    "TrainTestSplit_out = TrainTestSplit(data = data_new_df,\n",
    "                                        id_column=\"ID\",\n",
    "                                        train_size=0.80,\n",
    "                                        test_size=0.20,\n",
    "                                        seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d494b7-ad7a-428b-aa19-c745a1f9d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_df=TrainTestSplit_out.result[TrainTestSplit_out.result['TD_IsTrainRow'] == 1].drop(['TD_IsTrainRow'], axis = 1)\n",
    "test_new_df=TrainTestSplit_out.result[TrainTestSplit_out.result['TD_IsTrainRow'] == 0].drop(['TD_IsTrainRow'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a8ce4-d6de-49ce-b099-e82dbd56149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(df = train_new_df, table_name = 'final_train_data',if_exists='replace')\n",
    "copy_to_sql(df = test_new_df, table_name = 'final_test_data',if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c85b2db-cee0-498f-b73e-4c1c6c51e14b",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>8. Decision Forest </b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The Decision Forest is a powerful method used for predicting outcomes in both classification and regression problems. It's an improvement on the technique of combining (or \"bagging\") multiple decision trees. Normally, building a decision tree involves assessing the importance of each feature in the data to determine how to divide the information. This method takes a unique approach by only considering a random subset of features at each division point in the tree. This forces each decision tree within the \"forest\" to be different from one another, which ultimately improves the accuracy of the predictions. The function relies on a training dataset to develop a prediction model. Then, the DecisionForestPredict function uses the model built by the DecisionForest function to make predictions. It supports regression, binary, and multi-class classification tasks.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Typically, constructing a decision tree involves evaluating the value for each input feature in the data to select a split point. The function reduces the features to a random subset (that can be considered at each split point); the algorithm can force each decision tree in the forest to be very different to improve prediction accuracy. The function uses a training dataset to create a predictive model. The DecisionForestPredict function uses the model created by the DecisionForest function for making predictions. The function supports regression, binary, and multi-class classification.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Consider the following points:\n",
    "<li style = 'font-size:16px;font-family:Arial'>All input features are numeric. Convert the categorical columns to numerical columns as preprocessing step.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>For classification, class labels (ResponseColumn values) can only be integers. A maximum of 500 classes is supported for classification.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Observations with missing values in any input column will be ignored during training. To fill in missing values, use the SimpleImpute function.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>The number of trees built by the DecisionForest function depends on the values of NumTrees, TreeSize, and CoverageFactor, as well as the data distribution in the cluster. The trees are built simultaneously by all the processing units (AMPs) that have a non-empty portion of the data.</li>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9944c0-8c13-4e3b-8081-edb2e1730e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_df = DataFrame('final_train_data')\n",
    "test_new_df = DataFrame('final_test_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e72a2a-f0aa-41d5-83ed-a59077603d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionForest_out = DecisionForest(data = train_new_df, \n",
    "                            input_columns = [ 'ID','X0','X1','X2','X3','X4','X5','X6','X8','X47','X314','X118'\n",
    "                                             ,'X315','X127','X29','X115','X351','X151'], \n",
    "                            response_column = 'y', \n",
    "                            max_depth = 12, \n",
    "                            num_trees = 4, \n",
    "                            min_node_size = 1, \n",
    "                            mtry = -1, \n",
    "                            mtry_seed = 1, \n",
    "                            seed = 1, \n",
    "                            tree_type = 'REGRESSION')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa33acf-f428-4dc5-be09-0271feeabd07",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The DecisionForestPredict() function uses the model generated by the DecisionForest() function to generate predictions on a response variable for a test set of data. The model can be stored in either a teradataml DataFrame or a DecisionForest object.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f553c79d-9c58-4774-9c4e-75a01be520f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_forest_predict_out = TDDecisionForestPredict(object = DecisionForest_out,\n",
    "                                                        newdata = test_new_df,\n",
    "                                                        id_column = \"ID\",\n",
    "                                                        detailed = False,\n",
    "                                                        accumulate = [\"y\"]\n",
    "                                                        )\n",
    "decision_forest_predict_out.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5361977-5c32-4b13-8fe5-653ac96ab83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = decision_forest_predict_out.result.head(50)\n",
    "from teradataml import Figure\n",
    "figure = Figure(width=1000, height=700, heading=\"Actual vs Predicted using DecisionForest Classification\")\n",
    "df_plot.plot(x=df_plot.ID, y=[df_plot.y, df_plot.prediction], \n",
    "             style=['dark orange', 'green'], xlabel='Vehicla ID', ylabel='Time in test cycle',  grid_color='black',\n",
    "                   grid_linewidth=0.5, grid_linestyle=\"-\", legend=['Actual Value','Predicted Value'],figure=figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3e60a3-8c33-499f-813c-32dabe62ffc6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The RegressionEvaluator() function computes metrics to evaluate and compare multiple models and summarizes how close predictions are to their expected values.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166805b0-9b75-4907-bd86-d4692201ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    " RegressionEvaluator_out = RegressionEvaluator(data = decision_forest_predict_out.result,\n",
    "                                                  observation_column = \"y\",\n",
    "                                                  prediction_column = \"prediction\",\n",
    "                                                  freedom_degrees = [5, 28],\n",
    "                                                  independent_features_num = 15,\n",
    "                                                  metrics = ['MAE','MSE','RMSE','R2','FSTAT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66359627-ab9a-4dbd-a501-2318db4daab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_eval = RegressionEvaluator_out.result\n",
    "DF_eval = DF_eval.assign(model='Decision Forest')\n",
    "DF_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccbeeba-dc33-4106-a5f9-4ea6fe4fef3c",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>9. XGBoost </b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The XGBoost function, also known as eXtreme Gradient Boosting, is an implementation of the gradient boosted decision tree designed for speed and performance. It has recently been dominating applied machine learning.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In gradient boosting, each iteration fits a model to the residuals (errors) of the previous iteration to correct the errors made by existing models. The predicted residual is multiplied by this learning rate and then added to the previous prediction. Models are added sequentially until no further improvements can be made. It is called gradient boosting because it uses a gradient descent algorithm to minimize the loss when adding new models.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Gradient boosting involves three elements:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial'>A loss function to be optimized.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>A weak learner to make predictions.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>An additive model to add weak learners to minimize the loss function.</li></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The loss function used depends on the type of problem being solved. For example, regression may use a squared error and binary classification may use binomial. A benefit of the gradient boosting is that a new boosting algorithm does not have to be derived for each loss function. Instead, it provides a generic enough framework that any differentiable loss function can be used. The XGBoost function supports both regression and classification predictive modelling problems. The model that it creates is used in the XGBoostPredict function for making predictions. </p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ef03f-f299-45f4-975c-2d485280117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost_out = XGBoost(data=train_new_df,\n",
    "                            input_columns=['ID','X0','X1','X2','X3','X4','X5','X6','X8','X47','X314','X118',\n",
    "                                           'X315','X127','X29','X115','X351','X151'],\n",
    "                            response_column = 'y',\n",
    "                            max_depth=2,\n",
    "                            lambda1 = 1000.0,\n",
    "                            model_type='Regression',\n",
    "                            seed=1,\n",
    "                            shrinkage_factor=0.95,\n",
    "                            iter_num=24,\n",
    "                            min_node_size=1,\n",
    "                            num_boosted_trees=6,\n",
    "                            column_sampling=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed05487-d2f5-428e-8c15-48824ecf8e8f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>XGBoostPredict performs prediction for test input data using multiple simple trees in the trained model. The test input data should have the same attributes as used during the training phase, which can be up to 2048. These attributes are used to score based on the trees in the model.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The output contains prediction for each data point in the test data based on regression or classification. The prediction probability is computed based on the majority vote from participating trees. A higher probability implies a more confident prediction by the model. Majority of the trees result in the same prediction.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1cd213-1387-4246-98bd-8f55f7658533",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoostPredict_out = XGBoostPredict(newdata=test_new_df,\n",
    "                                          object=XGBoost_out.result,\n",
    "                                          id_column='ID',\n",
    "                                          model_type = 'regression',\n",
    "                                          object_order_column=['task_index', 'tree_num',\n",
    "                                                               'iter', 'tree_order'],\n",
    "                                          accumulate = 'y')\n",
    "xgb_result = XGBoostPredict_out.result\n",
    "xgb_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4824da-f934-4aa3-8594-b3b65cd6d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgb_plot = XGBoostPredict_out.result.head(50)\n",
    "from teradataml import Figure\n",
    "figure = Figure(width=1000, height=700, heading=\"Actual vs Predicted using XGBoost Classifier\")\n",
    "df_xgb_plot.plot(x=df_xgb_plot.ID, y=[df_xgb_plot.y, df_xgb_plot.Prediction], \n",
    "             style=['dark orange', 'green'], xlabel='Vehicla ID', ylabel='Time in test cycle',  grid_color='black',\n",
    "                   grid_linewidth=0.5, grid_linestyle=\"-\", legend=['Actual Value','Predicted Value'],figure=figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7111094-83b6-4ec7-8e72-5f9c6164b978",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The RegressionEvaluator function computes metrics to evaluate and compare multiple models and summarizes how close predictions are to their expected values.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'><b><i>Note:</b> Since we have sample data here the predicted values do not seem to be very near to the actual values. In scenarios with real data the parameters can be tweaked to get better predicted values.</i></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87920e8-7edf-4e0e-899c-b2ee47b47dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    " RegressionEvaluator_out = RegressionEvaluator(data = xgb_result,\n",
    "                                                  observation_column = \"y\",\n",
    "                                                  prediction_column = \"Prediction\",\n",
    "                                                  freedom_degrees = [5, 28],\n",
    "                                                  independent_features_num = 15,\n",
    "                                                  metrics = ['MAE','MSE','RMSE','R2','FSTAT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5640ac51-47a4-47ae-8546-bcb4b0bb9874",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_Eval = RegressionEvaluator_out.result\n",
    "XGB_Eval = XGB_Eval.assign(model='XGBoost')\n",
    "XGB_Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8c2531-e3cd-46a5-9769-be64a2fd24d7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The Metrics of the regression evaluator has the RMSE, R2 and the F-STAT metrics which are specified in the Metrics.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Thus, here we have used 2 different models to train and predict the data. The Regression evaluator is used to evaluate and compare the models. The Teradata In-Database functions are used for training, prediction and evaluation. In this case since we have sample data the result parameters may not be accurate for these models.</p>  \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Root mean squared error (RMSE)The most common metric for evaluating linear regression model performance is called root mean squared error, or RMSE. The basic idea is to measure how bad/erroneous the model’s predictions are when compared to actual observed values. So, a high RMSE is “bad” and a low RMSE is “good”.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The coefficient of determination — more commonly known as R² — allows us to measure the strength of the relationship between the response and predictor variables in the model. It’s just the square of the correlation coefficient R, so its values are in the range 0.0–1.0. Higher values of R- Squared is Good.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The metrics specified in the Metrics syntax element are displayed. For FSTAT, the following columns are displayed:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial'>F_score</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>F_Critcialvalue</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>p_value</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>F_Conclusion.</li></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here we can see the comparison for MAE,MSE,RMSE and R2 for XGBoost and DecisionForest.</p> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d88e33-68af-4d11-a780-50aeea0e93b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_df_eval = DF_eval.concat(XGB_Eval)\n",
    "transposed_df_eval.select(['model','MAE','MSE','RMSE','R2','F_SCORE','F_CRITICALVALUE','P_VALUE','F_CONCLUSION'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0895aba-2e9b-400f-8810-46ac016d64fe",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>Conclusion</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>This, with ClearScape Analytics, we can scale AI/ML quicker and more effectively to solve your most complex challenges, reduce cost and friction, and accelerate time to value throughout your organization. Teradata can help manufacturing clients achieve success by helping them to grow revenues, optimise asset uptime, boost product quality and improve efficiency in the face of growing global disruption and competition. The InDB Analytic functions of Vantage help improve speed, performance, and time-to value by minimizing data movement by handling data where it lies for reduced costs and heightened security.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c151e525-82e7-466b-b9f2-7773119fe38d",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>10. Cleanup</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Work Tables</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7416a835-394d-4ed2-bc3a-48f060e74cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['final_data','final_train_data','final_test_data']\n",
    "\n",
    "# Loop through the list of tables and execute the drop table command for each table\n",
    "for table in tables:\n",
    "    try:\n",
    "        db_drop_table(table_name = table)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace406bb-4354-4611-8204-cff8275c911f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>Databases and Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74588dc-5691-4e0e-a545-5389f776e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_GreenManufacturing');\" \n",
    "#Takes 40 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42baee5d-de56-43ec-a6f0-3fdbac49de52",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877b09f8-2ffb-4f55-8316-d6b2370d38f0",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>Resources:</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Let’s look at the elements we have available for reference for this notebook:</p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Filters:</b></p>\n",
    "<li style = 'font-size:16px;font-family:Arial'><b>Industry:</b> Manufacturing </li>\n",
    "<li style = 'font-size:16px;font-family:Arial'><b>Functionality:</b> Machine Learning</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'><b>Use Case:</b> Green Manufacturing</li></p>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Related Resources:</b></p>\n",
    "<li style = 'font-size:16px;font-family:Arial'><a href='https://www.teradata.com/Blogs/Hyper-scale-time-series-forecasting-done-right'>Hyper-scale time series forecasting done right</a></li>\n",
    "<li style = 'font-size:16px;font-family:Arial'><a href='https://www.teradata.com/resources/customer-videos/volvo-cars-uses-the-internet-of-things-to-enhance-customer-driving-experiences'>Use the Internet of Things to enhance their customer’s driving experience</a></li>\n",
    "<li style = 'font-size:16px;font-family:Arial'><a href='https://www.teradata.com/Industries/Manufacturing' >Achieve industry 4.0 using advanced manufacturing analytics at scale</a></li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b404312-6af8-4d9a-b238-42636c0fe5f0",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; border-bottom:3px solid #91A0Ab\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2023, 2024. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
