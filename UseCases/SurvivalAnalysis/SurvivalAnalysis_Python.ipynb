{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<header style=\"padding:1px;background:#f9f9f9;border-top:3px solid #00b2b1\"><img id=\"Teradata-logo\" src=\"https://www.teradata.com/Teradata/Images/Rebrand/Teradata_logo-two_color.png\" alt=\"Teradata\" width=\"220\" align=\"right\" />\n",
    "\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>Survival Analysis using teradataml</b>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Introduction:</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Machine learning can be useful in heart failure prediction because it can analyze large amounts of data from multiple sources and identify complex patterns that may be difficult for humans to recognize. This can potentially improve the accuracy of prediction models and help healthcare professionals identify patients who are at high risk for heart failure, allowing for earlier intervention and better outcomes.</p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Data:</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>This is a simulated dataset based on real hospital administrative data, which contains a random sample of emergency (unplanned) admissions for heart failure. The original records were linked to the national death registry in order to capture deaths that occur after discharge.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Downloading and installing additional software needed</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade teradataml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "    <i><b>*BEFORE proceeding, please RESTART the kernel to bring new software into Jupyter.</b></i>\n",
    "</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system packages\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from teradataml import *\n",
    "from teradataml import valib\n",
    "\n",
    "# Dataset packages \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "\n",
    "# plotting packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "%matplotlib inline\n",
    "configure.val_install_location = \"val\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>1. Initiate a connection to Vantage</b>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'> <b>Let's start by connecting to the Teradata system </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>You will be prompted to provide the password. Enter your password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)\n",
    "eng.execute('''SET query_band='DEMO=SurvivalAnalysis_Python.ipynb;' UPDATE FOR SESSION;''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have provided data for this demo on cloud storage. You can either run the demo using foreign tables to access the data without any storage on your environment or download the data to local storage, which may yield faster execution. Still, there could be considerations of available storage. Two statements are in the following cell, and one is commented out. You may switch which mode you choose by changing the comment string.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call get_data('DEMO_SurvivalAnalysis_cloud');\"        # Takes 10 seconds\n",
    "# %run -i ../run_procedure.py \"call get_data('DEMO_SurvivalAnalysis_local');\"        # Takes 20 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Next is an optional step – if you want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\"        # Takes 5 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>2. Read the data from Vantage as a teradataml Dataframe</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_failure = DataFrame(in_schema('DEMO_SurvivalAnalysis', 'heart_failure'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(heart_failure.shape)\n",
    "heart_failure.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The dataset above has 31 columns in total and the 'death' column is the predicted column where 1 means the patient died and 0 means he/she did not.\n",
    "<br>\n",
    "Let's check if the dataset is balanced w.r.t gender.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_gen = heart_failure.select(['gender','death']).groupby(['gender']).agg(['mean', 'count']).to_pandas()\n",
    "sns.barplot(x='gender', y='mean_death', data=grp_gen)\n",
    "plt.title('Mortality rate by gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above graph shows us that the number of deaths are equally distributed amoung the gender.</p>\n",
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>2. Data Prepration</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Feature scaling is performed during data pre-processing to handle highly varying magnitudes, values, or units. If feature scaling is not done, then a machine learning algorithm tends to weigh greater values higher and consider smaller values as lower ones, regardless of the unit of the values.\n",
    "<br>\n",
    "<br>\n",
    "By scaling the data, we can ensure that all the features have a similar scale, so the distance metric can properly consider both features. This can help the machine learning algorithm converge faster and produce more accurate predictions.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import ScaleFit, ScaleTransform\n",
    "\n",
    "sf_fit = ScaleFit(data = heart_failure, scale_method = 'STD', target_columns = ['2:30'])\n",
    "sf_trns = ScaleTransform(data = heart_failure, object = sf_fit.output, accumulate = ['\"id\"','death'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Splitting the data in training and testing datasets in 70:30 ratio.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_samples = sf_trns.result.sample(frac = [0.3, 0.7], randomize = True)\n",
    "copy_to_sql(tdf_samples[tdf_samples['sampleid'] == 2], table_name = 'heart_failure_train', schema_name = 'demo_user', if_exists = 'replace')\n",
    "copy_to_sql(tdf_samples[tdf_samples['sampleid'] == 1], table_name = 'heart_failure_test', schema_name = 'demo_user', if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_failure_train = DataFrame('heart_failure_train')\n",
    "heart_failure_test = DataFrame('heart_failure_test')\n",
    "print(\"Training Set = \"+str(heart_failure_train.shape[0])+\". Testing Set = \"+str(heart_failure_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>3. Model Training</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The function is an ensemble algorithm used for classification and regression predictive modeling problems. It is an extension of bootstrap aggregation (bagging) of decision trees. Typically, constructing a decision tree involves evaluating the value for each input feature in the data to select a split point.\n",
    "<br>\n",
    "<br>\n",
    "The function reduces the features to a random subset (that can be considered at each split point); the algorithm can force each decision tree in the forest to be very different to improve prediction accuracy.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from teradataml import DecisionForest\n",
    "\n",
    "DecisionForest_out = DecisionForest(data = heart_failure_train,\n",
    "                            input_columns = ['2:30'],\n",
    "                            response_column = 'death',\n",
    "                            max_depth = 5,\n",
    "                            num_trees = 20,\n",
    "                            min_node_size = 2,\n",
    "                            seed = 2,\n",
    "                            tree_type = 'CLASSIFICATION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>4. Model Testing</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>DecisionForestPredict outputs the probability that each observation is in the predicted class.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from teradataml import DecisionForestPredict\n",
    "\n",
    "decision_forest_predict_out = DecisionForestPredict(\n",
    "                                                        object = DecisionForest_out,\n",
    "                                                        newdata = heart_failure_test,\n",
    "                                                        id_column = \"id\",\n",
    "                                                        detailed = False,\n",
    "                                                        output_response_probdist = True,\n",
    "                                                        output_prob = True,\n",
    "                                                        output_responses =  ['0', '1'],\n",
    "                                                        terms = 'death'\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred=decision_forest_predict_out.result.to_pandas()\n",
    "rf_pred['prediction'] = rf_pred['prediction'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In the above result, the column <b>death</b> is ground truth, <b>prediction</b> is the predicted output and <b>(prob_0, prob_1)</b> are probabilities of the output class.\n",
    "<br>\n",
    "<br>\n",
    "The accuracy of the model is as follows:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", round((rf_pred['prediction'] == rf_pred['death']).mean() * 100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The ROC curve is a graph between TPR(True Positive Rate) and FPR(False Positive Rate). The area under the ROC curve is a metric of how well the model can distinguish between positive and negative classes. The higher the AUC, the better the model's performance in distinguishing between the positive and negative categories. AUC above 0.75 is generally considered decent.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pos_rate, true_pos_rate, _ = roc_curve(rf_pred.death, rf_pred['prob_1'].astype('float'))\n",
    "auc = roc_auc_score(rf_pred.death, rf_pred['prob_1'].astype('float'))\n",
    "plt.plot(false_pos_rate, true_pos_rate, label = 'DecisionForest'+\": auc=\"+str(round(auc,3)))\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Looking at the above ROC Curve, we can say that the model has performed decently well on testing data.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>9. Cleanup</b>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Cleanup work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.execute('DROP TABLE heart_failure_train;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.execute('DROP TABLE heart_failure_test;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_SurvivalAnalysis');\"        # Takes 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>Dataset:</b>\n",
    "\n",
    "- `id`: patient id\n",
    "- `death`: If the patient is deceased(boolean)\n",
    "- `los`: length of stay (in days)\n",
    "- `age`: age of the patient (in years)\n",
    "- `gender`: gender of the patient (1-female, 2-male)\n",
    "- `cancer`: If the patient has cancer (boolean)\n",
    "- `cabg`: If the patient has gone through Coronary Artery Bypass Graft procedure (boolean)\n",
    "- `crt`: If the patient has gone through Cardiac Resynchronization Therapy (boolean)\n",
    "- `defib`: If the patient has defibrillator (boolean)\n",
    "- `dementia`: If the patient has dementia (boolean)\n",
    "- `diabetes`: If the patient has diabetes (boolean)\n",
    "- `hypertension`: If the patient has hypertension (boolean)\n",
    "- `ihd`: If the patient has Ischemic Heart Disease (boolean)\n",
    "- `mental_health`: If the patient has been diagnosed with mental health issues (boolean)\n",
    "- `arrhythmias`: If the patient has arrhythmia (boolean)\n",
    "- `copd`: If the patient has Chronic Obstructive Pulmonary Disease (boolean)\n",
    "- `obesity`: If the patient has obesity (boolean)\n",
    "- `pvd`: If the patient has Peripheral Vascular Disease (boolean)\n",
    "- `renal_disease`: If the patient has Renal Disease (boolean)\n",
    "- `valvular_disease`: If the patient has Valvular Disease (boolean)\n",
    "- `metastatic_cancer`: If the patient has Metastatic Cancer (boolean)\n",
    "- `pacemaker`: If the patient has pacemaker (boolean)\n",
    "- `pneumonia`: If the patient has pneumonia (boolean)\n",
    "- `prior_appts_attended`: Number of prior appointments attended by the patient\n",
    "- `prior_dnas`: If the patient has takes Prior DNA test (boolean)\n",
    "- `pci`: If the patient has gone though Percutaneous Coronary Intervention procedure (boolean)\n",
    "- `senile`: If the patient has Senile amyloidosis (SSA) (boolean)\n",
    "- `fu_time`: Time since last follow-up (in days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<footer style=\"padding:10px;background:#f9f9f9;border-bottom:3px solid #394851\">Copyright © Teradata Corporation - 2023. All Rights Reserved.</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
