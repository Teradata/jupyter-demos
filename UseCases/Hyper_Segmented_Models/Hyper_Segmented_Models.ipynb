{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5b76617-7b0f-4978-a997-fe835d0f708e",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial;color:#F0F0F0; background- padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Streamlining Analytics with Hyper-Segmented Models in Teradata Vantage\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cb730a-b0de-4b7a-8450-5e50020296cf",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>Introduction</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Hyper-segmented models are advanced analytical frameworks that divide data into extremely detailed and specific segments, enabling highly customized insights and predictions. The need for hyper-segmented models arises from the growing demand for personalization and precision in decision-making across industries, particularly in customer-centric sectors like retail, finance, and healthcare. Hyper-segmentation allows businesses to extract more granular insights, enabling tailored marketing, personalized product recommendations, and optimized resource allocation. By addressing unique customer behaviors and preferences within specific micro-segments, companies can enhance customer satisfaction, boost operational efficiency, and improve profitability. The ability to deploy and manage hyper-segmented models at scale has become essential for staying competitive in fast-evolving markets.</p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Why Vantage?</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Teradata's Vantage platform offers a streamlined solution by integrating hyper-segmented model management with its parallel processing capabilities. Traditional features like group-by aggregation lay the groundwork for this approach which is further enhanced by advanced SQL functions, unbounded array frameworks (UAF) and Python integration. These capabilities enable businesses to train hundreds of models in parallel with a single Python command, simplifying processes that previously required specialized skills, manual data handling, and extensive coding.<br>\n",
    "In practical terms, this solution allows organizations to deploy and score multiple models across segmented data sets efficiently. By leveraging Teradata’s script table operator (STO) and external Python libraries, users can handle large-scale model training and scoring, while the interface ensures traceability, security, and flexibility in adjusting hyperparameters without redeployment. Furthermore, data scientists benefit from streamlined workflows, enabling faster iteration and enhanced control over model versioning, lineage, and parameter tracking.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>This is a functional demo where we will see how easy it is to <b>deploy and run Python Scikit-Learn Pipeline in Vantage</b>. The dataset used is a generated sample dataset.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f4d84-5411-4bb9-981b-d364b4eef484",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>1. Connect to Vantage.</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23dece8-78b1-4e53-a4ea-9bc7763566bd",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In the section, we import the required libraries and set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad85453-e4fd-4024-ba5d-6a56f7c40706",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade tdstone2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630a8ae6-e935-40b4-8f50-8c2d42e00cab",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Note: </b><i>The above statements may need to be uncommented if you run the notebooks on a platform other than ClearScape Analytics Experience that does not have the libraries installed. If you uncomment those installs, be sure to restart the kernel after executing those lines to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b5fc5e-b009-46db-a123-71d803f37823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from teradataml import *\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from tdstone2.tdshypermodel import HyperModel\n",
    "from tdstone2.tdstone import TDStone\n",
    "from tdstone2.utils import cleanup\n",
    "from tdstone2.tdstone import TDStone\n",
    "\n",
    "configure.byom_install_location = \"mldb\"\n",
    "\n",
    "display.max_rows = 5\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d0f3d7-3ada-4cc5-bc92-9eb6b1f23687",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell. Begin running steps with Shift + Enter keys.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a51710a-28e8-484a-b7f7-9a631ebe53dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8661ba2e-1ecb-4811-adbb-6904aa2e41a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=Hypersegmented_Model.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8761736e-411c-4bb4-9cbb-253fb4500cf3",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>2. Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have provided data for this demo on cloud storage. We have the option of either running the demo using foreign tables to access the data without using any storage on our environment or downloading the data to local storage, which may yield somewhat faster execution. However, we need to consider available storage. There are two statements in the following cell, and one is commented out. We may switch which mode we choose by changing the comment string.</p>   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8fbd58-90d5-46de-b6c8-2ce533f45335",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call get_data('DEMO_HyperModel_cloud');\"\n",
    " # Takes about 20 seconds\n",
    "#%run -i ../run_procedure.py \"call get_data('DEMO_HyperModel_local');\"\n",
    " # Takes about 50 secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897f7be9-c74d-46be-bfd5-0c09d45738db",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Optional step – We should execute the below step only if we want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9056da07-749a-4700-a501-7030fc64c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b867b2b8-8c99-4083-bc18-0ff6617f87ef",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>3. Setup the Framework</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "External Python scripts (.py files) can run within Vantage using the Script Table Operator (STO). There are few steps involved in setting up the Vantage to run the python script in-Db. The Python package tdstone2 streamlines and simplifies the execution process, enhancing efficiency and ease of use. In the below steps we will configure and prepare our TDStone instance. Cleanup is a precautionary step to clean up any existing objects in the specified schema to ensure a fresh environment. Then we will create our instance and call setup method. The last step is to cross check if the setup is working fine.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa0fc0b-13dd-4099-9c86-cc5f966cb3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup(schema='demo_user')            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e265e-0e6b-48d2-a7b2-17d2d589fddc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In the below code we will create a TDSTONE instance in schema specified and the location of the database search path for the SCRIPT execution that will be used in Vantage.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2351c91-ef96-4b3c-8159-16d13ed416a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sto = TDStone(schema_name = 'demo_user', SEARCHUIFDBPATH = 'demo_user')\n",
    "sto.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ab8e28-483a-4ae2-b566-1f544bf8bf38",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>This is an optional step to check if the paths are setup correctly by calling the PushFile method with no file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32430b43-c2a3-4a7f-ba8e-0157d32a3662",
   "metadata": {},
   "outputs": [],
   "source": [
    "sto.PushFile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61429d15-5e93-4750-88be-295d054640c7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Now we are ready to work with this framework, let us now create our Pipeline which we will deploy.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f655642",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>4. The Hyper-Segmented Dataset</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Let us take a look at the sample dataset we are using.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb52a782-fa57-4afa-97cb-4d0d3941fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataFrame(in_schema('DEMO_HyperModel', 'Dataset'))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6307b8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Let us group the dataset by the 'Partition_ID' column and counts the number of rows in each partition. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2a2d8c-2839-4be5-a841-4f093afedabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = dataset.groupby('Partition_ID').count()\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d0147e-af56-4400-8814-70c68efd8f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe5de8b-a4a1-4106-bd2a-6048ba273360",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>As we can see from above we have data in 4 partitions each with 1000 records.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896ca2c5-cef1-4d89-b321-7e29a28bb05b",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>5. Hyper-segmented model deployment</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17a2135-b2a6-4d67-af95-c30b59ecc45f",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.1 Engineering of the scikit-learn classifier pipeline</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a570e5fd",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'> For our sklearn pipeline we will use \n",
    " `StandardScaler` for feature scaling and a `OneClassSVM` for anomaly detection.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7552d2-cb2f-4538-b76e-398167697298",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_anomaly_detection = [\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('one_class_svm', OneClassSVM(\n",
    "        kernel='rbf',  # Radial Basis Function Kernel\n",
    "        nu=0.05,       # An upper bound on the fraction of training errors and a lower bound of the fraction of support vectors.\n",
    "        gamma='auto'   # Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’. If ‘auto’, 1/n_features will be used.\n",
    "    ))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474f18d8-08da-46c4-af28-19421d9bc750",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.2 Deployment of the scikit-learn pipeline</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6a3494",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "We define a dictionary named <b>model_parameters</b> that specifies the categorical columns and the feature columns to be used in the model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b196b3-3dde-4940-a4f8-af713e9c8fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = {\n",
    "    \"column_categorical\": ['Flag'],\n",
    "    \"column_names_X\": ['X1','X2','X3','X4','X5','X6','X7','X8','X9','Flag']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e433e77a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "    Below code creates an instance of <b>HyperModel</b> with various parameters including the TDStone\n",
    "    instance, metadata, the pipeline, model parameters, the dataset, and identifiers for rows, partitions, and folds. It also specifies that the model should be converted to ONNX format.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c347041-150f-43b8-834b-dfe0af6e7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = HyperModel(tdstone            = sto,\n",
    "                   metadata           = {'project': 'test'},\n",
    "                   skl_pipeline_steps = steps_anomaly_detection,\n",
    "                   model_parameters   = model_parameters,\n",
    "                   dataset            = in_schema('DEMO_HyperModel', 'Dataset'),\n",
    "                   id_row             = 'ID',\n",
    "                   id_partition       = 'Partition_ID',\n",
    "                   id_fold            = 'FOLD',\n",
    "                   fold_training      = 'train',\n",
    "                   convert_to_onnx    = True\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb2d458",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Let us list all the hyper models available in the TDStone instance.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d474e7-7b9b-4792-9af4-fb071803cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sto.list_hyper_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15653f32",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Below code cell retrieves the ID of the most recently created hyper model by sorting the list of hyper models by creation date in descending order.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f824de-bd86-403f-bd77-878a1c491dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = sto.list_hyper_models()[['ID','CREATION_DATE']].to_pandas().reset_index().sort_values('CREATION_DATE', ascending=False).iloc[0,0]\n",
    "id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cebf62",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Let us download the model using the ID retrieved in the previous cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a113e21-4d5f-407e-b3b0-bc4deaaf235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_model = HyperModel(tdstone=sto)\n",
    "existing_model.download(id=id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b66cdc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Below code retrieves the code and data associated with the downloaded model, including the data itself, and measures the time taken for this operation.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeec72b-a539-4ae0-92ca-39f6f406d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "code_and_data = existing_model.retrieve_code_and_data(with_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938af789-0619-424e-af32-51199c65d0bb",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.3 Local Execution for validation/debugging</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026234eb",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "We have downloaded the model in the above step, here we will execute tThis code cell executes the downloaded model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4f39bb-95a3-4f34-8c26-7a743f136e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(code_and_data['code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cec2f1a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Below code cell creates an instance of MyModel using the arguments retrieved from the downloaded model's code and data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e575942-a751-4144-95af-8dfc8241e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = MyModel(**code_and_data['arguments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50f8835",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'> Convert the 'Flag' column in the local data to a categorical type.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf4c520-5235-4be5-bc19-3df12964c2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_local = code_and_data['data']\n",
    "df_local['Flag'] = df_local['Flag'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d59f98b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Let us train the downloaded model and measure the time taken for this operation.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9609cb8d-8a19-4584-9064-db48010d9df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "local_model.fit(code_and_data['data'][code_and_data['data']['FOLD'] == 'train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d3c7fd",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Below code cell scores the local model using the entire dataset and measures the time taken for this operation.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ec69ec-dce9-466f-ac27-66ead4c34073",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "local_model.score(code_and_data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162d72ee-a52c-4bc5-b6cb-242465f0bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model.get_description()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf5924f-5002-4394-b44d-3c941a70df9e",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>6. Execution of the deployed HyperModel</b></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ceb441-eee6-4652-a1a2-50663fd26d8f",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>6.1 Models Training</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c75b43",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Below code trains the hyper model and measures the time taken for this operation.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086fe28e-fdc6-44fa-ba26-82ada8c97b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69adea5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Below code retrieves the trained models from the model object, groups them by TD_TIMECODE and MODEL_TYPE, counts the number of models in each group, and sorts the results in descending order based on TD_TIMECODE and MODEL_TYPE.\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f49f1e6-ca1a-4896-bcd5-46193888ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_trained_models().groupby(['TD_TIMECODE','MODEL_TYPE']).count().sort(['TD_TIMECODE','MODEL_TYPE'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52136232-6ab6-41c6-9e9a-87a705dad3f7",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>6.2 Model Scoring</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b2901b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Let us score the model and measure the time taken. </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f201c42c-e052-40b0-9703-402172e8b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a5ecb1",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Below retrieves the model predictions from the model object, groups them by TD_TIMECODE, and counts the number of predictions in each group.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f849efd8-5890-4636-bfcd-d3903999d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_model_predictions().groupby('TD_TIMECODE').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5636e4c9-bb03-41be-b3b8-4d45dba39464",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_model_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cebdc4-e239-4efb-a845-5fceeb8a866d",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>7. Model Lineage</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a09da4-0ced-4fbb-a36b-195b80f12fc5",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>7.1 Access to the list of deployed codes</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7da86a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Below code lists all the codes available in the sto object.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b612f08e-abea-4dc0-bb28-9db6bffd07ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sto.list_codes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a419b40b-96f3-4581-b4ee-2181bc5ccc18",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>7.2 List of deployed models (code + parameters)</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2906df2d",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Below code lists all the models available in the sto object.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01db108-8688-4ef9-a602-084a38923775",
   "metadata": {},
   "outputs": [],
   "source": [
    "sto.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20649235-85ea-43e3-8ce8-76b6420b1a04",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>7.3 List of available mappers (mapping between partitions and models or trained models)</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c706b9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Below code lists all the mappers available in the sto object.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea5a615-5bbc-4ed2-81c9-f7cc3e96f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "sto.list_mappers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996957a6-d287-4ef2-8e70-8f8375ccb430",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>7.4 List of Hypermodels ( models and mappers mapping)</b></p>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c32f6b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Below code lists all the hyper models available in the sto object.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d55a58-04ce-4202-9762-e8a388140473",
   "metadata": {},
   "outputs": [],
   "source": [
    "sto.list_hyper_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79b848f-337d-4ad3-a550-25b849883797",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>8. Use BYOM with ONNX models</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c0d1ea",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Below code retrieves the BYOM (Bring Your Own Model) catalog from the model object and stores it in the onnx_catalog variable. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7e5045-f1d4-45e4-99aa-39929fadda7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_catalog = model.get_byom_catalog()\n",
    "onnx_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33664221-33e6-4e57-a32d-13aa21a5ec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_catalog_local = onnx_catalog[['model_id','Partition_ID']].to_pandas(num_rows=1)\n",
    "onnx_catalog_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057c744f-bdb3-4896-9005-e269bd93c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "Partition_ID     = onnx_catalog_local.Partition_ID.values[0]\n",
    "model_id         = onnx_catalog_local.model_id.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ac2040",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Let us create an instance of ONNXPredict to generate predictions using the ONNX model. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b5ed89-1d1b-4689-b4a5-2b620498c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_ = ONNXPredict(\n",
    "    modeldata               = onnx_catalog[onnx_catalog.Partition_ID == Partition_ID],\n",
    "    newdata                 = dataset[dataset.Partition_ID == Partition_ID],\n",
    "    accumulate              = ['Partition_ID', 'ID'],\n",
    "    overwrite_cached_models = '*',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484daef9-af18-4985-988a-631e16fb7e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b744f15-83a7-4c43-9856-8109936ba470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's extract the scores field of the json\n",
    "query = f\"\"\"\n",
    "SELECT Partition_ID, ID, CAST(\"json_report\" as JSON).scores[0][0] as score \n",
    "from {predictions_.result._table_name}\n",
    "\"\"\"\n",
    "print(query)\n",
    "DataFrame.from_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1c2ec5-d72c-4d9f-b5c7-53962382eb9f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>Conclusion</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this demo we have seen the integration of Teradata's machine learning capabilities with `scikit-learn` , the use of ONNX for model deployment, and the comprehensive management of models and predictions within the Teradata environment. This approach leverages both Teradata's database strengths and the flexibility of Python's machine learning libraries.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c64925d-325f-40b3-8821-bd4c85a5bc99",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>9. Cleanup</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3df7ec-2e96-4ba7-8fe5-d8efa50664e9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>Work Tables/Views</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We need to clean up our work tables/views to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9aa0af-b914-41e0-a35b-0f5e3b99a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the list of views and execute the drop view command for each view\n",
    "for view in db_list_tables(object_name='%TDS%', object_type='view')['TableName'].tolist():\n",
    "    try:\n",
    "        db_drop_view(view_name=view, schema_name=\"demo_user\")\n",
    "        #print(view)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb18e0be-6547-4151-a8c8-b8c22ff039df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the list of tables and execute the drop table command for each table\n",
    "for table in db_list_tables(object_name='%TDS%', object_type='table')['TableName'].tolist():\n",
    "    try:\n",
    "        db_drop_table(table_name=table, schema_name=\"demo_user\")\n",
    "        #print(table)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0130cb-f4f0-4b90-bf05-d4f02f109fce",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'><b>Databases and Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffac04c6-2f00-4e02-a3ba-20b78f7d89c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_HyperModel');\" \n",
    "#Takes 40 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6839038-d4e8-444c-bd9f-e669122b6629",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acdd2ec-9964-48dc-bbd6-621b66386156",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#91A0AB; \">\n",
    "<div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "<div style=\"float:right;\">\n",
    "<div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2024. All Rights Reserved\n",
    "</div>\n",
    "</div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
