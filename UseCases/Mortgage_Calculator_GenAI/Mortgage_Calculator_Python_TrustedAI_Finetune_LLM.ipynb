{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38bc532d-c78c-4c89-b191-242da0733f39",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Mortgage Calculator chatbot using Generative AI with Vantage: Trusted AI (Finetune LLM)\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff71661-19b4-423a-867a-7c815b064c81",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Introduction</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the Mortgage Calculator chatbot using Generative AI demo, the combination of <b>RAG, Langchain, and LLM models</b> allows users to ask queries in layman's terms, retrieve relevant information from the Vantage tables, and generate accurate and concise answers based on the retrieved data. This integration of retrieval-based and generative-based approaches provides a powerful tool for extracting knowledge from structured sources and delivering user-friendly responses.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In this demo we will build conversational chatbot using <b>Fine-tuned OpenAI model</b> as LLM and LangChain framework, a powerful library for working with LLMs like GPT-3.5, GPT-4, Llamma-3, Mistral 7B, Mixtral 8x22B, etc. and JumpStart in ClearScape notebooks, a system is built where users can ask business questions in natural English and receive answers with data drawn from the relevant databases.</p>\n",
    "\n",
    "\n",
    "<center><img src=\"images/header.png\" alt=\"mortgage calc\"  width=800 height=800/></center>\n",
    "\n",
    "<br>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Before going any farther, let's get a better understanding of RAG, LangChain, and LLM.</p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'><li> <b>Retrieval-Augmented Generation (RAG):</b></li></ul>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> &emsp;  &emsp;RAG is a framework that combines the strengths of retrieval-based and generative-based approaches in question-answering systems.It utilizes both a retrieval model and a generative model to generate high-quality answers to user queries. The retrieval model is responsible for retrieving relevant information from a knowledge source, such as a database or documents. The generative model then takes the retrieved information as input and generates concise and accurate answers in natural language.</p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'><li> <b>Langchain:</b></li></ul>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> &emsp;  &emsp; LangChain is a framework that facilitates the integration and chaining of large language models with other tools and sources to build more sophisticated AI applications. LangChain does not serve its own LLMs; instead, it provides a standard way of communicating with a variety of LLMs, including those from OpenAI and HuggingFace. LangChain accelerates the development of AI applications with building blocks. We learn to leverage the following building blocks in this notebook:</p>\n",
    " \n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li> <b> LLMs</b> – LangChain's <code>llm</code> class is designed to provide a standard interface for all LLM it supports.   </li>\n",
    "    <li> <b> PromptTemplate</b>  - LangChain’s <code>PromptTemplate</code> class are predefined structures for generating prompts for LLM’s. They can be reused across different LLM's.</li>\n",
    "    <li> <b> Chains</b> – When we build complex AI applications, we may need to combine multiple calls to LLM’s and to other components  LangChain’s <code>chain</code> class allows us to link calls to LLM’s and components. The most common type of chaining in any LLM application is combining a prompt template with an LLM and optionally an output parser. </li>\n",
    "</ol>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'><li> <b> LLM Models (Large Language Models):</b></li></ul>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> &emsp;  &emsp; LLM models refer to the large-scale language models that are trained on vast amounts of text data.\n",
    "These models, such as <code>GPT-3.5 (Generative Pre-trained Transformer)</code>, <code>GPT-4</code> , <code>LLaMA 2</code> ,<code> Google's Gemini 1.5 pro</code> , <code>Anthropic Claude 3.0</code> , <code>Mistral 7B</code> ,<code>Mixtral 8x22B.</code> etc. are capable of generating human-like text responses. LLM models have been pre-trained on diverse sources of text data, enabling them to learn patterns, grammar, and context from a wide range of topics. They can be fine-tuned for specific tasks, such as question-answering, natural language understanding, and text generation.\n",
    "LLM models have achieved impressive results in various natural language processing tasks and are widely used in AI applications for generating human-like text responses.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbecee9-3896-4fb8-ae29-1a5570d0520e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>What is trusted AI?</b></p>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;color:#00233C'><strong>Trusted AI</strong> in the context of generative AI refers to the development and deployment of AI systems that prioritize ethical considerations, fairness, transparency, privacy, and security. Generative AI, which includes models like GPT (Generative Pre-trained Transformer), produces human-like text, images, or other data based on patterns learned from large datasets.</p>\n",
    "\n",
    "<ul style='font-size:16px;font-family:Arial;color:#00233C'>\n",
    "  <li><strong>Ethical Considerations:</strong> Trusted generative AI operates within ethical boundaries, ensuring that the generated content aligns with societal norms and values. It avoids promoting harmful or offensive content.</li>\n",
    "  <li><strong>Fairness:</strong> The AI model should produce outputs that are fair and unbiased across different demographic groups. It should not propagate stereotypes or discrimination.</li>\n",
    "  <li><strong>Transparency:</strong> The inner workings of the generative AI model should be transparent and understandable to stakeholders, including developers, users, and regulatory authorities. Transparency helps build trust and facilitates accountability.</li>\n",
    "  <li><strong>Privacy:</strong> Trusted generative AI respects user privacy by safeguarding sensitive information and ensuring that generated content does not compromise individuals' privacy rights. This includes anonymizing or minimizing personal data used in training.</li>\n",
    "  <li><strong>Security:</strong> AI models should be designed with robust security measures to prevent malicious actors from manipulating or exploiting the system. This includes protecting against adversarial attacks and ensuring the integrity of generated content.</li>\n",
    "  <li><strong>Accountability:</strong> Developers and organizations responsible for generative AI systems should be accountable for their actions and the outcomes produced by their models. This entails establishing clear lines of responsibility and mechanisms for addressing unintended consequences or ethical breaches.</li>\n",
    "  <li><strong>Continual Monitoring and Improvement:</strong> Trusted AI is an ongoing process that requires continual monitoring and improvement. Developers should regularly assess the performance of their generative AI models, address emerging ethical concerns, and incorporate feedback from stakeholders to enhance trustworthiness.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d96beb-51cf-4cce-bbec-d7aaedbdfaba",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Why Vantage?</b></p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Chatbot, powered by Machine Learning and Artificial Intelligence, offer numerous advantages in the context of improving customer experience, particularly in the banking and financial institutions sector. Traditional methods of visiting a bank or financial institution in person and providing extensive information, which is then manually reviewed by an officer, are often time-consuming, error-prone, and rely on outdated manual processes.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Vantage provides these same proven capabilities to search user details, proving personalized offers, helping to calculate mortgage,etc, integrated as native ClearScape Analytic functions. This allows organizations to drastically reduce human workforce by chatbot, while allowing for much more user friendly and easy interactions.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca49b9d-df0b-400a-acf8-0252ab8a2618",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233c'><b>Steps in the analysis:</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Configuring the environment</li>\n",
    "    <li>Connect to Vantage</li>\n",
    "    <li>Data Exploration</li>\n",
    "    <li>Fine tunning the OpenAI model</li>\n",
    "    <li>Setup LLM</li>\n",
    "    <li>Launch the Chatbot</li>\n",
    "    <li>Cleanup</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833b5bf-74af-42be-8543-3782e1da95dc",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233C;'>\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233c'>1. Configuring the environment</b>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Note:</b>The installation of the required libraries will take approximately <b>4 to 5 minutes</b> for the first-time installation. However, if the libraries are already installed, the execution will complete within 5 seconds.</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6027a7-888d-441f-abc7-a6ea1c45f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade -r requirements.txt --quiet\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca97cdce-0d5e-4e54-b404-da7bae24ef51",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <i>The above statements will install the required libraries to run this demo. To gain access to installed libraries after running this, restart the kernel.</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b160ce-5ace-4116-86b6-394d6502553b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Note:</b> The above statements may need to be uncommented if you run the notebooks on a platform other than ClearScape Analytics Experience that does not have the libraries installed. If you uncomment those installs, be sure to restart the kernel after executing those lines to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing zero zero: <b>0 0</b></i></p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98b8169-9164-4916-9966-660aa51e5395",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Note:</b> To ensure that the Chatbot interface reflects the latest changes, please reload the page by clicking the 'Reload' button or pressing F5 on your keyboard for <b>first-time only</b> This will update the notebook with the latest modifications, and you'll be able to interact with the Chatbot using the new libraries.</i></p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61067c88-2e9a-4c92-985b-34dc4ab74a13",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>1.1 Import the required libraries</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50a4aa-1211-44fc-8166-317c35253207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "display.print_sqlmr_query = False\n",
    "display.suppress_vantage_runtime_warnings = True\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# teradata lib\n",
    "from teradataml import *\n",
    "display.max_rows = 5\n",
    "\n",
    "\n",
    "# LLM\n",
    "import openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_core.callbacks import FileCallbackHandler\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain.agents.format_scratchpad.openai_tools import (\n",
    "    format_to_openai_tool_messages,\n",
    ")\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.utilities import SQLDatabase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59718f8-7af4-4d1a-abc7-a860eb7cbae3",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233C;'>\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233c'>2. Connection to Vantage and OpenAI</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430652d5-1fa7-412d-aac2-50e1969b6f5f",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>2.1 Connect to Vantage</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164cfc91-93ed-45b9-98ba-73b91a50c28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)\n",
    "execute_sql('''SET query_band='DEMO=PP_Mortgage_Calculator_Python_TrustedAI_Finetune_LLM.ipynb;' UPDATE FOR SESSION;''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1695a105-4b31-47b0-bcfa-52a4658dd86f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4153b889-0924-4e0f-acc8-6b0d440c77b3",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>2.2 Get the OpenAI API key</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e10add-4b3c-4fc5-9359-0b44737bba0f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>To utilize this demo, we need an OpenAI API key. If we don't have one yet, we can refer to the instructions provided in this guide to obtain our OpenAI API key. </p>\n",
    "\n",
    "\n",
    "<a href=\"..//Openai_setup_api_key/Openai_setup_api_key.md\" style=\"text-decoration:none;\" target=\"_blank\">\n",
    "    <button style=\"font-size:16px;font-family:Arial;color:#fff;background-color:#00233C;border:none;border-radius:5px;cursor:pointer;height:50px;line-height:50px;display:flex;align-items:center;\">OpenAI API Key Guide <span style=\"margin-left:10px;\">&#8658;</span></button>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd64269-9393-434a-ac26-0b8386fc0a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "# enter your OpenAI API key\n",
    "api_key = getpass.getpass(prompt=\"\\n Please Enter OpenAI API key: \")\n",
    "# OpenAI API\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beec557-411b-4418-acf3-2f28d3c6beac",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>2.3 Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the cell below, we are synthetically generating a few records for the <b>Customer</b> and <b>Interest</b> tables. This will allow us to test the functionality of our Chatbot with a small set of data before loading the entire dataset.For the Customer table, we are generating 10 records with randomized names, emails, and phone numbers, account details, etc.  We are also assigning a unique customer ID to each record. For the Interest table, we are generating 5 records with randomized interest rates based on minimum and maximum of credit score.  We are also assigning a unique interest ID to each record.By generating this sample data, we can quickly test the application's ability to display customer information and interests.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In addition to this, we are loading data for <b>RealEstate, Locality, NearbyLocality, School, and ShoppingCenter</b>. We take RealEstate data from Kaggle, clean it first, and then add it to Vantage tables in the below code.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b11997-40c6-4189-acef-97e0afe23f45",
   "metadata": {},
   "source": [
    "<p style='font-size:16px;font-family:Arial;color:#00233C'>We iterate through a dictionary mapping file names to primary keys, read corresponding CSV files using Pandas, and copy the data to Vantage using the teradataml <b>copy_to_sql</b> function. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0036808e-ed2a-4b81-9f30-c61ba9c7f55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dict = {\n",
    "    \"Customer\": \"CustomerID\",\n",
    "    \"Interest\": \"ID\",\n",
    "    \"RealEstate\": \"PropertyID\",\n",
    "    \"Locality\": \"LocalityID\",\n",
    "    \"NearbyLocality\": \"LocalityID\",\n",
    "    \"School\": \"SchoolID\",\n",
    "    \"ShoppingCenter\": \"StoreID\",\n",
    "}\n",
    "\n",
    "print(\"-\" * 25, \"data ingestion started\", \"-\" * 25)\n",
    "for file in files_dict:\n",
    "    df = pd.read_csv(os.path.join(\"./data/\", f\"{file}.csv\"))\n",
    "    print(\"Copying data to Vantage for: \", file)\n",
    "    print(f\"Data information: {df.shape}\")\n",
    "    copy_to_sql(\n",
    "        df, table_name=file, primary_index=files_dict[file], if_exists=\"replace\"\n",
    "    )\n",
    "\n",
    "print(\"-\" * 25, \"data ingestion completed\", \"-\" * 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f3fe2-ed63-4838-bb19-4c0d0157453d",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233C;'>\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233c'>3. Data Exploration</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The goal of the Mortgage Chatbot is to provide a user-friendly interface for individuals to quickly and easily find personalized mortgage information. The chatbot aims to streamline the mortgage process by allowing users to ask questions in natural language and receive accurate, concise answers and calculations. By integrating with Vantage, the chatbot can retrieve relevant data and perform calculations to provide users with tailored mortgage options, empowering them to make informed decisions and save time in their home buying journey. </p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In our database, we have total seven tables, we can categorize it into two: </p>\n",
    "    <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "                <li> Financial tables</li>\n",
    "                <li> Property tables</li>\n",
    "    </ol>\n",
    "\n",
    "<br/>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'><li> <b>Financial tables:</b></li></ol>\n",
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> There are two tables: <b>customer</b> and <b>interest</b>. The customer table contains personal and financial information, while the interest table has details on credit score ranges and their corresponding interest rates.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The data is synthetically generated, with a few rows of customer data, including name, address, email, account number, balance, income, and other relevant information.<p/>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Each row represents a snapshot of data captured at a specific point in time, and each column represents a different variable. The input dataset is as follows:</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> \n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Customer data</b> i.e. first-name, last-name, date of birth, address, city, account number, Balance, branch id, account status, income etc.</li>\n",
    "    <li><b>Interest data</b>: min credit score, max credit score, interest rate.</li>\n",
    "</ul>\n",
    "</p>\n",
    "<br/>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C', start=2><li> <b>Property tables:</b></li></ol>\n",
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We have five tables that cover various aspects, ranging from real estate to locality details. For instance, let's take the locality of <b>Larrakeyah</b>, situated <b>9.0 km away from the airport</b>, boasting a <b>livability score of 4.3.</b> In Larrakeyah, we find <b>three schools:</b> St John's Catholic College, Larrakeyah Primary School, and Essington International School. Moreover, there are <b>two shopping centers:</b> Larrakeyah Shopping Complex and Larrakeyah Supermart.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We see each row as a snapshot of data captured at a specific point in time, and each column represents a different variable. This is our input dataset.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> \n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "   <li><b>RealEstate data</b>:LocalityID, PropertyID, PropertyType, BuildingSize, LandSize, PreferredSize, OpenDate, ListingAgency, Price, Address, City, State, ZipCode, Phone, \n",
    "       BedroomCount, BathroomCount, ParkingCount</li>\n",
    "    <li><b>Locality data</b>: LocalityID, LocalityName, LocalityDescription, DistanceFromAirport, LivabilityScore</li>\n",
    "    <li><b>NearbyLocality data</b>: LocalityID, LocalityName, NearbyLocalityID</li>\n",
    "    <li><b>School data</b>: SchoolID, SchoolName, LocalityID</li>\n",
    "    <li><b>ShoppingCenter </b>: StoreID, StoreName, Type, LocalityID</li>\n",
    "</ul>\n",
    "</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The source data from <a href=\"https://www.kaggle.com/datasets/thedevastator/australian-housing-data-1000-properties-sampled\">kaggle</a> is loaded in Vantage with table named <i>RealEstate</i>.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b><i>*Please <a href=\"#datasetInfo\">click here</a> to scroll down to the end of the notebook for detailed column descriptions of the dataset.</i></b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda8e565-b58b-4cc6-8d9c-50790ca3dcab",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>3.1 Examine the Customer and Interest table</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Let's look at the sample data in Customer table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9951cf-e2b0-40d7-9a8f-a01c7f48ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_customer = DataFrame(\"Customer\")\n",
    "\n",
    "print(\"Data information: \\n\", tdf_customer.shape)\n",
    "tdf_customer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d6d954-b72f-41c3-9f8c-bc15cf74d672",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>There are 10 records in all, and there are 18 variables.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Now, let's delve into the interest table. Here, we determine interest rates based on customers' minimum and maximum credit scores.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cad00db-08e5-40d3-a3d2-2be92908a95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_interest = DataFrame(\"Interest\")\n",
    "\n",
    "print(\"Data information: \\n\", tdf_interest.shape)\n",
    "tdf_interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027b6add-e7fa-4381-8d73-2c6a86daaf7f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Let's examine that interest rate in light of a person's credit score. Here, we may determine the interest rate for each individual consumer by examining the credit score range min and max from the interest table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72874be1-a21c-4bd3-bbf3-8d346d89a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "    SELECT c.FirstName, c.LastName, c.CreditScore, i.InterestRate \n",
    "    FROM Customer c \n",
    "    JOIN Interest i ON c.CreditScore BETWEEN i.MinCreditScore AND i.MaxCreditScore\n",
    "    WHERE c.CustomerID = 'CID3058245';\n",
    "\"\"\"\n",
    "\n",
    "DataFrame.from_query(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626e8ab6-5e2b-42b3-aee7-cdd7e921b205",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We can observe that Customer John Doe possesses a credit score of 720, falling within the range of 670 to 739. Therefore, we will offer him a 3.9% interest rate.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59570bd2-6080-47ea-9221-29e0857b001e",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>3.2 Examine the property tables</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Let's look at the sample data in <b>RealEstate</b> table first.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad64fb76-c52d-47d6-9b56-33676481aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_real_estate = DataFrame(\"RealEstate\")\n",
    "\n",
    "print(\"Data information: \\n\", tdf_real_estate.shape)\n",
    "tdf_real_estate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fc813e-c9b4-4a0b-bd72-d8c0699fa09e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We can see that we have ample details about the property here, such as property type, land size, bedroom count, contact details, price, full address, etc. These are crucial details for customers when we search for properties.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Next, let's examine the sample data in our <b>Locality</b> table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616ed3d-07ac-4e22-9de1-26d7ef8c4bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_locality = DataFrame(\"Locality\")\n",
    "\n",
    "print(\"Data information: \\n\", tdf_locality.shape)\n",
    "tdf_locality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa12939b-905a-44b5-a8cb-a7feac803778",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the above table, we can gain a better understanding of the locality, including its distance from the airport and livability score.</p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Thirdly, let's review the sample data in our <b>NearbyLocality</b> table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d63118-b13c-4934-b75f-796c04fe2ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_nearby_locality = DataFrame(\"NearbyLocality\")\n",
    "\n",
    "print(\"Data information: \\n\", tdf_nearby_locality.shape)\n",
    "tdf_nearby_locality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d282ff89-5cce-4874-94b0-e77ed25ffbdf",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Next, let's review the sample data in our <b>School</b> table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cd070a-c269-4160-b99e-c7697c5fb423",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_school = DataFrame(\"School\")\n",
    "\n",
    "print(\"Data information: \\n\", tdf_school.shape)\n",
    "tdf_school"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a5128-f218-40db-94d8-d09a8c434e08",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Next, let's review the sample data in our <b>ShoppingCenter</b> table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b01a8f-c099-4bcf-86c3-86c351a0cb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_shopping_center = DataFrame(\"ShoppingCenter\")\n",
    "\n",
    "print(\"Data information: \\n\", tdf_shopping_center.shape)\n",
    "tdf_shopping_center"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffd19cf-7214-4cfc-b88f-74ccc4b6c845",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>3.3 Get database schema</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Build a consolidated view of Table Data Catalog by combining metadata stored for the database and table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e9e675-7385-4a31-9f27-c779f693a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_d = {\n",
    "    \"Customer\": tdf_customer.columns,\n",
    "    \"Interest\": tdf_interest.columns,\n",
    "    \"RealEstate\": tdf_real_estate.columns,\n",
    "    \"Locality\": tdf_locality.columns,\n",
    "    \"NearbyLocality\": tdf_nearby_locality.columns,\n",
    "    \"School\": tdf_school.columns,\n",
    "    \"ShoppingCenter\": tdf_shopping_center.columns,\n",
    "}\n",
    "\n",
    "\n",
    "def get_db_schema():\n",
    "    table_dicts = []\n",
    "    for k in main_d:\n",
    "        table_dicts.append(\n",
    "            {\n",
    "                # \"database_name\": database,\n",
    "                \"table_name\": k,\n",
    "                \"column_names\": main_d[k],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    database_schema_string = \"\\n\".join(\n",
    "        [\n",
    "            f\"Table: {table['table_name']}\\nColumns: {', '.join(table['column_names'])}\"\n",
    "            for table in table_dicts\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return database_schema_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bd3ec9-1336-4b0c-9693-0e86f2b7b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_schema = get_db_schema()\n",
    "print(database_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0c8ad7-ba4b-4823-9d34-4cec90afc810",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>To validate the queries generated by our Language Model (LLM), we employ the following function to assess their accuracy and return results.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c6cfeb-838d-4409-a283-e35c8cd3b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "\n",
    "def is_sql_return_results(qry):\n",
    "    with eng.connect() as connection:\n",
    "        results_as_dict = connection.execute(text(qry)).mappings().all()\n",
    "        print(f\"Total results from DB: {len(results_as_dict)}\")\n",
    "        return True if len(results_as_dict) > 0 else False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff72895-88d3-478b-94c5-7f6a6faa9f0b",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233C;'>\n",
    "\n",
    "\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233c'>4. Fine tunning the OpenAI model</b>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>In this section, we are fine-tuning the OpenAI model with a small number of records. This process will incur a few dollars on our OpenAI account.</b></i></p>\n",
    "</div>\n",
    "\n",
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>4.1 Prepare the data for Fine tunning the OpenAI model</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We need to prepare data for training our model. We should create a diverse set of demonstration conversations that resemble the conversations we will ask the model to respond to during inference in production.</p>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial;color:#00233c\">\n",
    "    OpenAI fine-tuning typically involves the following technical steps:\n",
    "</p>\n",
    "\n",
    "<ol style=\"font-size:16px;font-family:Arial;color:#00233c\">\n",
    "    <li><b>Model Selection:</b> Choose a pre-trained language model (such as GPT 3.5 or GPT-4) from OpenAI's available models based on the task and computational resources. For this demo, we'll utilize the GPT-3.5 Turbo model as our foundational model.</li>\n",
    "    <li><b>Dataset Selection and Preparation:</b> Select a dataset relevant to the task and pre-process it accordingly. This might involve cleaning, tokenization, and splitting into training, validation, and test sets. In this demo we have prepared Teradata style Question-SQL pair, which we will pass in the fine-tunning process.</li>\n",
    "    <li><b>Fine-tunning:</b> Train the model on the new dataset using techniques like back-propagation and gradient descent to update the weights based on prediction errors.</li>\n",
    "    <li><b>Hyperparameter Tuning:</b> Fine-tune hyperparameters such as learning rate, batch size, and regularization to optimize model performance.</li>\n",
    "    <li><b>Evaluation:</b> Assess the fine-tuned model's performance on a validation dataset to determine if further adjustments are needed.</li>\n",
    "    <li><b>Iterative Refinement:</b> Repeat the fine-tuning process if necessary, adjusting parameters and datasets until satisfactory performance is achieved.</li>\n",
    "</ol>\n",
    "\n",
    "<p style=\"font-size:16px;font-family:Arial;color:#00233c\">\n",
    "    OpenAI's fine-tuning process leverages the capabilities of their pre-trained models while adapting them to specific tasks or domains, allowing for efficient and effective utilization of these powerful language models. To read more about OpenAI fine-tunning guide, please click <a href=\"https://platform.openai.com/docs/guides/fine-tuning\">here.</a>\n",
    "</p>\n",
    "\n",
    "\n",
    "<center><img src=\"images/finetune2.jpg\" alt=\"finetuning \"  width=1122 height=479/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ea8176-316a-488e-9a70-386f811bd5ae",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Now, we'll load the Question-SQL pair data from the file and prepare it for fine-tuning.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b328e68-52b0-42c9-9298-39e56c04d173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read que-sql pairs from csv\n",
    "df_sql = pd.read_csv(\"./data/sql_queries.csv\")\n",
    "\n",
    "print(\"dataframe info: \", df_sql.shape)\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 500)\n",
    "pd.set_option(\"display.max_rows\", 5)\n",
    "df_sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b56514-a9b0-4522-9be6-d87c0d2479ed",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We have prepared 25 records for fine-tuning. Each row represents a question along with its correct version of Teradata-style SQL query.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We'll begin by preparing our data. When fine-tuning with the ChatCompletion format, each training example consists of a simple list of messages. For instance, an entry could appear as follows:</p>\n",
    "\n",
    "<code>{'messages': [{'content': 'You are a Teradata expert and you are tasked with '\n",
    "                          'generating SQL queries for Teradata based on user '\n",
    "                          'questions.',\n",
    "               'role': 'system'},\n",
    "              {'content': 'Question: Can you suggest apartments with a land '\n",
    "                          'size greater than 300 square meters and featuring '\n",
    "                          'at least two bedrooms in Gardiner Street?\\n',\n",
    "               'role': 'user'},\n",
    "              {'content': 'SELECT  PropertyID, PropertyType, BuildingSize, '\n",
    "                          'Price, Address, BedroomCount FROM RealEstate WHERE '\n",
    "                          'LandSize > 300 AND BedroomCount >= 2 AND Address '\n",
    "                          \"LIKE '%Gardiner Street%'\",\n",
    "               'role': 'assistant'}]}  \n",
    "    </code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7869516a-a95e-4270-a76a-d9002b78c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "\n",
    "system_message = \"You are a Teradata expert and you are tasked with generating SQL queries for Teradata based on user questions.\"\n",
    "\n",
    "\n",
    "def create_user_message(row):\n",
    "    return f\"\"\"Question: {row['question']}\\n\"\"\"\n",
    "\n",
    "\n",
    "def prepare_example_conversation(row):\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "\n",
    "    user_message = create_user_message(row)\n",
    "    messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "    messages.append({\"role\": \"assistant\", \"content\": row[\"sql\"]})\n",
    "\n",
    "    return {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69bdc05-bc91-49e9-a3d1-847617df32a9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "Let's now proceed with a subset of the dataset to serve as our training data. We can start with around 20-25 well-pruned examples. As we increase the size of the training set, we should observe performance scaling linearly, albeit with longer processing times for our tasks.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71228659-545f-41e0-943e-8321c12eeb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the first 15 rows of the dataset for training\n",
    "training_df = df_sql.loc[0:19]\n",
    "\n",
    "print(f\"training data info: {training_df.shape}\\n\")\n",
    "\n",
    "# apply the prepare_example_conversation function to each row of the training_df\n",
    "training_data = training_df.apply(prepare_example_conversation, axis=1).tolist()\n",
    "\n",
    "for example in training_data[:3]:\n",
    "    print(example, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8dec74-87fc-400e-a49f-ad05b25932b0",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the above output, we can observe that we've prepared the data for fine-tuning the OpenAI model. OpenAI expects a specific format for fine-tuning the model, where each training example must include roles for the <code>system</code>, <code>user</code>, and <code>assistant</code>.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We can offer both training data and, optionally, validation data. The inclusion of validation data ensures that our model doesn't overfit the training set.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0633932d-f086-4965-9943-7920ec5679a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = df_sql.loc[20:]\n",
    "print(f\"validation data info: {validation_df.shape}\\n\")\n",
    "\n",
    "# apply the prepare_example_conversation function to each row of the validation_df\n",
    "validation_data = validation_df.apply(prepare_example_conversation, axis=1).tolist()\n",
    "\n",
    "for example in validation_data[:3]:\n",
    "    print(example, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1399254e-4e39-44fa-ada6-009460a56c31",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In this demo we are taking first 20 records as training set and rest as validation set.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We then need to save our data as .jsonl files, where each line represents one training example conversation.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e15f4f9-0c4e-466a-b4ed-3c59a264aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_jsonl(data_list: list, filename: str) -> None:\n",
    "    with open(filename, \"w\") as out:\n",
    "        for ddict in data_list:\n",
    "            jout = json.dumps(ddict) + \"\\n\"\n",
    "            out.write(jout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9f8cd2-869f-44cf-99ec-14a4a2594931",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_name = \"data/tmp_sql_query_finetune_training.jsonl\"\n",
    "write_jsonl(training_data, training_file_name)\n",
    "\n",
    "validation_file_name = \"data/tmp_sql_query_finetune_validation.jsonl\"\n",
    "write_jsonl(validation_data, validation_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874c705a-45e4-496d-b0eb-920c7b0f9c7d",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We can now upload the files to OpenAI files endpoint for utilization by the fine-tuned model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f6cb80-d094-47b1-88d9-8660d06c2aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(api_key=api_key)\n",
    "\n",
    "with open(training_file_name, \"rb\") as training_fd:\n",
    "    training_response = client.files.create(file=training_fd, purpose=\"fine-tune\")\n",
    "\n",
    "training_file_id = training_response.id\n",
    "\n",
    "with open(validation_file_name, \"rb\") as validation_fd:\n",
    "    validation_response = client.files.create(file=validation_fd, purpose=\"fine-tune\")\n",
    "\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be1ab9a-dbab-4a42-b171-a463466df878",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Now, we can initiate our fine-tuning job using the generated files along with an optional suffix to distinguish the model. The response will include an ID that can be used to track updates on the job.</p>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Note: When we start a fine-tuning job, it may take some time to complete. Our job might be queued behind other tasks in our system, and training a model can vary from minutes to hours, depending on the model and dataset size. Once the model training is finished, we will receive an email confirmation.</b></i></p>\n",
    "</div>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Apart from creating a fine-tuning job, we can also list existing jobs, check the status of a job, or cancel a job.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Please note:</b> The files need to undergo processing by OpenAI system, so you may encounter a \"File not ready\" error initially. If that happens, just retry after a few minutes..</p>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Please note: </b>We will initiate the new fine-tuning request below. Let's execute it with care. Please note that each new request will incur a charge. This process will result in a few dollars being deducted from our OpenAI account.</i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cdc168-6f07-414e-b2ac-1c71668c98aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    suffix=\"td_sql\",\n",
    ")\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "\n",
    "job_id = response.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fae2a5-bd32-4982-bd86-0a1ba5f940ba",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We can make a GET request to the <a href='https://api.openai.com/v1/alpha/fine-tunes'>https://api.openai.com/v1/alpha/fine-tunes</a> endpoint to list our alpha fine-tuning jobs. In this case, we'll need to verify that the ID obtained from the previous step ultimately ends up with a status of \"succeeded.\"</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Once the fine-tuning process is completed, we can utilize the result_files to sample the results from the validation set (if one was uploaded). Additionally, we can utilize the ID from the fine_tuned_model parameter to invoke our trained model.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bb36ec-9cec-49de-b923-aec6bde3ff98",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We can monitor the progress of the fine-tuning process using the events endpoint. You can rerun the cell below several times until the fine-tuning is complete.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60004e9e-6997-4bfc-b599-cc4dbfc9bb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the fine-tuning to complete (this may take some time)\n",
    "status = openai.fine_tuning.jobs.retrieve(job_id).status\n",
    "print(f\"status: {status}\")\n",
    "\n",
    "start_time = time.time()\n",
    "while status != \"succeeded\":\n",
    "    print(f\"Status=[{status}]... {time.time() - start_time:.2f}s\", end=\"\\r\", flush=True)\n",
    "    time.sleep(5)\n",
    "    status = openai.fine_tuning.jobs.retrieve(job.id).status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8b870f-a6ff-4bd4-bda9-271c87ddb954",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.fine_tuning.jobs.list_events(job_id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688ec02d-0dc2-494b-9465-252e953a076f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Now that the fine-tuning process is complete, we can obtain the ID of the fine-tuned model from the job.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e519f3-e1af-48dc-95aa-693b137d9afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "\n",
    "if fine_tuned_model_id is None:\n",
    "    raise RuntimeError(\n",
    "        \"Fine-tuned model ID not found. Your job has likely not been completed yet.\"\n",
    "    )\n",
    "\n",
    "print(\"Fine-tuned model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89367d27-22ca-4a0e-b299-0f8e1a669157",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233C;'>\n",
    "<a id='section5'></a>\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233c'>5. Setup LLM </b>\n",
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>5.1 Connect to database using SQLAlchemy and Initialize the Large Language Model</b></p>    \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Under the hood, LangChain uses SQLAlchemy to connect to SQL database. The SQLDatabaseToolkit can therefore be used with any SQL dialect supported by SQLAlchemy, such as Teradata Vantage, MS SQL, MySQL, MariaDB, PostgreSQL, Oracle SQL, and SQLite. Please refer to the <a href=\"https://docs.sqlalchemy.org/en/20/\"> SQLAlchemy documentation</a> for more information about requirements for connecting to your database. The SQLDatabaseToolkit builds off of SQLDatabaseChain and is designed to answer more general questions about a database, as well as recover from errors.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055d8f1c-6dd6-4de8-be49-dfbcbc7bfc1c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Important Note:</b> The code below establishes a database connection for data sources and Large Language Models. Please note that the solution will only work if the database connection for your sources is defined in the cell below. In addition to this, to use OpenAI models, we have to set OpenAI API key to environment variable.</i></p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbceafb4-793b-4d62-ab22-c9d49ac9a759",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQLDatabase(eng)\n",
    "\n",
    "# fine_tuned_model_id = 'ft:gpt-3.5-turbo-0125:csaedev:td-sql:9PSVTFW4'\n",
    "# fine_tuned_model_id = 'ft:gpt-3.5-turbo-0125:csaedev:td-sql:9QrCXaMn'\n",
    "llm = ChatOpenAI(model=fine_tuned_model_id, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6983640-c595-4185-9390-76ad933f3870",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In this demo we will be using OpenAI’s <code>gpt-3.5-turbo-0125</code> model as LLM. To view list of available models on OpenAI <a href='https://platform.openai.com/docs/models'>click here</a></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In OpenAI's language models, the <b>temperature</b> parameter controls the randomness of the generated text. It affects the diversity and creativity of the model's responses. It is always a number between 0 and 1. A temperature of 0 means the responses will be very straightforward, almost deterministic (meaning you almost always get the same response to a given prompt). A temperature of 1 means the responses can vary wildly.</p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>A higher temperature value, such as 1.0, increases the randomness and diversity of the generated output. This can lead to more varied and surprising responses, but it may also result in less coherence and occasional nonsensical outputs. A higher temperature means that the model might select a word with slightly lower probability, leading to more variation, randomness and creativity. A very high temperature therefore increases the risk of <b>hallucination</b>, meaning that the model starts selecting words that will make no sense or be off the topic.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>On the other hand, a lower temperature value, such as 0.2 or below, reduces randomness and makes the model's output more focused and deterministic. The generated text is likely to be more conservative, sticking closely to patterns observed in the training data. A temperature of 0 means roughly that the model will always select the highest probability word.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Choosing an appropriate temperature value depends on the desired output. Higher temperatures can be useful for creative tasks or brainstorming, while lower temperatures are preferred when you need more control over the output, such as when generating specific responses or following a particular style.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680228a2-3bfa-44f4-8a02-b73fa8bf8e95",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>5.2 Setup SQLAgent</b></p> \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Before jumping into the chatbot, let us first understand what is an agent and why it might be preferred over a simple SQLChain.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>An agent is a component that has access to a suite of tools, including a Large Language Model (LLM). Its distinguishing characteristic lies in its ability to make informed decisions based on user input, utilizing the appropriate tools until it achieves a satisfactory answer. For example in the context of text-to-SQL, the LangChain SQLAgent will not give up if there is an error in executing the generated SQL. Instead, it will attempt to recover by interpreting the error in a subsequent LLM call and rectify the issue. Therefore, in theory, SQLAgent should outperform SQLChain in productivity and accuracy.</p>\n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We can think of agents as enabling tools for LLMs. Like how a human would use a calculator for maths or perform a Google search for information — agents allow an LLM to do the same thing.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f0cef5-bb5f-48f8-b557-4a8e208c926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "import ast\n",
    "\n",
    "# First, define custom callback handler implementations\n",
    "class ToolCallbackHandler(BaseCallbackHandler):\n",
    "    def __init__(self, sql=None):\n",
    "        if sql is None:\n",
    "            sql = {}\n",
    "\n",
    "\n",
    "    def on_tool_start(\n",
    "        self, serialized: Dict[str, Any], input_str: str, **kwargs: Any\n",
    "    ) -> Any:\n",
    "        name = serialized.get(\"name\")\n",
    "        print(f\"*** on_tool_start: *** {name}\")\n",
    "        if name in [\"sql_db_query\", \"sql_db_query_checker\"]:\n",
    "            _sql = ast.literal_eval(input_str)[\"query\"]\n",
    "            print(\"*** _sql: *** \", _sql)\n",
    "            if is_sql_return_results(_sql):\n",
    "                self.sql = _sql\n",
    "                print(f\"sql assigned: {self.sql}\")\n",
    "            else:\n",
    "                print(\"sql not assigned\")\n",
    "                self.sql = {}\n",
    "            return self.sql\n",
    "\n",
    "\n",
    "    def on_llm_end(self, output: str, **kwargs: Any) -> Any:\n",
    "        txt = output.generations[0][0].text\n",
    "        if txt != \"\":\n",
    "            print(\"--- on_llm_end ---\")\n",
    "            resp_dict = ast.literal_eval(output.generations[0][0].text)\n",
    "            _sql = resp_dict.get(\"SQL\", \"Key not found\")\n",
    "            _error = resp_dict.get(\"error\", \"Key not found\")\n",
    "            print(f\"_sql: {_sql}\")\n",
    "            print(f\"_error: {_error}\")\n",
    "            # set SQL\n",
    "            if is_sql_return_results(_sql):\n",
    "                self.sql2 = _sql\n",
    "                print(f\"sql2 assigned: {self.sql2}\")\n",
    "            else:\n",
    "                print(\"sql2 not assigned\")\n",
    "                self.sql2 = {}\n",
    "            return self.sql2\n",
    "\n",
    "# define handler\n",
    "tool_handler = ToolCallbackHandler()\n",
    "\n",
    "# define SQL Agent\n",
    "@tool\n",
    "def generate_sql(input: str) -> str:\n",
    "    \"\"\"Given an input question, first create a syntactically correct Teradata-style query to execute, then look at the results of the query and return the answer.\"\"\"\n",
    "    \n",
    "    generated_prompt = f'''You are a Teradata expert and you are tasked with generating SQL queries for Teradata based on user questions. \n",
    "    Your response should ONLY be based on the given context and follow the response guidelines and format instructions.\n",
    "\n",
    "        Use the following Tables:\\n{database_schema}\n",
    "\n",
    "        Here are some tips for writing Teradata style queries: \n",
    "        * Always use table aliases when your SQL statement involves more than one source \n",
    "        * Aggregated fields like COUNT(*) must be appropriately named \n",
    "        * Unless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 3 results by using SELECT TOP 3, note that LIMIT function does not works in Teradata DB.\n",
    "        * [Best] If the question can be answered with the available tables: {{'sql': <sql here>}} \n",
    "        * If the question cannot be answered with the available tables: {{'error': <explanation here>}} \n",
    "        * Remove unnecessary ORDER BY clauses unless required. \n",
    "        * Remember: Do not use 'LIMIT' or 'FETCH' keyword in the SQLQuery, instead of TOP keyword, For Example: To select top 3 results, use TOP keyword instead of LIMIT or FETCH.  \n",
    "\n",
    "        Response Guidelines: \n",
    "        * If the provided context is insufficient, please explain why it can't be generated.\n",
    "        * Most important: Always give property options with details like PropertyID, Property Type, Building Size, Price, Address, Bedroom Count. PropertyID is mandatory in the response.\n",
    "        * Critical Instruction: Ensure responses are exclusively derived from query results. Refrain from generating or adding synthetic data in any form.\n",
    "        * Most important: The function should return the relevant answer for the question asked only based on Query results.\n",
    "\n",
    "        Given a user's question about this data, write a valid Teradata SQL query that accurately extracts or calculates the requested information from these tables and adheres to SQL best practices for Teradata database, optimizing for readability and performance where applicable. Do not try to make any answer\n",
    "        Alway return Final output in json format.\n",
    "                Final output:\n",
    "                    - SQL:\n",
    "                    - Answer:'''\n",
    "\n",
    "\n",
    "    # print(f\"\\n\\n generated_prompt: \\n\\n{generated_prompt} \\n\\n\")\n",
    "\n",
    "\n",
    "    messages = [\n",
    "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "        AIMessage(content=generated_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    "\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "    agent_executor = create_sql_agent(\n",
    "        llm,\n",
    "        db=db,\n",
    "        agent_type=\"openai-tools\",\n",
    "        verbose=True,\n",
    "        prompt=prompt,\n",
    "        max_iterations=10,\n",
    "        max_execution_time=20,\n",
    "        handle_parsing_errors=True,\n",
    "        return_intermediate_steps=True,\n",
    "        handle_sql_errors=True,\n",
    "        max_tokens=4000,\n",
    "    )\n",
    "\n",
    "\n",
    "    return agent_executor.run(input, callbacks=[tool_handler])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97e139d-d129-44c2-bf42-181d7b928164",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the code above, we're initializing SQLAgent by passing in LLM, SQLDatabaseToolkit, database, and agent type as OpenAI tools. Agents use an LLM to determine the best course of action and execute it. An action can either be using a tool and observing its output, or responding to the user. <a href='https://python.langchain.com/docs/modules/agents/agent_types/'>Here</a> are the agents available in LangChain.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>OpenAI tools in LangChain refer to the integration of OpenAI's language models with external tools and services to enhance their capabilities and provide more accurate and informative responses. LangChain is a framework that enables the development of applications powered by language models, and it supports the use of OpenAI models as the language understanding component.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The OpenAI tools in LangChain are designed to overcome the limitations of language models, such as the lack of recency and specificity in their training data, by allowing them to access external knowledge bases and APIs dynamically. This enables the models to answer questions with context directly from search engines, APIs, or internal databases, and to perform intermediate steps to gather relevant information. Please refer this <a href='https://python.langchain.com/v0.1/docs/modules/agents/agent_types/openai_tools/'>openai-tools</a> for more information.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f923edc3-4242-4ab4-8512-a7d7353b7210",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233C;'>\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233c'>6. Launch the Chatbot</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In this demo we are using ChatOpenAI model with Memory. This advanced technology allows us to store and recall conversations, enabling our chatbot to provide more personalized and informed responses.As a mortgage advisor, our chatbot is trained to assist with a wide range of loan-related inquiries. Whether you're looking to purchase a new home, refinance an existing loan, or simply have questions about the mortgage process, our chatbot is here to help.To begin, we'll set the prompt for our chatbot to work as a mortgage advisor. This will enable it to provide tailored advice and guidance based on your unique needs and circumstances.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adb0962-73b3-4f07-abcb-377b2e382458",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Note:</b>Please note that our chatbot is specifically designed to address questions related to mortgage loans. If you have a question outside of this scope, we kindly ask that you refrain from asking it. This will help us provide you with the most accurate and efficient assistance possible.</i></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6647969-a008-47c6-93de-0a4769da02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# default customer\n",
    "CustomerID = \"CID3058245\"\n",
    "\n",
    "# define tools\n",
    "tools = [generate_sql]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "llm_fm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    return_messages=True,\n",
    "    memory_key=\"chat_history\",\n",
    "    llm=llm_fm,\n",
    ")\n",
    "\n",
    "# For writing logs\n",
    "from loguru import logger\n",
    "\n",
    "now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "logfile = f\"./logs/sql_agent_output_{now}.log\"\n",
    "logger.add(\n",
    "    logfile,\n",
    "    colorize=True,\n",
    "    enqueue=True,\n",
    "    level=\"DEBUG\",\n",
    "    backtrace=True,\n",
    "    diagnose=True,\n",
    "    format=\"{time} {level} {message}\",\n",
    ")\n",
    "file_handler = FileCallbackHandler(logfile)\n",
    "config = {\"callbacks\": [file_handler]}\n",
    "\n",
    "# main prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            f\"\"\"You'll be working as property advisor and mortgage advisor and I will play the role of the user.\n",
    "            \n",
    "            * General Instructions for Chatbot:\n",
    "            1) Start the chat with greeting only if user starts with greeting. Greet user by starting the message: \n",
    "              ## Welcome to Property and Mortgage Chatbot! \\n\n",
    "              I'm here to provide you with expert advice and answers. \\n\n",
    "              ### Let's get started! \\n\n",
    "              Could you please share your property preferences with me?\n",
    "            2) Ask questions sequentially - pausing between each question to wait for a response before proceeding to the next.\n",
    "            3) Most important: Do not ask all the questions together, ask one by one.\n",
    "            4) Whenever possible, give the answer in bulleted points and title in markup. like ##\n",
    "            5) Consider current user: {CustomerID}\n",
    "            6) If the user fails to provide a response or says 'I don't know' for a question, automatically call the 'generate_sql' function to retrieve the answer from the database.\n",
    "            7) Most important: If 'generate_sql' function fail to give the answer, then just say \"Sorry, I am unable to get the answer.\" Do not make any answer by yourself.\n",
    "            \n",
    "            * Instructions to follow when working as a property advisor:\n",
    "            1) As a property advisor first ask a series of questions related to property like preferred locality, number of bedrooms, etc.  \n",
    "            2) As a property advisor, Always end your response with the next Question. Do not ask same question more than one time.\n",
    "            3) As a property advisor, you have direct access of property data includes tables like RealEstate, Locality, NearbyLocality,  ShoppingCenter, School. \n",
    "            Only Suggest properties that exist in these tables.\n",
    "            4) Most important: Always give property options with details like Property ID, Property Type, Building Size, Price, Address, Bedroom Count. PropertyID is mandatory in the response.\n",
    "            5) Most important: Once you suggest the property, ask user Do you like this or shall I suggest more? Once the user select the property, then only perform a role of mortgage advisor.\n",
    "            \n",
    "            * Instructions to follow when working as a mortgage advisor:\n",
    "            1) Most important: Once user select the property then only ask for mortgage related questions like monthly income, credit score, bank balance etc.\n",
    "            2) As a mortgage advisor for the bank you have direct access to the banks data for user. The banks data includes tables like Customer and Interest\n",
    "            3) Once user select a property, then only ask about mortgage related questions. You can ask question like below one by one:\n",
    "             -  question 1: Income: What is your total annual income, including any additional sources of income?\n",
    "             -  question 2: What is your employment status?\n",
    "             -  question 3: What's your credit score? I can help you find out which interest rates you qualify for.\n",
    "            4) Most important: Call the 'generate_sql' only when user is not able give the answer related to income or credit score when working as mortgage advisor.\n",
    "            5) Do not call unnecessarily the 'generate_sql' function until it is really needed when working as mortgage advisor.\n",
    "            6) At the end of above 3 questions provide a succinct summary paragraph of these details.\n",
    "            \n",
    "            \n",
    "            * Remember the Instructions for final output:\n",
    "            1) Provide a succinct summary paragraph of these details as a response to the client but don't show the method of calculation. \n",
    "            Follow with a formatted table of monthly amounts (gross income, tax obligation, mortgage obligation, expenses, remaining disposable income).\n",
    "            Also provide best property options based on user's data.\n",
    "            2) Provide an opinion as to whether the mortgage is affordable and what the maximum borrowing amount could be\n",
    "            3) Most important: If 'generate_sql' function fail to give the answer, then just say \"Sorry, I am unable to get the answer.\" Do not make any answer by yourself.\n",
    "            4) Most Important: Give me reasoning as well as answers for this given questions. \n",
    "                Instructions for Reasoning:\n",
    "                    - Give me Reasoning in details.\n",
    "                    - Only one sentence reasoning would be good.\n",
    "                    - Be transparent and Unbiased so user can trust on answer.\n",
    "            5) Most important: Reasoning is mandatory in the final summary.\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# define agent\n",
    "agent = (\n",
    "    RunnablePassthrough.assign(\n",
    "        agent_scratchpad=lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        )\n",
    "    )\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")\n",
    "\n",
    "# define Agent executor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    "    max_iterations=10,\n",
    "    handle_parsing_errors=True,\n",
    "    max_execution_time=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b8440f-3934-4fa1-b0fb-d8cff5f80dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_properties(response):\n",
    "    prop_ids = re.findall(r\"Property ID:\\*\\* (\\d+)\", response)\n",
    "    if len(prop_ids) == 0:\n",
    "        prop_ids = re.findall(r\"PropertyID:\\*\\* (\\d+)\", response)\n",
    "    if len(prop_ids) == 0:\n",
    "        prop_ids = re.findall(r\"Property ID: (\\d+)\", response)\n",
    "    return prop_ids\n",
    "\n",
    "\n",
    "def validate_property_ids(property_ids):\n",
    "    property_ids = \",\".join(property_ids)\n",
    "\n",
    "    q = f\"\"\"SELECT PropertyID FROM demo_user.RealEstate WHERE PropertyID in ({property_ids})\"\"\"\n",
    "    temp_df1 = DataFrame.from_query(q)\n",
    "    logger.info(f\"temp_df1 shape: {temp_df1.shape}\")\n",
    "\n",
    "    return True if len(property_ids.split(\",\")) == temp_df1.shape[0] else False\n",
    "\n",
    "\n",
    "def find_partial_match(arr, target, min_match=3):\n",
    "    for element in arr:\n",
    "        count = 0\n",
    "        for word in element.split():\n",
    "            if word.lower() in target.lower():\n",
    "                count += 1\n",
    "        if count >= min_match:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "questions = [\n",
    "    \"What is your total annual income, including any additional sources of income?\",\n",
    "    \"What is your employment status?\",\n",
    "    \"What's your credit score?\",\n",
    "]\n",
    "\n",
    "\n",
    "def validate_response(response_output):\n",
    "    apl_msg = \"\"\"We apologize for the inconvenience. There could be various reasons for this issue, including:\n",
    "    - It seems we couldn't find an answer, which might be due to limited data and table information.\n",
    "    - To enhance our suggestions, could you please provide additional criteria or try asking the same question again later?\n",
    "    - Technical issues might be causing this delay.\n",
    "    - Thank you for your cooperation. Please try again later.\"\"\"\n",
    "\n",
    "    if \"Welcome to Property and Mortgage Chatbot\" in response_output:\n",
    "        logger.info(\" Entered into greet\")\n",
    "        if hasattr(tool_handler, \"sql\"):\n",
    "            tool_handler.sql = {}\n",
    "        return True, response_output\n",
    "    elif \"Agent stopped due to max iterations\" in response_output:\n",
    "        logger.info(\" Agent stopped due to max iterations \")\n",
    "        if hasattr(tool_handler, \"sql\"):\n",
    "            logger.info(f\" tool_handler {tool_handler.sql} \\n resetting now\")\n",
    "            tool_handler.sql = {}\n",
    "        logger.info(\n",
    "            \" Agent stopped due to max iterations, exiting with apologies msg... \"\n",
    "        )\n",
    "        return False, apl_msg\n",
    "    elif \"Sorry, I am unable to get the answer\" not in response_output:\n",
    "        logger.info(\n",
    "            \" looks valid response, validating properties and SQL\", level=\"DEBUG\"\n",
    "        )\n",
    "        # get prop ids from response\n",
    "        property_ids = get_properties(response_output)\n",
    "        logger.info(f\"found property_ids: {property_ids}\")\n",
    "\n",
    "        # first validate properties if retrieved property_ids\n",
    "        if len(property_ids) > 0 and validate_property_ids(property_ids):\n",
    "            logger.info(\" property validated \")\n",
    "\n",
    "            if hasattr(tool_handler, \"sql\"):\n",
    "                logger.info(f\" tool_handler SQL: {tool_handler.sql} \\n resetting now\")\n",
    "                tool_handler.sql = {}\n",
    "            logger.info(\" property validation done.. returning the response..\")\n",
    "            return True, response_output\n",
    "        elif (\n",
    "            hasattr(tool_handler, \"sql\")\n",
    "            and len(tool_handler.sql) > 0\n",
    "            and is_sql_return_results(tool_handler.sql)\n",
    "        ):  # if not a property related question\n",
    "            logger.info(\" there are valid SQL but not valid property \")\n",
    "\n",
    "            if hasattr(tool_handler, \"sql\"):\n",
    "                logger.info(f\" tool_handler SQL: {tool_handler.sql} \\n resetting now\")\n",
    "                tool_handler.sql = {}\n",
    "\n",
    "            logger.info(\" SQL is valid, returning the response..\")\n",
    "            return True, response_output\n",
    "        else:\n",
    "            logger.info(\n",
    "                \" there are NO valid SQL and no valid property, might be working as mortgage advisor... \"\n",
    "            )\n",
    "\n",
    "            if hasattr(tool_handler, \"sql\"):\n",
    "                logger.info(f\" tool_handler SQL: {tool_handler.sql} \\n resetting now\")\n",
    "                tool_handler.sql = {}\n",
    "\n",
    "            if find_partial_match(questions, response_output):\n",
    "                logger.info(\n",
    "                    \" Found at least 3 matching words! seems it working as mortgage advisor.. returning the response..\"\n",
    "                )\n",
    "                return False, response_output\n",
    "\n",
    "            logger.info(\n",
    "                \" there are NO valid SQL and no valid property, not working as mortgage advisor, exiting with apologies msg... \"\n",
    "            )\n",
    "            return False, apl_msg\n",
    "    else:\n",
    "        if hasattr(tool_handler, \"sql\"):\n",
    "            logger.info(f\" tool_handler SQL: {tool_handler.sql} \\ resetting now\")\n",
    "            tool_handler.sql = {}\n",
    "\n",
    "        logger.info(\"It seems wrong response, exiting with apologies msg... \")\n",
    "        return False, apl_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6228de91-fc5f-4d8e-a524-ed98215f5519",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Note:</b>Chatbot is accessing multiple components, including databases and LLMs. This may cause a brief delay in responses. Your patience is appreciated.</i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be7711c-b47c-42b0-b35f-ee90f25558e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>6.1 User Guide: Property and Mortgage Chatbot</b></p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Welcome to our Property and Mortgage Chatbot! We're here to help you effectively interact with our chatbot, providing assistance in both property selection and mortgage advice. Whether you're looking for your dream home or seeking mortgage options, we're here to guide you every step of the way.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Getting Started:</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "  <li>Initiate the chatbot by sending us a greeting message. Simply say \"Hello\" or any other friendly greeting to start the conversation.</li>\n",
    "</ol>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Property Advisor:</b></p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "  <li><strong>Property Search:</strong> Ask us questions about properties, localities, amenities, etc. For example:\n",
    "    <ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "            <li><i>What is the mean price of 3 bedroom apartments in Larrakeyah area?</i></li>\n",
    "            <li><i>Can you provide information about the livability of the Bayview area?</i></li>\n",
    "            <li><i>Which agency handles property listings in the Woolner area?</i></li>\n",
    "            <li><i>Can you suggest apartments with a land size greater than 300 square meters and featuring at least two bedrooms?</i> </li>\n",
    "            <li><i>Can you suggest me properties within a 15-kilometer radius of the airport has the highest number of bedrooms?</i> </li>\n",
    "        </ul></li>\n",
    "  <li><strong>Select Property:</strong> Once you find a property of interest, note down its Property ID.</li>\n",
    "  <li><strong>Switch to Mortgage Advisor:</strong> To proceed to the mortgage advisory phase, provide type text with the Property ID of the selected property. For example: <i>I really like this property with ID 1351007</i></li>\n",
    "</ol>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Mortgage Advisor:</b></p>\n",
    "\n",
    "<ol  style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "  <li><strong>Provide Details:</strong> We'll ask for specific details such as your annual income, employment status, etc.</li>\n",
    "  <li><strong>Summary:</strong> Based on the information you provide, we'll generate a summary of the property and mortgage details.</li>\n",
    "  <li><strong>Affordability Calculation:</strong> You will receive information on the maximum house price you can afford based on your income and other relevant factors.</li>\n",
    "</ol>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Tips for Effective Interaction:</b></p>\n",
    "\n",
    "<ul  style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "  <li>Be specific and clear with your queries to receive accurate responses.</li>\n",
    "  <li>Provide accurate information when prompted, as it will help us provide personalized assistance.</li>\n",
    "  <li>Note down the Property ID of any property you are interested in to seamlessly transition to the mortgage advisory phase.</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Our Property and Mortgage Chatbot is designed to simplify your property search and mortgage process. By seamlessly transitioning from property advisor to mortgage advisor, we provide comprehensive assistance tailored to your needs. Start your journey now by sending us a greeting message and let us guide you towards your dream home and a suitable mortgage option!</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dc825c-f45f-4639-86fe-6cd9110cf1a8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Sample summary: </b>An example of the tentative output the chatbot will provide at the end is shown below.</i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd07764-9d47-4578-a49b-54ebdd180df3",
   "metadata": {},
   "source": [
    "<pre style='border: 1px; border-color:#00233C; border-style: outset; padding: 15px'>Based on the data, the credit score of the user with CID3058245 is 720.\n",
    "\n",
    "Summary: The user has an annual income of $5000, is employed full-time, and has a credit score of 720.\n",
    "\n",
    "<b> Mortgage Details Summary:</b>\n",
    "- <b>Income:</b> $5000\n",
    "- <b>Employment Status:</b> Full-time\n",
    "- <b>Credit Score:</b> 720\n",
    "\n",
    "<b>Monthly Amounts:</b>\n",
    "| Gross Income | Tax Obligation | Mortgage Obligation | Expenses | Remaining Disposable Income |\n",
    "|--------------|----------------|---------------------|----------|-----------------------------|\n",
    "| $5000        | $750           | $1500               | $1000    | $1750                       |\n",
    "\n",
    "<b>Best Property Options based on User's Data:</b>\n",
    "- <b>Property ID: 1351007</b>\n",
    "  - Property Type: Apartment\n",
    "  - Building Size: 120 sqm\n",
    "  - Price: $450,000\n",
    "  - Address: 2/1 Brolga Street, Rapid Creek\n",
    "  - Bedroom Count: 2\n",
    "  - Bathroom Count: 2\n",
    "  - Parking Count: 1\n",
    "\n",
    "<b>Affordability Opinion:</b> The mortgage is affordable with a remaining disposable income of $1750.\n",
    "\n",
    "<b>Maximum Borrowing Amount:</b> $150,000\n",
    "\n",
    "<b>Reasoning:</b> The user's income of $5000, employment status, and credit score of 720 make the mortgage affordable with a comfortable remaining disposable income.</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2398d71e-cdae-4a64-bc14-03a503b9523d",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>6.2 Open the Chabot</b></p>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i>It's time to chat with the bot! Let's get started with our conversation.</i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df82c07-05d0-4630-ba74-7bd6b77955a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "\n",
    "pn.extension(design=\"material\")\n",
    "\n",
    "# clear the memory\n",
    "memory.clear()\n",
    "\n",
    "\n",
    "def callback(contents, user, instance):\n",
    "    response = agent_executor.invoke({\"input\": contents}, config=config)\n",
    "    is_valid_response, final_res = validate_response(response[\"output\"])\n",
    "    return final_res\n",
    "\n",
    "\n",
    "pn.chat.ChatInterface(\n",
    "    callback=callback,\n",
    "    show_rerun=False,\n",
    "    show_undo=False,\n",
    "    show_clear=False,\n",
    "    width=800,\n",
    "    height=400,\n",
    ").servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e0695f-cb92-4c79-af24-535a31582f7b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'>If the chatbot didn't work when you pressed ENTER, on your first time using this demo on your environment, did you use F5 to reload the site? See instructions at the top of the notebook.\n",
    "If you asked a question and got no response after a few minutes, it is possible that you will need to type 0 0 to restart the kernel and re-run the demo. Questions outside the model seem to confuse the chatbot.</p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b8b817-c0ff-42b3-a651-c8268ac40942",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233C;'>\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233c'>7 Cleanup</b>\n",
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>7.1 Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Cleanup work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aacb87c-0d81-40f0-8754-608d47e602cc",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'> <b>7.2 Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b398148-9486-4535-8c06-d3f77669bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in [\n",
    "    \"Customer\",\n",
    "    \"Interest\",\n",
    "    \"RealEstate\",\n",
    "    \"Locality\",\n",
    "    \"NearbyLocality\",\n",
    "    \"School\",\n",
    "    \"ShoppingCenter\",\n",
    "]:\n",
    "\n",
    "    try:\n",
    "        db_drop_table(t)\n",
    "\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef4cbe-1beb-4c65-ac60-ffd6250668a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae971f90-bef1-4228-bcbf-c333e9843284",
   "metadata": {},
   "source": [
    "<b id=\"datasetInfo\" style = 'font-size:20px;font-family:Arial;color:#00233c'>Dataset:</b>\n",
    "\n",
    "**Customer Table**\n",
    "- `CustomerID`: unique row customer id\n",
    "- `FirstName`: customer first name\n",
    "- `LastName`: customer last name\n",
    "- `DateOfBirth`: customer birth date\n",
    "- `Gender` : customer gender (categorical: \"M\",\"F\",)\n",
    "- `Address` : customer full address\n",
    "- `City`: city of customer (categorical: 'Almond','Geneva')\n",
    "- `LocalityID`: unique row locality id (Numeric)\n",
    "- `Country`: country of customer (categorical: 'USA')\n",
    "- `Email`: customer email\n",
    "- `PhoneNumber`: customer phone number\n",
    "- `AccountNumber`: customer account number\n",
    "- `AccountType`: customer account type\n",
    "- `AccountStatus`: customer account status (categorical: 'Active','Inactive')\n",
    "- `Balance`: account balance, in dollar (numeric)\n",
    "- `BranchID`: branch id\n",
    "- `CreditScore`: customer credit score\n",
    "- `Income`: customer's monthly income, in dollar (numeric)\n",
    "\n",
    "**Interest Table**\n",
    "- `ID`: unique row id\n",
    "- `MinCreditScore`: min credit score\n",
    "- `MaxCreditScore`: max credit score\n",
    "- `InterestRate`: rate of interest\n",
    "\n",
    "**RealEstate**\n",
    "- `LocalityID`: unique row locality id (Numeric)\n",
    "- `PropertyID`: unique row property id (Numeric)\n",
    "- `PropertyType`: type of property being listed (categorical: 'Apartment','House', 'Unit')\n",
    "- `BuildingSize`: size of the property's building, in square meters. (Numeric)\n",
    "- `LandSize`: size of the property's land, in square meters. (Numeric)\n",
    "- `PreferredSize`: preferred size of the property, in square meters. (Numeric)\n",
    "- `OpenDate`: date that the property was first listed for sale. (Date)\n",
    "- `ListingAgency`: agency that is listing the property\n",
    "- `Price`: listing price of the property\n",
    "- `Address`: property's address\n",
    "- `City`: city that the property is located in\n",
    "- `State`: state that the property is located in\n",
    "- `ZipCode`: zip code that the property is located in\n",
    "- `Phone`: listing agent's phone number\n",
    "- `BedroomCount`: number of bedrooms in the property\n",
    "- `BathroomCount`: number of bathrooms in the property\n",
    "- `ParkingCount`: number of parking spaces in the property\n",
    "\n",
    " **Locality data**\n",
    " - `LocalityID`: unique row locality id (Numeric)\n",
    " - `LocalityName`: locality name\n",
    " - `LocalityDescription`: locality description\n",
    " - `DistanceFromAirport`: distance from airport to locality (Numeric)\n",
    " - `LivabilityScore`: locality livability score (Numeric)\n",
    " \n",
    "**NearbyLocality data**\n",
    "- `LocalityID`: unique row locality id (Numeric)\n",
    "- `LocalityName`: locality name (Numeric)\n",
    "- `NearbyLocalityID`: Unique row locality id (Numeric)\n",
    "\n",
    "**School data**\n",
    "- `SchoolID`: unique row school id (Numeric)\n",
    "- `SchoolName`: school name\n",
    "- `LocalityID`: unique row locality id (Numeric)\n",
    "\n",
    "**ShoppingCenter**\n",
    "- `StoreID`: unique row store id (Numeric)\n",
    "- `StoreName`: store name\n",
    "- `Type`: type of shopping center (categorical: 'Grocery Store','Shopping Mall')\n",
    "- `LocalityID`: unique row school id (Numeric)\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233c'><b>Dataset source:</b> <a href = 'https://www.kaggle.com/datasets/thedevastator/australian-housing-data-1000-properties-sampled'>kaggle</a></p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233c'><b>Links:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Teradataml Python reference: <a href = 'https://docs.teradata.com/search/all?query=Python+Package+User+Guide&content-lang=en-US'>here</a></li>\n",
    "    <li>Langchain Python reference: <a href='https://python.langchain.com/docs/get_started/introduction.html'>here</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5463848-592f-4321-b852-287e133872dd",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2023, 2024. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
