{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38bc532d-c78c-4c89-b191-242da0733f39",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Mortgage Calculator chatbot using Generative AI with Vantage: Trusted AI (RAG)\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff71661-19b4-423a-867a-7c815b064c81",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Introduction</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the Mortgage Calculator chatbot using Generative AI demo, the combination of <b>RAG, Langchain, and LLM models</b> allows users to ask queries in layman's terms, retrieve relevant information from the Vantage tables, and generate accurate and concise answers based on the retrieved data. This integration of retrieval-based and generative-based approaches provides a powerful tool for extracting knowledge from structured sources and delivering user-friendly responses.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In this demo we will build conversational chatbot using LangChain, a powerful library for working with LLMs like GPT-3.5, GPT-4, Mistral 7B, Mixtral 8x22B, etc. and JumpStart in ClearScape notebooks, a system is built where users can ask business questions in natural English and receive answers with data drawn from the relevant databases.</p>\n",
    "\n",
    "\n",
    "<center><img src=\"images/header.png\" alt=\"mortgage calc\"  width=800 height=800/></center>\n",
    "\n",
    "<br>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Before going any farther, let's get a better understanding of RAG, LangChain, and LLM.</p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'><li> <b>Retrieval-Augmented Generation (RAG):</b></li></ul>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> &emsp;  &emsp;RAG is a framework that combines the strengths of retrieval-based and generative-based approaches in question-answering systems.It utilizes both a retrieval model and a generative model to generate high-quality answers to user queries. The retrieval model is responsible for retrieving relevant information from a knowledge source, such as a database or documents. The generative model then takes the retrieved information as input and generates concise and accurate answers in natural language.</p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'><li> <b>Langchain:</b></li></ul>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> &emsp;  &emsp; LangChain is a framework that facilitates the integration and chaining of large language models with other tools and sources to build more sophisticated AI applications. LangChain does not serve its own LLMs; instead, it provides a standard way of communicating with a variety of LLMs, including those from OpenAI and HuggingFace. LangChain accelerates the development of AI applications with building blocks. We learn to leverage the following building blocks in this notebook:</p>\n",
    " \n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li> <b> LLMs</b> – LangChain's <code>llm</code> class is designed to provide a standard interface for all LLM it supports.   </li>\n",
    "    <li> <b> PromptTemplate</b>  - LangChain’s <code>PromptTemplate</code> class are predefined structures for generating prompts for LLM’s. They can be reused across different LLM's.</li>\n",
    "    <li> <b> Chains</b> – When we build complex AI applications, we may need to combine multiple calls to LLM’s and to other components  LangChain’s <code>chain</code> class allows us to link calls to LLM’s and components. The most common type of chaining in any LLM application is combining a prompt template with an LLM and optionally an output parser. </li>\n",
    "</ol>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'><li> <b> LLM Models (Large Language Models):</b></li></ul>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> &emsp;  &emsp; LLM models refer to the large-scale language models that are trained on vast amounts of text data.\n",
    "These models, such as <code>GPT-3.5 (Generative Pre-trained Transformer)</code>, <code>GPT-4</code> , <code>Llama 3</code> ,<code> Google's Gemini 1.5 pro</code> , <code>Anthropic Claude 3.0</code> , <code>Mistral 7B</code> ,<code>Mixtral 8x22B.</code> etc. are capable of generating human-like text responses. LLM models have been pre-trained on diverse sources of text data, enabling them to learn patterns, grammar, and context from a wide range of topics. They can be fine-tuned for specific tasks, such as question-answering, natural language understanding, and text generation.\n",
    "LLM models have achieved impressive results in various natural language processing tasks and are widely used in AI applications for generating human-like text responses.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c580be87-0e72-43af-95ad-42578b88bf11",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>What is trusted AI?</b></p>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;color:#00233C'><strong>Trusted AI</strong> in the context of generative AI refers to the development and deployment of AI systems that prioritize ethical considerations, fairness, transparency, privacy, and security. Generative AI, which includes models like GPT (Generative Pre-trained Transformer), produces human-like text, images, or other data based on patterns learned from large datasets.</p>\n",
    "\n",
    "<ul style='font-size:16px;font-family:Arial;color:#00233C'>\n",
    "  <li><strong>Ethical Considerations:</strong> Trusted generative AI operates within ethical boundaries, ensuring that the generated content aligns with societal norms and values. It avoids promoting harmful or offensive content.</li>\n",
    "  <li><strong>Fairness:</strong> The AI model should produce outputs that are fair and unbiased across different demographic groups. It should not propagate stereotypes or discrimination.</li>\n",
    "  <li><strong>Transparency:</strong> The inner workings of the generative AI model should be transparent and understandable to stakeholders, including developers, users, and regulatory authorities. Transparency helps build trust and facilitates accountability.</li>\n",
    "  <li><strong>Privacy:</strong> Trusted generative AI respects user privacy by safeguarding sensitive information and ensuring that generated content does not compromise individuals' privacy rights. This includes anonymizing or minimizing personal data used in training.</li>\n",
    "  <li><strong>Security:</strong> AI models should be designed with robust security measures to prevent malicious actors from manipulating or exploiting the system. This includes protecting against adversarial attacks and ensuring the integrity of generated content.</li>\n",
    "  <li><strong>Accountability:</strong> Developers and organizations responsible for generative AI systems should be accountable for their actions and the outcomes produced by their models. This entails establishing clear lines of responsibility and mechanisms for addressing unintended consequences or ethical breaches.</li>\n",
    "  <li><strong>Continual Monitoring and Improvement:</strong> Trusted AI is an ongoing process that requires continual monitoring and improvement. Developers should regularly assess the performance of their generative AI models, address emerging ethical concerns, and incorporate feedback from stakeholders to enhance trustworthiness.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d96beb-51cf-4cce-bbec-d7aaedbdfaba",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Why Vantage?</b></p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Chatbot, powered by Machine Learning and Artificial Intelligence, offer numerous advantages in the context of improving customer experience, particularly in the banking and financial institutions sector. Traditional methods of visiting a bank or financial institution in person and providing extensive information, which is then manually reviewed by an officer, are often time-consuming, error-prone, and rely on outdated manual processes.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Vantage provides these same proven capabilities to search user details, proving personalized offers, helping to calculate mortgage,etc, integrated as native ClearScape Analytic functions. This allows organizations to drastically reduce human workforce by chatbot, while allowing for much more user friendly and easy interactions.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca49b9d-df0b-400a-acf8-0252ab8a2618",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233c'><b>Steps in the analysis:</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Configuring the environment</li>\n",
    "    <li>Connect to Vantage</li>\n",
    "    <li>Data Exploration</li>\n",
    "    <li>Setup VectorDB</li>\n",
    "    <li>Setup LLM</li>\n",
    "    <li>Launch the Chatbot</li>\n",
    "    <li>Cleanup</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833b5bf-74af-42be-8543-3782e1da95dc",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233C;'>\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233c'>1. Configuring the environment</b>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Note:</b>The installation of the required libraries will take approximately <b>4 to 5 minutes</b> for the first-time installation. However, if the libraries are already installed, the execution will complete within 5 seconds.</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6027a7-888d-441f-abc7-a6ea1c45f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade -r requirements.txt --quiet\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca97cdce-0d5e-4e54-b404-da7bae24ef51",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <i>The above statements will install the required libraries to run this demo. To gain access to installed libraries after running this, restart the kernel.</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b160ce-5ace-4116-86b6-394d6502553b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Note:</b> We may need to uncomment the above statements if we run the notebooks on a platform other than ClearScape Analytics Experience that does not have the libraries installed. If we uncomment those installs, we should be sure to restart the kernel after executing those lines to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing zero zero: <b>0 0</b></i></p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98b8169-9164-4916-9966-660aa51e5395",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Note:</b> To ensure that our Chatbot interface reflects the latest changes, please reload the page by clicking the 'Reload' button or pressing F5 on our keyboard for <b>first-time only</b>. This will update the notebook with the latest modifications, and we'll be able to interact with the Chatbot using the new libraries.</i></p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61067c88-2e9a-4c92-985b-34dc4ab74a13",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>1.1 Import the required libraries</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50a4aa-1211-44fc-8166-317c35253207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "display.print_sqlmr_query = False\n",
    "display.suppress_vantage_runtime_warnings = True\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# teradata lib\n",
    "from teradataml import *\n",
    "display.max_rows = 5\n",
    "\n",
    "\n",
    "# LLM\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_core.callbacks import FileCallbackHandler\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "\n",
    "from langchain.agents.format_scratchpad.openai_tools import (\n",
    "    format_to_openai_tool_messages,\n",
    ")\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "# helpers\n",
    "from utils.chromadb_helper import ChromaDB_VectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59718f8-7af4-4d1a-abc7-a860eb7cbae3",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233C;'>\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233c'>2. Connection to Vantage and OpenAI</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b504548-5baf-44c0-964e-53fa9773934a",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>2.1 Connect to Vantage</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f458384d-7c3b-4ee7-a36f-8c9ceb985111",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)\n",
    "execute_sql('''SET query_band='DEMO=PP_Mortgage_Calculator_Python_TrustedAI_Finetune_LLM.ipynb;' UPDATE FOR SESSION;''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f02c0d-5c4c-4838-bf89-4945bdf4acd0",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acee54a-4170-41fa-9d3b-473bb11e9301",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>2.2 Get the OpenAI API key</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c3f448-75ed-4247-ba0e-623af577ba09",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>To utilize this demo, we need an OpenAI API key. If we don't have one yet, we can refer to the instructions provided in this guide to obtain our OpenAI API key. </p>\n",
    "\n",
    "\n",
    "<a href=\"..//Openai_setup_api_key/Openai_setup_api_key.md\" style=\"text-decoration:none;\" target=\"_blank\">\n",
    "    <button style=\"font-size:16px;font-family:Arial;color:#fff;background-color:#00233C;border:none;border-radius:5px;cursor:pointer;height:50px;line-height:50px;display:flex;align-items:center;\">OpenAI API Key Guide <span style=\"margin-left:10px;\">&#8658;</span></button>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744f0f34-de6a-4d34-a96e-de6b21899c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "# enter your OpenAI API key\n",
    "api_key = getpass.getpass(prompt=\"\\n Please Enter OpenAI API key: \")\n",
    "# OpenAI API\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beec557-411b-4418-acf3-2f28d3c6beac",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>2.3 Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the cell below, we are synthetically generating a few records for the <b>Customer</b> and <b>Interest</b> tables. This will allow us to test the functionality of our Chatbot with a small set of data before loading the entire dataset.For the Customer table, we are generating 10 records with randomized names, emails, and phone numbers, account details, etc.  We are also assigning a unique customer ID to each record. For the Interest table, we are generating 5 records with randomized interest rates based on minimum and maximum of credit score.  We are also assigning a unique interest ID to each record.By generating this sample data, we can quickly test the application's ability to display customer information and interests.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In addition to this, we are loading data for <b>RealEstate, Locality, NearbyLocality, School, and ShoppingCenter</b>. We take RealEstate data from Kaggle, clean it first, and then add it to Vantage tables in the below code.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b11997-40c6-4189-acef-97e0afe23f45",
   "metadata": {},
   "source": [
    "<p style='font-size:16px;font-family:Arial;color:#00233C'>We iterate through a dictionary mapping file names to primary keys, read corresponding CSV files using Pandas, and copy the data to Vantage using the teradataml <b>copy_to_sql</b> function. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0036808e-ed2a-4b81-9f30-c61ba9c7f55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dict = {\n",
    "    \"Customer\": \"CustomerID\",\n",
    "    \"Interest\": \"ID\",\n",
    "    \"RealEstate\": \"PropertyID\",\n",
    "    \"Locality\": \"LocalityID\",\n",
    "    \"NearbyLocality\": \"LocalityID\",\n",
    "    \"School\": \"SchoolID\",\n",
    "    \"ShoppingCenter\": \"StoreID\",\n",
    "}\n",
    "\n",
    "print(\"-\" * 25, \"data ingestion started\", \"-\" * 25)\n",
    "for file in files_dict:\n",
    "    df = pd.read_csv(os.path.join(\"./data/\", f\"{file}.csv\"))\n",
    "    print(\"Copying data to Vantage for: \", file)\n",
    "    print(f\"Data information: {df.shape}\")\n",
    "    copy_to_sql(\n",
    "        df, table_name=file, primary_index=files_dict[file], if_exists=\"replace\"\n",
    "    )\n",
    "\n",
    "print(\"-\" * 25, \"data ingestion completed\", \"-\" * 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f3fe2-ed63-4838-bb19-4c0d0157453d",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233C;'>\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233c'>3. Data Exploration</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The goal of the Mortgage Chatbot is to provide a user-friendly interface for individuals to quickly and easily find personalized mortgage information. The chatbot aims to streamline the mortgage process by allowing users to ask questions in natural language and receive accurate, concise answers and calculations. By integrating with Vantage, the chatbot can retrieve relevant data and perform calculations to provide users with tailored mortgage options, empowering them to make informed decisions and save time in their home buying journey. </p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In our database, we have total seven tables, we can categorize it into two: </p>\n",
    "    <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "                <li> Financial tables</li>\n",
    "                <li> Property tables</li>\n",
    "    </ol>\n",
    "\n",
    "<br/>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'><li> <b>Financial tables:</b></li></ol>\n",
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> There are two tables: <b>customer</b> and <b>interest</b>. The customer table contains personal and financial information, while the interest table has details on credit score ranges and their corresponding interest rates.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The data is synthetically generated, with a few rows of customer data, including name, address, email, account number, balance, income, and other relevant information.<p/>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Each row represents a snapshot of data captured at a specific point in time, and each column represents a different variable. The input dataset is as follows:</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> \n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Customer data</b> i.e. first-name, last-name, date of birth, address, city, account number, Balance, branch id, account status, income etc.</li>\n",
    "    <li><b>Interest data</b>: min credit score, max credit score, interest rate.</li>\n",
    "</ul>\n",
    "</p>\n",
    "<br/>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C', start=2><li> <b>Property tables:</b></li></ol>\n",
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We have five tables that cover various aspects, ranging from real estate to locality details. For instance, let's take the locality of <b>Larrakeyah</b>, situated <b>9.0 km away from the airport</b>, boasting a <b>livability score of 4.3.</b> In Larrakeyah, we find <b>three schools:</b> St John's Catholic College, Larrakeyah Primary School, and Essington International School. Moreover, there are <b>two shopping centers:</b> Larrakeyah Shopping Complex and Larrakeyah Supermart.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We see each row as a snapshot of data captured at a specific point in time, and each column represents a different variable. This is our input dataset.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> \n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "   <li><b>RealEstate data</b>:LocalityID, PropertyID, PropertyType, BuildingSize, LandSize, PreferredSize, OpenDate, ListingAgency, Price, Address, City, State, ZipCode, Phone, \n",
    "       BedroomCount, BathroomCount, ParkingCount</li>\n",
    "    <li><b>Locality data</b>: LocalityID, LocalityName, LocalityDescription, DistanceFromAirport, LivabilityScore</li>\n",
    "    <li><b>NearbyLocality data</b>: LocalityID, LocalityName, NearbyLocalityID</li>\n",
    "    <li><b>School data</b>: SchoolID, SchoolName, LocalityID</li>\n",
    "    <li><b>ShoppingCenter </b>: StoreID, StoreName, Type, LocalityID</li>\n",
    "</ul>\n",
    "</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The source data from <a href=\"https://www.kaggle.com/datasets/thedevastator/australian-housing-data-1000-properties-sampled\">kaggle</a> is loaded in Vantage with table named <i>RealEstate</i>.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b><i>*Please <a href=\"#datasetInfo1\">click here</a> to scroll down to the end of the notebook for detailed column descriptions of the dataset.</i></b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda8e565-b58b-4cc6-8d9c-50790ca3dcab",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>3.1 Examine the Customer and Interest table</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Let's look at the sample data in Customer table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9951cf-e2b0-40d7-9a8f-a01c7f48ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_customer = DataFrame(\"Customer\")\n",
    "\n",
    "print(\"Data information: \\n\", tdf_customer.shape)\n",
    "tdf_customer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d6d954-b72f-41c3-9f8c-bc15cf74d672",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>There are 10 records in all, and there are 18 variables.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Now, let's delve into the interest table. Here, we determine interest rates based on customers' minimum and maximum credit scores.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cad00db-08e5-40d3-a3d2-2be92908a95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_interest = DataFrame(\"Interest\")\n",
    "\n",
    "print(\"Data information: \\n\", tdf_interest.shape)\n",
    "tdf_interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027b6add-e7fa-4381-8d73-2c6a86daaf7f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Let's examine that interest rate in light of a person's credit score. Here, we may determine the interest rate for each individual consumer by examining the credit score range min and max from the interest table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72874be1-a21c-4bd3-bbf3-8d346d89a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "    SELECT c.FirstName, c.LastName, c.CreditScore, i.InterestRate \n",
    "    FROM Customer c \n",
    "    JOIN Interest i ON c.CreditScore BETWEEN i.MinCreditScore AND i.MaxCreditScore\n",
    "    WHERE c.CustomerID = 'CID3058245';\n",
    "\"\"\"\n",
    "\n",
    "DataFrame.from_query(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626e8ab6-5e2b-42b3-aee7-cdd7e921b205",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We can observe that Customer John Doe possesses a credit score of 720, falling within the range of 670 to 739. Therefore, we will offer him a 3.9% interest rate.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59570bd2-6080-47ea-9221-29e0857b001e",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>3.2 Examine the property tables</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Let's look at the sample data in <b>RealEstate</b> table first.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad64fb76-c52d-47d6-9b56-33676481aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_real_estate = DataFrame(\"RealEstate\")\n",
    "\n",
    "print(\"Data information: \\n\", tdf_real_estate.shape)\n",
    "tdf_real_estate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fc813e-c9b4-4a0b-bd72-d8c0699fa09e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We can see that we have ample details about the property here, such as property type, land size, bedroom count, contact details, price, full address, etc. These are crucial details for customers when we search for properties.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Next, let's examine the sample data in our <b>Locality</b> table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616ed3d-07ac-4e22-9de1-26d7ef8c4bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_locality = DataFrame(\"Locality\")\n",
    "\n",
    "print(\"Data information: \\n\", tdf_locality.shape)\n",
    "tdf_locality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa12939b-905a-44b5-a8cb-a7feac803778",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the above table, we can gain a better understanding of the locality, including its distance from the airport and livability score.</p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Thirdly, let's review the sample data in our <b>NearbyLocality</b> table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d63118-b13c-4934-b75f-796c04fe2ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_nearby_locality = DataFrame(\"NearbyLocality\")\n",
    "\n",
    "print(\"Data information: \\n\", tdf_nearby_locality.shape)\n",
    "tdf_nearby_locality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d282ff89-5cce-4874-94b0-e77ed25ffbdf",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Next, let's review the sample data in our <b>School</b> table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cd070a-c269-4160-b99e-c7697c5fb423",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_school = DataFrame(\"School\")\n",
    "\n",
    "print(\"Data information: \\n\", tdf_school.shape)\n",
    "tdf_school"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a5128-f218-40db-94d8-d09a8c434e08",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Next, let's review the sample data in our <b>ShoppingCenter</b> table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b01a8f-c099-4bcf-86c3-86c351a0cb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_shopping_center = DataFrame(\"ShoppingCenter\")\n",
    "\n",
    "print(\"Data information: \\n\", tdf_shopping_center.shape)\n",
    "tdf_shopping_center"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffd19cf-7214-4cfc-b88f-74ccc4b6c845",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>3.3 Get database schema</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Build a consolidated view of Table Data Catalog by combining metadata stored for the database and table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e9e675-7385-4a31-9f27-c779f693a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_d = {\n",
    "    \"Customer\": tdf_customer.columns,\n",
    "    \"Interest\": tdf_interest.columns,\n",
    "    \"RealEstate\": tdf_real_estate.columns,\n",
    "    \"Locality\": tdf_locality.columns,\n",
    "    \"NearbyLocality\": tdf_nearby_locality.columns,\n",
    "    \"School\": tdf_school.columns,\n",
    "    \"ShoppingCenter\": tdf_shopping_center.columns,\n",
    "}\n",
    "\n",
    "\n",
    "def get_db_schema():\n",
    "    table_dicts = []\n",
    "    for k in main_d:\n",
    "        table_dicts.append(\n",
    "            {\n",
    "                # \"database_name\": database,\n",
    "                \"table_name\": k,\n",
    "                \"column_names\": main_d[k],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    database_schema_string = \"\\n\".join(\n",
    "        [\n",
    "            f\"Table: {table['table_name']}\\nColumns: {', '.join(table['column_names'])}\"\n",
    "            for table in table_dicts\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return database_schema_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bd3ec9-1336-4b0c-9693-0e86f2b7b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_schema = get_db_schema()\n",
    "print(database_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c6cfeb-838d-4409-a283-e35c8cd3b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "\n",
    "\n",
    "def is_sql_return_results(qry):\n",
    "\n",
    "\n",
    "    with eng.connect() as connection:\n",
    "\n",
    "\n",
    "        results_as_dict = connection.execute(text(qry)).mappings().all()\n",
    "\n",
    "\n",
    "        print(f\"Total results from DB: {len(results_as_dict)}\")\n",
    "\n",
    "\n",
    "        return True if len(results_as_dict) > 0 else False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed56e186-3b79-4dde-bb2c-3d4a0f539876",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233c'><b>4. Setup VectorDB</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In this step we'll build a VectorDB by passing documents, DDL and SQL queries which will helps to SQLAgent for build accurate queries. We are using Chroma vectorDB here, to read more about it please click <a href='https://docs.trychroma.com/'>here.</a> This step can be divided into 2 phases.</p>\n",
    "\n",
    "<ul style='font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li><b>Phase-1 Training:</b>\n",
    "        <ul style='font-size:16px;font-family:Arial;color:#00233C'>\n",
    "            <li><b>Train with DDL Statements: </b>They contain information about our table names, columns, data types, and relationships in our database.</li>\n",
    "            <li><b>Train with Documentation: </b>We may want to add documentation about our business terminology or definitions, which can help us, as well as the LLM, to build a better SQL.</li>\n",
    "            <li><b>Train with Teradata SQL: </b>We can also add SQL queries to our training data. This is useful if we have some queries already stored in the VectorDB. So, if a user asks a similar question, the LLM can retrieve reference SQL from the VectorDB.</li></ul>\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'><li><b>Phase-2 Inference: </b>\n",
    "<ol style='font-size:16px; font-family:Arial; color:#00233C;'>\n",
    "  <li>User asks a question.</li>\n",
    "  <li>The question is converted into embeddings.</li>\n",
    "  <li>These embeddings are used to search the VectorDB for similar SQL queries, tables, or documents.</li>\n",
    "  <li>VectorDB returns the top 3 similar documents/SQL queries/DDL statements.</li>\n",
    "  <li>The retrieved information is passed to the next step for generating the prompt.</li>\n",
    "  <li>A prompt generator constructs a prompt based on the retrieved information.</li>\n",
    "  <li>The constructed prompt is passed to SQLAgent or the LLM to generate the final SQL query.</li>\n",
    "  <li>The final SQL query is executed on Teradata.</li>\n",
    "</ol>\n",
    "</li></ul>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following diagram illustrates the architecture.</p>\n",
    "\n",
    "<center><img src=\"images/rag_arch.png\" alt=\"rag\"  width=852 height=669/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73860257-1ad3-477c-9c52-957dd71937c4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the below code will build a vectorDB and store the data under <code>chroma_vectordb</code> directive.</p></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cad28b-90c8-4c72-a09d-9c00fc13dccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rag(db):\n",
    "    print(\"--\" * 25, \" training started \", \"--\" * 25)\n",
    "\n",
    "    ## add docs\n",
    "    db.add_documentation(\n",
    "        documentation=\"Our business is dedicated to assisting users in finding the optimal properties and navigating the complexities of mortgage calculations.\"\n",
    "    )\n",
    "\n",
    "    # read que-sql pairs from csv\n",
    "    df_sql = pd.read_csv(\"./data/sql_queries.csv\")\n",
    "\n",
    "    ## add SQL\n",
    "    for index, row in df_sql.iterrows():\n",
    "        # print(f\"Question: {row['question']} \\nSQL: {row['sql']}\\n\")\n",
    "        db.add_question_sql(question=row[\"question\"], sql=row[\"sql\"])\n",
    "\n",
    "    # add ddl\n",
    "    db.add_ddl(ddl=database_schema)\n",
    "    print(\"--\" * 25, \" training completed \", \"--\" * 25)\n",
    "\n",
    "\n",
    "# define vectordb\n",
    "chroma = ChromaDB_VectorStore()\n",
    "train_rag(chroma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b0567-6a55-42da-af87-a9672f7feeca",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>At any time, we can inspect the training data that the package is able to reference.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807dd6b9-ce41-4d95-8347-80222322f283",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma.get_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95764e3-69a8-433a-8c0a-55824ffc7857",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We have the capability to remove training data if there's obsolete or incorrect information by passing the <code>xxx-id</code></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679ec89d-8b6a-48ce-b459-936282d5f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chroma.remove_training_data(id=\"xx-sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9132faf3-5e5b-44d3-b473-e8f9349bf2e5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We utilize this method to generate a prompt for the LLM (Large Language Model) to generate accurate SQL queries by passing user's question.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d06a95e-72f3-4b7c-a814-721d3c49adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_from_vectordb(question):\n",
    "    question_sql_list = chroma.get_similar_question_sql(question)\n",
    "    ddl_list = chroma.get_related_ddl(question)\n",
    "    doc_list = chroma.get_related_documentation(question)\n",
    "\n",
    "    initial_prompt = None\n",
    "    return chroma.get_sql_prompt(\n",
    "        initial_prompt=initial_prompt,\n",
    "        question=question,\n",
    "        question_sql_list=question_sql_list,\n",
    "        ddl_list=ddl_list,\n",
    "        doc_list=doc_list,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9647745b-ce30-400e-9bdc-ceabdf0c47ba",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>To take a look at how the prompt looks, simply uncomment the code below and modify the question if desired.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c48578-b88f-42a4-b776-be7f93eb0707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"which is the best locality near to city center?\"\n",
    "# generated_prompt = generate_prompt_from_vectordb(question)\n",
    "# print(generated_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89367d27-22ca-4a0e-b299-0f8e1a669157",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233C;'>\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233c'>5. Setup LLM </b>\n",
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>5.1 Connect to database using SQLAlchemy and Initialize the Large Language Model</b></p>    \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Under the hood, LangChain uses SQLAlchemy to connect to SQL database. The SQLDatabaseToolkit can therefore be used with any SQL dialect supported by SQLAlchemy, such as Teradata Vantage, MS SQL, MySQL, MariaDB, PostgreSQL, Oracle SQL, and SQLite. Please refer to the <a href=\"https://docs.sqlalchemy.org/en/20/\"> SQLAlchemy documentation</a> for more information about requirements for connecting to your database. The SQLDatabaseToolkit builds off of SQLDatabaseChain and is designed to answer more general questions about a database, as well as recover from errors.</p>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Important Note:</b> The code below establishes a database connection for data sources and Large Language Models. Please note that the solution will only work if the database connection for your sources is defined in the cell below. In addition to this, to use OpenAI models, we have to set OpenAI API key to environment variable.</i></p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbceafb4-793b-4d62-ab22-c9d49ac9a759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define DB\n",
    "db = SQLDatabase(eng)\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI API\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6983640-c595-4185-9390-76ad933f3870",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In this demo we will be using OpenAI’s <code>gpt-3.5-turbo-0125</code> model as LLM. To view list of available models on OpenAI <a href='https://platform.openai.com/docs/models'>click here</a></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In OpenAI's language models, the <b>temperature</b> parameter controls the randomness of the generated text. It affects the diversity and creativity of the model's responses. It is always a number between 0 and 1. A temperature of 0 means the responses will be very straightforward, almost deterministic (meaning we almost always get the same response to a given prompt). A temperature of 1 means the responses can vary wildly.</p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>A higher temperature value, such as 1.0, increases the randomness and diversity of the generated output. This can lead to more varied and surprising responses, but it may also result in less coherence and occasional nonsensical outputs. A higher temperature means that the model might select a word with slightly lower probability, leading to more variation, randomness and creativity. A very high temperature therefore increases the risk of <b>hallucination</b>, meaning that the model starts selecting words that will make no sense or be off the topic.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>On the other hand, a lower temperature value, such as 0.2 or below, reduces randomness and makes the model's output more focused and deterministic. The generated text is likely to be more conservative, sticking closely to patterns observed in the training data. A temperature of 0 means roughly that the model will always select the highest probability word.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Choosing an appropriate temperature value depends on the desired output. Higher temperatures can be useful for creative tasks or brainstorming, while lower temperatures are preferred when we need more control over the output, such as when generating specific responses or following a particular style.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680228a2-3bfa-44f4-8a02-b73fa8bf8e95",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>5.2 Setup SQLAgent</b></p> \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Before jumping into the chatbot, let us first understand what is an agent and why it might be preferred over a simple SQLChain.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>An agent is a component that has access to a suite of tools, including a Large Language Model (LLM). Its distinguishing characteristic lies in its ability to make informed decisions based on user input, utilizing the appropriate tools until it achieves a satisfactory answer. For example in the context of text-to-SQL, the LangChain SQLAgent will not give up if there is an error in executing the generated SQL. Instead, it will attempt to recover by interpreting the error in a subsequent LLM call and rectify the issue. Therefore, in theory, SQLAgent should outperform SQLChain in productivity and accuracy.</p>\n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We can think of agents as enabling tools for LLMs. Like how a human would use a calculator for maths or perform a Google search for information — agents allow an LLM to do the same thing.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f0cef5-bb5f-48f8-b557-4a8e208c926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "import uuid\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain_core.agents import AgentAction\n",
    "import ast\n",
    "\n",
    "\n",
    "# First, define custom callback handler implementations\n",
    "class ToolCallbackHandler(BaseCallbackHandler):\n",
    "    def __init__(self, sql=None):\n",
    "        if sql is None:\n",
    "            sql = {}\n",
    "\n",
    "    def on_tool_start(\n",
    "        self, serialized: Dict[str, Any], input_str: str, **kwargs: Any\n",
    "    ) -> Any:\n",
    "        name = serialized.get(\"name\")\n",
    "        print(f\"*** on_tool_start: *** {name}\")\n",
    "        if name in [\"sql_db_query\", \"sql_db_query_checker\"]:\n",
    "            _sql = ast.literal_eval(input_str)[\"query\"]\n",
    "            print(\"*** _sql: *** \", _sql)\n",
    "            if is_sql_return_results(_sql):\n",
    "                self.sql = _sql\n",
    "                print(f\"sql assigned: {self.sql}\")\n",
    "            else:\n",
    "                print(\"sql not assigned\")\n",
    "                self.sql = {}\n",
    "            return self.sql\n",
    "\n",
    "    def on_llm_end(self, output: str, **kwargs: Any) -> Any:\n",
    "        txt = output.generations[0][0].text\n",
    "        if txt != \"\":\n",
    "            print(\"--- on_llm_end ---\")\n",
    "            # print('TXT: \\n\\n', txt, '\\n\\n')\n",
    "            resp_dict = ast.literal_eval(output.generations[0][0].text)\n",
    "            _sql = resp_dict.get(\"SQL\", \"Key not found\")\n",
    "            _error = resp_dict.get(\"error\", \"Key not found\")\n",
    "            print(f\"_sql: {_sql}\")\n",
    "            print(f\"_error: {_error}\")\n",
    "\n",
    "            # set SQL\n",
    "            if is_sql_return_results(_sql):\n",
    "                self.sql2 = _sql\n",
    "                print(f\"sql2 assigned: {self.sql2}\")\n",
    "            else:\n",
    "                print(\"sql2 not assigned\")\n",
    "                self.sql2 = {}\n",
    "            return self.sql2\n",
    "\n",
    "\n",
    "# define handler\n",
    "tool_handler = ToolCallbackHandler()\n",
    "\n",
    "\n",
    "# define SQL Agent\n",
    "@tool\n",
    "def generate_sql(input: str) -> str:\n",
    "    \"\"\"Given an input question, first create a syntactically correct Teradata-style query to execute, then look at the results of the query and return the answer.\"\"\"\n",
    "    generated_prompt = generate_prompt_from_vectordb(input)\n",
    "\n",
    "    generated_prompt = (\n",
    "        generated_prompt\n",
    "        + \"\"\"Alway return Final output in json format.\n",
    "                Final output:\n",
    "                    - SQL:\n",
    "                    - Answer:\"\"\"\n",
    "    )\n",
    "    # print(f\"\\n\\n generated_prompt: \\n\\n{generated_prompt} \\n\\n\")\n",
    "\n",
    "    messages = [\n",
    "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "        AIMessage(content=generated_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(messages)\n",
    "    agent_executor = create_sql_agent(\n",
    "        llm,\n",
    "        db=db,\n",
    "        agent_type=\"openai-tools\",\n",
    "        verbose=True,\n",
    "        prompt=prompt,\n",
    "        max_iterations=10,\n",
    "        max_execution_time=20,\n",
    "        handle_parsing_errors=True,\n",
    "        return_intermediate_steps=True,\n",
    "        handle_sql_errors=True,\n",
    "        max_tokens=4000,\n",
    "    )\n",
    "\n",
    "    return agent_executor.run(input, callbacks=[tool_handler])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97e139d-d129-44c2-bf42-181d7b928164",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the code above, we're initializing SQLAgent by passing in LLM, SQLDatabaseToolkit, database, and agent type as OpenAI tools. Agents use an LLM to determine the best course of action and execute it. An action can either be using a tool and observing its output, or responding to the user. <a href='https://python.langchain.com/docs/modules/agents/agent_types/'>Here</a> are the agents available in LangChain.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>OpenAI tools in LangChain refer to the integration of OpenAI's language models with external tools and services to enhance their capabilities and provide more accurate and informative responses. LangChain is a framework that enables the development of applications powered by language models, and it supports the use of OpenAI models as the language understanding component.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The OpenAI tools in LangChain are designed to overcome the limitations of language models, such as the lack of recency and specificity in their training data, by allowing them to access external knowledge bases and APIs dynamically. This enables the models to answer questions with context directly from search engines, APIs, or internal databases, and to perform intermediate steps to gather relevant information. Please refer this <a href='https://python.langchain.com/v0.1/docs/modules/agents/agent_types/openai_tools/'>openai-tools</a> for more information.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f923edc3-4242-4ab4-8512-a7d7353b7210",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233C;'>\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233c'>6. Launch the Chatbot</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In this demo we are using ChatOpenAI model with Memory. This advanced technology allows us to store and recall conversations, enabling our chatbot to provide more personalized and informed responses.As a mortgage advisor, our chatbot is trained to assist with a wide range of loan-related inquiries. Whether you're looking to purchase a new home, refinance an existing loan, or simply have questions about the mortgage process, our chatbot is here to help.To begin, we'll set the prompt for our chatbot to work as a mortgage advisor. This will enable it to provide tailored advice and guidance based on your unique needs and circumstances.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adb0962-73b3-4f07-abcb-377b2e382458",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Note:</b>Please note that our chatbot is specifically designed to address questions related to mortgage loans. If we have a question outside of this scope, we kindly ask that we refrain from asking it. This will help us provide ourselves with the most accurate and efficient assistance possible.</i></p> </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6647969-a008-47c6-93de-0a4769da02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# default customer\n",
    "CustomerID = \"CID3058245\"\n",
    "\n",
    "# define tools\n",
    "tools = [generate_sql]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    return_messages=True,\n",
    "    memory_key=\"chat_history\",\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "# For writing logs\n",
    "from loguru import logger\n",
    "\n",
    "now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "logfile = f\"./logs/rag_sql_agent_output_{now}.log\"\n",
    "logger.add(\n",
    "    logfile,\n",
    "    colorize=True,\n",
    "    enqueue=True,\n",
    "    level=\"DEBUG\",\n",
    "    backtrace=True,\n",
    "    diagnose=True,\n",
    "    format=\"{time} {level} {message}\",\n",
    ")\n",
    "file_handler = FileCallbackHandler(logfile)\n",
    "config = {\"callbacks\": [file_handler]}\n",
    "\n",
    "# main prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            f\"\"\"You'll be working as property advisor and mortgage advisor and I will play the role of the user.\n",
    "            \n",
    "            * General Instructions for Chatbot:\n",
    "            1) Start the chat with greeting and ask the questions to user as mentioned below. Greet user by starting the message: \n",
    "              ## Welcome to Property and Mortgage Chatbot! \\n\n",
    "              I'm here to provide you with expert advice and answers. \\n\n",
    "              ### Let's get started! \\n\n",
    "              Could you please share your property preferences with me?\n",
    "            2) Ask questions sequentially - pausing between each question to wait for a response before proceeding to the next.\n",
    "            3) Most important: Do not ask all the questions together, ask one by one.\n",
    "            4) Whenever possible, give the answer in bulleted points and title in markup. like ##\n",
    "            5) Consider current user: {CustomerID}\n",
    "            6) If the user fails to provide a response or says 'I don't know' for a question, automatically call the 'generate_sql' function to retrieve the answer from the database.\n",
    "            7) Most important: If 'generate_sql' function fail to give the answer, then just say \"Sorry, I am unable to get the answer.\" Do not make any answer by yourself.\n",
    "            \n",
    "            * Instructions to follow when working as a property advisor:\n",
    "            1) As a property advisor first ask a series of questions related to property like preferred locality, number of bedrooms, etc.  \n",
    "            2) As a property advisor, Always end your response with the next Question. Do not ask same question more than one time.\n",
    "            3) As a property advisor, you have direct access of property data includes tables like RealEstate, Locality, NearbyLocality,  ShoppingCenter, School. \n",
    "            Only Suggest properties that exist in these tables.\n",
    "            4) Always give property options with details like Property ID, Property Type, Building Size, Price, Address, Bedroom Count.\n",
    "            5) Most important: Once you suggest the property, ask user Do you like this or shall I suggest more? Once the user select the property, then only perform a role of mortgage advisor.\n",
    "            \n",
    "            * Instructions to follow when working as a mortgage advisor:\n",
    "            1) Most important: Once user select the property then only ask for mortgage related questions like monthly income, credit score, bank balance etc.\n",
    "            2) As a mortgage advisor for the bank you have direct access to the banks data for user. The banks data includes tables like Customer and Interest\n",
    "            3) Once user select a property, then only ask about mortgage related questions. You can ask question like below one by one:\n",
    "             -  question 1: Income: What is your total annual income, including any additional sources of income?\n",
    "             -  question 2: What is your employment status?\n",
    "             -  question 3: What's your credit score? I can help you find out which interest rates you qualify for.\n",
    "            4)  Do not call unnecessarily the 'generate_sql' function until it is really needed when working as mortgage advisor.\n",
    "            5) Do not call unnecessarily the 'generate_sql' function until it is really needed when working as mortgage advisor.\n",
    "            6) At the end of above 3 questions provide a succinct summary paragraph of these details.\n",
    "            \n",
    "            \n",
    "            * Remember the Instructions for final output:\n",
    "            1) Provide a succinct summary paragraph of these details as a response to the client but don't show the method of calculation. \n",
    "            Follow with a formatted table of monthly amounts (gross income, tax obligation, mortgage obligation, expenses, remaining disposable income).\n",
    "            Also provide best property options based on user's data.\n",
    "            2) Provide an opinion as to whether the mortgage is affordable and what the maximum borrowing amount could be\n",
    "            3) Most important: If 'generate_sql' function fail to give the answer, then just say \"Sorry, I am unable to get the answer.\" Do not make any answer by yourself.\n",
    "            4) Most Important: Give me reasoning as well as answers for this given questions. \n",
    "                Instructions for Reasoning:\n",
    "                    - Give me Reasoning in details.\n",
    "                    - Only one sentence reasoning would be good.\n",
    "                    - Be transparent and Unbiased so user can trust on answer.\n",
    "            5) Most important: Reasoning is mandatory in the final summary.\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# define agent\n",
    "agent = (\n",
    "    RunnablePassthrough.assign(\n",
    "        agent_scratchpad=lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        )\n",
    "    )\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")\n",
    "\n",
    "# define Agent executor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    "    max_iterations=10,\n",
    "    handle_parsing_errors=True,\n",
    "    max_execution_time=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b8440f-3934-4fa1-b0fb-d8cff5f80dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_properties(response):\n",
    "    prop_ids = re.findall(r\"Property ID:\\*\\* (\\d+)\", response)\n",
    "    if len(prop_ids) == 0:\n",
    "        prop_ids = re.findall(r\"PropertyID:\\*\\* (\\d+)\", response)\n",
    "    if len(prop_ids) == 0:\n",
    "        prop_ids = re.findall(r\"Property ID: (\\d+)\", response)\n",
    "    return prop_ids\n",
    "\n",
    "\n",
    "def validate_property_ids(property_ids):\n",
    "    property_ids = \",\".join(property_ids)\n",
    "\n",
    "    q = f\"\"\"SELECT PropertyID FROM demo_user.RealEstate WHERE PropertyID in ({property_ids})\"\"\"\n",
    "    temp_df1 = DataFrame.from_query(q)\n",
    "    logger.info(f\"temp_df1 shape: {temp_df1.shape}\")\n",
    "\n",
    "    return True if len(property_ids.split(\",\")) == temp_df1.shape[0] else False\n",
    "\n",
    "\n",
    "def find_partial_match(arr, target, min_match=3):\n",
    "    for element in arr:\n",
    "        count = 0\n",
    "        for word in element.split():\n",
    "            if word.lower() in target.lower():\n",
    "                count += 1\n",
    "        if count >= min_match:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "questions = [\n",
    "    \"What is your total annual income, including any additional sources of income?\",\n",
    "    \"What is your employment status?\",\n",
    "    \"What's your credit score?\",\n",
    "]\n",
    "\n",
    "\n",
    "def validate_response(response_output):\n",
    "    apl_msg = \"\"\"We apologize for the inconvenience. There could be various reasons for this issue, including:\n",
    "    - It seems we couldn't find an answer, which might be due to limited data and table information.\n",
    "    - To enhance our suggestions, could you please provide additional criteria or try asking the same question again later?\n",
    "    - Technical issues might be causing this delay.\n",
    "    - Thank you for your cooperation. Please try again later.\"\"\"\n",
    "\n",
    "    if \"Welcome to Property and Mortgage Chatbot\" in response_output:\n",
    "        logger.info(\" Entered into greet\")\n",
    "        if hasattr(tool_handler, \"sql\"):\n",
    "            tool_handler.sql = {}\n",
    "        return True, response_output\n",
    "    elif \"Agent stopped due to max iterations\" in response_output:\n",
    "        logger.info(\" Agent stopped due to max iterations \")\n",
    "        if hasattr(tool_handler, \"sql\"):\n",
    "            logger.info(f\" tool_handler {tool_handler.sql} \\n resetting now\")\n",
    "            tool_handler.sql = {}\n",
    "        logger.info(\n",
    "            \" Agent stopped due to max iterations, exiting with apologies msg... \"\n",
    "        )\n",
    "        return False, apl_msg\n",
    "    elif \"Sorry, I am unable to get the answer\" not in response_output:\n",
    "        logger.info(\n",
    "            \" looks valid response, validating properties and SQL\", level=\"DEBUG\"\n",
    "        )\n",
    "        # get prop ids from response\n",
    "        property_ids = get_properties(response_output)\n",
    "        logger.info(f\"found property_ids: {property_ids}\")\n",
    "\n",
    "        # first validate properties if retrieved property_ids\n",
    "        if len(property_ids) > 0 and validate_property_ids(property_ids):\n",
    "            logger.info(\" property validated \")\n",
    "\n",
    "            if hasattr(tool_handler, \"sql\"):\n",
    "                logger.info(f\" tool_handler SQL: {tool_handler.sql} \\n resetting now\")\n",
    "                tool_handler.sql = {}\n",
    "            logger.info(\" property validation done.. returning the response..\")\n",
    "            return True, response_output\n",
    "        elif (\n",
    "            hasattr(tool_handler, \"sql\")\n",
    "            and len(tool_handler.sql) > 0\n",
    "            and is_sql_return_results(tool_handler.sql)\n",
    "        ):  # if not a property related question\n",
    "            logger.info(\" there are valid SQL but not valid property \")\n",
    "\n",
    "            if hasattr(tool_handler, \"sql\"):\n",
    "                logger.info(f\" tool_handler SQL: {tool_handler.sql} \\n resetting now\")\n",
    "                tool_handler.sql = {}\n",
    "\n",
    "            logger.info(\" SQL is valid, returning the response..\")\n",
    "            return True, response_output\n",
    "        else:\n",
    "            logger.info(\n",
    "                \" there are NO valid SQL and no valid property, might be working as mortgage advisor... \"\n",
    "            )\n",
    "\n",
    "            if hasattr(tool_handler, \"sql\"):\n",
    "                logger.info(f\" tool_handler SQL: {tool_handler.sql} \\n resetting now\")\n",
    "                tool_handler.sql = {}\n",
    "\n",
    "            if find_partial_match(questions, response_output):\n",
    "                logger.info(\n",
    "                    \" Found at least 3 matching words! seems it working as mortgage advisor.. returning the response..\"\n",
    "                )\n",
    "                return False, response_output\n",
    "\n",
    "            logger.info(\n",
    "                \" there are NO valid SQL and no valid property, not working as mortgage advisor, exiting with apologies msg... \"\n",
    "            )\n",
    "            return False, apl_msg\n",
    "    else:\n",
    "        if hasattr(tool_handler, \"sql\"):\n",
    "            logger.info(f\" tool_handler SQL: {tool_handler.sql} \\ resetting now\")\n",
    "            tool_handler.sql = {}\n",
    "\n",
    "        logger.info(\"It seems wrong response, exiting with apologies msg... \")\n",
    "        return False, apl_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6228de91-fc5f-4d8e-a524-ed98215f5519",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Note:</b>Chatbot is accessing multiple components, including databases and LLMs. This may cause a brief delay in responses. Your patience is appreciated.</i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaf68fe-495a-4be4-b409-af722cd988c8",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>6.1 User Guide: Property and Mortgage Chatbot</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Welcome to our Property and Mortgage Chatbot We're here to help ourselves effectively interact with our chatbot, providing assistance in both property selection and mortgage advice. Whether we're looking for our dream home or seeking mortgage options, we're here to guide ourselves every step of the way.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Getting Started:</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "  <li>Initiate the chatbot by sending us a greeting message. Simply say \"Hello\" or any other friendly greeting to start the conversation.</li>\n",
    "</ol>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Property Advisor:</b></p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "  <li><strong>Property Search:</strong> Ask us questions about properties, localities, amenities, etc. For example:\n",
    "    <ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "            <li><i>What is the mean price of 3 bedroom apartments in Larrakeyah area?</i></li>\n",
    "            <li><i>Can you provide information about the livability of the Bayview area?</i></li>\n",
    "            <li><i>Which agency handles property listings in the Woolner area?</i></li>\n",
    "            <li><i>Can you suggest apartments with a land size greater than 300 square meters and featuring at least two bedrooms?</i> </li>\n",
    "        </ul></li>\n",
    "  <li><strong>Select Property:</strong> Once we find a property of interest, note down its Property ID.</li>\n",
    "  <li><strong>Switch to Mortgage Advisor:</strong> To proceed to the mortgage advisory phase, provide type text with the Property ID of the selected property. For example: <i>I really like this property with ID 1351007</i></li>\n",
    "</ol>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Mortgage Advisor:</b></p>\n",
    "\n",
    "<ol  style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "  <li><strong>Provide Details:</strong> We'll ask for specific details such as your annual income, employment status, etc.</li>\n",
    "  <li><strong>Summary:</strong> Based on the information we provide, we'll generate a summary of the property and mortgage details.</li>\n",
    "  <li><strong>Affordability Calculation:</strong> We will receive information on the maximum house price we can afford based on our income and other relevant factors.</li>\n",
    "</ol>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Tips for Effective Interaction:</b></p>\n",
    "\n",
    "<ul  style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "  <li>Be specific and clear with your queries to receive accurate responses.</li>\n",
    "  <li>Provide accurate information when prompted, as it will help us provide personalized assistance.</li>\n",
    "  <li>We note down the Property ID of any property we are interested in to seamlessly transition to the mortgage advisory phase.</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Our Property and Mortgage Chatbot is designed to simplify our property search and mortgage process. By seamlessly transitioning from property advisor to mortgage advisor, we provide comprehensive assistance tailored to our needs. Start our journey now by sending a greeting message and let us guide ourselves towards our dream home and a suitable mortgage option!</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5b535c-c96e-4b39-b9b7-069d788b5623",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i><b>Sample summary: </b>An example of the tentative output the chatbot will provide at the end is shown below.</i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84043e4f-ed5a-4b21-8555-d14a743fa81a",
   "metadata": {},
   "source": [
    "<pre style='border: 1px; border-color:#00233C; border-style: outset; padding: 15px'>Based on the data, the credit score of the user with CID3058245 is 720.\n",
    "\n",
    "Summary: The user has a monthly income of $5000, is employed full-time, and has a credit score of 720.\n",
    "\n",
    "<b> Mortgage Details Summary:</b>\n",
    "- <b>Income:</b> $5000\n",
    "- <b>Employment Status:</b> Full-time\n",
    "- <b>Credit Score:</b> 720\n",
    "\n",
    "<b>Monthly Amounts:</b>\n",
    "| Gross Income | Tax Obligation | Mortgage Obligation | Expenses | Remaining Disposable Income |\n",
    "|--------------|----------------|---------------------|----------|-----------------------------|\n",
    "| $5000        | $750           | $1500               | $1000    | $1750                       |\n",
    "\n",
    "<b>Best Property Options based on User's Data:</b>\n",
    "- <b>Property ID: 1351007</b>\n",
    "  - Property Type: Apartment\n",
    "  - Building Size: 120 sqm\n",
    "  - Price: $450,000\n",
    "  - Address: 2/1 Brolga Street, Rapid Creek\n",
    "  - Bedroom Count: 2\n",
    "  - Bathroom Count: 2\n",
    "  - Parking Count: 1\n",
    "\n",
    "<b>Affordability Opinion:</b> The mortgage is affordable with a remaining disposable income of $1750.\n",
    "\n",
    "<b>Maximum Borrowing Amount:</b> $150,000\n",
    "\n",
    "<b>Reasoning:</b> The user's income of $5000, employment status, and credit score of 720 make the mortgage affordable with a comfortable remaining disposable income.</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2398d71e-cdae-4a64-bc14-03a503b9523d",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>6.2 Open the Chabot</b></p>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><i>It's time to chat with the bot! Let's get started with our conversation.</i></p>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Important Note: </b> This chatbot is designed to minimize hallucinations. If we detect an inaccurate response or experience technical issues, we will notify you with \"We apologize for the inconvenience.\" If you encounter this error, <b>please retry your question to receive a corrected answer.</b></p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df82c07-05d0-4630-ba74-7bd6b77955a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "\n",
    "pn.extension(design=\"material\")\n",
    "\n",
    "# clear the memory\n",
    "memory.clear()\n",
    "\n",
    "\n",
    "def callback(contents, user, instance):\n",
    "    response = agent_executor.invoke({\"input\": contents}, config=config)\n",
    "    is_valid_response, final_res = validate_response(response[\"output\"])\n",
    "    if (\n",
    "        len(contents) > 30\n",
    "        and is_valid_response\n",
    "        and hasattr(tool_handler, \"sql\")\n",
    "        and len(tool_handler.sql) > 0\n",
    "    ):\n",
    "        # add que to vectordb\n",
    "        chroma.add_question_sql(question=contents, sql=tool_handler.sql)\n",
    "\n",
    "    return final_res\n",
    "\n",
    "\n",
    "pn.chat.ChatInterface(\n",
    "    callback=callback,\n",
    "    show_rerun=False,\n",
    "    show_undo=False,\n",
    "    show_clear=False,\n",
    "    width=800,\n",
    "    height=400,\n",
    ").servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e0695f-cb92-4c79-af24-535a31582f7b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style='font-size:16px;font-family:Arial;color:#00233C'>If the chatbot didn't work when we pressed ENTER, on our first time using this demo on our environment, did we use F5 to reload the site? See instructions at the top of the notebook. If we asked a question and got no response after a few minutes, it is possible that we will need to type 0 0 to restart the kernel and re-run the demo. Questions outside the model seem to confuse the chatbot.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b8b817-c0ff-42b3-a651-c8268ac40942",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233C;'>\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233c'>7 Cleanup</b>\n",
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>7.1 Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Cleanup work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aacb87c-0d81-40f0-8754-608d47e602cc",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'> <b>7.2 Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b398148-9486-4535-8c06-d3f77669bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in [\n",
    "    \"Customer\",\n",
    "    \"Interest\",\n",
    "    \"RealEstate\",\n",
    "    \"Locality\",\n",
    "    \"NearbyLocality\",\n",
    "    \"School\",\n",
    "    \"ShoppingCenter\",\n",
    "]:\n",
    "\n",
    "    try:\n",
    "        db_drop_table(t)\n",
    "\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef4cbe-1beb-4c65-ac60-ffd6250668a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae971f90-bef1-4228-bcbf-c333e9843284",
   "metadata": {},
   "source": [
    "<b id=\"datasetInfo1\" style = 'font-size:20px;font-family:Arial;color:#00233c'>Dataset:</b>\n",
    "\n",
    "**Customer Table**\n",
    "- `CustomerID`: unique row customer id\n",
    "- `FirstName`: customer first name\n",
    "- `LastName`: customer last name\n",
    "- `DateOfBirth`: customer birth date\n",
    "- `Gender` : customer gender (categorical: \"M\",\"F\",)\n",
    "- `Address` : customer full address\n",
    "- `City`: city of customer (categorical: 'Almond','Geneva')\n",
    "- `LocalityID`: unique row locality id (Numeric)\n",
    "- `Country`: country of customer (categorical: 'USA')\n",
    "- `Email`: customer email\n",
    "- `PhoneNumber`: customer phone number\n",
    "- `AccountNumber`: customer account number\n",
    "- `AccountType`: customer account type\n",
    "- `AccountStatus`: customer account status (categorical: 'Active','Inactive')\n",
    "- `Balance`: account balance, in dollar (numeric)\n",
    "- `BranchID`: branch id\n",
    "- `CreditScore`: customer credit score\n",
    "- `Income`: customer's monthly income, in dollar (numeric)\n",
    "\n",
    "**Interest Table**\n",
    "- `ID`: unique row id\n",
    "- `MinCreditScore`: min credit score\n",
    "- `MaxCreditScore`: max credit score\n",
    "- `InterestRate`: rate of interest\n",
    "\n",
    "**RealEstate**\n",
    "- `LocalityID`: unique row locality id (Numeric)\n",
    "- `PropertyID`: unique row property id (Numeric)\n",
    "- `PropertyType`: type of property being listed (categorical: 'Apartment','House', 'Unit')\n",
    "- `BuildingSize`: size of the property's building, in square meters. (Numeric)\n",
    "- `LandSize`: size of the property's land, in square meters. (Numeric)\n",
    "- `PreferredSize`: preferred size of the property, in square meters. (Numeric)\n",
    "- `OpenDate`: date that the property was first listed for sale. (Date)\n",
    "- `ListingAgency`: agency that is listing the property\n",
    "- `Price`: listing price of the property\n",
    "- `Address`: property's address\n",
    "- `City`: city that the property is located in\n",
    "- `State`: state that the property is located in\n",
    "- `ZipCode`: zip code that the property is located in\n",
    "- `Phone`: listing agent's phone number\n",
    "- `BedroomCount`: number of bedrooms in the property\n",
    "- `BathroomCount`: number of bathrooms in the property\n",
    "- `ParkingCount`: number of parking spaces in the property\n",
    "\n",
    " **Locality data**\n",
    " - `LocalityID`: unique row locality id (Numeric)\n",
    " - `LocalityName`: locality name\n",
    " - `LocalityDescription`: locality description\n",
    " - `DistanceFromAirport`: distance from airport to locality (Numeric)\n",
    " - `LivabilityScore`: locality livability score (Numeric)\n",
    " \n",
    "**NearbyLocality data**\n",
    "- `LocalityID`: unique row locality id (Numeric)\n",
    "- `LocalityName`: locality name (Numeric)\n",
    "- `NearbyLocalityID`: Unique row locality id (Numeric)\n",
    "\n",
    "**School data**\n",
    "- `SchoolID`: unique row school id (Numeric)\n",
    "- `SchoolName`: school name\n",
    "- `LocalityID`: unique row locality id (Numeric)\n",
    "\n",
    "**ShoppingCenter**\n",
    "- `StoreID`: unique row store id (Numeric)\n",
    "- `StoreName`: store name\n",
    "- `Type`: type of shopping center (categorical: 'Grocery Store','Shopping Mall')\n",
    "- `LocalityID`: unique row school id (Numeric)\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233c'><b>Dataset source:</b> <a href = 'https://www.kaggle.com/datasets/thedevastator/australian-housing-data-1000-properties-sampled'>kaggle</a></p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233c'><b>Links:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Teradataml Python reference: <a href = 'https://docs.teradata.com/search/all?query=Python+Package+User+Guide&content-lang=en-US'>here</a></li>\n",
    "    <li>Langchain Python reference: <a href='https://python.langchain.com/docs/get_started/introduction.html'>here</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5463848-592f-4321-b852-287e133872dd",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2023, 2024. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
