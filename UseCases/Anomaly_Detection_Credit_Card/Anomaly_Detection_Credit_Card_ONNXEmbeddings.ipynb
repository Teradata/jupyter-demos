{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdca389d-76a1-4633-90b5-7bffb82efba4",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Anomaly Detection in Credit Card\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f1c117-359a-448e-a8f8-ab66739620d7",
   "metadata": {},
   "source": [
    "<p style='font-size:20px;font-family:Arial;'><b>Credit Card Fraud Detection using K-Means Clustering:</b></p> \n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "Detecting fraudulent transactions is crucial for financial security. This approach leverages <b>K-Means clustering</b> to group similar transactions and identifies anomalies based on <b>Euclidean distance</b>, where fraud-like patterns deviate significantly from normal spending behaviors.\n",
    "</p>\n",
    "\n",
    "<ul style='font-size:16px;font-family:Arial;'>\n",
    "    <li><strong>Anomaly Detection:</strong> Identifies outliers based on their distance from the cluster center, marking transactions that deviate from normal spending patterns.</li>\n",
    "    <li><strong>Vector Embeddings:</strong> Converts categorical transaction data into vector representations to improve clustering accuracy.</li>\n",
    "    <li><strong>Feature Engineering:</strong> Includes transaction amount, location, time, and merchant category to enhance fraud detection.</li>\n",
    "    <li><strong>Dimensionality Reduction:</strong> Uses t-SNE to visualize clusters and detect fraudulent transactions that do not fit normal behavior.</li>\n",
    "    <li><strong>Scalability:</strong> Works efficiently on large datasets by leveraging K-Means for unsupervised learning and anomaly detection.</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>Why Vantage?</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "    Teradata’s integration with <b>LLMs and hosting capabilities in-DB</b>, along with the Open Analytics Framework, would enable customers to run NLP models at scale. The key challenges noted for on-prem customers—such as data movement latency and lack of access to cloud models—are valid. By bringing language models within Vantage, Teradata can provide a significant advantage to on-prem customers by allowing them to run NLP models without needing to move large amounts of data to and from external services.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edab1fa-b726-482b-ac6d-757fc214ff88",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>Downloading and installing additional software needed</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3706bc-4823-4b8b-bff7-56488f37ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "!pip install wordcloud nltk --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b81191c-82d6-4cad-a5f2-deea94aa4e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "!pip install --force-reinstall pillow --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3c5e96-f353-4d9b-8f61-af67579d07d0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;'><b>Note: </b><i>The above libraries have to be installed. Restart the kernel after executing these cells to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing <b> 0 0</b></i> (zero zero) and pressing <i>Enter</i>.</p>\n",
    "</div>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330da9c2-61e0-42b7-a27b-fe762cc741ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "# Data manipluation and Visualization libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# Teradata libraries\n",
    "from teradataml import *\n",
    "from teradataml import (\n",
    "    create_context, \n",
    "    delete_byom, \n",
    "    display,\n",
    "    execute_sql,\n",
    "    save_byom,\n",
    "    remove_context,\n",
    "    in_schema,\n",
    "    KMeans,\n",
    "    DataFrame,\n",
    "    db_drop_table,\n",
    "    db_drop_view\n",
    ")\n",
    "display.max_rows = 5\n",
    "\n",
    "# NLP libraries\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "\n",
    "# machine learning libraries\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f4f7c4-35a9-4440-88af-2bdfffa264a6",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>1. Initiate a connection to Vantage</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>You will be prompted to provide the password. Enter your password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318175ff-a36b-4dca-8201-220c295c44a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29a59be-ae73-4b5d-ac58-3df5b6acb358",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=Anomaly_Detection_Credit_Card.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6043d4f5-af7c-4dfb-85a5-1ada0dad417e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0957d7af-d2a7-4204-9cf5-b99d6d0cbd32",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;'><b>Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>We have provided data for this demo on cloud storage. You can either run the demo using foreign tables to access the data without any storage on your environment or download the data to local storage, which may yield faster execution. Still, there could be considerations of available storage. Two statements are in the following cell, and one is commented out. You may switch which mode you choose by changing the comment string.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81963f5f-4301-4dca-a827-bb227b4920ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ../run_procedure.py \"call get_data('DEMO_CreditCard_cloud');\" \n",
    "# takes about 20seconds, estimated space: 0 MB\n",
    "%run -i ../run_procedure.py \"call get_data('DEMO_CreditCard_local');\" \n",
    "# takes about 35 seconds, estimated space: 11 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4dd908-6215-4489-847d-02d5b12511a2",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Next is an optional step – if you want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071d2c83-a8e4-4b7d-96aa-9798745c718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fd17e9-a5df-4f5c-a90f-29ca784d6e0e",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>2. Generate real time data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5d8bfb-1690-4b98-9921-6582d68360c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_cc = DataFrame(in_schema(\"DEMO_CreditCard\",\"Credit_Card\"))\n",
    "tdf_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eae51e-2c33-4559-be30-aa8227377c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_cc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ff3a95-861b-45d8-b6c3-b87037893bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing in database\n",
    "copy_to_sql(df = tdf_cc, table_name = \"credit_card_db\", if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f73719-8cc1-4006-8b80-bb4c3d2a39b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = DataFrame.from_table('credit_card_db')\n",
    "tdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7d35b3-4ffa-4fcb-b08a-5a0bcfe93fa6",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-;\">\n",
    "<b style = 'font-size:18px;font-family:Arial;'>2.1 Real-time Data Collection\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b575c8-074d-422d-9c2e-f6f584934bca",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>This simulated data mimics the real-time process, where transaction details are captured continuously, enabling anomaly detection in real-time credit card activity.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18805ba-c888-4ad9-9ed4-2669e578c934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real time data collection\n",
    "def fetching_real_time_data():\n",
    "    contract_types = [\"Cash loans\", \"Revolving loans\"]\n",
    "    genders = [\"M\", \"F\"]\n",
    "    own_car = [\"Y\", \"N\"]\n",
    "    family_status = [\"Married\", \"Single\", \"Separated\"]\n",
    "    house_types = [\"Block of flats\", \"House\", \"Municipal\"]\n",
    "    occupations = [\"Sales staff\", \"Managers\", \"Core staff\", \"None\"]\n",
    "\n",
    "    records = []\n",
    "    for _ in range(10):\n",
    "        record = {\n",
    "            \"SK_ID_CURR\": random.randint(456255, 999999),\n",
    "            \"TARGET\": random.choice([0, 1]),\n",
    "            \"NAME_CONTRACT_TYPE\": random.choice(contract_types),\n",
    "            \"CODE_GENDER\": random.choice(genders),\n",
    "            \"FLAG_OWN_CAR\": random.choice(own_car),\n",
    "            \"CNT_CHILDREN\": random.randint(0, 5),\n",
    "            \"AMT_INCOME_TOTAL\": round(random.uniform(117000000, 117100000), 2),\n",
    "            \"NAME_FAMILY_STATUS\": random.choice(family_status),\n",
    "            \"REGION_POPULATION_RELATIVE\": round(random.uniform(0.001, 0.05), 6),\n",
    "            \"FLAG_MOBIL\": 1,\n",
    "            \"FLAG_EMP_PHONE\": random.choice([0, 1]),\n",
    "            \"CNT_FAM_MEMBERS\": random.randint(1, 6),\n",
    "            \"HOUSETYPE_MODE\": random.choice(house_types),\n",
    "            \"OCCUPATION_TYPE\": random.choice(occupations),\n",
    "            \"AGE\": random.randint(20, 70)\n",
    "        }\n",
    "        records.append(record)\n",
    "    \n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1395cc1c-8385-4a85-af55-b05e5c04e3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for real-time data fetching\n",
    "def fetch_data():\n",
    "    all_data = [] \n",
    "\n",
    "    print(\"\\nInitializing real-time credit card data fetch...\\n\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"Do you want to fetched updated credit card record? (yes to start, stop to end): \").strip().lower()\n",
    "        \n",
    "        if user_input == 'yes':\n",
    "            print(\"Fetching new credit card record...\", end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            time.sleep(random.uniform(0.5, 1.5))\n",
    "\n",
    "            data = fetching_real_time_data()\n",
    "            print(\" Data fetched successfully!\")\n",
    "            all_data.append(data)\n",
    "        elif user_input == 'stop':\n",
    "            print(\"\\nStopping the data collection. Finalizing...\\n\")\n",
    "            time.sleep(1)\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid input. Please enter 'yes' to generate a record or 'stop' to end.\")\n",
    "    \n",
    "    if all_data:\n",
    "        print(\"\\nFinalizing the dataset...\\n\")\n",
    "        time.sleep(1)\n",
    "        print(\"Merging all generated records...\\n\")\n",
    "        print(\"Inserted new records\")\n",
    "        return pd.concat(all_data, ignore_index=True)\n",
    "    else:\n",
    "        print(\"No records fetched, returning an empty DataFrame.\")  \n",
    "        return pd.DataFrame(columns=['TransactionID', 'Amount'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d363eba3-194f-4da7-91cb-6c1a2c88e106",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>3. Load HuggingFace Model</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>To generate embeddings, we need an ONNX model capable of transforming text into vector representations. We use a pretrained model from [Teradata's Hugging Face repository](https://huggingface.co/Teradata/gte-base-en-v1.5), such as gte-base-en-v1.5. The model and its tokenizer are downloaded and stored in Vantage tables as BLOBs using the save_byom function.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a666bad9-cf57-4bc0-9827-387835ace447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e5a433-be7f-40f5-b804-27c782fa16c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "model_name = \"bge-small-en-v1.5\"\n",
    "number_dimensions_output = 384\n",
    "model_file_name = \"model.onnx\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e2e148-2933-43ad-ab55-ce100c778b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Download Model from Teradata HuggingFace Page\n",
    "\n",
    "hf_hub_download(repo_id=f\"Teradata/{model_name}\", filename=f\"onnx/{model_file_name}\", local_dir=\"./\")\n",
    "hf_hub_download(repo_id=f\"Teradata/{model_name}\", filename=f\"tokenizer.json\", local_dir=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5de02e-3698-4378-9ae4-92af24ad3d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    db_drop_table(\"embeddings_models\")\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    db_drop_table(\"embeddings_tokenizers\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184e1cd5-244d-430e-ba5e-2d2c55aa78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load Models into Vantage\n",
    "# a) Embedding model\n",
    "save_byom(model_id = model_name, # must be unique in the models table\n",
    "               model_file = f\"onnx/{model_file_name}\",\n",
    "               table_name = 'embeddings_models' )\n",
    "# b) Tokenizer\n",
    "save_byom(model_id = model_name, # must be unique in the models table\n",
    "              model_file = 'tokenizer.json',\n",
    "              table_name = 'embeddings_tokenizers') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a71207-feb6-49b7-9654-5bc05776b46d",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Recheck the installed model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a50bf-6bb2-4654-a9bf-ca55921dff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = DataFrame('embeddings_models')\n",
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f7c0e5-8278-4ed3-9cd5-8ed933a3be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_token = DataFrame('embeddings_tokenizers')\n",
    "df_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96ece44-ea5e-488e-ab8e-a17f8a49e443",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>3. Create the Embeddings</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1fc506-b84b-4793-8dfb-d01dfc26576a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'> Let us take a look at our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e86da75-f55b-4104-9a66-a4aeca61768e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DF_CC = DataFrame(in_schema(\"DEMO_CreditCard\",\"Credit_Card\"))\n",
    "DF_CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d7df1-0f9c-4b91-bf01-5b4c464ce9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_CC.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f10526f-040f-44bd-a77c-feb5bc549266",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial'>3.2 Creation of Views and Final Embeddings Table\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2f0f8a-9ce4-418c-882d-377d818b8b2e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "Now it's time to generate the embeddings using <b>ONNXEmbeddings</b>.<br>We run the ONNXEmbeddings function to generate embeddings for a small subset of records. The model is <b>loaded into the cache memory on each node</b>, and Teradata's <b>Massively Parallel Processing (MPP)</b> architecture ensures that embeddings are computed in parallel using <b>ONNX Runtime</b> on each node.  <br>Having said that, generating embeddings for the entire training set can be time-consuming, especially when working on a system with limited resources. In the <b>ClearScape Analytics experience</b>, only a <b>4 AMP system</b> with constrained RAM and CPU power is available. To ensure smooth execution, we test embedding generation on a small sample and use <b>pre-calculated embeddings</b> for the remainder of demo. In a real-life scenario you would tyipically encounter multiple hundred AMPs with much more compute power!<br>Also have a look at the most important input parameters of this <b>ONNXEmbeddings</b> function.\n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "<li><b>InputTable</b>: The source table containing the text to be embedded. </li>\n",
    "<li><b>ModelTable</b>: The table storing the ONNX model.                    </li>\n",
    "<li><b>TokenizerTable</b>: The table storing the tokenizer JSON file.       </li>\n",
    "<li><b>Accumulate</b>: Specifies additional columns to retain in the output </li>  \n",
    "<li><b>OutputFormat</b>: Specifies the data format of the output embeddings (<b>FLOAT32(768)</b>, matching the model's output dimension).</li>\n",
    "</ul>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "Since embedding generation is computationally expensive, we only process <b>10 records for testing</b> and rely on precomputed embeddings for further analysis.  \n",
    "</p>\n",
    "\n",
    "\n",
    "<p style='font-size:18px;font-family:Arial;'><b>Generate Embeddings</b></p>    \n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "Generating embeddings will take approximately <b>10-15 minutes.</b>\n",
    "</p>\n",
    "\n",
    "\n",
    "<center><img src=\"images/visual.svg\" alt=\"embeddings_decision\" width=1300 height=1400/></center>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "<i><b>\n",
    "These embeddings will later be used in anomaly detection by comparing the similarity between different transactions. By converting each transaction into a vector representation, we can identify outliers or anomalies based on the distance between vectors.</b></i>\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1c15d1-801c-42f5-8eb9-76bd56572e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "configure.byom_install_location = \"mldb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8ecabd-8afb-498d-add7-9bf324c0e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_sample1000 = DataFrame.from_query(\"SELECT top 1000 SK_ID_CURR AS id, cast(AMT_INCOME_TOTAL as VARCHAR(50)) AS txt FROM credit_card_db t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f0233-98f6-4910-a1a3-2100138e94d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = DataFrame.from_query(f\"select * from embeddings_models where model_id = '{model_name}'\")\n",
    "my_tokenizer = DataFrame.from_query(f\"select model as tokenizer from embeddings_tokenizers where model_id = '{model_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01788d68-b80d-4156-87f3-2ed5b4468114",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_embeddings_sample = ONNXEmbeddings(\n",
    "    newdata = DF_sample1000,\n",
    "    modeldata = my_model, \n",
    "    tokenizerdata = my_tokenizer, \n",
    "    accumulate = [\"id\", \"txt\"],\n",
    "    model_output_tensor = \"sentence_embedding\",\n",
    "    output_format = f'FLOAT32({number_dimensions_output})',\n",
    "    enable_memory_check = False\n",
    ").result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c751f0-a326-4615-b244-02e2ed43419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_embeddings_sample.show_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77082467-617d-4056-a0eb-370d85b2ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_embeddings_sample.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e100f0-7220-492c-92db-a9cafbd84b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(DF_embeddings_sample, table_name=\"DF_embeddings_table\" , if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243e6bf2-6f84-440a-a336-619b264f2f53",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-;\">\n",
    "<b style = 'font-size:18px;font-family:Arial;'>3.3 Elbow Method\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8fe480-ae00-44ba-8399-2dc0da5d2fc7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>In this step, we apply the <b>Elbow Method</b> to determine the optimal number of clusters for the KMeans clustering algorithm. The Elbow Method helps in selecting the number of clusters that best represents the data by analyzing the <b>Total Within-Cluster Sum of Squares (Total_WithinSS)</b>.</p>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "For each number of clusters, we print the `Total_WithinSS` value, which represents the compactness of the clusters.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcd0880-cd94-4099-a1b9-664a4ca197dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embedding features (excluding ID and text columns)\n",
    "embedding_column_list = [col for col in DF_embeddings_sample.columns if col not in [\"id\", \"txt\"]]\n",
    "\n",
    "total_withinss_values = []\n",
    "\n",
    "for num_clusters in range(5, 10):\n",
    "    # Perform KMeans clustering\n",
    "    kmeans_out = KMeans(data=DataFrame('DF_embeddings_table'), #DF_embeddings_sample,\n",
    "                        id_column=\"id\",\n",
    "                        target_columns=embedding_column_list,\n",
    "                        num_clusters=num_clusters,\n",
    "                        num_init=10,\n",
    "                        iter_max=50\n",
    "                        )\n",
    "    result_table = kmeans_out.result\n",
    "    result_table_df = result_table[['td_modelinfo_kmeans']]\n",
    "    df = result_table_df.assign(has_name = result_table_df.td_modelinfo_kmeans.str.contains('Total_WithinSS', na = False))\n",
    "    df1 = df[df.has_name == 1]\n",
    "    df2 = df1.drop(columns =['has_name'])\n",
    "    df3 = dict(df2.to_pandas()['td_modelinfo_kmeans'])\n",
    "    \n",
    "    # Access the value associated with key 0\n",
    "    value_str = df3[0]\n",
    "\n",
    "    # Split the string by ':' and strip any leading/trailing whitespace\n",
    "    numeric_str = value_str.split(':')[1].strip()\n",
    "    numeric_value = round(float(numeric_str), 2)\n",
    "    total_withinss_values.append(numeric_value)\n",
    "    \n",
    "    # Display the numeric value for each number of clusters\n",
    "    print(f'Number of clusters: {num_clusters}, Total_WithinSS: {numeric_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254dea5b-3294-453f-981b-61a0ba184a1e",
   "metadata": {},
   "source": [
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "The resulting plot provides a visual representation of the relationship between the number of clusters and the <b>Total_WithinSS</b>. The \"elbow\" in the plot will suggest the optimal `k` for further analysis.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ff0f93-e147-436f-97fb-f14eeb9c0ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the elbow graph\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(5, 10), total_withinss_values, marker='o', linestyle='--', color='b')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Total Within-Cluster Sum of Squares (Total_WithinSS)')\n",
    "plt.title('Elbow Method for Optimal Number of Clusters')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d6e53c-c060-4a77-8afb-9a33e33e26b4",
   "metadata": {},
   "source": [
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "In this step, we calculate the differences between successive WCSS values and use the second-order differences to identify the <b>Elbow Point</b>, which helps in selecting the optimal number of clusters (`k`).\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6864c73-0bd7-409d-a23d-543418948cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the differences between successive WCSS values\n",
    "wcss_diff = np.diff(total_withinss_values)\n",
    "\n",
    "# Calculate the second-order differences to find the largest drop\n",
    "wcss_diff2 = np.diff(wcss_diff)\n",
    "\n",
    "# Find the index of the maximum curvature (Elbow Point)\n",
    "optimal_k_index = np.argmin(wcss_diff2) + 2 \n",
    "\n",
    "print(f'Optimal number of clusters (K) based on Elbow Method: {optimal_k_index}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76981b9-b76d-49ae-b7d2-93b702e98591",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>4. Run K-Means on the Embeddings Store and then build final table with Cluster ID assignments to rows</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b67ea4-8315-4cfa-9d96-0c874f4f5588",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>The K-means() function groups a set of observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid). This algorithm minimizes the objective function, that is, the total Euclidean distance of all data points from the center of the cluster</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88af4dc7-7807-433e-b9b3-a73bc4ef6fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Teradata-compatible int\n",
    "optimal_k_index = int(optimal_k_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164765c9-f33d-44bd-bfda-595d54742113",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_column_list = [col for col in DF_embeddings_sample.columns if col not in [\"id\", \"txt\"]]\n",
    "\n",
    "num_clusters = optimal_k_index\n",
    "kmeans_out = KMeans(\n",
    "    id_column=\"id\",\n",
    "    data=DataFrame('DF_embeddings_table'),\n",
    "    target_columns=embedding_column_list,\n",
    "    num_init=10,\n",
    "    num_clusters=num_clusters,\n",
    "    iter_max=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae20a99a-d014-46ec-bd78-36a4b477d346",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>The output below shows cluster assignment for each row.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085b9114-8176-4bce-af2d-4576beade12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the result\n",
    "kmeans_out.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0561f1c1-d934-44c2-82ef-4fd50f223cb8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Let's check how many data points each cluster has.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df0601-5ccc-40f6-8e87-8ae9ef492b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying KMeans Predict\n",
    "KMeansPredict_out_1 = KMeansPredict(data=DataFrame('DF_embeddings_table'),\n",
    "                                    object=kmeans_out.result,\n",
    "                                    #accumulate=\"ram\",\n",
    "                                    output_distance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec03099-5cad-4bb6-9e9e-085b9aa5b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result DataFrames.\n",
    "KMeansPredict_out_1.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffbc18a-cdce-40e6-af10-18e13264417e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Let's check how many data points each cluster has.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e76c06-d748-48d8-8594-74f9954fc1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of each clustered\n",
    "kmeans_df = KMeansPredict_out_1.result\n",
    "d2 = kmeans_df.groupby('td_clusterid_kmeans').count()\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94fc3c0-a05f-4174-b8b7-584667de9e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine embeddings and clusterid\n",
    "clustered_df = DataFrame('DF_embeddings_table').join(\n",
    "    other = kmeans_df,\n",
    "    on = [\"id\"],\n",
    "    how = \"inner\",\n",
    "    lprefix=\"l\",\n",
    "    rprefix=\"r\"\n",
    ")\n",
    "\n",
    "clustered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23545df-0b7d-4422-a026-62e51662ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing into database\n",
    "copy_to_sql(df = clustered_df, table_name = \"clustered_data\", if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73763700-d50a-41cd-879a-ec534c1983e3",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>5. Visualization</b>\n",
    "\n",
    "<hr style='height:1px;border:none;background-;'> \n",
    "\n",
    "<p style='font-size:18px;font-family:Arial;'><b>5.1 Visualization of Clusters</b></p> \n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>The graph illustrates the clustering of transactions into distinct groups for credit card fraud detection using anomaly detection. Based on the analysis, the data has been divided into optimal clusters, each representing a unique transaction pattern. This clustering approach helps identify potential fraudulent activities by distinguishing normal and anomalous transaction behaviors, enabling more targeted fraud detection and prevention efforts.</p>\n",
    "\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>This visualization helps us explore the structure of the clusters and visually identify <b>anomalies</b> (points that deviate significantly from their respective cluster centers). The use of <b>diamonds for anomalies</b> and <b>circles for normal data points</b> provides a clear and intuitive way to distinguish between outliers and inliers in the data, making it easier to detect potential fraudulent or unusual activity.</p>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>The interactive nature of the plot allows for an engaging exploration of the data, where users can hover over points to view more detailed information.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947c2b12-eac5-4b14-9798-92e4d132c64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "# import mplcursors  # for hover tooltips (optional)\n",
    "\n",
    "clus = clustered_df.to_pandas()\n",
    "# --- Perform t-SNE ---\n",
    "tsne = TSNE(n_components=2, random_state=123)\n",
    "tsne_result = tsne.fit_transform(clus.iloc[:, 3:-1])\n",
    "\n",
    "# --- Create visualization DataFrame ---\n",
    "tsne_df = pd.DataFrame(tsne_result, columns=['tsne_1', 'tsne_2'])\n",
    "tsne_df['cluster_id'] = clus['td_clusterid_kmeans']\n",
    "tsne_df['customer_id'] = clus['l_id']\n",
    "tsne_df['amount'] = clus['txt']  # rename for clarity\n",
    "\n",
    "# Truncate text values\n",
    "tsne_df['truncated_amount'] = tsne_df['amount'].apply(\n",
    "    lambda x: f\"{x[:50]}...\" if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "# --- Compute cluster centers ---\n",
    "cluster_centers = tsne_df.groupby('cluster_id')[['tsne_1', 'tsne_2']].mean()\n",
    "\n",
    "# --- Compute distance to cluster center ---\n",
    "def euclidean_distance(row):\n",
    "    center = cluster_centers.loc[row['cluster_id']]\n",
    "    return np.sqrt((row['tsne_1'] - center['tsne_1'])**2 + (row['tsne_2'] - center['tsne_2'])**2)\n",
    "\n",
    "tsne_df['distance'] = tsne_df.apply(euclidean_distance, axis=1)\n",
    "\n",
    "# --- Mark anomalies per cluster (top 5% distance) ---\n",
    "tsne_df['is_anomaly'] = tsne_df.groupby('cluster_id')['distance'].transform(\n",
    "    lambda x: x > x.quantile(0.95)\n",
    ")\n",
    "\n",
    "# --- Plot using Matplotlib ---\n",
    "plt.figure(figsize=(12, 9))\n",
    "palette = sns.color_palette('tab10', n_colors=tsne_df['cluster_id'].nunique())\n",
    "\n",
    "# Draw normal and anomaly points separately\n",
    "for i, cluster in enumerate(sorted(tsne_df['cluster_id'].unique())):\n",
    "    cluster_data = tsne_df[tsne_df['cluster_id'] == cluster]\n",
    "    \n",
    "    # Normal points\n",
    "    normal_points = cluster_data[~cluster_data['is_anomaly']]\n",
    "    plt.scatter(\n",
    "        normal_points['tsne_1'], normal_points['tsne_2'],\n",
    "        label=f'Cluster {cluster}',\n",
    "        color=palette[i],\n",
    "        alpha=0.7,\n",
    "        edgecolor='k',\n",
    "        s=50,\n",
    "        marker='o'\n",
    "    )\n",
    "    \n",
    "    # Anomalies\n",
    "    anomalies = cluster_data[cluster_data['is_anomaly']]\n",
    "    plt.scatter(\n",
    "        anomalies['tsne_1'], anomalies['tsne_2'],\n",
    "        color=palette[i],\n",
    "        marker='D',  # diamond marker\n",
    "        edgecolor='black',\n",
    "        s=120,\n",
    "        label=f'Anomaly (Cluster {cluster})'\n",
    "    )\n",
    "\n",
    "# --- Plot cluster centers ---\n",
    "plt.scatter(\n",
    "    cluster_centers['tsne_1'], cluster_centers['tsne_2'],\n",
    "    color='black', s=250, marker='X', label='Cluster Centers'\n",
    ")\n",
    "\n",
    "plt.title('t-SNE Visualization of Clusters with Anomaly Detection', fontsize=16, weight='bold')\n",
    "plt.xlabel('Dimension-1', fontsize=14)\n",
    "plt.ylabel('Dimension-2', fontsize=14)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaf1a3d-3ef3-4276-bb6b-185ac76ac98a",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>6. Real-time data Fetching</b>\n",
    "\n",
    "<hr style='height:1px;border:none;background-;'> \n",
    "\n",
    "<p style='font-size:18px;font-family:Arial;'><b>6.1 Data Fetching Process</b></p> \n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>The <code>fetch_data()</code> function allows the user to fetch new credit card transaction records in real-time. By entering <b>'yes'</b>, the system fetches and stores 10 new records, simulating live data collection. Entering <b>'stop'</b> terminates the data fetching process, finalizing and merging all collected records into a dataset.</p>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb89cc35-45ba-47eb-a945-a788936f4d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Real time credit card data\n",
    "tdf = fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb751c3a-ae7f-4b22-a94a-370a3d9b2567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in database\n",
    "copy_to_sql(tdf, table_name=\"credit_card_db\", if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588ead2c-d5c3-44ba-a1cc-7fdded8bbd7d",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>7. Create the Embeddings</b>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>we generate and store the embeddings for the credit card transaction data. The embeddings are created using a pre-trained model, which transforms the transaction data into vectorized representations that can be used for anomaly detection.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd1062-8b39-4dd6-97f5-1ddf236883f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = DataFrame.from_table('credit_card_db')\n",
    "tdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6526cb17-fcdc-4bc9-9a25-d9542708049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_sample1000 = DataFrame.from_query(\"SELECT SK_ID_CURR AS id, cast(AMT_INCOME_TOTAL as VARCHAR(50)) AS txt FROM credit_card_db t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb709f-95c9-4781-b676-d7697dfa31b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Embeddings\n",
    "DF_embeddings_sample = ONNXEmbeddings(\n",
    "    newdata = DF_sample1000,\n",
    "    modeldata = my_model, \n",
    "    tokenizerdata = my_tokenizer, \n",
    "    accumulate = [\"id\", \"txt\"],\n",
    "    model_output_tensor = \"sentence_embedding\",\n",
    "    output_format = f'FLOAT32({number_dimensions_output})',\n",
    "    enable_memory_check = False\n",
    ").result\n",
    "print(\"All steps completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc29b692-24dc-41c6-8020-580ecfa9b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View sample data\n",
    "DF_embeddings_sample.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe5bea4-b0f0-450d-a278-e355bf2b50d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View shape of dataframe\n",
    "DF_embeddings_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f70bd7c-d8a9-4a5d-a15b-43f0c66fcfd2",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>8. Applying KMeans Prediction</b>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>We apply the <b>KMeans Prediction</b> to predict the cluster assignments for the dataset using the previously trained KMeans model. This allows us to label the data points with the clusters they belong to and further analyze the results.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328c005f-8b7f-41fe-97f2-b298d215780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying KMeansPredict\n",
    "KMeansPredict_out_1 = KMeansPredict(data=DF_embeddings_sample,\n",
    "                                    object=kmeans_out.result,\n",
    "                                    #accumulate=\"ram\",\n",
    "                                    output_distance=False)\n",
    "\n",
    "# Print the result DataFrames.\n",
    "KMeansPredict_out_1.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f17343-caea-463b-a551-76ebe38ee9e9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Let's check how many data points each cluster has.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6034148e-9b58-459e-bc58-e79ecf3301ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of each clusterid\n",
    "kmeans_df = KMeansPredict_out_1.result\n",
    "d2 = kmeans_df.groupby('td_clusterid_kmeans').count()\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad46ac4-6fa7-444e-8fd0-aee611fb87b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine embeddings and clusterid\n",
    "clustered_df = DF_embeddings_sample.join(\n",
    "    other = kmeans_df,\n",
    "    on = [\"id\"],\n",
    "    how = \"inner\",\n",
    "    lprefix=\"l\",\n",
    "    rprefix=\"r\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db23f821-fe14-4ee1-a58b-dffb46a8f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in database\n",
    "copy_to_sql(df = clustered_df, table_name = \"clustered_data\", if_exists=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617cb194-75f7-488f-9797-1ed04d4ee210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View updated data\n",
    "clustered_df = DataFrame.from_table('clustered_data')\n",
    "clustered_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c30e37-e8ff-4918-8040-5feab3eaea51",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>5. Visualization</b>\n",
    "\n",
    "<hr style='height:1px;border:none;background-;'> \n",
    "\n",
    "<p style='font-size:18px;font-family:Arial;'><b>5.1 Visualization of Clusters</b></p> \n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>This visualization helps us explore the structure of the clusters and visually identify <b>anomalies</b> (points that deviate significantly from their respective cluster centers). The use of <b>diamonds for anomalies</b> and <b>circles for normal data points</b> provides a clear and intuitive way to distinguish between outliers and inliers in the data, making it easier to detect potential fraudulent or unusual activity.</p>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>The interactive nature of the plot allows for an engaging exploration of the data, where users can hover over points to view more detailed information.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627a87dc-82de-4862-9eb2-5b0a86725325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "# import mplcursors  # for hover tooltips (optional)\n",
    "\n",
    "clus = clustered_df.to_pandas()\n",
    "# --- Perform t-SNE ---\n",
    "tsne = TSNE(n_components=2, random_state=123)\n",
    "tsne_result = tsne.fit_transform(clus.iloc[:, 3:-1])\n",
    "\n",
    "# --- Create visualization DataFrame ---\n",
    "tsne_df = pd.DataFrame(tsne_result, columns=['tsne_1', 'tsne_2'])\n",
    "tsne_df['cluster_id'] = clus['td_clusterid_kmeans']\n",
    "tsne_df['customer_id'] = clus['l_id']\n",
    "tsne_df['amount'] = clus['txt']  # rename for clarity\n",
    "\n",
    "# Truncate text values\n",
    "tsne_df['truncated_amount'] = tsne_df['amount'].apply(\n",
    "    lambda x: f\"{x[:50]}...\" if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "# --- Compute cluster centers ---\n",
    "cluster_centers = tsne_df.groupby('cluster_id')[['tsne_1', 'tsne_2']].mean()\n",
    "\n",
    "# --- Compute distance to cluster center ---\n",
    "def euclidean_distance(row):\n",
    "    center = cluster_centers.loc[row['cluster_id']]\n",
    "    return np.sqrt((row['tsne_1'] - center['tsne_1'])**2 + (row['tsne_2'] - center['tsne_2'])**2)\n",
    "\n",
    "tsne_df['distance'] = tsne_df.apply(euclidean_distance, axis=1)\n",
    "\n",
    "# --- Mark anomalies per cluster (top 5% distance) ---\n",
    "tsne_df['is_anomaly'] = tsne_df.groupby('cluster_id')['distance'].transform(\n",
    "    lambda x: x > x.quantile(0.95)\n",
    ")\n",
    "\n",
    "# --- Plot using Matplotlib ---\n",
    "plt.figure(figsize=(12, 9))\n",
    "palette = sns.color_palette('tab10', n_colors=tsne_df['cluster_id'].nunique())\n",
    "\n",
    "# Draw normal and anomaly points separately\n",
    "for i, cluster in enumerate(sorted(tsne_df['cluster_id'].unique())):\n",
    "    cluster_data = tsne_df[tsne_df['cluster_id'] == cluster]\n",
    "    \n",
    "    # Normal points\n",
    "    normal_points = cluster_data[~cluster_data['is_anomaly']]\n",
    "    plt.scatter(\n",
    "        normal_points['tsne_1'], normal_points['tsne_2'],\n",
    "        label=f'Cluster {cluster}',\n",
    "        color=palette[i],\n",
    "        alpha=0.7,\n",
    "        edgecolor='k',\n",
    "        s=50,\n",
    "        marker='o'\n",
    "    )\n",
    "    \n",
    "    # Anomalies\n",
    "    anomalies = cluster_data[cluster_data['is_anomaly']]\n",
    "    plt.scatter(\n",
    "        anomalies['tsne_1'], anomalies['tsne_2'],\n",
    "        color=palette[i],\n",
    "        marker='D',  # diamond marker\n",
    "        edgecolor='black',\n",
    "        s=120,\n",
    "        label=f'Anomaly (Cluster {cluster})'\n",
    "    )\n",
    "\n",
    "# --- Plot cluster centers ---\n",
    "plt.scatter(\n",
    "    cluster_centers['tsne_1'], cluster_centers['tsne_2'],\n",
    "    color='black', s=250, marker='X', label='Cluster Centers'\n",
    ")\n",
    "\n",
    "plt.title('t-SNE Visualization of Clusters with Anomaly Detection', fontsize=16, weight='bold')\n",
    "plt.xlabel('Dimension-1', fontsize=14)\n",
    "plt.ylabel('Dimension-2', fontsize=14)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a90ced-9661-4af4-b780-e8ae9cb938a2",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>Conclusion</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>In this demo we have seem that how we can run HuggingFace Embedding Model (BAAI/bge-small-1.5) in ONNX format and run it in database parallelly to create embeddings. We have done KMeans Clustering to group for credit card fraud detection using anomaly detection and interactive t-SNE visualization allowed us to explore the clusters, distinguish anomalies using <b>diamond shapes</b>, and analyze the structure of the data more intuitively.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027a661b-9fdd-4199-b244-173735883c7e",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>6. Cleanup</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1981cb-7a28-43d9-840c-f54c717c58b3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;'><b>Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Cleanup work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119feed2-a05f-406a-a4c4-c2a7ed5bb793",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['credit_card_embeddings_store', 'credit_card_db', 'clustered_data','DF_embeddings_table']\n",
    "\n",
    "# Loop through the list of tables and execute the drop table command for each table\n",
    "for table in tables:\n",
    "    try:\n",
    "        db_drop_table(table_name=table)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "views = ['credit_card_tokenized_for_embeddings','credit_card_embeddings']\n",
    "\n",
    "for view in views:\n",
    "    try:\n",
    "        db_drop_view(view_name=view)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8646065d-6c32-498d-910e-3e4b99a6e492",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba960e62-874e-4aed-a74f-4a66234d3dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_CreditCard_cloud');\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f221d7-2113-489a-b138-ea9044db364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af970dd0-3a23-4ff8-8920-65169fea36f5",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial'>Dataset:</b>\n",
    "\n",
    "- `SK_ID_CURR`: Customer ID\n",
    "- `TARGET`: Target (0 = No, 1 = Yes)\n",
    "- `NAME_CONTRACT_TYPE`: Contract type (e.g., Cash loans, Revolving loans)\n",
    "- `CODE_GENDER`: Gender (Female / Male)\n",
    "- `FLAG_OWN_CAR`: Car ownership status (Y = Yes, N = No)\n",
    "- `CNT_CHILDREN`: Number of children\n",
    "- `AMT_INCOME_TOTAL`: Total income\n",
    "- `NAME_FAMILY_STATUS`: Family status (e.g., Married, Separated, Single)\n",
    "- `REGION_POPULATION_RELATIVE`: Relative population of the region\n",
    "- `FLAG_MOBIL`: Mobile phone status (1 = Yes)\n",
    "- `FLAG_EMP_PHONE`: Employment phone status (0 = No, 1 = Yes)\n",
    "- `CNT_FAM_MEMBERS`: Number of family members\n",
    "- `HOUSETYPE_MODE`: Type of house (e.g., Block of flats, House, Municipal)\n",
    "- `OCCUPATION_TYPE`: Occupation (e.g., None, Sales staff, Managers)\n",
    "- `AGE`: Age of the customer\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Links:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Teradataml Python reference: <a href = 'https://docs.teradata.com/search/all?query=Python+Package+User+Guide&content-lang=en-US'>here</a></li>\n",
    "    <li>KMeans reference: <a href = 'https://docs.teradata.com/search/all?query=KMeans&value-filters=vrm_release~%252220.00.00.03%2522&content-lang=en-US'>here</a></li>\n",
    "    <li>KMeansPredict reference: <a href = 'https://docs.teradata.com/search/all?query=KMeansPredict&value-filters=vrm_release~%252220.00.00.03%2522&content-lang=en-US'>here</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0019ec92-984a-418a-b895-031fcbf9f5db",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2025. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
