{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdca389d-76a1-4633-90b5-7bffb82efba4",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Anomaly Detection in Credit Card\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f1c117-359a-448e-a8f8-ab66739620d7",
   "metadata": {},
   "source": [
    "<p style='font-size:20px;font-family:Arial;'><b>Credit Card Fraud Detection using K-Means Clustering:</b></p> \n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "Detecting fraudulent transactions is crucial for financial security. This approach leverages <b>K-Means clustering</b> to group similar transactions and identifies anomalies based on <b>Euclidean distance</b>, where fraud-like patterns deviate significantly from normal spending behaviors.\n",
    "</p>\n",
    "\n",
    "<ul style='font-size:16px;font-family:Arial;'>\n",
    "    <li><strong>Anomaly Detection:</strong> Identifies outliers based on their distance from the cluster center, marking transactions that deviate from normal spending patterns.</li>\n",
    "    <li><strong>Vector Embeddings:</strong> Converts categorical transaction data into vector representations to improve clustering accuracy.</li>\n",
    "    <li><strong>Feature Engineering:</strong> Includes transaction amount, location, time, and merchant category to enhance fraud detection.</li>\n",
    "    <li><strong>Dimensionality Reduction:</strong> Uses t-SNE to visualize clusters and detect fraudulent transactions that do not fit normal behavior.</li>\n",
    "    <li><strong>Scalability:</strong> Works efficiently on large datasets by leveraging K-Means for unsupervised learning and anomaly detection.</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>Why Vantage?</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "    Teradata’s integration with <b>LLMs and hosting capabilities in-DB</b>, along with the Open Analytics Framework, would enable customers to run NLP models at scale. The key challenges noted for on-prem customers—such as data movement latency and lack of access to cloud models—are valid. By bringing language models within Vantage, Teradata can provide a significant advantage to on-prem customers by allowing them to run NLP models without needing to move large amounts of data to and from external services.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edab1fa-b726-482b-ac6d-757fc214ff88",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>Downloading and installing additional software needed</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3706bc-4823-4b8b-bff7-56488f37ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "!pip install wordcloud nltk --quiet --no-warn-script-location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b81191c-82d6-4cad-a5f2-deea94aa4e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "!pip install --force-reinstall pillow --quiet --no-warn-script-location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3c5e96-f353-4d9b-8f61-af67579d07d0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;'><b>Note: </b><i>The above libraries have to be installed. Restart the kernel after executing these cells to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing <b> 0 0</b></i> (zero zero) and pressing <i>Enter</i>.</p>\n",
    "</div>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330da9c2-61e0-42b7-a27b-fe762cc741ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "# Data manipluation and Visualization libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "# Teradata libraries\n",
    "from teradatamlwidgets import *\n",
    "from teradataml import (\n",
    "    configure,\n",
    "    concat,\n",
    "    create_context, \n",
    "    delete_byom, \n",
    "    display,\n",
    "    copy_to_sql,\n",
    "    execute_sql,\n",
    "    save_byom,\n",
    "    remove_context,\n",
    "    in_schema,\n",
    "    ScaleFit,\n",
    "    ScaleTransform, \n",
    "    VectorDistance,\n",
    "    KMeans,\n",
    "    KMeansPredict,\n",
    "    DataFrame,\n",
    "    db_drop_table,\n",
    "    db_drop_view,\n",
    "    ONNXEmbeddings\n",
    ")\n",
    "display.max_rows = 5\n",
    "\n",
    "# NLP libraries\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "\n",
    "# machine learning libraries\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f4f7c4-35a9-4440-88af-2bdfffa264a6",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>1. Initiate a connection to Vantage</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>You will be prompted to provide the password. Enter your password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318175ff-a36b-4dca-8201-220c295c44a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29a59be-ae73-4b5d-ac58-3df5b6acb358",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=Anomaly_Detection_Credit_Card_ONNXEmbeddings.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6043d4f5-af7c-4dfb-85a5-1ada0dad417e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0957d7af-d2a7-4204-9cf5-b99d6d0cbd32",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;'><b>Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>We have provided data for this demo on cloud storage. You can either run the demo using foreign tables to access the data without any storage on your environment or download the data to local storage, which may yield faster execution. Still, there could be considerations of available storage. Two statements are in the following cell, and one is commented out. You may switch which mode you choose by changing the comment string.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81963f5f-4301-4dca-a827-bb227b4920ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ../run_procedure.py \"call get_data('DEMO_CreditCard_cloud');\" \n",
    "# takes about 20seconds, estimated space: 0 MB\n",
    "%run -i ../run_procedure.py \"call get_data('DEMO_CreditCard_local');\" \n",
    "# takes about 35 seconds, estimated space: 11 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4dd908-6215-4489-847d-02d5b12511a2",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Next is an optional step – if you want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071d2c83-a8e4-4b7d-96aa-9798745c718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fd17e9-a5df-4f5c-a90f-29ca784d6e0e",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>2. Loading sample data for the demo</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5d8bfb-1690-4b98-9921-6582d68360c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_cc_original_data = DataFrame(in_schema(\"DEMO_CreditCard\",\"Credit_Card\"))\n",
    "tdf_cc_original_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eae51e-2c33-4559-be30-aa8227377c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_cc_original_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ff3a95-861b-45d8-b6c3-b87037893bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing a copy in database\n",
    "copy_to_sql(df = tdf_cc_original_data, table_name = \"credit_card_db\", if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f73719-8cc1-4006-8b80-bb4c3d2a39b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_CC = DataFrame.from_table('credit_card_db')\n",
    "DF_CC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f213f4-faaf-4a5e-9a2d-fe895ebc530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_CC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7d35b3-4ffa-4fcb-b08a-5a0bcfe93fa6",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-;\">\n",
    "<b style = 'font-size:18px;font-family:Arial;'>2.1 Real-time Data Collection\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b575c8-074d-422d-9c2e-f6f584934bca",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>This simulated data mimics the real-time process, where transaction details are captured continuously, enabling anomaly detection in real-time credit card activity. We will built our prediction model with testing with sample historical data, then we will save the artifacts, as a last step we will use the same artifacts to detect anomalies in simulated real-time data generated by the functions below.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18805ba-c888-4ad9-9ed4-2669e578c934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real time data collection\n",
    "def fetching_real_time_data():\n",
    "    contract_types = [\"Cash loans\", \"Revolving loans\"]\n",
    "    genders = [\"M\", \"F\"]\n",
    "    own_car = [\"Y\", \"N\"]\n",
    "    family_status = [\"Married\", \"Single\", \"Separated\"]\n",
    "    house_types = [\"Block of flats\", \"House\", \"Municipal\"]\n",
    "    occupations = [\"Sales staff\", \"Managers\", \"Core staff\", \"None\"]\n",
    "\n",
    "    records = []\n",
    "    for _ in range(10):\n",
    "        record = {\n",
    "            \"SK_ID_CURR\": random.randint(456255, 999999),\n",
    "            \"TARGET\": random.choice([0, 1]),\n",
    "            \"NAME_CONTRACT_TYPE\": random.choice(contract_types),\n",
    "            \"CODE_GENDER\": random.choice(genders),\n",
    "            \"FLAG_OWN_CAR\": random.choice(own_car),\n",
    "            \"CNT_CHILDREN\": random.randint(0, 5),\n",
    "            \"AMT_INCOME_TOTAL\": round(random.uniform(117000000, 117100000), 2),\n",
    "            \"NAME_FAMILY_STATUS\": random.choice(family_status),\n",
    "            \"REGION_POPULATION_RELATIVE\": round(random.uniform(0.001, 0.05), 6),\n",
    "            \"FLAG_MOBIL\": 1,\n",
    "            \"FLAG_EMP_PHONE\": random.choice([0, 1]),\n",
    "            \"CNT_FAM_MEMBERS\": random.randint(1, 6),\n",
    "            \"HOUSETYPE_MODE\": random.choice(house_types),\n",
    "            \"OCCUPATION_TYPE\": random.choice(occupations),\n",
    "            \"AGE\": random.randint(20, 70)\n",
    "        }\n",
    "        records.append(record)\n",
    "    \n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1395cc1c-8385-4a85-af55-b05e5c04e3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for real-time data fetching\n",
    "def fetch_data():\n",
    "    all_data = [] \n",
    "\n",
    "    print(\"\\nInitializing real-time credit card data fetch...\\n\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"Do you want to fetched updated credit card record? (yes to start, stop to end): \").strip().lower()\n",
    "        \n",
    "        if user_input == 'yes':\n",
    "            print(\"Fetching new credit card record...\", end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            time.sleep(random.uniform(0.5, 1.5))\n",
    "\n",
    "            data = fetching_real_time_data()\n",
    "            print(\" Data fetched successfully!\")\n",
    "            all_data.append(data)\n",
    "        elif user_input == 'stop':\n",
    "            print(\"\\nStopping the data collection. Finalizing...\\n\")\n",
    "            time.sleep(1)\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid input. Please enter 'yes' to generate a record or 'stop' to end.\")\n",
    "    \n",
    "    if all_data:\n",
    "        print(\"\\nFinalizing the dataset...\\n\")\n",
    "        time.sleep(1)\n",
    "        print(\"Merging all generated records...\\n\")\n",
    "        print(\"Inserted new records\")\n",
    "        return pd.concat(all_data, ignore_index=True)\n",
    "    else:\n",
    "        print(\"No records fetched, returning an empty DataFrame.\")  \n",
    "        return pd.DataFrame(columns=['TransactionID', 'Amount'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d363eba3-194f-4da7-91cb-6c1a2c88e106",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>3. Load HuggingFace Model</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>To generate embeddings, we need an ONNX model capable of transforming text into vector representations. We use a pretrained model from [Teradata's Hugging Face repository](https://huggingface.co/Teradata/gte-base-en-v1.5), such as gte-base-en-v1.5. The model and its tokenizer are downloaded and stored in Vantage tables as BLOBs using the save_byom function.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a666bad9-cf57-4bc0-9827-387835ace447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e5a433-be7f-40f5-b804-27c782fa16c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "model_name = \"bge-small-en-v1.5\"\n",
    "number_dimensions_output = 384\n",
    "model_file_name = \"model.onnx\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4208af-desc",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial'>3.1 Download and Store Model\n",
    "</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>In this step, we download the ONNX embedding model and tokenizer from Hugging Face, then store them as BLOBs in Vantage tables using the <b>save_byom</b> function. This allows the model to be cached and reused across multiple nodes for parallel embedding generation.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e2e148-2933-43ad-ab55-ce100c778b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Download Model from Teradata HuggingFace Page\n",
    "\n",
    "hf_hub_download(repo_id=f\"Teradata/{model_name}\", filename=f\"onnx/{model_file_name}\", local_dir=\"./\")\n",
    "hf_hub_download(repo_id=f\"Teradata/{model_name}\", filename=f\"tokenizer.json\", local_dir=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5de02e-3698-4378-9ae4-92af24ad3d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    db_drop_table(\"embeddings_models\")\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    db_drop_table(\"embeddings_tokenizers\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184e1cd5-244d-430e-ba5e-2d2c55aa78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load Models into Vantage\n",
    "# a) Embedding model\n",
    "save_byom(model_id = model_name, # must be unique in the models table\n",
    "               model_file = f\"onnx/{model_file_name}\",\n",
    "               table_name = 'embeddings_models' )\n",
    "# b) Tokenizer\n",
    "save_byom(model_id = model_name, # must be unique in the models table\n",
    "              model_file = 'tokenizer.json',\n",
    "              table_name = 'embeddings_tokenizers') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a71207-feb6-49b7-9654-5bc05776b46d",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Recheck the installed model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a50bf-6bb2-4654-a9bf-ca55921dff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = DataFrame('embeddings_models')\n",
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f7c0e5-8278-4ed3-9cd5-8ed933a3be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_token = DataFrame('embeddings_tokenizers')\n",
    "df_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96ece44-ea5e-488e-ab8e-a17f8a49e443",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>4. Create the Embeddings</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1fc506-b84b-4793-8dfb-d01dfc26576a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'> Let us take a look at the demo data once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e86da75-f55b-4104-9a66-a4aeca61768e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DF_CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d7df1-0f9c-4b91-bf01-5b4c464ce9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_CC.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f10526f-040f-44bd-a77c-feb5bc549266",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial'>4.1 Creation of Views and Final Embeddings Table\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2f0f8a-9ce4-418c-882d-377d818b8b2e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "Now it's time to generate the embeddings using <b>ONNXEmbeddings</b>.<br>We run the ONNXEmbeddings function to generate embeddings for a small subset of records. The model is <b>loaded into the cache memory on each node</b>, and Teradata's <b>Massively Parallel Processing (MPP)</b> architecture ensures that embeddings are computed in parallel using <b>ONNX Runtime</b> on each node.  <br>Having said that, generating embeddings for the entire training set can be time-consuming, especially when working on a system with limited resources. In the <b>ClearScape Analytics experience</b>, only a <b>4 AMP system</b> with constrained RAM and CPU power is available. To ensure smooth execution, we test embedding generation on a small sample and use <b>pre-calculated embeddings</b> for the remainder of demo. In a real-life scenario you would tyipically encounter multiple hundred AMPs with much more compute power!<br>Also have a look at the most important input parameters of this <b>ONNXEmbeddings</b> function.\n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "<li><b>InputTable</b>: The source table containing the text to be embedded. </li>\n",
    "<li><b>ModelTable</b>: The table storing the ONNX model.                    </li>\n",
    "<li><b>TokenizerTable</b>: The table storing the tokenizer JSON file.       </li>\n",
    "<li><b>Accumulate</b>: Specifies additional columns to retain in the output </li>  \n",
    "<li><b>OutputFormat</b>: Specifies the data format of the output embeddings (<b>FLOAT32(384)</b>, matching the model's output dimension).</li>\n",
    "</ul>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "Since embedding generation is computationally expensive, we only process <b>10 records for testing</b> and rely on precomputed embeddings for further analysis.  \n",
    "</p>\n",
    "\n",
    "\n",
    "<p style='font-size:18px;font-family:Arial;'><b>Generate Embeddings</b></p>    \n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "Generating embeddings will take approximately <b>10-15 minutes.</b>\n",
    "</p>\n",
    "\n",
    "\n",
    "<center><img src=\"images/visual.svg\" alt=\"embeddings_decision\" width=700 style=\"border: 4px solid #404040; border-radius: 10px;\"/></center>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "<i><b>\n",
    "These embeddings will later be used in anomaly detection by comparing the similarity between different transactions. By converting each transaction into a vector representation, we can identify outliers or anomalies based on the distance between vectors.</b></i>\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1c15d1-801c-42f5-8eb9-76bd56572e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure Teradata Bring Your Own Model Artifacts\n",
    "configure.byom_install_location = \"mldb\"\n",
    "my_model = DataFrame.from_query(f\"select * from embeddings_models where model_id = '{model_name}'\")\n",
    "my_tokenizer = DataFrame.from_query(f\"select model as tokenizer from embeddings_tokenizers where model_id = '{model_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87db2e34-185c-4cf2-886a-0a165e568f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    SK_ID_CURR AS id,\n",
    "    NAME_CONTRACT_TYPE || ' ' ||\n",
    "    CODE_GENDER || ' ' ||\n",
    "    FLAG_OWN_CAR || ' ' ||\n",
    "    NAME_FAMILY_STATUS || ' ' ||\n",
    "    COALESCE(HOUSETYPE_MODE, '') || ' ' ||\n",
    "    COALESCE(OCCUPATION_TYPE, '') || ' ' ||\n",
    "    CAST(CNT_CHILDREN AS VARCHAR(50)) || ' ' ||\n",
    "    CAST(REGION_POPULATION_RELATIVE AS VARCHAR(50)) || ' ' ||\n",
    "    CAST(CNT_FAM_MEMBERS AS VARCHAR(50)) || ' ' ||\n",
    "    CAST(AMT_INCOME_TOTAL AS VARCHAR(50)) AS txt\n",
    "FROM credit_card_db\n",
    "SAMPLE 100\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8ecabd-8afb-498d-add7-9bf324c0e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_sample100 = DataFrame.from_query(query)\n",
    "DF_sample100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01788d68-b80d-4156-87f3-2ed5b4468114",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_embeddings_training = ONNXEmbeddings(\n",
    "    newdata = DF_sample100,\n",
    "    modeldata = my_model, \n",
    "    tokenizerdata = my_tokenizer, \n",
    "    accumulate = [\"id\",\"txt\"],\n",
    "    model_output_tensor = \"sentence_embedding\",\n",
    "    output_format = f'FLOAT32({number_dimensions_output})',\n",
    "    enable_memory_check = False\n",
    ").result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c751f0-a326-4615-b244-02e2ed43419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_embeddings_training.show_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bc1729-b126-4a85-85f9-77e087878eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradatamlwidgets import *\n",
    "DF_embeddings_training.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912d72d3-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Store the generated embeddings in a permanent table for use in K-Means clustering and subsequent analysis.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e100f0-7220-492c-92db-a9cafbd84b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(DF_embeddings_training, table_name=\"embeddings_table_training\" , if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243e6bf2-6f84-440a-a336-619b264f2f53",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-;\">\n",
    "<b style = 'font-size:18px;font-family:Arial;'>4.2 Elbow Method\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8fe480-ae00-44ba-8399-2dc0da5d2fc7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>In this step, we apply the <b>Elbow Method</b> to determine the optimal number of clusters for the KMeans clustering algorithm. The Elbow Method helps in selecting the number of clusters that best represents the data by analyzing the <b>Total Within-Cluster Sum of Squares (Total_WithinSS)</b>.</p>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "For each number of clusters, we print the `Total_WithinSS` value, which represents the compactness of the clusters.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254dea5b-3294-453f-981b-61a0ba184a1e",
   "metadata": {},
   "source": [
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "The resulting plot provides a visual representation of the relationship between the number of clusters and the <b>Total_WithinSS</b>. The \"elbow\" in the plot will suggest the optimal `k` for further analysis.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d6e53c-c060-4a77-8afb-9a33e33e26b4",
   "metadata": {},
   "source": [
    "<p style='font-size:16px;font-family:Arial;'>\n",
    "In this step, we calculate the differences between successive WCSS values and use the second-order differences to identify the <b>Elbow Point</b>, which helps in selecting the optimal number of clusters (`k`).\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a969a8a-5d8b-45de-afc7-2f4733b0524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbo_method_calculation(embeddings_sample_df: DataFrame, embedding_columns: list, k_values: list) -> list:\n",
    "    total_withinss_values = []\n",
    "    for num_clusters in k_values:\n",
    "        kmeans_out = KMeans(\n",
    "            data=embeddings_sample_df,\n",
    "            id_column=\"id\",\n",
    "            target_columns=embedding_column_list,\n",
    "            num_clusters=num_clusters,\n",
    "            num_init=10,\n",
    "            iter_max=50\n",
    "        )\n",
    "        \n",
    "        result_table = kmeans_out.result\n",
    "        \n",
    "        # Convert to pandas FIRST, then filter\n",
    "        result_pandas = result_table.to_pandas()\n",
    "        \n",
    "        # Filter in pandas instead of teradataml\n",
    "        filtered_rows = result_pandas[\n",
    "            result_pandas['td_modelinfo_kmeans'].str.contains('Total_WithinSS', na=False)\n",
    "        ]\n",
    "        \n",
    "        if len(filtered_rows) == 0:\n",
    "            print(f\"Warning: No Total_WithinSS found for {num_clusters} clusters\")\n",
    "            continue\n",
    "        \n",
    "        value_str = filtered_rows['td_modelinfo_kmeans'].iloc[0]\n",
    "        numeric_str = value_str.split(':')[1].strip()\n",
    "        numeric_value = round(float(numeric_str), 2)\n",
    "        total_withinss_values.append(numeric_value)\n",
    "               \n",
    "        print(f'Number of clusters: {num_clusters}, Total_WithinSS: {numeric_value}')\n",
    "\n",
    "    # Ensure k_values matches the actual data collected\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(k_values[:len(total_withinss_values)], total_withinss_values, marker='o', linestyle='--', color='b')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Total Within-Cluster Sum of Squares (Total_WithinSS)')\n",
    "    plt.title('Elbow Method for Optimal Number of Clusters')\n",
    "    plt.xticks(k_values[:len(total_withinss_values)])  # Show only integer ticks\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    return total_withinss_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c98b48-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>The function below identifies the optimal number of clusters by finding the elbow point in the Total Within-Cluster Sum of Squares curve. It calculates angles at each point and selects the cluster count where the curve bends most sharply.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0285d1e1-0257-49cc-9b53-2d685183feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_elbow_point(total_withinss_values: list, k_values: list) -> int:\n",
    "    # Need at least 3 values for second-order differences\n",
    "    if len(total_withinss_values) < 3:\n",
    "        print(\"Not enough data points to determine optimal K\")\n",
    "    else:\n",
    "        wcss_diff = np.diff(total_withinss_values)   # First derivative (length: n-1)\n",
    "        wcss_diff2 = np.diff(wcss_diff)              # Second derivative (length: n-2)\n",
    "        \n",
    "        # Add 2 to get index in original k_values (because we lost 2 elements from two diff operations)\n",
    "        elbow_index = np.argmax(wcss_diff2) + 2  # Use argmax, not argmin (see explanation)\n",
    "        optimal_k_index = k_values[elbow_index]\n",
    "      \n",
    "    print(f'Rate of WCSS change between K values: {wcss_diff}')\n",
    "    print(f'Change in rate (acceleration): {wcss_diff2}')\n",
    "    print(f'Index where curve bends most: {elbow_index}')\n",
    "    print(f'Optimal number of clusters (K) based on Elbow Method: {optimal_k_index}')\n",
    "    return optimal_k_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd4758d-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Extract the list of embedding columns (emb_0 through emb_383) to be used as features for K-Means clustering.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fad408f-38df-4039-8a45-0c6def4ee441",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_column_list = [col for col in DF_embeddings_training.columns if col not in [\"id\", \"txt\"]]\n",
    "k_values = list(range(5, 10))\n",
    "total_withinss_values = elbo_method_calculation(DF_embeddings_training, embedding_column_list, k_values)\n",
    "optimal_k = find_elbow_point(total_withinss_values, k_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76981b9-b76d-49ae-b7d2-93b702e98591",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>5. Run K-Means on the Embeddings Store and then build final table with Cluster ID assignments to rows</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b67ea4-8315-4cfa-9d96-0c874f4f5588",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>The K-means() function groups a set of observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid). This algorithm minimizes the objective function, that is, the total Euclidean distance of all data points from the center of the cluster</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9c3c03-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>The function below encapsulates the complete K-Means training workflow. It trains the model, generates predictions with distances, computes cluster statistics, and calculates the 95th percentile distance threshold for each cluster. These thresholds serve as boundaries for identifying anomalies.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b1c1c6-5c8a-4b50-82dd-b488150db035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kmeans_model(embeddings_table: str, feature_columns: list, num_clusters: int) -> dict:\n",
    "    kmeans_trained = KMeans(\n",
    "    id_column=\"id\",\n",
    "    data=DataFrame(embeddings_table),\n",
    "    target_columns=feature_columns,\n",
    "    num_init=10,\n",
    "    num_clusters=num_clusters,\n",
    "    iter_max=50,\n",
    "    )\n",
    "\n",
    "    trained_key_means_df = kmeans_trained.result\n",
    "    \n",
    "    clustered_data = KMeansPredict(data=DataFrame(embeddings_table),\n",
    "                                    object=trained_key_means_df,\n",
    "                                    output_distance=True)\n",
    "    \n",
    "    cluster_stats = clustered_data.result.groupby('td_clusterid_kmeans').count()\n",
    "\n",
    "    training_data_scored = DataFrame(embeddings_table).join(\n",
    "    other = clustered_data.result[['id', 'td_clusterid_kmeans', 'td_distance_kmeans']],\n",
    "    on = [\"id\"],\n",
    "    how = \"inner\",\n",
    "    lprefix=\"l\",\n",
    "    rprefix=\"r\"\n",
    "    )\n",
    "\n",
    "    thresholds_df = training_data_scored[['td_clusterid_kmeans','td_distance_kmeans']].groupby('td_clusterid_kmeans').percentile(0.95)\n",
    "    \n",
    "\n",
    "\n",
    "    copy_to_sql(trained_key_means_df, table_name='kmeans_trained_model', if_exists='replace')\n",
    "    copy_to_sql(training_data_scored, table_name='kmeans_scored_training_output', if_exists='replace')\n",
    "    copy_to_sql(cluster_stats, table_name='kmeans_cluster_stats', if_exists='replace')\n",
    "    copy_to_sql(thresholds_df, table_name='kmeans_thresholds', if_exists='replace')  \n",
    "\n",
    "    return {\n",
    "        'kmeans_model_trained_table': 'kmeans_trained_model',\n",
    "        'kmeans_scored_training_table': 'kmeans_scored_training_output',\n",
    "        'kmeans_cluster_stats_table': 'kmeans_cluster_stats',\n",
    "        'kmeans_thresholds_table': 'kmeans_thresholds'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8a062f-d1d5-43b0-8c8d-1640779fc94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifacts = train_kmeans_model('embeddings_table_training', embedding_column_list, optimal_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96832bcd-409f-49d3-8c9a-6f7cd010f554",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>The output below shows cluster assignment for each row.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ca9a10-bea0-4671-bfff-2053491d41a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_scored_training_data = DataFrame(model_artifacts['kmeans_scored_training_table'])\n",
    "kmeans_scored_training_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e13933-6976-4029-b1ee-64b553ca82d3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Let's check how many data points each cluster has.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34363aa4-87c4-4af1-92ff-b55d29e3b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_cluster_stats_df = DataFrame(model_artifacts['kmeans_cluster_stats_table'])\n",
    "kmeans_cluster_stats_df[['td_clusterid_kmeans','count_id']].head(optimal_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03473a3-ab69-428c-879d-62792a1b9a9e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>And the thresholds</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d89bd56-9bf7-425c-a426-d3b6234b0b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_thresholds_df = DataFrame(model_artifacts['kmeans_thresholds_table'])\n",
    "kmeans_thresholds_df.head(optimal_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73763700-d50a-41cd-879a-ec534c1983e3",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>6. Visualization</b>\n",
    "\n",
    "<hr style='height:1px;border:none;background-;'> \n",
    "\n",
    "<p style='font-size:18px;font-family:Arial;'><b>6.1 Visualization of Clusters</b></p> \n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>The graph illustrates the clustering of transactions into distinct groups for credit card fraud detection using anomaly detection. Based on the analysis, the data has been divided into optimal clusters, each representing a unique transaction pattern. This clustering approach helps identify potential fraudulent activities by distinguishing normal and anomalous transaction behaviors, enabling more targeted fraud detection and prevention efforts.</p>\n",
    "\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>This visualization helps us explore the structure of the clusters and visually identify <b>anomalies</b> (points that deviate significantly from their respective cluster centers). The use of <b>diamonds for anomalies</b> and <b>circles for normal data points</b> provides a clear and intuitive way to distinguish between outliers and inliers in the data, making it easier to detect potential fraudulent or unusual activity.</p>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>The interactive nature of the plot allows for an engaging exploration of the data, where users can hover over points to view more detailed information.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8912a8-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>The visualization function below applies <b>t-SNE</b> (t-distributed Stochastic Neighbor Embedding) to reduce the high-dimensional embeddings to 2D for plotting. It calculates distances from cluster centers and marks the top 5% most distant points as anomalies.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1e4f2f-0fbd-419f-ab3c-223957957761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clusters(clustered_data: DataFrame):   \n",
    "    clus = clustered_data.to_pandas()\n",
    "    # --- Perform t-SNE ---\n",
    "    tsne = TSNE(n_components=2, random_state=123)\n",
    "    tsne_result = tsne.fit_transform(clus.iloc[:, 3:-2])\n",
    "\n",
    "    # --- Create visualization DataFrame ---\n",
    "    tsne_df = pd.DataFrame(tsne_result, columns=['tsne_1', 'tsne_2'])\n",
    "    tsne_df['cluster_id'] = clus['td_clusterid_kmeans']\n",
    "    tsne_df['record_id'] = clus['l_id']\n",
    "    tsne_df['features'] = clus['txt']  # rename for clarity\n",
    "\n",
    "    # Truncate text values\n",
    "    tsne_df['truncated_features'] = tsne_df['features'].apply(\n",
    "        lambda x: f\"{x[:50]}...\" if isinstance(x, str) else x\n",
    "    )\n",
    "\n",
    "    # --- Compute cluster centers ---\n",
    "    cluster_centers = tsne_df.groupby('cluster_id')[['tsne_1', 'tsne_2']].mean()\n",
    "\n",
    "    # --- Compute distance to cluster center ---\n",
    "    def euclidean_distance(row):\n",
    "        center = cluster_centers.loc[row['cluster_id']]\n",
    "        return np.sqrt((row['tsne_1'] - center['tsne_1'])**2 + (row['tsne_2'] - center['tsne_2'])**2)\n",
    "\n",
    "    tsne_df['distance'] = tsne_df.apply(euclidean_distance, axis=1)\n",
    "\n",
    "    # --- Mark anomalies per cluster (top 5% distance) ---\n",
    "    tsne_df['is_anomaly'] = tsne_df.groupby('cluster_id')['distance'].transform(\n",
    "        lambda x: x > x.quantile(0.95)\n",
    "    )\n",
    "\n",
    "    # --- Plot using Matplotlib ---\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    palette = sns.color_palette('tab10', n_colors=tsne_df['cluster_id'].nunique())\n",
    "\n",
    "    # Draw normal and anomaly points separately\n",
    "    for i, cluster in enumerate(sorted(tsne_df['cluster_id'].unique())):\n",
    "        cluster_data = tsne_df[tsne_df['cluster_id'] == cluster]\n",
    "        \n",
    "        # Normal points\n",
    "        normal_points = cluster_data[~cluster_data['is_anomaly']]\n",
    "        plt.scatter(\n",
    "            normal_points['tsne_1'], normal_points['tsne_2'],\n",
    "            label=f'Cluster {cluster}',\n",
    "            color=palette[i],\n",
    "            alpha=0.7,\n",
    "            edgecolor='k',\n",
    "            s=50,\n",
    "            marker='o'\n",
    "        )\n",
    "        \n",
    "        # Anomalies\n",
    "        anomalies = cluster_data[cluster_data['is_anomaly']]\n",
    "        plt.scatter(\n",
    "            anomalies['tsne_1'], anomalies['tsne_2'],\n",
    "            color=palette[i],\n",
    "            marker='D',  # diamond marker\n",
    "            edgecolor='black',\n",
    "            s=120,\n",
    "            label=f'Anomaly (Cluster {cluster})'\n",
    "        )\n",
    "\n",
    "    # --- Plot cluster centers ---\n",
    "    plt.scatter(\n",
    "        cluster_centers['tsne_1'], cluster_centers['tsne_2'],\n",
    "        color='black', s=250, marker='X', label='Cluster Centers'\n",
    "    )\n",
    "\n",
    "    plt.title('t-SNE Visualization of Clusters with Anomaly Detection', fontsize=16, weight='bold')\n",
    "    plt.xlabel('Dimension-1', fontsize=14)\n",
    "    plt.ylabel('Dimension-2', fontsize=14)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a755a6a5-94da-4bfe-b03e-0dbebfa78f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_clusters(kmeans_scored_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3615ffd5-3e34-46a7-9a77-086f59b8cc81",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>7. Anomaly Prediction</b>\n",
    "\n",
    "<hr style='height:1px;border:none;background-;'> \n",
    "\n",
    "<p style='font-size:18px;font-family:Arial;'><b>7.1 Predict Anomalies</b></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26de1a86-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>The anomaly prediction function joins the scored data with the cluster thresholds and flags each transaction as an anomaly (1) or normal (0) based on whether its distance exceeds the cluster's 95th percentile threshold.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44717811-03ff-4d51-afb3-b264f98fdbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_anomalies(scored_data_table: str, thresholds_table: str, output_table: str) -> dict:\n",
    "    scored_data_df = DataFrame(scored_data_table)\n",
    "    thresholds_df = DataFrame(thresholds_table)\n",
    "\n",
    "    prediction_df = scored_data_df.join(\n",
    "        other=thresholds_df,\n",
    "        on='td_clusterid_kmeans',\n",
    "        how='inner',\n",
    "        lsuffix='_l',\n",
    "        rsuffix='_r'\n",
    "    )\n",
    "\n",
    "    from teradataml import case\n",
    "\n",
    "    prediction_df = prediction_df.assign(\n",
    "        anomaly = case(\n",
    "            [(prediction_df['td_distance_kmeans'] > prediction_df['percentile_td_distance_kmeans'], 1)],\n",
    "            else_=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "    copy_to_sql(prediction_df, table_name=output_table, if_exists='replace')\n",
    "\n",
    "    return {\n",
    "        'anomaly_prediction_table': output_table\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7e7a4b-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>We apply the anomaly prediction function to our training data to identify transactions that deviate significantly from their assigned cluster patterns.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b42c577-f2fa-46fd-83f6-3f0aecc66f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_anomalies(model_artifacts['kmeans_scored_training_table'],model_artifacts['kmeans_thresholds_table'], 'training_data_predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5f818b-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Let us view the prediction results. The <b>anomaly</b> column indicates whether each transaction is flagged as anomalous (1) or normal (0).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3063a15-37eb-47f5-b2d0-0a5d47d3183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_training_df= DataFrame('training_data_predictions')\n",
    "predictions_training_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9547eb-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Examine the distribution of anomalies across clusters to understand which transaction patterns are most likely to be flagged as suspicious.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8170c7a9-b1bb-4fc4-bcc1-873a85e89970",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_training_df[predictions_training_df['anomaly'] == 1].groupby('td_clusterid_kmeans__r').count()[['td_clusterid_kmeans__r','count_anomaly']].head(optimal_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaf1a3d-3ef3-4276-bb6b-185ac76ac98a",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>8. Real-time data Fetching</b>\n",
    "\n",
    "<hr style='height:1px;border:none;background-;'> \n",
    "\n",
    "<p style='font-size:18px;font-family:Arial;'><b>8.1 Data Fetching Process</b></p> \n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>The <code>fetch_data()</code> function allows the user to fetch new credit card transaction records in real-time. By entering <b>'yes'</b>, the system fetches and stores 10 new records, simulating live data collection. Entering <b>'stop'</b> terminates the data fetching process, finalizing and merging all collected records into a dataset.</p>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb89cc35-45ba-47eb-a945-a788936f4d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Real time credit card data\n",
    "tdf = fetch_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49bed12-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Store the fetched real-time data in the database for subsequent processing and embedding generation.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb751c3a-ae7f-4b22-a94a-370a3d9b2567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in database\n",
    "copy_to_sql(tdf, table_name=\"credit_card_db_test\", if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588ead2c-d5c3-44ba-a1cc-7fdded8bbd7d",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>9. Create the Embeddings on Fetched Data</b>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>we generate and store the embeddings for the credit card transaction data. The embeddings are created using a pre-trained model, which transforms the transaction data into vectorized representations that can be used for anomaly detection.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5920ea8c-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Load and verify the test data from the database to confirm the data was stored correctly.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd1062-8b39-4dd6-97f5-1ddf236883f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = DataFrame.from_table('credit_card_db_test')\n",
    "tdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f618b103-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Prepare the test data by concatenating relevant features into a single text column, following the same format used for training data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0679119d-0149-497e-9189-2de6f2147693",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    SK_ID_CURR AS id,\n",
    "    NAME_CONTRACT_TYPE || ' ' ||\n",
    "    CODE_GENDER || ' ' ||\n",
    "    FLAG_OWN_CAR || ' ' ||\n",
    "    NAME_FAMILY_STATUS || ' ' ||\n",
    "    COALESCE(HOUSETYPE_MODE, '') || ' ' ||\n",
    "    COALESCE(OCCUPATION_TYPE, '') || ' ' ||\n",
    "    CAST(CNT_CHILDREN AS VARCHAR(50)) || ' ' ||\n",
    "    CAST(REGION_POPULATION_RELATIVE AS VARCHAR(50)) || ' ' ||\n",
    "    CAST(CNT_FAM_MEMBERS AS VARCHAR(50)) || ' ' ||\n",
    "    CAST(AMT_INCOME_TOTAL AS VARCHAR(50)) AS txt\n",
    "FROM credit_card_db_test\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab5167e-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Execute the query to create the formatted text representation of test transaction data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6526cb17-fcdc-4bc9-9a25-d9542708049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_test_data = DataFrame.from_query(query)\n",
    "DF_test_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c27022b-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Generate embeddings for the test data using the same ONNX model and tokenizer. These embeddings will be used to predict cluster assignments and detect anomalies in the new transactions.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb709f-95c9-4781-b676-d7697dfa31b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Embeddings\n",
    "DF_embeddings_test = ONNXEmbeddings(\n",
    "    newdata = DF_test_data,\n",
    "    modeldata = my_model, \n",
    "    tokenizerdata = my_tokenizer, \n",
    "    accumulate = [\"id\", \"txt\"],\n",
    "    model_output_tensor = \"sentence_embedding\",\n",
    "    output_format = f'FLOAT32({number_dimensions_output})',\n",
    "    enable_memory_check = False\n",
    ").result\n",
    "print(\"All steps completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc29b692-24dc-41c6-8020-580ecfa9b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View sample data\n",
    "DF_embeddings_test.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe5bea4-b0f0-450d-a278-e355bf2b50d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View shape of dataframe\n",
    "DF_embeddings_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f70bd7c-d8a9-4a5d-a15b-43f0c66fcfd2",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>10. Applying KMeans Prediction</b>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>We apply the <b>KMeans Prediction</b> to predict the cluster assignments for the dataset using the previously trained KMeans model. This allows us to label the data points with the clusters they belong to and further analyze the results.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ebd05a-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Let us verify the model artifacts that were saved during training. These include the trained K-Means model, scored training output, cluster statistics, and distance thresholds.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f65111-46ae-4143-aba3-03571d6022f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_artifacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753dbcc9-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Apply the trained K-Means model to the test embeddings to predict cluster assignments and calculate distances. The <b>output_distance=True</b> parameter ensures we get the distance to the nearest cluster center for anomaly detection.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328c005f-8b7f-41fe-97f2-b298d215780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying KMeansPredict\n",
    "kmeans_scored_test_data = KMeansPredict(data=DF_embeddings_test,\n",
    "                                    object=DataFrame(model_artifacts['kmeans_model_trained_table']),\n",
    "                                    output_distance=True)\n",
    "\n",
    "# Print the result DataFrames.\n",
    "kmeans_scored_test_data_df = kmeans_scored_test_data.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597ea4c0-6402-4700-b609-07e1a76d554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_scored_test_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f17343-caea-463b-a551-76ebe38ee9e9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Let's check how many data points each cluster has.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6034148e-9b58-459e-bc58-e79ecf3301ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of each clusterid\n",
    "kmeans_scored_test_data_df.groupby('td_clusterid_kmeans').count().head(optimal_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6af8d4e-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Store the scored test data with cluster assignments and distances in the database.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb0271b-0efe-4c10-9d22-6a47cdc2ab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(kmeans_scored_test_data_df, 'kmeans_scored_test_output', if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eec8d2f-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Apply the anomaly detection function to the test data using the established thresholds from training. Transactions exceeding their cluster's distance threshold will be flagged as anomalies.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d8604e-56fd-4fea-a23c-b9348c857da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_anomalies('kmeans_scored_test_output',model_artifacts['kmeans_thresholds_table'], 'test_data_predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e38e54-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>View the anomaly predictions for the test data. The <b>anomaly</b> column shows which transactions have been flagged as potential fraud.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1b6b75-4043-4cd1-860e-7ec47833e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_df= DataFrame('test_data_predictions')\n",
    "predictions_test_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c30e37-e8ff-4918-8040-5feab3eaea51",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>11. Visualization</b>\n",
    "\n",
    "<hr style='height:1px;border:none;background-;'> \n",
    "\n",
    "<p style='font-size:18px;font-family:Arial;'><b>11.1 Visualization of Clusters</b></p> \n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>This visualization helps us explore the structure of the clusters and visually identify <b>anomalies</b> (points that deviate significantly from their respective cluster centers). The use of <b>diamonds for anomalies</b> and <b>circles for normal data points</b> provides a clear and intuitive way to distinguish between outliers and inliers in the data, making it easier to detect potential fraudulent or unusual activity.</p>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>The interactive nature of the plot allows for an engaging exploration of the data, where users can hover over points to view more detailed information.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9718e74c-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Join the test embeddings with their cluster predictions and distances to create a complete scored dataset for anomaly detection.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627a87dc-82de-4862-9eb2-5b0a86725325",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_scored = DF_embeddings_test.join(\n",
    "other = kmeans_scored_test_data_df[['id', 'td_clusterid_kmeans', 'td_distance_kmeans']],\n",
    "on = [\"id\"],\n",
    "how = \"inner\",\n",
    "lprefix=\"l\",\n",
    "rprefix=\"r\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6af5683-88e1-47cd-97ff-49ca58824f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_scored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305c3bef-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Combine the training and test scored data to visualize both datasets together, allowing us to see how the new transactions compare to the established cluster patterns.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f372fe-5aba-4683-aa6c-d53e41659d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_clustered_data = concat([kmeans_scored_training_data, test_data_scored], allow_duplicates=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f2467d-e82d-40e5-88b4-282767bb141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_clustered_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5ea4e1-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Visualize the test data clusters using t-SNE to see how the real-time transactions are positioned relative to the learned cluster patterns. Anomalies will appear as diamond shapes, indicating transactions that deviate from normal behavior.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646ae66c-b7f3-4b92-b3c2-f88d1664ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_clusters(combined_clustered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a90ced-9661-4af4-b780-e8ae9cb938a2",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>Conclusion</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>In this demo we have seem that how we can run HuggingFace Embedding Model (BAAI/bge-small-1.5) in ONNX format and run it in database parallelly to create embeddings. We have done KMeans Clustering to group for credit card fraud detection using anomaly detection and interactive t-SNE visualization allowed us to explore the clusters, distinguish anomalies using <b>diamond shapes</b>, and analyze the structure of the data more intuitively.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027a661b-9fdd-4199-b244-173735883c7e",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>12. Cleanup</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1981cb-7a28-43d9-840c-f54c717c58b3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;'><b>Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Cleanup work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119feed2-a05f-406a-a4c4-c2a7ed5bb793",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [\n",
    "    'credit_card_db',\n",
    "    'embeddings_models',\n",
    "    'embeddings_tokenizers',\n",
    "    'embeddings_table_training',\n",
    "    'kmeans_trained_model',\n",
    "    'kmeans_scored_training_output',\n",
    "    'kmeans_cluster_stats',\n",
    "    'kmeans_thresholds',\n",
    "    'training_data_predictions',\n",
    "    'credit_card_db_test',\n",
    "    'kmeans_scored_test_output',\n",
    "    'test_data_predictions'\n",
    "]\n",
    "\n",
    "# Loop through the list of tables and execute the drop table command for each table\n",
    "for table in tables:\n",
    "    try:\n",
    "        db_drop_table(table_name=table)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "views = ['credit_card_tokenized_for_embeddings','credit_card_embeddings']\n",
    "\n",
    "for view in views:\n",
    "    try:\n",
    "        db_drop_view(view_name=view)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8646065d-6c32-498d-910e-3e4b99a6e492",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba960e62-874e-4aed-a74f-4a66234d3dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_CreditCard_local');\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f647d68f-desc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Close the connection to Vantage to release resources.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f221d7-2113-489a-b138-ea9044db364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af970dd0-3a23-4ff8-8920-65169fea36f5",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial'>Dataset:</b>\n",
    "\n",
    "- `SK_ID_CURR`: Customer ID\n",
    "- `TARGET`: Target (0 = No, 1 = Yes)\n",
    "- `NAME_CONTRACT_TYPE`: Contract type (e.g., Cash loans, Revolving loans)\n",
    "- `CODE_GENDER`: Gender (Female / Male)\n",
    "- `FLAG_OWN_CAR`: Car ownership status (Y = Yes, N = No)\n",
    "- `CNT_CHILDREN`: Number of children\n",
    "- `AMT_INCOME_TOTAL`: Total income\n",
    "- `NAME_FAMILY_STATUS`: Family status (e.g., Married, Separated, Single)\n",
    "- `REGION_POPULATION_RELATIVE`: Relative population of the region\n",
    "- `FLAG_MOBIL`: Mobile phone status (1 = Yes)\n",
    "- `FLAG_EMP_PHONE`: Employment phone status (0 = No, 1 = Yes)\n",
    "- `CNT_FAM_MEMBERS`: Number of family members\n",
    "- `HOUSETYPE_MODE`: Type of house (e.g., Block of flats, House, Municipal)\n",
    "- `OCCUPATION_TYPE`: Occupation (e.g., None, Sales staff, Managers)\n",
    "- `AGE`: Age of the customer\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Links:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Teradataml Python reference: <a href = 'https://docs.teradata.com/search/all?query=Python+Package+User+Guide&content-lang=en-US'>here</a></li>\n",
    "    <li>KMeans reference: <a href = 'https://docs.teradata.com/search/all?query=KMeans&value-filters=vrm_release~%252220.00.00.03%2522&content-lang=en-US'>here</a></li>\n",
    "    <li>KMeansPredict reference: <a href = 'https://docs.teradata.com/search/all?query=KMeansPredict&value-filters=vrm_release~%252220.00.00.03%2522&content-lang=en-US'>here</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0019ec92-984a-418a-b895-031fcbf9f5db",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; border-bottom:3px solid\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2025. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
