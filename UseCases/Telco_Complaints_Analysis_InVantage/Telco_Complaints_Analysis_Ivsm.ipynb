{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df79517-1e4f-420a-b7e3-fbb2bb44009d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       From Complaints to Clarity:<br> Uncovering Hidden Trends in Telco Customer Feedback\n",
    " <br>       \n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 150px; height: auto; margin-top: 20pt;\">\n",
    "  <br>\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e1b65b-2d1a-4122-82fb-24c90b84ed0a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial'><b>Introduction:</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "    In this notebook, we will demonstrate how <b>Teradata helps Telcos turn customer complaints into valuable insights.</b><br>\n",
    "By analyzing customer feedback, we’ll reveal hidden trends and patterns, allowing companies to understand and address customer experience challenges more effectively.\n",
    "<br><br>\n",
    "This demo will build an interactive dashboard that provides a clear, real-time view of these trends, helping decision-makers improve customer satisfaction.\n",
    "<br><br>\n",
    "Discover how Teradata's unique <code>GenAI</code> based approach ensures reliable and consistent results, making it an essential tool for the telecommunications industry.\n",
    "<br><br>\n",
    "Tracking the evolution of topics over time is essential for understanding patterns, behaviors, and emerging trends in large datasets of text. In industries such as customer support, social media monitoring, and market research, identifying how topics shift over time can provide valuable insights for decision-making and strategy development. Traditional manual analysis methods, however, can be labor-intensive and prone to human bias.<br>\n",
    "In this demo, we explore a dynamic approach to topic trend analysis by combining message embeddings with topic embeddings, leveraging vector distance calculations to measure similarity between the two.\n",
    "<br><br>\n",
    "While the specific example can be applied across many sectors, we’ll focus on a use case using a synthetic dataset of fictitious telco-related complaints. This dataset contains complaints about various telecommunications services, providing valuable insights into customer sentiment and trends. By categorizing these complaints by topic, businesses can gain a deeper understanding of customer concerns in the telecommunications sector and adjust their strategies to address emerging issues more effectively.<br>\n",
    "To achieve this, we will:\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Generate embeddings for both customer messages and inferred/predefined topics</li>\n",
    "    <li>Calculate vector distances between message and topic embeddings to assess similarity</li>\n",
    "    <li>Feed the results into a dashboard to display topic trends over time, with configurable similarity thresholds and message counts</li>\n",
    "</ul>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "<center><img src=\"images/workflow_topictrend.png\" alt=\"workflow_topictrend\" style=\"border: 4px solid #404040; border-radius: 10px;\"/></center>\n",
    "<p style = 'font-size:16px;font-family:Arial'>This method provides an efficient way to not only categorize messages by topic but also track how these topics evolve over time, offering actionable insights into changing customer concerns, emerging issues, and overall trends.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a628f056-dbee-4ec4-a5d4-b7a860cbaa80",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>Downloading and installing additional software needed</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a325ffa-f4ab-44fb-b729-adeaf9e9df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install wordcloud nltk --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc16152-9448-4b1c-a398-7a3a94bac040",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --force-reinstall pillow --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669afc49-343d-4bf1-96f4-b49ed7a75261",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5639a5-1b8c-4001-8f20-45221b039f6e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;'><b>Note: </b><i>The above libraries have to be installed. Restart the kernel after executing these cells to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing <b> 0 0</b></i> (zero zero) and pressing <i>Enter</i>.</p>\n",
    "</div>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18116bca-b8af-4360-bf4a-a420451777b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Data manipluation and Visualization libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# Teradata libraries\n",
    "from teradataml import (\n",
    "    create_context, \n",
    "    delete_byom, \n",
    "    display,\n",
    "    execute_sql,\n",
    "    save_byom,\n",
    "    copy_to_sql,\n",
    "    remove_context,\n",
    "    in_schema,\n",
    "    KMeans,\n",
    "    KMeansPredict,\n",
    "    VectorDistance,\n",
    "    DataFrame,\n",
    "    DATE,\n",
    "    db_drop_table,\n",
    "    db_drop_view,\n",
    ")\n",
    "display.max_rows = 5\n",
    "from sqlalchemy.sql import literal_column as col\n",
    "\n",
    "# NLP libraries\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "# machine learning libraries\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d689b8-787e-470c-820d-2d794d92ccf1",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>1. Initiate a connection to Vantage</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>You will be prompted to provide the password. Enter your password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e801c-31af-48bc-af16-0f150cec7c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1916ffa0-c72c-4980-a100-d13904fc3f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=Telco_Complaints_Analysis_Ivsm.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039fbd7c-8dc2-4508-8216-492ee83c59d8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded1b2e3-5391-4025-8428-093b4ecfff56",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;'><b>Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>We have provided data for this demo on cloud storage. You can either run the demo using foreign tables to access the data without any storage on your environment or download the data to local storage, which may yield faster execution. Still, there could be considerations of available storage. Two statements are in the following cell, and one is commented out. You may switch which mode you choose by changing the comment string.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16973665-4402-466e-bd51-8b3e279bb866",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call get_data('DEMO_Telco_Complaints_local');\" # Takes 2 minutes\n",
    "#%run -i ../run_procedure.py \"call get_data('DEMO_Telco_Complaints_cloud');\" # Takes 2 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05175b33-b1a0-4292-ad58-a155c0892491",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Next is an optional step – if you want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e6f604-ef55-4503-88ac-7dd584fbd601",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39506f3-d7ce-4301-b756-cacebd2621fe",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>2. Confirmation for functions</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Before starting let us confirm that the required functions are installed.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f458c7-d659-41d2-b455-8e77244599a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "df_check= DataFrame.from_query('''select count(*) as cnt from dbc.tablesV where databasename = 'ivsm';''')\n",
    "if df_check.get_values()[0][0] >= 10:\n",
    "    print('Functions are installed, please continue.')\n",
    "else:\n",
    "    print('Functions are not installed, please go to Instalization notebook before proceeding further')\n",
    "    display(Markdown(\"[Initialization Notebook](./Initialization_and_Model_Load.ipynb)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d755479-839b-4c36-b6f9-6d3026bd9abb",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>3. Create the Embeddings</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a4fcab-3bc1-44fb-acb8-76dfa09c70f4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'> Let us take a look at our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22728822-81f3-412f-b1d8-dd9e20314bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DF_complaints = DataFrame(in_schema('DEMO_Telco_Complaints', 'telco_consumer_complaints'))\n",
    "DF_complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435fcd99-141c-44a9-9f58-2133122aceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_complaints.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33261854-6678-4d64-86f0-1c9e6ff2b9ac",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial;'>3.1 Creation of the view with tokenized original texts</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555acbe1-e959-4fa5-aff5-f886fc126447",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "While generating embeddings for the entire training set is possible, it can be time-consuming on a system with limited resources. In the ClearScape Analytics setup, we are working with just a 4 AMP system with restricted RAM and CPU. To keep the process smooth, we generate embeddings on a small sample and use pre-calculated embeddings for the rest of this blog post. In practice, you would normally have access to hundreds of AMPs and significantly more compute power.<br>    \n",
    "    This code creates a view named <code>v_complaints_tokenized_for_embeddings</code> that contains tokenized consumer complaint data for embedding purposes. It selects the <code>id</code>, <code>txt</code> (complaint text), <code>input_ids</code> (tokenized representations), and <code>attention_mask</code> from a tokenization function <code>ivsm.tokenizer_encode</code>.</b> We are taking a subset of 100 ids for demonstartion purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11cdbe4-e229-4394-9f78-592f2eba50c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = \"\"\"\n",
    "REPLACE VIEW v_complaints_tokenized_for_embeddings AS (\n",
    "  SELECT \n",
    "    id, \n",
    "    txt, \n",
    "    IDS AS input_ids, \n",
    "    attention_mask \n",
    "  FROM \n",
    "    ivsm.tokenizer_encode(\n",
    "      ON (\n",
    "        SELECT \n",
    "          row_id AS id, \n",
    "          txt \n",
    "        FROM \n",
    "          DEMO_Telco_Complaints.telco_consumer_complaints where row_id <100\n",
    "      ) ON (\n",
    "        SELECT \n",
    "          model AS tokenizer \n",
    "        FROM \n",
    "          embeddings_tokenizers \n",
    "        WHERE \n",
    "          model_id = 'bge-small-en-v1.5'\n",
    "      ) DIMENSION\n",
    "      USING \n",
    "          ColumnsToPreserve('id', 'txt')\n",
    "          OutputFields('IDS', 'ATTENTION_MASK')\n",
    "          MaxLength(1024)\n",
    "          PadToMaxLength('True')\n",
    "          TokenDataType('INT64')\n",
    "    ) a\n",
    ");\n",
    "\"\"\"\n",
    "try:\n",
    "    execute_sql(qry)\n",
    "    print('View Created')\n",
    "except Exception as e:\n",
    "    print('View creation failed')\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc5cafc-c1f8-45c8-8f19-51384411f4e9",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial;'>3.2 Creation of the view with calculated binary embeddings</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba897e85-f7b5-4281-92d5-d24f5c6a1a09",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>This code creates a view named <code>complaints_embeddings</code> that stores the computed embeddings (vector representations) of consumer complaint texts. The embeddings are generated using the <code>ivsm.IVSM_score</code> function, which scores/tokenizes input data based on a specific model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c54badc-3660-42fc-9c8f-ca746473a805",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry=\"\"\"\n",
    "REPLACE VIEW complaints_embeddings AS (\n",
    "  SELECT \n",
    "    * \n",
    "  FROM \n",
    "    ivsm.IVSM_score(\n",
    "      ON v_complaints_tokenized_for_embeddings ON (\n",
    "        SELECT \n",
    "          * \n",
    "        FROM \n",
    "          embeddings_models \n",
    "        WHERE \n",
    "          model_id = 'bge-small-en-v1.5'\n",
    "      ) dimension\n",
    "      USING \n",
    "          ColumnsToPreserve('id', 'txt')\n",
    "          ModelType('ONNX')\n",
    "          BinaryInputFields('input_ids', 'attention_mask')\n",
    "          BinaryOutputFields('sentence_embedding')\n",
    "          Caching('inquery')\n",
    "    ) a\n",
    ");\n",
    "\"\"\"\n",
    "try:\n",
    "    execute_sql(qry)\n",
    "    print('View Created')\n",
    "except Exception as e:\n",
    "    print('View creation failed')\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ac7184-1e6f-4ac2-a7de-6ea4df50edef",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>3.3 Creating Final Embeddings table</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>In this last step we will create embeddings table creating a column for each embedding essentially converting an array to separate columns.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bfa2f9-ecef-4991-82d2-05977ae11e6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#takes about 2minutes for 100 row_ids\n",
    "start = time.time()\n",
    "qry=(\"\"\"\n",
    "     CREATE multiset TABLE complaints_embeddings_store AS (\n",
    "      SELECT \n",
    "        * \n",
    "      FROM \n",
    "        ivsm.vector_to_columns(\n",
    "          ON complaints_embeddings \n",
    "        USING \n",
    "          ColumnsToPreserve('id', 'txt') \n",
    "          VectorDataType('FLOAT32')\n",
    "          VectorLength(384) \n",
    "          OutputColumnPrefix('emb_')\n",
    "          InputColumnName('sentence_embedding')\n",
    "        ) a\n",
    "    ) WITH DATA PRIMARY index(id)\n",
    "    \"\"\")\n",
    "\n",
    "try:\n",
    "        print(\"Embedding process started at\",time.ctime())\n",
    "        start = time.time()\n",
    "        execute_sql(qry)\n",
    "        end = time.time()\n",
    "        print('Table Created')\n",
    "        print(\"Total time to run tokenization+embeddings took = \",(end-start)/60, \" min on 2nodes 4Amp VM\")\n",
    "        df_emb = DataFrame('complaints_embeddings_store')\n",
    "        \n",
    "        \n",
    "except:\n",
    "        db_drop_table('complaints_embeddings_store')\n",
    "        start = time.time()\n",
    "        execute_sql(qry)\n",
    "        end = time.time()\n",
    "        print('Table Created')\n",
    "        print(\"Total time to run tokenization+embeddings took = \",(end-start)/60, \" min on 2nodes 4Amp VM\")\n",
    "        df_emb = DataFrame('complaints_embeddings_store')\n",
    "\n",
    "print(\"\\nEmbeddings generated and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763261bd-d95b-47b7-ba7c-8a5eb7f3c636",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de20fdc-917e-42e8-b666-ed753e503626",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'> Here we can see how the embeddings are generated for the compalint text we have given.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ac23c0-8ecf-412c-b504-3b7a91a38644",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>4. Topic Generation</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680e433a-ff47-495f-8c97-7601c300851c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>When identifying topics from or for textual data, there are generally two approaches:  \n",
    "<ol style = 'font-size:16px;font-family:Arial;'><li>\n",
    "    <b>Domain Knowledge-Driven Approach:</b> Topics are predefined based on expert knowledge or business rules.  </li>\n",
    "    <li><b>Data-Driven Approach:</b>Topics emerge organically from the data itself using unsupervised learning techniques. </li>\n",
    "    </ol>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "    For this analysis, we adopt the <b>data-driven approach</b>, allowing the structure of the dataset to define the topics rather than imposing predefined categories.  For this, we leverage the <b>semantic similarity</b> between text embeddings to group similar complaints. Instead of manually defining topics, we let a clustering algorithm <b>TD_KMEANS</b> discover natural groupings within the data.  \n",
    "<br>\n",
    "To ensure manageability, we limit our analysis to 5 clusters. After applying K-Means clustering to the complaint embeddings, we identify the centroids of these clusters, which represent the most central points of each topic group. To understand the nature of each cluster, we extract the 20 distinct complaints closest to each centroid, as these provide the most representative examples of the topic. Instead of manually assigning labels, we leverage a powerful large language model (LLM) to analyze these representative complaints and generate meaningful topic names.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb308fea-8601-448e-b28e-c8371aaa996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_embeddings = DataFrame(in_schema('DEMO_Telco_Complaints', 'telco_consumer_embeddings'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0de756d-145e-4a63-bff9-8db780bd4fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_column_list = [col for col in DF_embeddings.columns if col not in [\"id\", \"txt\"]]\n",
    "\n",
    "num_clusters = 5\n",
    "kmeans_out = KMeans(\n",
    "    id_column=\"id\",\n",
    "    data=DF_embeddings,\n",
    "    target_columns=embedding_column_list,\n",
    "    output_cluster_assignment=True,\n",
    "    num_init=10,\n",
    "    num_clusters=num_clusters,\n",
    "    iter_max=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62616030-117d-477d-9851-a9a4fab16aff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(kmeans_out.show_query())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac0e6a6-8947-40a0-afcc-786d6388e0ed",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>The output below shows cluster assignment for each row.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa7f4f1-57f9-4d57-aefe-46eec5c989a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_out.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda2b439-13b2-4894-bd4f-96bd5162cdd7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Let's check how many data points each cluster has.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e985c8d7-92b3-4bdd-9d12-27305978f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_df = kmeans_out.result\n",
    "d2 = kmeans_df.groupby('td_clusterid_kmeans').count()\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8123bd8d-aec8-4102-a27a-cbfbb02688aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(kmeans_out.model_data, \"complaints_clustermodel\", if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81bc022-49ae-4746-98e2-fb77fdae70a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the distance of each message to their cluster centroid. We pick the 20 closest messages\n",
    "DF_clusterdistance = KMeansPredict(\n",
    "    data = DF_embeddings,\n",
    "    object = DataFrame(\"complaints_clustermodel\"),\n",
    "    output_distance = True   \n",
    ").result\n",
    "\n",
    "\n",
    "DF_clusterdistance = DF_clusterdistance.assign(\n",
    "    rank_distance = DF_clusterdistance.td_distance_kmeans.window(\n",
    "            partition_columns=DF_clusterdistance.td_clusterid_kmeans,\n",
    "            order_columns=DF_clusterdistance.td_distance_kmeans\n",
    "        ).dense_rank()\n",
    "    )\n",
    "\n",
    "DF_clusterdistance_top = DF_clusterdistance.loc[DF_clusterdistance.rank_distance<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a56c37-2ef3-4cad-a4ed-ed570b6abe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_clusterdistance_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4afa86-8fac-4b4e-89ec-cccf75cf8cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_topmesages = DF_clusterdistance_top.join(\n",
    "    DF_complaints.select([\"row_id\",\"txt\"]),\n",
    "    how = \"inner\",\n",
    "    on =  [\"id = row_id\"],\n",
    "    lsuffix= \"a\"\n",
    ").select([\"td_clusterid_kmeans\", \"txt\"]).drop_duplicate()\n",
    "DF_topmesages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935ab7b1-72f7-461f-9535-efa0df784bb2",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>5. Visualization</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.1 WordCloud Visualization</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c078c8ac-b559-48c0-8ef0-68e7479691de",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Let's visualize all the clusters through wordcloud visualization.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef151e0b-5708-49d9-ad70-11599d0704ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Cloud all those clusters\n",
    "for i in range(0, num_clusters):\n",
    "    filtered_df = DF_topmesages[DF_topmesages.td_clusterid_kmeans == i]\n",
    "    df = filtered_df.to_pandas()\n",
    "    total_rows = len(df)\n",
    "\n",
    "    sw = ['x','xx','xxx','xxxx','xxxxx','xxxxxx']\n",
    "    es = list(set(stopwords.words('english')))\n",
    "    es.extend(sw)\n",
    "\n",
    "    text_tokens = word_tokenize(' '.join(df['txt']),preserve_line=True)\n",
    "    l_text_tokens = [item.lower() for item in text_tokens]\n",
    "    tokens_without_sw = [word for word in l_text_tokens if word not in es]\n",
    "\n",
    "    all_text = pd.Series(tokens_without_sw)\n",
    "\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,4))\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_text)\n",
    "\n",
    "    col_sum = tfidf_matrix.sum(axis=0).A.squeeze()\n",
    "    k = 5\n",
    "    top_indices = np.argsort(col_sum)[-k:][::-1]\n",
    "\n",
    "    dense = tfidf_matrix.todense()\n",
    "    df = pd.DataFrame(dense, columns=vectorizer.get_feature_names_out())\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    top_terms = feature_names[top_indices]\n",
    "    cluster_name = '_'.join(top_terms).upper()\n",
    "\n",
    "    print(\"Cluster #\" + str(i)+\": \"+cluster_name+\"\\n # of Rows: \"+str(total_rows)+\"\\n\")\n",
    "    # Generate a word cloud\n",
    "    wordcloud = WordCloud(width=800, \\\n",
    "                          height=400, \\\n",
    "                          background_color='white',\\\n",
    "                          collocations=True,\\\n",
    "                          max_words=100,\\\n",
    "                          min_word_length=1, \\\n",
    "                         ).generate_from_frequencies(df.T.sum(axis=1))\n",
    "\n",
    "    # Plot the word cloud\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='gaussian')\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud for Text Data (TF-IDF)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b18331-766e-43b1-baae-f16a782c10fe",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;'> \n",
    "\n",
    "<p style='font-size:18px;font-family:Arial;'><b>5.2 Visualization of Clusters with Complaints</b></p> \n",
    "\n",
    "<p style='font-size:16px;font-family:Arial;'>The graph displays the clustering of complaints into distinct groups. Based on the analysis, the data has been divided into 5 optimal clusters, each representing a unique pattern or category of complaints. This clustering approach helps to identify the key areas or types of complaints that are most prevalent, allowing for more targeted investigation and resolution efforts.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f845f1-cf03-46b2-a734-073835053871",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_df = DF_embeddings.join(\n",
    "    other = kmeans_df,\n",
    "    on = [\"id\"],\n",
    "    how = \"inner\",\n",
    "    lprefix=\"l\",\n",
    "    rprefix=\"r\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653f1398-e497-48bf-93e8-cd0e1bf495d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb = DataFrame('kmeans_features').to_pandas()\n",
    "clus = clustered_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c63aeb0-ff9a-497f-8622-c67403e474b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=123)\n",
    "tsne_result = tsne.fit_transform(clus.iloc[:, 3:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c7d20-11de-446e-9014-5b7450b65269",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df = pd.DataFrame(tsne_result, columns=['tsne_1', 'tsne_2'])\n",
    "tsne_df['cluster_id'] = clus['td_clusterid_kmeans']\n",
    "tsne_df['complaint_id'] = clus['l_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1172672-bf05-4077-ac21-ae1038b81a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame combining t-SNE results with complaint information\n",
    "tsne_complaint_df = pd.DataFrame(tsne_result, columns=['tsne_1', 'tsne_2'])\n",
    "tsne_complaint_df['cluster_id'] = clus['td_clusterid_kmeans']\n",
    "tsne_complaint_df['complaint_id'] = clus['l_id']\n",
    "tsne_complaint_df['complaint'] = clus['txt']\n",
    "\n",
    "# Truncate text for hover data\n",
    "max_chars = 50  # Maximum characters to display\n",
    "tsne_complaint_df['truncted_complaint'] = clus['txt'].apply(lambda x: x[:max_chars] + '...' if len(x) > max_chars else x)\n",
    "\n",
    "# Plot using Plotly Express\n",
    "fig = px.scatter(tsne_complaint_df, x='tsne_1', y='tsne_2', color='cluster_id',\n",
    "                 hover_data=['complaint_id', 'truncted_complaint', 'cluster_id'])\n",
    "\n",
    "fig.update_traces(marker=dict(size=15))\n",
    "fig.update_layout(\n",
    "    title='t-SNE Visualization of Clusters with Complaints',\n",
    "    xaxis_title='dimension-1',\n",
    "    yaxis_title='dimension-2',\n",
    "    xaxis=dict(tickangle=45),\n",
    "    width=1000,\n",
    "    height=800,\n",
    "    hoverlabel=dict(\n",
    "        bgcolor=\"white\",\n",
    "        font_size=16,\n",
    "        font_family=\"Rockwell\"\n",
    "    ),\n",
    "    autosize=False,\n",
    ")\n",
    "\n",
    "# Customize the hovertemplate\n",
    "fig.update_traces(hovertemplate=\"<b>Complaint ID:</b> %{customdata[0]}<br>\"\n",
    "                                 \"<b>Complaint:</b> %{customdata[1]}<br>\"\n",
    "                                 \"<b>Cluster ID:</b> %{customdata[2]}<br><extra></extra>\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fda723e-4617-4fbf-bbe9-f85cd392b5ac",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>6. Get Topic Names by asking a LLM</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "To leverage the summarization capabilities of large-scale language models, we use a multi-billion parameter model to generate meaningful topic names based on representative complaints from each cluster. This step requires an OpenAI API key, as the model runs through an external API. If you don't have an OpenAI API key, use the pre-generated topic names below.<br>Also, feel free to play around with the prompt and see how this changes the cluster names.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20238b6e-e61e-4e83-9e4c-c56dcac1e6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to True, if you have an OpenAI key\n",
    "I_Have_an_OpenAI_API_Key = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f198d7d-85e7-4138-a4e3-36e146fabae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if I_Have_an_OpenAI_API_Key:\n",
    "    import os, getpass\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OPENAI API KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd07538-6c74-4e27-adcf-7ef8a507c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if I_Have_an_OpenAI_API_Key:\n",
    "    prompt_template = \"\"\"Your task is to identify a common topic of 10 messages that have shown similar vector embeddings. \n",
    "    Your answer should be exactly one sentence, maximal 10 words long, summarising the topic. You can skip unneccary filler words.\n",
    "    The answer should not be starting with \"The common topic of the messages is\", or \"the topic is\", or \"Customers are complaining\" etc.\n",
    "    \n",
    "    Here are the 10 messages:\n",
    "    \n",
    "    {messages}\n",
    "    \n",
    "    ====\n",
    "    Topic:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba2679b-0e0b-42d9-a65f-15d3a69f483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topmessages=DF_topmesages.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cc953c-6c0a-484c-8476-596294286743",
   "metadata": {},
   "outputs": [],
   "source": [
    "if I_Have_an_OpenAI_API_Key:\n",
    "    from openai import OpenAI\n",
    "    results =  {}\n",
    "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    for i in range (5):\n",
    "        cluster_feedback = '\\n\\n'.join(df_topmessages[df_topmessages['td_clusterid_kmeans'] == i]['txt'])\n",
    "        this_prompt = prompt_template.format(messages = cluster_feedback)\n",
    "        try:\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": this_prompt,\n",
    "                    }\n",
    "                ],\n",
    "                model=\"gpt-4o\",\n",
    "                temperature=0,\n",
    "                max_tokens=4096\n",
    "            )\n",
    "            results[i] = chat_completion.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Failed to call OpenAI API: {str(e)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73709a1-d5e8-4a41-a916-c2a9b74ff2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not I_Have_an_OpenAI_API_Key :\n",
    "    #pre-defined topics\n",
    "    results = {\n",
    "            0: 'Network Coverage',\n",
    "            1: 'Call Drops',\n",
    "            2: 'Internet Speed',\n",
    "            3: 'Billing Errors',\n",
    "            4: 'Overcharging'\n",
    "}\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e89db58-aa11-4ca1-a590-ee7b0a18cc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dict → DataFrame with 2 columns\n",
    "df = pd.DataFrame(list(results.items()), columns=[\"id\", \"txt\"])\n",
    "copy_to_sql(df,table_name='telco_topics_of_interest', if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a47e0c-349f-422b-a7b4-0f2d5e3a2049",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>7. Generate Embeddings for Topics and  get Similarity</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efce204-74d7-4d2c-93a9-1a096f8b9eab",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "Now that we have abstracted topics from the data, we need to generate embeddings for them. This step is crucial because, in the next phase, we will calculate the <b>pairwise similarity</b> between complaints and topics, effectively computing a <b>Cartesian product</b> of all complaint-topic pairs.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b139738-a57f-46d2-99ee-96ab8eedee2c",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>7.1 Generating Embedding for Topics Data</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>We will generate the embeddings for the Topics data in 3 steps as explained earlier in section 3.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167c4db7-60ef-434c-a65f-cb30a5dd9ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = ('''\n",
    "replace view v_topics_tokenized_for_embeddings as (\n",
    "    select\n",
    "        id,\n",
    "        txt,\n",
    "        IDS as input_ids,\n",
    "        attention_mask\n",
    "    from ivsm.tokenizer_encode(\n",
    "        on (select * from telco_topics_of_interest)\n",
    "        on (select model as tokenizer from embeddings_tokenizers \n",
    "            where model_id = 'bge-small-en-v1.5') DIMENSION\n",
    "        USING\n",
    "            ColumnsToPreserve('id', 'txt')\n",
    "            OutputFields('IDS', 'ATTENTION_MASK')\n",
    "            MaxLength(1024)\n",
    "            PadToMaxLength('True')\n",
    "            TokenDataType('INT64')\n",
    "    ) a\n",
    ")\n",
    "''')\n",
    "try:\n",
    "    execute_sql(qry)\n",
    "    print('View Created')\n",
    "except Exception as e:\n",
    "    print('View creation failed')\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a43d9f-00d8-4e26-98e8-df54074ce889",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = ('''\n",
    "replace view topics_embeddings as (\n",
    "    select \n",
    "            *\n",
    "    from ivsm.IVSM_score(\n",
    "            on v_topics_tokenized_for_embeddings  -- table with data to be scored\n",
    "            on (select * from embeddings_models where model_id = 'bge-small-en-v1.5') dimension\n",
    "            using\n",
    "                ColumnsToPreserve('id', 'txt') -- columns to be copied from input table\n",
    "                ModelType('ONNX') -- model format\n",
    "                BinaryInputFields('input_ids', 'attention_mask') -- enables binary input vectors\n",
    "                BinaryOutputFields('sentence_embedding')\n",
    "                Caching('inquery') -- tun on model caching within the query\n",
    "        ) a \n",
    ")\n",
    "''')\n",
    "try:\n",
    "    execute_sql(qry)\n",
    "    print('View Created')\n",
    "except Exception as e:\n",
    "    print('View creation failed')\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c689215-8c98-49ac-bc2b-6966821b2252",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry = ('''\n",
    "create table topics_embeddings_store as (\n",
    "    select \n",
    "            *\n",
    "    from ivsm.vector_to_columns(\n",
    "            on topics_embeddings\n",
    "            using\n",
    "                ColumnsToPreserve('id', 'txt') \n",
    "                VectorDataType('FLOAT32')\n",
    "                VectorLength(384)\n",
    "                OutputColumnPrefix('emb_')\n",
    "                InputColumnName('sentence_embedding')\n",
    "        ) a \n",
    ") with data\n",
    "''')\n",
    "try:\n",
    "    execute_sql(qry)\n",
    "    print('Table Created')\n",
    "except:\n",
    "    db_drop_table('topics_embeddings_store')\n",
    "    execute_sql(qry)\n",
    "    print('Table Created')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f80201-c285-41cd-ba6e-94b17aa65944",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic = DataFrame('topics_embeddings_store')\n",
    "df_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd6f085-630f-401b-8139-3f2840ca81c9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'> As we can see from the above, we have generated embeddings for the topic data.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a357ab-11f9-4a6c-9901-18289189bbc0",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>7.2 Semantic Similarity</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Now we will run Semantic Similarity of the Topics Embeddings against the Complaints Embeddings table. Vector Distance is a measure of the similarity or dissimilarity between two vectors in multidimensional space. We will use Vantage's TD_VectorDistance function. The <b>TD_VectorDistance</b> function accepts a table of target vectors and a table of reference vectors and returns a table that contains the distance between target-reference pairs. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2059155f-33df-4fe8-89eb-fb98bbeb0fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_new_vectdist = VectorDistance(\n",
    "        target_data = DF_embeddings,\n",
    "        target_id_column = \"id\",\n",
    "        reference_data = df_topic,\n",
    "        ref_id_column = \"id\",\n",
    "        distance_measure= \"COSINE\",    \n",
    "        target_feature_columns=\"emb_0:emb_383\",\n",
    "        ref_feature_columns=\"emb_0:emb_383\",\n",
    "        volatile = True\n",
    "    ).result.join(\n",
    "         DF_complaints,\n",
    "        on = [\"target_id = row_id\"],\n",
    "        how = \"left\").join(\n",
    "         df_topic.select([\"id\",\"txt\"]),\n",
    "         on = [\"reference_id = id\"],\n",
    "         how = \"left\",rsuffix = 'topic')\n",
    "DF_new_vectdist=DF_new_vectdist.assign(similarity = 1.0-DF_new_vectdist.distance)\n",
    "DF_new_vectdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc886c8-cd35-4fdd-914c-251d4fddfa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying the top 2 records for each reference_id from the similarity result created\n",
    "window = DF_new_vectdist.window(partition_columns=\"reference_id\",\n",
    "                           order_columns=\"similarity\",\n",
    "                           sort_ascending=False)\n",
    "df = window.rank()\n",
    "df[df.col_rank.isin([1,2])].sort(['reference_id','col_rank']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c201c57-879f-4a5d-92b1-839bb594f106",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>7.3 Interactive Dashboard for BI reporting</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>As a final step, we build a dashboard designed to serve as a <b>business intelligence (BI) reporting tool</b>, allowing us to analyze how topic prevalence changes over time. This interactive dashboard provides a structured way to explore complaint trends and refine topic detection dynamically.\n",
    "<ul style = 'font-size:16px;font-family:Arial;'>Dashboard Requirements\n",
    "    <li><b>Visualizing topic trends:</b> Display the number of complaints per topic per month using a <b>multi-line chart</b>, filtering only those complaints with a similarity score above a defined threshold (default: <b>0.6</b>).</li>  \n",
    "<li><b>Dynamic threshold adjustment:</b> Allow users to modify the similarity threshold, automatically updating the visualization in real time.  \n",
    "    </li></ul>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "The dashboard logic is encapsulated in the <code>`topics_widget.py`</code> module.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847dfbbf-e660-4bd9-85d1-945e750ce493",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_new_vectdist.assign(\n",
    "             topic_id = DF_new_vectdist.reference_id,\n",
    "             topic = DF_new_vectdist.txt_topic,\n",
    "             year_month = col(\"td_month_begin(complaint_date)\")\n",
    "            ).select([\"row_id\", \"topic_id\",\"topic\",\"similarity\", \"year_month\"  ]).to_sql(\"consumer_complaint_topic_similarity\", if_exists = \"replace\",\n",
    "            primary_index = [\"year_month\", \"topic_id\"], \n",
    "            types= {\"year_month\":DATE},\n",
    "            temporary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ba98cc-b333-4b95-95cf-123c34fb112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_new_similarity = DataFrame(\"consumer_complaint_topic_similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1386784-1e18-430c-867b-968b3bc2adcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils/topics_distance.py\n",
    "%run utils/topics_widget.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23793d3e-559f-4c24-98da-06ae89a26342",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_complaints_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cf8020-c8c9-4ff1-85e5-30a467a2e572",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>Conclusion</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>In this demo we have seen that how a <b>fully data-driven approach</b> can help analyze large volumes of text data, automatically identifying topics and tracking their trends over time. Instead of relying on <b>prompt engineering</b> to classify messages—which can be inconsistent, expensive, and hard to scale—we used <b>embeddings, clustering and Vector Distance</b> to get a <b>deterministic and repeatable</b> solution.  <br>\n",
    "By applying <b>K-Means clustering</b> on complaint embeddings, we discovered topics without predefining them. A <b>large language model (LLM)</b> then helped generate human-readable names for these clusters, but only once—keeping costs low while still benefiting from its summarization power. From there, we converted topic names into embeddings and calculated <b>vector similarities</b>, allowing us to efficiently map messages to topics in a <b>scalable and automated</b> way.<br>The final step was building an <b>interactive BI dashboard</b> that lets users explore topic trends over time and tweak similarity thresholds. <br>\n",
    "With this approach, we get the <b>best of both worlds</b>: the flexibility of unsupervised learning, the power of embeddings, and the practicality of real-time reporting—all while keeping things <b>scalable, cost-efficient, and environmentally friendly</b>.    \n",
    "</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c55b0d-6159-4a8c-a3c2-e87df578fbfc",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>6. Cleanup</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8710e68-dd46-4115-9ec3-928588b803bc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;'><b>Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Cleanup work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f170503-df80-49cd-a85e-8417619f54ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['complaints_embeddings_store','complaints_clustermodel','telco_topics_of_interest','topics_embeddings_store','consumer_complaint_topic_similarity']\n",
    "\n",
    "# Loop through the list of tables and execute the drop table command for each table\n",
    "for table in tables:\n",
    "    try:\n",
    "        db_drop_table(table_name=table)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "views = ['v_complaints_tokenized_for_embeddings','complaints_embeddings','v_topics_tokenized_for_embeddings','topics_embeddings']\n",
    "\n",
    "for view in views:\n",
    "    try:\n",
    "        db_drop_view(view_name=view)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c47c2b-7d73-4237-95b9-a2c7c04a4947",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b057f0da-0043-472d-b762-8bcd1b8404bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_Telco_Complaints');\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae18ad9-9836-46a0-9810-f42e9ef5c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08206109-4d2a-4a7f-a169-c60709384d05",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2025. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
