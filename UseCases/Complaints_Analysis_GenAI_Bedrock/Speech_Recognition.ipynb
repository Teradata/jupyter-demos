{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c49e3cf-e89a-40b0-8e6a-414d8ec337a6",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Complaints Analysis using Vantage and AWS Bedrock\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26752df7-32dc-42f9-b2a4-6db953108237",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#00233c'><b>Introduction:</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Analyzing consumer complaints using audio files conversations involves leveraging advanced technologies like large language models (LLM) and AWS Bedrock to extract insights from unstructured data. This process can be applied to various sectors, including financial services, telecommunications, and e-commerce, to improve customer experience and protect consumer rights.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233c'><b>Steps in the analysis:</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Configuring the environment</li>\n",
    "    <li>Configuring AWS CLI</li>\n",
    "    <li>Define Anthropic model and Prompt</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ebe8de-14d7-4ee4-a726-5acd2bbc0669",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>1. Configuring the environment</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f231b3-7dbf-4379-b9d3-9f09be350c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install --upgrade -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54d7c1c-10d7-407a-ba2a-a4550615f9ea",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note: </b><i>Please restart the kernel after executing these two lines. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c233ee65-c69c-4ea4-8964-d4b53acdb5cd",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;background-color:#00233C;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>1.1 Import the required libraries</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e495ff-d24d-4f26-84d3-9192ae149dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import getpass\n",
    "\n",
    "# teradataml\n",
    "from teradataml import *\n",
    "\n",
    "from IPython.display import Markdown, Audio\n",
    "display.max_rows = 5\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a57f400-6d82-4f0c-b9d5-d8048bf48a31",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>2. Configuring AWS CLI</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following cell will prompt us for the following information:</p>\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "<li><b>aws_access_key_id</b>: Enter your AWS access key ID</li>\n",
    "<li><b>aws_secret_access_key</b>: Enter your AWS secret access key</li>\n",
    "<li><b>region name</b>: Enter the AWS region you want to configure (e.g., us-east-1)</li>\n",
    "<ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f2a8a6-5a5b-483d-81e7-46682c764bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_aws():\n",
    "    print(\"configure the AWS CLI\")\n",
    "    # enter the access_key/secret_key\n",
    "    access_key = getpass.getpass(\"aws_access_key_id \")\n",
    "    secret_key = getpass.getpass(\"aws_secret_access_key \")\n",
    "    region_name = getpass.getpass(\"region name\")\n",
    "\n",
    "    #set to the env\n",
    "    !aws configure set aws_access_key_id {access_key}\n",
    "    !aws configure set aws_secret_access_key {secret_key}\n",
    "    !aws configure set default.region {region_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26271aff-8dbe-49ce-9f42-7384e5f91c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "does_access_key_exists = !aws configure get aws_access_key_id\n",
    "\n",
    "if len(does_access_key_exists) == 0:\n",
    "    configure_aws()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d35535e-a819-420a-bcae-206927b43eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws configure list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1b1d2e-3d79-4e79-851d-a1d3a342777c",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>3. Define Anthropic model and Prompt</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following section defines the type of Claude 3 model used. Here we use <b>Claude 3 Sonnet</b></p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here the architecture diagram of audio analysis using Bedrock.</p>\n",
    "<center><img src=\"images/architecture_bedrock_audio.png\" alt=\"architecture\"  width=515 height=526/></center>\n",
    "\n",
    "<br/>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The project architecture consists of three main steps:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>We initiate the process by uploading an audio file to the source folder of our S3 bucket, which we've configured to send an event notification to a Lambda function whenever a new object is created.</li>\n",
    "    <li>We receive the event notification in our Lambda function, <code>s3_trigger_transcribe</code> which then initiates an Amazon Transcribe job using the uploaded file as the source media. The results of the transcription are saved to the transcription folder of the same S3 bucket.</li>\n",
    "    <li>We leverage an Event Rule from Amazon EventBridge to monitor Amazon Transcribe jobs that start with \"summarizer-\" and have either a COMPLETED or FAILED status. When we detect a job in one of these states, we automatically send the Transcribe job details to our Lambda function, eventbridge-bedrock-inference. This function takes the transcript, formats it, and crafts an instruction prompt for a Bedrock large language model (LLM) to distill the essence of the audio content. Finally, we store the summarized results in the processed folder of the same S3 bucket.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc02bf92-329e-474b-9df2-209a2e86297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "bucket_name = \"csae-usecases\"\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "def upload_files_to_s3(mp3_files):\n",
    "    print('\\n Step 1. Uploading files.')\n",
    "    for audio_file_name in mp3_files:\n",
    "        file_path = os.path.join(os.getcwd(), \"audio_files\", audio_file_name)\n",
    "\n",
    "        # Upload the file to the S3 bucket\n",
    "        object_name = \"consumer_complaints/speech_analysis/source/\" + audio_file_name\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            s3.upload_fileobj(file, bucket_name, object_name)\n",
    "            print(f\"File '{file_path}' uploaded to '{bucket_name}/{object_name}'\")\n",
    "\n",
    "\n",
    "def retrieve_summary(active_job_dict):\n",
    "    print('\\n Step 3. Generating the final output, please wait..')\n",
    "    wait_time = 12 * len(active_job_dict)\n",
    "    print('wait time: ', wait_time)\n",
    "    time.sleep(wait_time)\n",
    "    print('please wait...')\n",
    "    prefix = \"consumer_complaints/speech_analysis/processed/\"\n",
    "\n",
    "    # Call the list_objects_v2 method with the Prefix parameter\n",
    "    response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "\n",
    "    summaries_dict = {}\n",
    "    for file_name, _job_name in active_job_dict.items():\n",
    "        for obj in response.get(\"Contents\", []):\n",
    "            if _job_name in obj[\"Key\"]:\n",
    "                print(f\"file_name: {file_name} | _job_name: {_job_name}\")\n",
    "                try:\n",
    "                    # Get the object from S3\n",
    "                    obj = s3.get_object(\n",
    "                        Bucket=bucket_name, Key=f\"{prefix}{_job_name}.txt\"\n",
    "                    )\n",
    "\n",
    "                    # Read the contents of the file and add to summary dict\n",
    "                    summaries_dict[file_name] = obj[\"Body\"].read().decode(\"utf-8\")\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred: {e}\")\n",
    "    print('processing done..')\n",
    "    return summaries_dict\n",
    "\n",
    "\n",
    "def list_mp3_files(directory):\n",
    "    mp3_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".mp3\"):\n",
    "                mp3_files.append(file)\n",
    "    return mp3_files\n",
    "\n",
    "\n",
    "def start_process():\n",
    "    response = s3.list_buckets()\n",
    "    directory_path = \"./audio_files\"\n",
    "    mp3_files = list_mp3_files(directory_path)\n",
    "\n",
    "    # Upload files to s3\n",
    "    upload_files_to_s3(mp3_files)\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Monitor transcription status\n",
    "    # Create a Transcribe client\n",
    "    transcribe = boto3.client(\"transcribe\")\n",
    "    active_job_names = []\n",
    "    active_job_dict = {}\n",
    "    # List active transcription jobs\n",
    "    try:\n",
    "        response = transcribe.list_transcription_jobs(Status=\"IN_PROGRESS\")\n",
    "        active_jobs = response[\"TranscriptionJobSummaries\"]\n",
    "\n",
    "        # Sort active jobs by creation time\n",
    "        active_jobs.sort(key=lambda job: job[\"CreationTime\"], reverse=True)\n",
    "\n",
    "        # Print the list of active jobs\n",
    "        if len(active_jobs) > 0:\n",
    "            print(\"\\n Step 2. Generating the transcription. \\nActive transcription jobs:\")\n",
    "            for job in active_jobs:\n",
    "                _job_name = job[\"TranscriptionJobName\"]\n",
    "                print(f\"- {_job_name} ({job['TranscriptionJobStatus']})\")\n",
    "\n",
    "                job_name_response = transcribe.get_transcription_job(\n",
    "                    TranscriptionJobName=_job_name\n",
    "                )\n",
    "                audio_file_name = job_name_response[\"TranscriptionJob\"][\"Media\"][\n",
    "                    \"MediaFileUri\"\n",
    "                ].split(\"/\")[-1]\n",
    "                active_job_dict[audio_file_name] = _job_name\n",
    "\n",
    "            # Assign the latest job name to job_name\n",
    "            job_name = active_jobs[0][\"TranscriptionJobName\"]\n",
    "            active_job_names.append(job_name)\n",
    "            print(f\"\\n*** active_job_dict *** \\n\\n {active_job_dict}\")\n",
    "\n",
    "            print(f\"\\nThe latest transcription job is: {job_name}\\n\")\n",
    "        else:\n",
    "            print(\"No active transcription jobs found.\")\n",
    "\n",
    "    except transcribe.exceptions.BadRequestException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    except transcribe.exceptions.InternalFailureException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    except transcribe.exceptions.LimitExceededException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    max_retries = 180  # Maximum number of retries\n",
    "    retry_delay = 15  # Delay between retries (in seconds)\n",
    "\n",
    "    # Monitor/poll for transcription status\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
    "            job_status = response[\"TranscriptionJob\"][\"TranscriptionJobStatus\"]\n",
    "            print(f\"Job status: {job_status}\")\n",
    "\n",
    "            if job_status == \"COMPLETED\":\n",
    "                transcription_file_uri = response[\"TranscriptionJob\"][\"Transcript\"][\n",
    "                    \"TranscriptFileUri\"\n",
    "                ]\n",
    "                print(f\"Transcription file: {transcription_file_uri}\")\n",
    "                break\n",
    "            elif job_status == \"FAILED\":\n",
    "                failure_reason = response[\"TranscriptionJob\"][\"FailureReason\"]\n",
    "                print(f\"Job failed: {failure_reason}\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Job is still in progress. Retrying in {retry_delay} seconds...\")\n",
    "                time.sleep(retry_delay)\n",
    "                retries += 1\n",
    "\n",
    "        except transcribe.exceptions.BadRequestException as e:\n",
    "            print(f\"Error: {e}\")\n",
    "        except transcribe.exceptions.InternalFailureException as e:\n",
    "            print(f\"Error: {e}\")\n",
    "        except transcribe.exceptions.LimitExceededException as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "    # Retrieve the summary\n",
    "    return retrieve_summary(active_job_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc29e24-d3d3-4b89-a299-6f70b3581071",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = start_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d483ab-12b1-44da-962b-fe0bc13b4c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "for file_name, response in summaries.items():\n",
    "    desc = f'''<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "        <p style = 'font-size:18px;font-family:Arial;color:#00233C'> <b>For file: {file_name} </b></p>'''\n",
    "    display(Markdown(desc))\n",
    "    display(Audio((f\"audio_files/{file_name}\")))\n",
    "    display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c05788-5048-42fd-8327-ae8e1c52e114",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2024. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
