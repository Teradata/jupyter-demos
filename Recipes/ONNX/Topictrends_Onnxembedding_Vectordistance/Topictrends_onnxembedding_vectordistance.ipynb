{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b08e2d1e-b7ac-4056-85a7-2d0f53d2b994",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Topic Trend Dashboard using ONNXEmbeddings and VectorDistance\n",
    " <br>       \n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 150px; height: auto; margin-top: 20pt;\">\n",
    "  <br>\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef06847a-c10a-45a8-9f80-88cfff07268b",
   "metadata": {},
   "source": [
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>Introduction</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "Tracking the evolution of topics over time is essential for understanding patterns, behaviors, and emerging trends in large datasets of text. In industries such as customer support, social media monitoring, and market research, identifying how topics shift over time can provide valuable insights for decision-making and strategy development. Traditional manual analysis methods, however, can be labor-intensive and prone to human bias.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "In this blog post, we explore a dynamic approach to topic trend analysis by combining message embeddings with topic embeddings, leveraging vector distance calculations to measure similarity between the two. The resulting data will be fed into an interactive dashboard, enabling users to monitor the frequency of topics over specific time periods and set similarity thresholds for enhanced relevance.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "While the specific example can be applied across many sectors, we’ll focus on a use case using the Consumer Complaint Database from the Consumer Financial Protection Bureau. This dataset contains complaints about financial products and services, providing valuable insights into consumer sentiment and trends. By categorizing these complaints by topic, businesses can gain a deeper understanding of customer concerns in the consumer finance sector and adjust their strategies to address emerging issues more effectively.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>To achieve this, we will:   \n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "  <li>Generate embeddings for both customer messages and inferred/predefined topics</li>\n",
    "  <li>Calculate vector distances between message and topic embeddings to assess similarity</li>\n",
    "  <li>Feed the results into a dashboard to display topic trends over time, with configurable similarity thresholds and message counts</li>\n",
    "   <li>Enable entries of new topics in the dashboard, allowing ad-hoc analyses.</li>\n",
    "</ul>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The approach is visually represented in this diagram:\n",
    "</p>\n",
    "\n",
    "<img src=images/workflow_topictrend.png style=\"border: 4px solid #404040; border-radius: 10px;\"/>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "This method provides an efficient way to not only categorize messages by topic but also track how these topics evolve over time, offering actionable insights into changing customer concerns, emerging issues, and overall trends.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee56559-ffc8-4f4e-90ad-d63823677342",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;'><b>Dataset Overview</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "For this analysis, we use the <b>Consumer Complaint Database</b>, a publicly available dataset from the **Consumer Financial Protection Bureau (CFPB)** in the United States. This dataset contains consumer complaints related to financial products and services, helping to identify trends and issues affecting consumers. The CFPB collects and publishes these complaints to promote transparency and consumer protection in the financial industry. The dataset has been used by researchers, regulators, and businesses to analyze market trends, detect fraud, and improve customer service.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The full dataset, starting from 2011, contains over 8 million complaints. For this blog post, we apply filters to focus on a manageable subset for analysis. We apply the following filters and obtain around 80k complaints:</p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "  <li><b>Time Range</b>: Full year 2024</li>\n",
    "  <li><b>Consent</b>: Complaints where consumers have provided consent to publish their narratives</li>\n",
    "  <li><b>Geographic Scope</b>: Complaints from the state of California</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The filtered dataset can be accessed here:<a href=\"https://www.consumerfinance.gov/data-research/consumer-complaints/search/api/v1/?consumer_consent_provided=Consent%20provided&date_received_max=2024-12-31&date_received_min=2024-01-01&field=all&format=csv&no_aggs=true&size=80767&state=CA\" target=\"_blank\">Download Filtered Dataset (CSV)</a> and is licensed under the Creative Commons Attribution-ShareAlike 3.0 Unported License.</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f96ca5d-0a1f-47bd-a28d-70dbdb87ab4b",
   "metadata": {},
   "source": [
    "\n",
    "| **Field Name**                 | **Description**                                                             |\n",
    "|--------------------------------|-----------------------------------------------------------------------------|\n",
    "| `complaint_id`                 | Unique identifier for each complaint.                                       |\n",
    "| `date_received`                | Date the complaint was received by the CFPB.                               |\n",
    "| `product`                      | The type of financial product (e.g., mortgage, credit card).               |\n",
    "| `sub_product`                  | More specific product type (e.g., FHA mortgage, private student loan).     |\n",
    "| `issue`                        | The issue the consumer is complaining about (e.g., loan modification).     |\n",
    "| `sub_issue`                    | More detailed issue category.                                              |\n",
    "| `consumer_complaint_narrative`  | The consumer's description of the complaint.                              |\n",
    "| `company_public_response`       | The company's public response to the complaint.                            |\n",
    "| `company`                      | The financial institution involved.                                        |\n",
    "| `state`                        | The state where the consumer is located.                                   |\n",
    "| `zip_code`                     | The consumer's ZIP code.                                                   |\n",
    "| `tags`                         | Tags indicating special characteristics of the complaint (e.g., servicemember). |\n",
    "| `consumer_consent_provided`     | Indicates if the consumer consented to publish their narrative.           |\n",
    "| `submitted_via`                | How the complaint was submitted (e.g., web, phone).                       |\n",
    "| `date_sent_to_company`         | Date the complaint was forwarded to the company.                          |\n",
    "| `company_response`             | The company's response to the complaint.                                   |\n",
    "| `timely_response`              | Indicates if the company responded in a timely manner.                    |\n",
    "| `consumer_disputed`            | Indicates if the consumer disputed the company's response.                 |\n",
    "| `complaint_what_happened`      | A detailed narrative of the consumer's experience.                        |\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>In the following sections, we will walk through the methodology for embedding generation, similarity analysis, and dashboard visualization.\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb03307-f194-4e8a-bd17-7238c148d722",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>1. Connect to Vantage, Import python packages and explore the dataset</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887f7709-f574-497c-a38d-f4a5c8bebe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20f14aa-975d-4548-9658-0aeb07d09ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install teradataml --upgrade\n",
    "!pip install teradatasqlalchemy --upgrade\n",
    "!pip install teradataml-plus --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83feb41d-a5ed-4738-8918-d0ea3edd24d4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;'><b>Note: </b><i>The above libraries have to be installed. Restart the kernel after executing these cells to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing <b> 0 0</b></i> (zero zero) and pressing <i>Enter</i>.</p>\n",
    "</div>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23eec43-a498-48f1-a183-79c475269ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tdmlplus\n",
    "from teradataml import *\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import os, getpass\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1477744-269b-4eda-b6dc-20d78145412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports a function `display_dataframes_in_tabs` and `display_wordclouds_in_tabs`\n",
    "%run utils/tab_widget.py\n",
    "list_relevant_tables = [] # we will be adding names of relevant tables progressivley into this list to display the tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b53eef-08e1-4435-b6db-440a5658edd1",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial;'> 1.1 Connect to Vantage</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb7124c-b25c-4cab-9f7c-733ec5665d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i /home/jovyan/JupyterLabRoot/UseCases/startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fac117-defc-49b8-88d5-f9d0a63ca61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=Topictrends_onnxembedding_vectordistance.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30292b80-553b-4073-9cec-cc4665789d36",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;'><b>Getting Data for This Demo</b></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e403be2d-cf73-46a1-848d-284b8fbbc9c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run utils/_dataload.ipynb \n",
    "#takes currently 15 minutes (as it's more than 600 MB of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e18735-1764-4a87-83e2-bbd7b24a75e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_relevant_tables.append(\"consumer_complaints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d7fd0-be87-4ea0-b03e-5beb0e496528",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_dataframes_in_tabs(list_relevant_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9919a6d-b0ee-4e27-819e-90eb2d7cb4f0",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>In addition, we want to check if our database has already got the required functionality to generate embeddings.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b814ad3-6171-4e4f-b557-ecdfa1e7c723",
   "metadata": {},
   "outputs": [],
   "source": [
    "VCL = False # current system is VCE/VCore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e758f760-1b3c-4acf-ab55-f92babf4f2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if VCL:\n",
    "    results = execute_sql(\"help database mldb\").fetchall()\n",
    "else:\n",
    "    results = execute_sql(\"help user mldb\").fetchall()\n",
    "\n",
    "embeddings_functions = [x[0] for x in results if x[0].startswith(\"ONNXEmbeddings\")]\n",
    "if len(embeddings_functions) >0:#\n",
    "    print(\"\\n\".join(embeddings_functions))\n",
    "    print(\"---------------------\\nONNXEmbeddings is installed\")\n",
    "else:\n",
    "    print(\"ONNXEmbeddings is not installed. Please Upgrade to BYOM version 6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e886d4-c0b6-4121-8816-0b04442cee06",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>2. Load HuggingFace Model</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>To generate embeddings, we need an ONNX model capable of transforming text into vector representations. We use a pretrained model from\n",
    "<a href=\"https://huggingface.co/Teradata/gte-base-en-v1.5\" target=\"_blank\">Teradata's Hugging Face repository</a>   , such as gte-base-en-v1.5. The model and its tokenizer are downloaded and stored in Vantage tables as BLOBs using the save_byom function.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20c4997-da7e-4b6f-90b7-6dfba1cb1c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "model_name = \"gte-base-en-v1.5\"\n",
    "number_dimensions_output = 768\n",
    "model_file_name = \"model.onnx\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa86f05-a927-4f73-8260-03bea2c5e38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Download Model from Teradata HuggingFace Page\n",
    "hf_hub_download(repo_id=f\"Teradata/{model_name}\", filename=f\"tokenizer.json\", local_dir=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d212f2-4c04-4907-93ee-43b753e5d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the command line syntax as it is more reliable then the python function\n",
    "!hf download Teradata/{model_name} onnx/{model_file_name} --local-dir ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ed6d95-cbad-4d65-89f3-3dc0f61a46b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    db_drop_table(\"embeddings_models\")\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    db_drop_table(\"embeddings_tokenizers\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f4ceb7-28e1-4b2b-b114-8b5f93023c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load Models into Vantage\n",
    "# a) Embedding model\n",
    "save_byom(model_id = model_name, # must be unique in the models table\n",
    "               model_file = f\"onnx/{model_file_name}\",\n",
    "               table_name = 'embeddings_models' )\n",
    "# b) Tokenizer\n",
    "save_byom(model_id = model_name, # must be unique in the models table\n",
    "              model_file = 'tokenizer.json',\n",
    "              table_name = 'embeddings_tokenizers') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcfaf03-f157-47fd-bbbd-214818ae0f0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_dataframes_in_tabs([\"embeddings_models\",\"embeddings_tokenizers\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0866a8cb-18f6-45e6-ba47-3f76d3d6552a",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>3. Create the Embeddings</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cf2472-a2f3-4376-9386-0c8077752ffa",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial;'>3.1 Generate Embeddings with ONNXEmbeddings</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca6a73e-c252-40bf-a331-ace4d2869f71",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "Now it's time to generate the embeddings using <b>ONNXEmbeddings</b>.<br>We run the ONNXEmbeddings function to generate embeddings for a small subset of records. The model is <b>loaded into the cache memory on each node</b>, and Teradata's <b>Massively Parallel Processing (MPP)</b> architecture ensures that embeddings are computed in parallel using <b>ONNX Runtime</b> on each node.  <br>Having said that, generating embeddings for the entire training set can be time-consuming, especially when working on a system with limited resources. In the <b>ClearScape Analytics experience</b>, only a <b>4 AMP system</b> with constrained RAM and CPU power is available. To ensure smooth execution, we test embedding generation on a small sample and use <b>pre-calculated embeddings</b> for the remainder of demo. In a real-life scenario you would tyipically encounter multiple hundred AMPs with much more compute power!<br>Also have a look at the most important input parameters of this <b>ONNXEmbeddings</b> function.\n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "<li><b>InputTable</b>: The source table containing the text to be embedded. </li>\n",
    "<li><b>ModelTable</b>: The table storing the ONNX model.                    </li>\n",
    "<li><b>TokenizerTable</b>: The table storing the tokenizer JSON file.       </li>\n",
    "<li><b>Accumulate</b>: Specifies additional columns to retain in the output </li>  \n",
    "<li><b>OutputFormat</b>: Specifies the data format of the output embeddings (<b>FLOAT32(768)</b>, matching the model's output dimension).</li>\n",
    "</ul>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "Since embedding generation is computationally expensive, we only process <b>10 records for testing</b> and rely on precomputed embeddings for further analysis.  \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b9e98c-ee03-43cc-a0d4-eb7d66084955",
   "metadata": {},
   "outputs": [],
   "source": [
    "configure.byom_install_location = \"mldb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915dfd15-e6be-41a8-91bb-3e831c64f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_sample10 = DataFrame.from_query(\"SELECT TOP 10 t.row_id, t.consumer_complaint_narrative as txt FROM consumer_complaints t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8b2b25-6e06-4a46-bbe4-019aa9823655",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = DataFrame.from_query(f\"select * from embeddings_models where model_id = '{model_name}'\")\n",
    "my_tokenizer = DataFrame.from_query(f\"select model as tokenizer from embeddings_tokenizers where model_id = '{model_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db306ec-12a4-4327-aca3-1e09a55c6c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_embeddings_sample = ONNXEmbeddings(\n",
    "    newdata = DF_sample10,\n",
    "    modeldata = my_model, \n",
    "    tokenizerdata = my_tokenizer, \n",
    "    accumulate = [\"row_id\", \"txt\"],\n",
    "    model_output_tensor = \"sentence_embedding\",\n",
    "    output_format = f'FLOAT32({number_dimensions_output})',\n",
    "    enable_memory_check = False\n",
    ").result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbea8f2c-8399-4ba4-817a-5cec13b40cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# using to_pandas() to truncate the txt column. \n",
    "DF_embeddings_sample.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cac7dc-83ea-4401-add3-e145fae86987",
   "metadata": {},
   "source": [
    "The pre-computed embeddings are stored in the table `consumer_embeddings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea28a7e1-1ab2-4130-835f-cc3d41e757ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_relevant_tables.append(\"consumer_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e1fb4e-d8f8-48f2-95ef-317faab51208",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_embeddings = DataFrame(\"consumer_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524de641-03f2-46e6-beb5-fcef30777a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dataframes_in_tabs(list_relevant_tables,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd967a0-45ad-4818-8282-4e24ee7e57f0",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>4. Topic Generation</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>When identifying topics from or for textual data, there are generally two approaches:  \n",
    "<ol style = 'font-size:16px;font-family:Arial;'><li>\n",
    "    <b>Domain Knowledge-Driven Approach:</b> Topics are predefined based on expert knowledge or business rules.  </li>\n",
    "    <li><b>Data-Driven Approach:</b>Topics emerge organically from the data itself using unsupervised learning techniques. </li>\n",
    "    </ol>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "    For this analysis, we adopt the <b>data-driven approach</b>, allowing the structure of the dataset to define the topics rather than imposing predefined categories.  For this, we leverage the <b>semantic similarity</b> between text embeddings to group similar complaints. Instead of manually defining topics, we let a clustering algorithm <b>TD_KMEANS</b> discover natural groupings within the data.  \n",
    "<br>\n",
    "To ensure manageability, we limit our analysis to 5 clusters. After applying K-Means clustering to the complaint embeddings, we identify the centroids of these clusters, which represent the most central points of each topic group. To understand the nature of each cluster, we extract the 20 distinct complaints closest to each centroid, as these provide the most representative examples of the topic. Instead of manually assigning labels, we leverage a powerful large language model (LLM) to analyze these representative complaints and generate meaningful topic names.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b33c04-b6b9-4b74-a62e-6c10d327d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this step takes roughly 20 minutes. Note we build a cluster model on >80k rows and >700 dimensions on a small demo system.\n",
    "# If you want to speed it up, reduce the number of iter_max\n",
    "num_clusters = 10 # 10 topics\n",
    "kmeans_out = KMeans(\n",
    "    id_column=\"row_id\",\n",
    "    data=DF_embeddings,\n",
    "    target_columns=\"emb_0:emb_767\",\n",
    "    output_cluster_assignment=False,\n",
    "    num_init=10,\n",
    "    num_clusters=num_clusters,\n",
    "    iter_max=50,\n",
    "    seed= 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97923f2a-85d3-4df7-b9ee-fe0aaf534c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kmeans_out.show_query())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51ae5fe-a769-4191-8882-ea478eb6579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(kmeans_out.model_data, \"complaints_clustermodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06beda86-7678-4014-b8f5-72b262e4ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_relevant_tables.append(\"complaints_clustermodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0f8508-4350-4a08-b65b-c4e963e8cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dataframes_in_tabs(list_relevant_tables,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca51c91-67c0-4094-a177-e0beb6d06c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the distance of each message to their cluster centroid. We pick the 20 closest messages\n",
    "DF_clusterdistance = KMeansPredict(\n",
    "    data = DF_embeddings,\n",
    "    object = DataFrame(\"complaints_clustermodel\"),\n",
    "    output_distance = True   \n",
    ").result\n",
    "\n",
    "\n",
    "DF_clusterdistance = DF_clusterdistance.assign(\n",
    "    rank_distance = DF_clusterdistance.td_distance_kmeans.window(\n",
    "            partition_columns=DF_clusterdistance.td_clusterid_kmeans,\n",
    "            order_columns=DF_clusterdistance.td_distance_kmeans\n",
    "        ).dense_rank()\n",
    "    )\n",
    "\n",
    "DF_clusterdistance_top = DF_clusterdistance.loc[DF_clusterdistance.rank_distance<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be06e7e-5d8a-48d4-836a-f0e3e2958638",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_complaints = DataFrame('consumer_complaints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c7e444-7d44-488e-a562-36b2f2339c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_topmesages = DF_clusterdistance_top.join(\n",
    "    DF_complaints.select([\"row_id\",\"consumer_complaint_narrative\"]),\n",
    "    how = \"inner\",\n",
    "    on =  [\"row_id = row_id\"],\n",
    "    lsuffix= \"a\"\n",
    ").select([\"td_clusterid_kmeans\", \"consumer_complaint_narrative\"]).drop_duplicate()\n",
    "df_topmessages = DF_topmesages.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec569f7-faaa-46b0-8b66-58e05a30c2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topmessages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892de86d-b9c0-41dd-9057-bb2bab9d5ce6",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>5. Visualization</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial;'><b>5.1 WordCloud Visualization</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87834a5d-4b0a-42ca-affe-eee59b5109f9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Let's visualize all the clusters through wordcloud visualization.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb02dcc-298a-4e1b-b01b-a42af985edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordclouds = []\n",
    "for i in range(10):\n",
    "    cluster_feedback = ' '.join(\n",
    "        df_topmessages[df_topmessages['td_clusterid_kmeans'] == i]['consumer_complaint_narrative'])\n",
    "    wordclouds.append(WordCloud(width=800, height=400, background_color='white').generate(cluster_feedback))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d5d9b7-7289-431b-8cfb-ec54c78e801e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from tab_widget.py\n",
    "display_wordclouds_in_tabs(wordclouds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2fe8e1-c991-4f09-b76a-754ac398a76f",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>6. Get Topic Names by asking a LLM</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "To leverage the summarization capabilities of large-scale language models, we use a multi-billion parameter model to generate meaningful topic names based on representative complaints from each cluster. This step requires an OpenAI API key, as the model runs through an external API. If you don't have an OpenAI API key, use the pre-generated topic names below.<br>Also, feel free to play around with the prompt and see how this changes the cluster names.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b04189-9ed2-41f2-a115-6f754692451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to True, if you have an OpenAI key\n",
    "I_Have_an_OpenAI_API_Key = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2441d811-e76e-4091-9471-9666640684b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if I_Have_an_OpenAI_API_Key:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OPENAI API KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f067326-f5be-4dc0-9bb6-dccbf04243a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if I_Have_an_OpenAI_API_Key:\n",
    "    prompt_template = \"\"\"Your task is to identify a common topic of 10 messages that have shown similar vector embeddings. \n",
    "    Your answer should be exactly one sentence, maximal 10 words long, summarising the topic. You can skip unneccary filler words.\n",
    "    The answer should not be starting with \"The common topic of the messages is\", or \"the topic is\", or \"Customers are complaining\" etc.\n",
    "    \n",
    "    Here are the 10 messages:\n",
    "    \n",
    "    {messages}\n",
    "    \n",
    "    ====\n",
    "    Topic:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0287b978-b92c-458c-9d71-dfcc03112ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if I_Have_an_OpenAI_API_Key:\n",
    "    from openai import OpenAI\n",
    "    results =  {}\n",
    "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    for i in range (10):\n",
    "        cluster_feedback = '\\n\\n'.join(df_topmessages[df_topmessages['td_clusterid_kmeans'] == i]['consumer_complaint_narrative'])\n",
    "        this_prompt = prompt_template.format(messages = cluster_feedback)\n",
    "        try:\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": this_prompt,\n",
    "                    }\n",
    "                ],\n",
    "                model=\"gpt-4o\",\n",
    "                temperature=0,\n",
    "                max_tokens=4096\n",
    "            )\n",
    "            results[i] = chat_completion.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Failed to call OpenAI API: {str(e)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413c0fad-9b3b-4aa6-8045-82baa16c7c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not I_Have_an_OpenAI_API_Key :\n",
    "    #pre-defined topics\n",
    "    results = {\n",
    "                 0: 'Fraudulent charges and denied claims by banks.',\n",
    "                 1: 'Violation of consumer privacy rights under Fair Credit Reporting Act.',\n",
    "                 2: 'Identity theft and fraudulent credit report disputes.',\n",
    "                 3: 'Disputing inaccurate late payment information on credit reports.',\n",
    "                 4: 'Disputes over inaccuracies and violations in credit reports.',\n",
    "                 5: 'Identity theft and removal of fraudulent credit report entries.',\n",
    "                 6: 'Credit reporting errors and disputes with financial institutions.',\n",
    "                 7: 'Identity theft and fraudulent accounts affecting credit reports.',\n",
    "                 8: 'Credit report inaccuracies and data breach concerns.',\n",
    "                 9: 'Credit report inaccuracies and data breach concerns.'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8996243-2e1f-4b9c-98f6-97924b81aec1",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>7. Generate Embeddings for Topics and  get Similarity</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126c2294-2b7f-426a-a8d2-d54e66227525",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "Now that we have abstracted topics from the data, we need to generate embeddings for them. This step is crucial because, in the next phase, we will calculate the <b>pairwise similarity</b> between complaints and topics, effectively computing a <b>Cartesian product</b> of all complaint-topic pairs.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb665665-8e5f-4d28-b821-cf800422fdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils/topics_distance.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed65369b-0c99-4302-8510-53efc329c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    db_drop_table(\"complaint_topics\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    db_drop_table(\"consumer_complaint_topic_similarity\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec055e4b-039b-41b3-ba8d-b62d3255df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates tables complaint_topics (generates embeddings) and consumer_complaint_topic_similarity (calculates cross-wise vector distances), takes 2 minutes\n",
    "calculate_similarity_topics(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e59804-b459-48e5-ae59-bdd585457283",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_relevant_tables.append(\"complaint_topics\") # embeddings for topics\n",
    "list_relevant_tables.append(\"consumer_complaint_topic_similarity\") # similarity between complaints and topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd45bb5-8511-4095-abfc-d5ef2bc95a62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_dataframes_in_tabs(list_relevant_tables,-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0061a4d1-b399-4d16-83c3-ccbd4f5bfc30",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>7.1 Interactive Dashboard for BI reporting</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>As a final step, we build a dashboard designed to serve as a <b>business intelligence (BI) reporting tool</b>, allowing us to analyze how topic prevalence changes over time. This interactive dashboard provides a structured way to explore complaint trends and refine topic detection dynamically.\n",
    "<ul style = 'font-size:16px;font-family:Arial;'>Dashboard Requirements\n",
    "    <li><b>Visualizing topic trends:</b> Display the number of complaints per topic per month using a <b>multi-line chart</b>, filtering only those complaints with a similarity score above a defined threshold (default: <b>0.6</b>).</li>  \n",
    "<li><b>Dynamic threshold adjustment:</b> Allow users to modify the similarity threshold, automatically updating the visualization in real time.  \n",
    "    </li></ul>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "The dashboard logic is encapsulated in the <code>`topics_widget.py`</code> module.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc9a43c-eab0-4922-8382-caf77f6ffac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils/topics_widget.py\n",
    "#to get get_complaints_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8742fc95-5eb9-49d7-b035-80ba217a5e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.renderers.default = \"notebook_connected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1cf377-8e44-43da-913c-1dabd3347cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_complaints_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a76969-ef4b-4865-94e1-fc350e027484",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>Conclusion</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>In this demo we have seen that how a <b>fully data-driven approach</b> can help analyze large volumes of text data, automatically identifying topics and tracking their trends over time. Instead of relying on <b>prompt engineering</b> to classify messages—which can be inconsistent, expensive, and hard to scale—we used <b>embeddings, clustering and Vector Distance</b> to get a <b>deterministic and repeatable</b> solution.  <br>\n",
    "By applying <b>K-Means clustering</b> on complaint embeddings, we discovered topics without predefining them. A <b>large language model (LLM)</b> then helped generate human-readable names for these clusters, but only once—keeping costs low while still benefiting from its summarization power. From there, we converted topic names into embeddings and calculated <b>vector similarities</b>, allowing us to efficiently map messages to topics in a <b>scalable and automated</b> way.<br>The final step was building an <b>interactive BI dashboard</b> that lets users explore topic trends over time and tweak similarity thresholds. <br>\n",
    "With this approach, we get the <b>best of both worlds</b>: the flexibility of unsupervised learning, the power of embeddings, and the practicality of real-time reporting—all while keeping things <b>scalable, cost-efficient, and environmentally friendly</b>.    \n",
    "</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03ee1cf-5355-48df-a227-133f6d6aeb60",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>8. Cleanup</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8064510f-ebf3-4672-a4de-325ba4f7f595",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;'><b>Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Cleanup work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffebece3-06ef-40c2-8f22-6bc20751d288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to False so you can resume this notebook later without having to load all the data, again.\n",
    "delete_embeddings = False\n",
    "\n",
    "if delete_embeddings:\n",
    "    %run utils/_dataremove.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc1cd33-622e-472f-bfdc-0b9dda1aae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76febde-d5dd-42c9-b133-cc22012e8a13",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2025. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
