{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579a1566-b499-4a28-b093-c5e20c4926aa",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Supervised Text Classification using ONNXEmbeddings and BYOM\n",
    " <br>       \n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 150px; height: auto; margin-top: 20pt;\">\n",
    "  <br>\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aa7760-27eb-4427-8cc3-e7ddf6e94d5d",
   "metadata": {},
   "source": [
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>Introduction</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "Text classification is a crucial task in natural language processing (NLP) with applications across various domains, including healthcare, customer support, and log analysis. When dealing with manually labeled text data, training a supervised classification model can significantly enhance automation and decision-making. However, creating and classifying text manually is often expensive and time-consuming.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "In this blog post, we explore a practical approach to text classification using ONNXEmbeddings and the Bring Your Own Model (BYOM) framework. This method allows for efficient embedding generation and classification model deployment directly within a database, enabling real-time predictions and decision support.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "Even though the specific example is more or less arbitrary, our focus will be on a medical use case: classifying patient conditions based on medical abstracts written by doctors. Given the high volume of abstracts reviewed daily in hospitals, an assistive technology that can accurately predict the condition category can be invaluable.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>To achieve this, we will:   \n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "  <li>Generate text embeddings from medical abstracts</li>\n",
    "  <li>Train a supervised classification model on these embeddings</li>\n",
    "  <li>Deploy both the embedding generation and classification model using ONNX</li>\n",
    "</ul>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The approach is further illustrated in this diagram:\n",
    "</p>\n",
    "\n",
    "<img src=images/workflow.png style=\"border: 4px solid #404040; border-radius: 10px;\"/>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "This approach provides an alternative to simple zero-shot classification, where vector similarity to predefined target descriptions is used. Instead, by leveraging a dataset of historically labeled data—whether binary, multi-class, or multiple binary classifications—we can achieve superior accuracy and interpretability in classification tasks.</p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>Dataset Overview</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "We use the <b>Medical Abstracts Text Classification Dataset</b>, originally compiled by Schopf, Braun, and Matthes (2023) in their paper <i>\"Evaluating Unsupervised Text Classification: Zero-Shot and Similarity-Based Approaches.\"</i> This dataset contains medical abstracts categorized into five condition types:</p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "  <li>Digestive system diseases</li>\n",
    "  <li>Cardiovascular diseases</li>\n",
    "  <li>Neoplasms</li>\n",
    "  <li>Nervous system diseases</li>\n",
    "  <li>General pathological conditions</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The dataset consists of 11,550 training records and 2,888 test records. While the training set includes class labels, the goal is to predict the classes for the test dataset.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>For those interested, the dataset is publicly available on  <a href=\"https://github.com/sebischair/Medical-Abstracts-TC-Corpus.git\" target=\"_blank\">GitHub Repository</a> and is licensed under the Creative Commons Attribution-ShareAlike 3.0 Unported License.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>In the following sections, we will walk through the training and deployment workflows, showcasing how ONNX embeddings and a BYOM approach can streamline text classification for real-world applications.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9550e8-557d-4efb-b6e4-032f0bf3f3d5",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>1. Connect to Vantage, Import python packages and explore the dataset</b></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c3bd78-a876-4021-adb5-332054b7f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdc3405-c79d-4bd9-8913-7ce41f41e22a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install teradataml --upgrade\n",
    "!pip install huggingface_hub --upgrade\n",
    "!pip install teradataml-plus --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9b4b5d-3540-4d1e-ae7f-837e4be42005",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;'><b>Note: </b><i>The above libraries have to be installed. Restart the kernel after executing these cells to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing <b> 0 0</b></i> (zero zero) and pressing <i>Enter</i>.</p>\n",
    "</div>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9da9ae-c4aa-41af-9add-c2aa4518ca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import tdmlplus\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import catboost\n",
    "import onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "import onnxruntime as rt\n",
    "from teradataml import *\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import re\n",
    "import json\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c10306-04b9-425e-ade1-c74fb300bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils/tab_widget.py # imports a function `display_dataframes_in_tabs`\n",
    "list_relevant_tables = [] # we will be adding names of relevant tables progressivley into this list to display "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf2a87d-4eb0-4f61-9b7e-cecf70168f28",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial;'> 1.1 Connect to Vantage</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b062c24e-85a7-4fb5-9498-cdf7d5d4803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../../UseCases/startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3494447-4a4c-40c1-bec7-43f25efd3b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=Telco_Customer_Churn_EFS.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a109c9-9430-491b-9bd7-e56982df313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils/_dataload.ipynb # takes about 1 minute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f3c91a-69b6-4438-bbc3-05ccd33e262e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>In addition, we want to check if our database has already got the required functionality to generate embeddings.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5490aecb-095a-4dc9-baee-1c887049ea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.from_query(\"select InfoKey, InfoData FROM DBC.DBCInfoV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e02215-64e0-4fe6-a157-f87d59f347a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "VCL = False # current system is VCE/VCore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28605d5e-cb94-4487-bb0e-f7e0577a74fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if VCL:\n",
    "    results = execute_sql(\"help database mldb\").fetchall()\n",
    "else:\n",
    "    results = execute_sql(\"help user mldb\").fetchall()\n",
    "\n",
    "embeddings_functions = [x[0] for x in results if x[0].startswith(\"ONNXEmbeddings\")]\n",
    "if len(embeddings_functions) >0:#\n",
    "    print(\"\\n\".join(embeddings_functions))\n",
    "    print(\"---------------------\\nONNXEmbeddings is installed\")\n",
    "else:\n",
    "    print(\"ONNXEmbeddings is not installed. Please Upgrade to BYOM version 6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5fd943-bf04-4e0c-ab40-f6956d1ebad2",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>2. Data Exploration</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ec9f9f-e30f-460c-8136-eb4773e23679",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Before training our model, we first inspect the dataset to understand its structure. We use the function <code>display_dataframes_in_tabs()</code>, which presents the three key tables as interactive tabs in an IPython widget.</p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "<li>medical_train and medical_test: These datasets have the same schema with three columns:</li>\n",
    "<ul>\n",
    "<li>row_id: Unique identifier for each record.</li>\n",
    "<li>medical_abstract: The textual description of a patient's condition.</li>\n",
    "<li>condition_label: A numerical label (1-5) representing the diagnosed condition.</li>\n",
    "</ul>\n",
    "<li>medical_labels: A lookup table mapping condition labels to their respective names:</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125aa131-5962-4582-a5de-b83cee1e08f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_relevant_tables+=[\"medical_train\",\"medical_test\",\"medical_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6b5505-c9a9-475a-9c03-03e7bae719f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_dataframes_in_tabs(list_relevant_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bedb777-3251-4e6d-9e1b-69e21e78b3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_train_raw = DataFrame(\"medical_train\")\n",
    "DF_test_raw = DataFrame(\"medical_test\")\n",
    "DF_labels = DataFrame(\"medical_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d88499-9ffa-40ec-8d98-d4a4c8d32b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_labels = DF_labels.to_pandas().set_index(\"condition_label\")\n",
    "condition_dict = df_labels.to_dict()[\"condition_name\"]\n",
    "condition_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fbd0fa-0761-4df0-8329-a6d5505be878",
   "metadata": {},
   "source": [
    "<p  style = 'font-size:16px;font-family:Arial;'>To check the distribution of the classes that we are going to predict, we need to perform aggregation. The best way to do this is in the database. It will reduce memory usage and speed up processing. By keeping the heavy computation in the database and only retrieving summarized results, we minimize data transfer and optimize performance.</p>\n",
    "<p  style = 'font-size:16px;font-family:Arial;'>Although the image below shows us that the dataset is not perfectly balanced, each condition category still has a sufficient number of examples for training a reliable classification model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611d2809-b4d5-43f4-b1e1-76d990616099",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_agg = (DF_train_raw\n",
    "     .groupby(\"condition_label\")\n",
    "     .agg([DF_train_raw['row_id'].count().alias(\"num_rows\")]))\n",
    "df_agg = DF_agg.to_pandas().sort_values(\"condition_label\")\n",
    "df_agg[\"condition\"] = df_agg.condition_label.astype(str) +\" - \"+ df_agg.condition_label.map(condition_dict)\n",
    "df_agg.plot(x = \"condition\", y = \"num_rows\", kind = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d9f924-5c83-4295-b0a8-ba6b6541e70c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>3. Load HuggingFace Model</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d1a57f-79b5-4c0d-b1ea-7a3764483e90",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>To generate embeddings, we need an ONNX model capable of transforming text into vector representations. We use a pretrained model from\n",
    "<a href=\"https://huggingface.co/Teradata/gte-base-en-v1.5\" target=\"_blank\">Teradata's Hugging Face repository</a>    \n",
    "such as gte-base-en-v1.5. The model and its tokenizer are downloaded and stored in Vantage tables as BLOBs using the save_byom function.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9028892c-ac8c-4382-b85f-86d8c98155ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "model_name = \"gte-base-en-v1.5\"\n",
    "number_dimensions_output = 768\n",
    "model_file_name = \"model.onnx\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5431afe-e4ff-42e2-9f6d-1316a74df95a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Download Model from Teradata HuggingFace Page\n",
    "hf_hub_download(repo_id=f\"Teradata/{model_name}\", filename=f\"tokenizer.json\", local_dir=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be662ede-9833-46b4-9567-6f2571ec1608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the command line syntax as it is more reliable then the python function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70554e95-e2f6-445c-aa07-15d4a520027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hf download Teradata/{model_name} onnx/{model_file_name} --local-dir ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b10e2e-7b49-4455-88cb-1e02a66b8f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    db_drop_table(\"embeddings_models\")\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    db_drop_table(\"embeddings_tokenizers\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef6d63-2bf0-4ac6-ab80-f47b5d8d62d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load Models into Vantage\n",
    "# a) Embedding model\n",
    "save_byom(model_id = model_name, # must be unique in the models table\n",
    "               model_file = f\"onnx/{model_file_name}\",\n",
    "               table_name = 'embeddings_models' )\n",
    "# b) Tokenizer\n",
    "save_byom(model_id = model_name, # must be unique in the models table\n",
    "              model_file = 'tokenizer.json',\n",
    "              table_name = 'embeddings_tokenizers') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28696ddb-4f4e-4bde-bf8e-b984343fb895",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dataframes_in_tabs([\"embeddings_models\",\"embeddings_tokenizers\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12588bd6-b543-4052-9535-79fd86df64dd",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>4. Generate Embeddings with ONNXEmbeddings</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da73beb-0078-425b-b1a6-e179c82e22b5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Now it's time to generate the embeddings using <code>ONNXEmbeddings</code>.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>We run the <code>ONNXEmbeddings</code> function to generate embeddings for a small subset of records. The model is <b>loaded into the cache memory on each node</b>, and Teradata's <b>Massively Parallel Processing (MPP)</b> architecture ensures that embeddings are computed in parallel using <b>ONNX Runtime</b> on each node.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Having said that, generating embeddings for the entire training set can be time-consuming, especially when working on a system with limited resources. In the <b>ClearScape Analytics experience</b>, only a <b>4 AMP system</b> with constrained RAM and CPU power is available. To ensure smooth execution, we test embedding generation on a small sample and use <b>pre-calculated embeddings</b> for the remainder of this blog post. In a real-life scenario you would typically encounter multiple hundred AMPs with much more compute power.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Also have a look at the most important input parameters of this <code>ONNXEmbeddings</code> function.</p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial;'> \n",
    "<li><code><b>InputTable</b></code>: The source table containing the text to be embedded. Here, we use a subquery to rename <code>medical_abstract</code> to <code>txt</code> since <code>ONNXEmbeddings</code> expects the input column to be named <code>txt</code>.</li>\n",
    "<li><code><b>ModelTable</b></code>: The table storing the ONNX model.</li>\n",
    "<li><code><b>TokenizerTable</b></code>: The table storing the tokenizer JSON file.</li>\n",
    "<li><code><b>Accumulate</b></code>: Specifies additional columns to retain in the output (<code>row_id</code>, <code>condition_label</code>, and <code>txt</code>).</li>\n",
    "<li><code><b>OutputFormat</b></code>: Specifies the data format of the output embeddings (<code>FLOAT32(768)</code>, matching the model's output dimension).</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Since embedding generation is computationally expensive, we only process <b>10 records for testing</b> and rely on precomputed embeddings for further analysis.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b667256-6da5-4dd3-a690-c2352aa82c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "configure.byom_install_location = \"mldb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7629573-cef6-4d52-bbfa-4eafb783ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_sample10 = DataFrame(\"medical_train\")\n",
    "DF_sample10 = DF_sample10.assign(txt = DF_sample10.medical_abstract).top(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1242ad6-e3f8-42df-874c-f7090be98a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = DataFrame.from_query(f\"select * from {username}.embeddings_models where model_id = '{model_name}'\")\n",
    "my_tokenizer = DataFrame.from_query(f\"select model as tokenizer from {username}.embeddings_tokenizers where model_id = '{model_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c3c9cf-d06d-4cc0-b5fd-2e50d75c9019",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 4: Test ONNXEmbeddings Function\n",
    "# Note that ONNXEmbeddings expects the 'payload' column to be 'txt'. \n",
    "# If it has got a different name, just rename it in a subquery/CTE.\n",
    "DF_embeddings10 = ONNXEmbeddings(\n",
    "    newdata = DF_sample10,\n",
    "    modeldata = my_model,\n",
    "    tokenizerdata = my_tokenizer, \n",
    "    accumulate = ['row_id','condition_label', 'txt'],\n",
    "    model_output_tensor = \"sentence_embedding\",\n",
    "    output_format = f'FLOAT32({number_dimensions_output})',\n",
    "    enable_memory_check = False    \n",
    ").result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc227b4-afe9-4724-9f1c-ea847c19feb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DF_embeddings10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26afdff2-aae2-4b93-9377-ae68e65f9e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_relevant_tables.append(\"medical_train_embedding\")\n",
    "DF_train_embeddings = DataFrame(\"medical_train_embedding\")\n",
    "DF_train_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3842edd-6b20-4919-91c3-ea40e176a8e8",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d55f28-f0d2-44d6-867c-b84e908952c8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;'><b>5. Visualizing Embeddings with t-SNE</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Once we have generated embeddings for the texts, the next step is to visualize them using <a href=\"https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding\" target=\"_blank\">t-SNE (t-Distributed Stochastic Neighbor Embedding)</a>        \n",
    ". t-SNE is a dimensionality reduction technique that projects the high-dimensional embeddings into two dimensions for easier visualization, while preserving the local structure of the data. By plotting the embeddings, we aim to gain insights into how well the model has captured the underlying structure of the data, specifically how the classes, labeled by human analysts, are distributed in the embedding space.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>In this case, after creating the embeddings in Teradata, we are looking to uncover any patterns or clusters in the data that align with the analyst-assigned labels. The coloring of the plot represents the target classes, and what we expect to see is some degree of separation between these classes. If we observe distinct clusters for each class, it suggests that the embeddings effectively capture the differences between the labels.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412999e5-8e13-44bd-9a31-2456a72254e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_embeddings = DataFrame(\"medical_train_embedding\").to_pandas()\n",
    "\n",
    "df_train_embeddings = df_train_embeddings.sort_values(\"condition_label\").reset_index()\n",
    "df_train_embeddings[\"condition\"] = df_train_embeddings.condition_label.astype(str) +\" - \"+ df_train_embeddings.condition_label.map(condition_dict)\n",
    "\n",
    "X = df_train_embeddings[[f\"emb_{i}\" for i in range(number_dimensions_output)]].values\n",
    "y = df_train_embeddings[\"condition\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fb6f86-fb1e-439b-8d36-74b24d6114e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings and class labels\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "df_tsne = pd.DataFrame(X_tsne, columns = [\"tsne_1\",\"tsne_2\"])\n",
    "df_tsne[\"condition\"] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e90c61-23d9-4ab1-b3d5-9989f54e7463",
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.renderers.default = \"notebook_connected\"\n",
    "\n",
    "def plot_tsne_plotly(this_df):\n",
    "    palette = sns.color_palette(\"tab10\", n_colors=len(this_df[\"condition\"].unique())).as_hex()\n",
    "    fig = px.scatter(\n",
    "        this_df, \n",
    "        x=\"tsne_1\", \n",
    "        y=\"tsne_2\", \n",
    "        color=\"condition\", \n",
    "        title=\"t-SNE Visualization of Embeddings\",\n",
    "        labels={\"tsne_1\": \"t-SNE Component 1\", \"tsne_2\": \"t-SNE Component 2\"},\n",
    "        opacity=0.3,\n",
    "        color_discrete_sequence=palette,\n",
    "        size_max=50 \n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        legend_title_text=\"Condition\",\n",
    "        legend=dict(x=1.05, y=1, traceorder=\"normal\"),\n",
    "        width=1200,  # Set the width\n",
    "        height=800,  # Set the height to be the same as the width\n",
    "            plot_bgcolor='white',  # Set the background color to white\n",
    "        xaxis=dict(showgrid=False,range=[-110, 110]),  # Remove the grid for the x-axis\n",
    "        yaxis=dict(showgrid=False,range=[-110, 110])   # Remove the grid for the y-axis\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be45afae-1317-4b41-a234-aa86770939cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = plot_tsne_plotly(df_tsne)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a233ff4c-316c-485f-a3bc-906b93091666",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Take some time to understand the plot. If you have created the plotly chart, you can select/unselect different conditions by double-clicking on the entry in the legend.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Looking at the t-SNE scatterplot, we can see that most labels form clear groups in different areas of the plot, showing that the embeddings capture meaningful differences between the texts. For example, the yellow label (2 - digestive system dieseases) has at least four separate clusters spread out across the plot. This suggests that even though the texts share the same label, they have distinct differences. Simply using one topic vector for this category wouldn't work well using Vector Distance, so a more advanced supervised model is needed to handle these variations.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>On the other hand, the \"5 - general pathological conditions\" category (category 5) doesn't form a clear cluster. This is expected, as this category is broad and covers a wide range of topics, which makes it harder to group the texts together. This shows why it's useful to train a supervised machine learning model — it can learn these differences and improve the classification by recognizing the complexity within each category.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64db8c15-ae7e-402b-ad57-ecf3f46f5541",
   "metadata": {},
   "source": [
    "\n",
    "<img src=images/tsne_embeddings.gif style=\"border: 4px solid #404040; border-radius: 10px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6288aff8-0801-4e06-911d-df75fde3f931",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb7fb02-8e71-4939-acc0-883f55107c91",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;'><b>6. Train and Evaluate Catboost Model for Classification</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Next, we train a supervised machine learning model to classify the texts based on the embeddings. While many models could work, we choose CatBoost for its strong performance with minimal tuning required.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4ef51a-5f44-432d-909a-48a3c1adac01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "key = \"row_id\"\n",
    "target = \"condition\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "model_catb = catboost.CatBoostClassifier(loss_function=\"MultiClass\", iterations=100)\n",
    "\n",
    "model_catb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925874ab-f400-46de-83d6-457a4b25d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the test set\n",
    "y_pred = model_catb.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61288d95-6f37-495b-bdd2-49c1c36e5f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the confusion matrix\n",
    "cm_df = pd.DataFrame(cm, index=model_catb.classes_, columns=model_catb.classes_)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abd124e-ed0c-4666-a3ae-14579244046f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>The model shows decent performance, with an overall accuracy of 51%. However, it's important to note that the \"general pathological conditions\" category is the largest group and has the highest confusion. This makes it harder to distinguish, as texts in this category often overlap with other diseases. Ignoring this category, the scores for the other groups would be significantly higher. Some categories, like \"digestive system diseases\" and \"nervous system diseases,\" have lower precision and recall, which could be due to the difficulty in distinguishing these diseases from others, or the presence of multiple conditions in the same text.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feba9fc-4845-41a2-b0e2-e3b8949bb320",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>If you're not satisfied with the results and want to improve performance, there are several steps you can take:</p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "<li>Increase the number of iterations during model training to allow CatBoost to learn more from the data.</li>\n",
    "<li>Tune the hyperparameters of the model to find the optimal configuration for your dataset. You can find more details on parameter tuning <a href=\"https://catboost.ai/docs/en/concepts/parameter-tuning\" target=\"_blank\">here</a>  .</li>\n",
    "<li>Consider adding structured data, such as patient information, disease history, or physiological measurements, to provide the model with more context and improve predictions.</li>\n",
    "<li>Fine-tuning the embeddings model could also help capture more relevant features. Alternatively, you might want to try using an open-source model that has already been trained on medical data, as this could bring better results.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ebd004-5c27-4d66-b84b-497eabcd3e6c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>The next step is to convert the model to the ONNX format, making it compatible for deployment within Vantage. We then test the model by running it in a local ONNX runtime to ensure it works as expected. Finally, we upload the model into a table for further use.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f5e166-059c-4caf-9df6-3d192068e5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnxfile_catb = \"catb-medical.onnx\"\n",
    "model_catb_id = \"catb_medical\"\n",
    "\n",
    "model_catb.save_model(onnxfile_catb,\n",
    "                 format=\"onnx\",\n",
    "    export_parameters={\n",
    "        'onnx_domain': 'ai.catboost',\n",
    "        'onnx_model_version': 1,\n",
    "        'onnx_doc_string': 'model for MultiClassification of medical abstracts',\n",
    "        'onnx_graph_name': 'CatBoostModel_for_MultiClassification'\n",
    "    })\n",
    "\n",
    "sess = rt.InferenceSession(onnxfile_catb)\n",
    "\n",
    "label, probabilities = sess.run(['label', 'probabilities'],\n",
    "                                {'features': X[:3].astype(np.float32)})\n",
    "print(probabilities)\n",
    "\n",
    "model_table_name = \"medical_models\"\n",
    "try:\n",
    "    db_drop_table(model_table_name)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "save_byom(model_id = model_catb_id, \n",
    "               model_file =  onnxfile_catb, \n",
    "               table_name =  model_table_name)\n",
    "\n",
    "display_dataframes_in_tabs([model_table_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d632f1-a492-4361-b158-6fa9bc5ac147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DF_test_embeddings = DataFrame(\"medical_test_embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1959d26a-1ed3-4b27-84de-f358af6d9210",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>Next, we will test the inference in-database using ONNXPredict. We utilize the ONNXPredict Python wrapper from <code>teradataml</code>, and by using the <code>show_query()</code> function, we can confirm that it's running as an actual in-database function.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca71f293-15e4-4487-802b-3d4436b38d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "configure.byom_install_location = \"mldb\"\n",
    "\n",
    "onnxpred_obj = ONNXPredict(\n",
    "    newdata = DF_test_embeddings,\n",
    "    modeldata = DataFrame(model_table_name),\n",
    "    accumulate = [\"row_id\", \"condition_label\"],\n",
    "    overwrite_cached_models = \"*\",\n",
    "    model_input_fields_map = f\"features=emb_0:emb_{number_dimensions_output-1}\" \n",
    "\n",
    ")\n",
    "\n",
    "print(onnxpred_obj.show_query())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac4842-86db-4838-baf9-72c32cb13291",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "onnxpred_obj.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226b1e65-9ef8-45bf-a90f-d134aa786bae",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039f6e67-e7db-47a2-835b-b99f7e53568a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;'><b>7. Deployment</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>The optimal deployment scenario for an MPP system like Vantage is through batch processing, where new data is processed in regular intervals such as hourly, daily, weekly, or monthly. In this case, you could combine the SQL for ONNXEmbeddings and ONNXPredict into a single SQL query and deploy it as part of an ETL job. After processing, you can review the results, filter out uncertain predictions, and provide them to analysts for further review. With their feedback, you can retrain the models to improve performance.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Another deployment scenario involves ad-hoc probability predictions, where medical personnel enter a text and want to see the probabilities in real-time. For this, we can build an interactive widget that allows quick, on-the-spot inference, providing instant insights for medical diagnosis. This is what we do in the final chapter.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a10d73-a534-494f-b4e1-cc5a3f1bd216",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;'><b>Widget</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a04ccd-26c6-4737-81d4-3a849da03415",
   "metadata": {},
   "source": [
    "<p  style = 'font-size:16px;font-family:Arial;'><b>Disclaimer</b>: This tool should not be used for actual diagnosis. It is solely for showcasing the capability of combining embeddings with labeled data and supervised machine learning.</p>\n",
    "<p  style = 'font-size:16px;font-family:Arial;'>The widget is designed for diagnosis using pure SQL, making it easy to integrate into a dashboard. Below find a preview of what the widget will look like.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c167de5-af82-49a8-ba1c-5de2142037e6",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62114ca8-4e5a-4f1e-80c2-e597983cac63",
   "metadata": {},
   "source": [
    "\n",
    "<img src=images/textclassificationwidget.gif style=\"border: 4px solid #404040; border-radius: 10px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7352f830-ca48-4845-b95e-d67aab2ae98e",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Below you will find the code. We go trough it step by step:</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'><code><b>get_query(text)</b></code></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "<li><b>Sanitize Input:</b>The function starts by sanitizing the user input <code>text</code> to prevent SQL injection attacks using a regular expression (<code>re.sub</code>). It removes harmful characters such as single quotes, double dashes, semicolons, and backslashes.</li>\n",
    "<li><b>Generate SQL Query:</b> A SQL query is constructed using the sanitized input. The query runs the <code>ONNXEmbeddings</code> function to generate embeddings from the input text using a specified model. The result is stored in a CTE (Common Table Expression) called <code>embeddings_output</code>.</li>\n",
    "<li><b>Run Prediction:</b> The <code>ONNXPredict</code> function is then applied to the embeddings output to generate predictions based on the trained model in the <code>medical_models</code> table. The prediction result is returned.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4e279a-47eb-45a1-b8c0-7b105374c21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query(text):\n",
    "\n",
    "    # to avoid sql injection, we sanitize the input\n",
    "    text = re.sub(r\"(')|(--)|(;)|(\\\\)\", lambda match: {\"'\": \"\", \"--\": \" \", \";\": \" \", \"\\\\\": \"\"}[match.group()], text)\n",
    "    \n",
    "    complete_query = f\"\"\"\n",
    "    WITH embeddings_output AS (\n",
    "    SELECT \n",
    "            *\n",
    "    from mldb.ONNXEmbeddings(\n",
    "            on (SELECT 1 as row_id, CAST('{text}' AS VARCHAR(10000)) as txt ) as InputTable\n",
    "            on (select * from embeddings_models where model_id = '{model_name}') as ModelTable DIMENSION\n",
    "            on (select model as tokenizer from embeddings_tokenizers where model_id = '{model_name}') as TokenizerTable DIMENSION\n",
    "            using\n",
    "                ModelOutputTensor('sentence_embedding')\n",
    "                EnableMemoryCheck('false')\n",
    "                Accumulate('row_id')\n",
    "                OutputFormat('FLOAT32({number_dimensions_output})')\n",
    "                OverwriteCachedModel('false')\n",
    "        ) a )\n",
    "    \n",
    "    SELECT * FROM \"mldb\".ONNXPredict(\n",
    "        ON embeddings_output AS InputTable\n",
    "        PARTITION BY ANY \n",
    "        ON \"medical_models\" AS ModelTable\n",
    "        DIMENSION\n",
    "        USING\n",
    "        Accumulate('row_id')\n",
    "        OverwriteCachedModel('n')\n",
    "        ModelInputFieldsMap('features=emb_0:emb_{number_dimensions_output-1}')\n",
    "    ) as sqlmr\n",
    "    \n",
    "    \"\"\"\n",
    "    return complete_query\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09278fd1-f126-48fb-8f72-484d663b7b9f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'><code><b>get_predictions(query)</b></code></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "<li><b>Execute SQL Query: </b>This function takes the generated query from <code>get_query()</code> and executes it using <code>execute_sql(query)</code>. It fetches the result of the query as a single row, without the overhead of creating a DataFrame, that would require collecting metadata, too.</li>\n",
    "<li><b>Return Predictions: </b>The predictions are returned as a JSON string, which contains the predicted probabilities for different conditions.</li>    \n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa07655-e86e-4fef-b16d-7ab6a5abba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(query):\n",
    "    input_array = execute_sql(query).fetchall()[0]\n",
    "    return input_array\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805635fe-ce38-40a0-9fb0-d68d9b73976d",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'><code><b>create_bar_chart(input_array)</b></code>:</p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "<li><b>Parse JSON: </b>The JSON string containing the predicted probabilities is parsed using <code>json.loads()</code>.</li>    \n",
    "<li><b>Extract and Sort Data: </b>The probabilities are extracted from the parsed data and sorted by the condition labels.</li>    \n",
    "<li><b>Generate Bar Chart: </b>A bar chart is created using <code>plotly.graph_objects</code> to visually display the probabilities of different conditions. The X-axis shows the diseases, and the Y-axis shows the associated probabilities.</li>    \n",
    "<li><b>Return Chart: </b>The bar chart figure is returned for display.</li>    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec66925-33e7-4d3f-95ee-354627699b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bar_chart(input_array):\n",
    "    # Parse the JSON string\n",
    "    data = json.loads(input_array[1])\n",
    "    \n",
    "    # Extract the value sub dict\n",
    "    value_dict = data['probabilities'][0]['value']\n",
    "    sorted_value_dict = dict(sorted(value_dict.items(), key=lambda item: item[0]))\n",
    "    \n",
    "    # Create the bar chart\n",
    "    fig = go.Figure(data=[go.Bar(x=list(sorted_value_dict.keys()), y=list(sorted_value_dict.values()))])\n",
    "    \n",
    "    # Set chart title and labels\n",
    "    fig.update_layout(\n",
    "        title=\"Probabilities of Different Conditions\",\n",
    "        xaxis_title=\"Disease\",\n",
    "        yaxis_title=\"Probability\"\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b494961c-8582-49ff-90c8-cc4ad8209676",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'><code><b>create_probability_app()</b></code></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;'>\n",
    "<li><b>Create UI Elements: </b>The app UI is created using <code>ipywidgets</code>:</li>\n",
    "<ul>\n",
    "    <li>A header is displayed at the top.</li>\n",
    "    <li>A text area is provided for inputting the medical abstract.</li>\n",
    "    <li>A button is added that triggers the probability calculation.</li>\n",
    "    <li>Tabs are created to display either the probability plot or the SQL query for transparency.</li>\n",
    "</ul>\n",
    "<li><b>Define Button Action: </b>When the \"Get Probabilities\" button is clicked, the text entered in the textarea is passed to the <code>get_query()</code> function to generate the SQL query, and then to <code>get_predictions()</code> to get the probabilities.</li>\n",
    "<li><b>Display Results: </b>The SQL query and the bar chart with the predicted probabilities are displayed in the respective tabs. The SQL query is shown in a markdown format for transparency, and the bar chart visualizes the predicted probabilities.</li>\n",
    "<li><b>Launch App: </b>Finally, the layout is displayed, showing the input area, button, and the two tabs for the results.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075712f2-c7d2-4d77-8181-24cce9216699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_probability_app():\n",
    "    # Create the header\n",
    "    header = widgets.HTML(value=\"<h1>Calculate Probabilities of Different Conditions Based on Medical Abstract</h1>\")\n",
    "\n",
    "    # Create the textarea for the medical abstract\n",
    "    textarea = widgets.Textarea(\n",
    "        value='',\n",
    "        placeholder='Enter medical abstract here...',\n",
    "        layout=widgets.Layout(width='95%', height='200px')\n",
    "    )\n",
    "\n",
    "    # Create the button to get probabilities\n",
    "    button = widgets.Button(\n",
    "        description='Get Probabilities',\n",
    "        button_style='primary'\n",
    "    )\n",
    "\n",
    "    # Create the VBox for the left side\n",
    "    left_vbox = widgets.VBox([textarea, button])\n",
    "\n",
    "    # Create the tabs\n",
    "    tab_contents = ['Probability Plot', 'Query']\n",
    "    plot_output = widgets.Output()\n",
    "    query_output = widgets.Output()\n",
    "    tab_children = [plot_output, query_output]\n",
    "    tabs = widgets.Tab()\n",
    "    tabs.children = tab_children\n",
    "    for i in range(len(tab_contents)):\n",
    "        tabs.set_title(i, tab_contents[i])\n",
    "\n",
    "    # Create the overall layout\n",
    "    app_layout = widgets.VBox([\n",
    "        header,\n",
    "        widgets.AppLayout(\n",
    "            header=None,\n",
    "            left_sidebar=left_vbox,\n",
    "            center=tabs,\n",
    "            right_sidebar=None,\n",
    "            footer=None\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    def on_get_probabilities(text_input):\n",
    "        query_output.clear_output()\n",
    "        plot_output.clear_output()\n",
    "        if not text_input:\n",
    "            return\n",
    "        \n",
    "        this_query = get_query(text_input)\n",
    "        \n",
    "        with query_output:\n",
    "            query_md = Markdown(f\"\"\"```sql\\n{this_query}\\n```\"\"\")\n",
    "            display(query_md)\n",
    "        \n",
    "        this_plot = create_bar_chart(get_predictions(this_query))\n",
    "        \n",
    "        with plot_output:\n",
    "            display(this_plot)\n",
    "\n",
    "    def button_clicked(b):\n",
    "        on_get_probabilities(textarea.value)\n",
    "\n",
    "    button.on_click(button_clicked)\n",
    "\n",
    "    # Display the layout\n",
    "    display(app_layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c165b0ea-f638-4c2a-bac6-3e3e4d7d62ed",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'><b>Try it Out</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>You can try out the application with this example text; I have let Copilot create this medical abstract based on 5 examples of condition label 3. Let's see if that works:</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'><code>Early initiation of physical therapy (PT) has been hypothesized to improve functional outcomes in stroke patients. This study aimed to evaluate the effects of early PT on recovery post-stroke. We conducted a retrospective analysis of 300 stroke patients who received PT within 48 hours of stroke onset (early PT group) and compared them to 300 patients who began PT after 48 hours (delayed PT group). Functional outcomes were assessed using the Modified Rankin Scale (mRS) at 3, 6, and 12 months post-stroke. The early PT group demonstrated significantly better mRS scores at all time points (p < 0.01). Additionally, the early PT group had a lower incidence of complications such as pneumonia and deep vein thrombosis (p < 0.05). These findings suggest that early initiation of PT is associated with improved functional outcomes and reduced complications in stroke patients. Further prospective studies are warranted to confirm these results and to explore the underlying mechanisms.</code></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Also, check out the \"Query\" tab to view the SQL query generated for this input. This allows you to see the exact SQL query executed behind the scenes for full transparency!</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2e7351-f813-4eb2-a652-ca0ecd861f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to create and display the app\n",
    "create_probability_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a83008-cffd-4c52-9a23-3ab2c6ccae41",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;'><b>Conclusion</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443ab247-a689-4f3b-9dd3-2be8d5a747e9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;'>In this blog post, we've seen how leveraging manually created labels on top of texts can be a great starting point for helping analysts focus only on the \"difficult\" cases, significantly improving their workflow. By generating embeddings with ONNXEmbedding on a powerful MPP CPU system, you can achieve performance similar to a small GPU cluster, making it accessible for larger-scale analysis.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>We also explored the power of t-SNE to visualize how close examples of similar or different classes are, providing valuable insights into the structure of your data. Whether you're using an open-source supervised ML model via BYOM or running models directly in the database, this approach allows you to incorporate any model into the pipeline effectively.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>Finally, by stacking ONNXEmbedding and ONNXPredict together, you can easily serve both batch inference and ad-hoc queries, offering flexibility for a variety of deployment scenarios. With these tools, you can significantly streamline medical diagnosis workflows and improve the efficiency of your data processing pipeline.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e6e3bf-9fbb-40b6-a385-ee9ece4cebd2",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;'>6. Cleanup</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c003e08-1ec3-430e-be1e-5a85f928c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils/_dataremove.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25e55d9-b45f-4676-ba1c-6a3470706a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c5df17-794e-472c-adcc-ecc0460cf5df",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2025. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
