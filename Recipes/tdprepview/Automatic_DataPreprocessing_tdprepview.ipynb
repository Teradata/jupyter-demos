{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf175dea-fcb3-4812-ae4d-5aefcdf312c9",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Automatic Data Pre-Processing with tdprepview\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8aa536-ca60-4418-939e-b168e3ed7eb8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial'><b>Introduction</b></p>\n",
    "\n",
    "<center><img src=\"images/tdprepview_logo.png\"/ width=\"500px\" height=\"300px\"></center>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Python Package that creates Data Preparation Pipelines in Views written in Teradata-SQL.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>If you're a data science practitioner looking for a fast and efficient approach to prepare datasets for any tabular supervised or unsupervised machine learning with ClearScape Analytics, this package and notebook is what you need. This notebook is about preparing the data to predict customer churn for a bank. However, the methods and strategies are broadly applicable across all use cases that require data preprocessing of tabular data.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf9fe2e-f478-4d97-8fb1-15ba19cae166",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial'><b>What is <code>tdprepview</code>?</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66fbd7b-b569-4ceb-b53c-06c88afc7195",
   "metadata": {},
   "source": [
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "<li> A Python package that creates data preparation Pipelines in Views written in Teradata-SQL.</li>\n",
    "<li> No Python client needed for transforming data with fitted pipelines.</li>\n",
    "<li> Rationale: Most data preprocessing functions can be expressed in plain Teradata-SQL.</li>\n",
    "  <ol style = 'font-size:16px;font-family:Arial'>\n",
    "   <li> E.g., Imputation --> COALESCE</li>\n",
    "  <li> But writing this manually is tiresome and error-prone.</li>\n",
    "      <li> Why not let a Python Package do that for you?</li></ol>\n",
    "<li> What it is not: </li>\n",
    "  <ol><li>It is not a package for data exploration or feature engineering that relies on aggregation of rows. It is really for the final step, transforming everything into a clean analytic data set (ADS).</li></ol></ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9625b11c-5826-4e22-aca3-180770e9d5a1",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial'><b>How will <code>tdprepview</code> improve your data preprocessing work?</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6e7058-8d27-4fa6-8752-660d5bc1e314",
   "metadata": {},
   "source": [
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Super easy and fast to develop with.</li>\n",
    "    <ul style = 'font-size:16px;font-family:Arial'>\n",
    "        <li>Picks up well-known sklearn-API.</li>\n",
    "        <li>Lightweight thanks to encapsulating pipelines as views.</li></ul>\n",
    "<li> Super fast execution runtime, </li>\n",
    "    <ul style = 'font-size:16px;font-family:Arial'>\n",
    "        <li> Thanks to row-wise transformation queries Teradata-SQL.</li>\n",
    "      </ul>\n",
    "<li> Super compatible and future-proof.</li> \n",
    "     <ul style = 'font-size:16px;font-family:Arial'>\n",
    "        <li> Only Teradata-SQL is created.</li>\n",
    "      </ul>\n",
    "<li> Robust, transparent & reusable.</li>\n",
    "<li> (Semi-)automatic pipeline creation based on heuristics and properties of the data.</li>\n",
    "<li> Suits well with Teradata's Bring Your Own Model (BYOM) capability:</li>\n",
    " <ul style = 'font-size:16px;font-family:Arial'>\n",
    "        <li> All data preparation is done in Vantage, only the perfectly clean training set is used for training off-Vantage.</li>\n",
    "      </ul>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253b2f83-9eca-4a81-bdfa-ab41e378629e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial'><b> What Preprocessors are included in <code>tdprepview</code>?</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d12732a-e06b-45cc-856d-81b74cd9dd88",
   "metadata": {},
   "source": [
    "<img alt=\"tdprepview\" width=98% src=\"images/supportedpreprocessors_v131.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a77cdb-75f0-4bc9-bfad-c44430d58599",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial'><b>What are the key features of <code>tdprepview</code>?</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9381ea5e-fa24-4106-92c0-087c0c1af690",
   "metadata": {},
   "source": [
    "<img alt=\"tdprepview\" width=100% src=\"images/tdprepview_keyfeatures.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6329508-8aaf-4c05-9c29-a6c005422af6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial'><b>Where can i get <code>tdprepview</code>?</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3249bef3-e24d-4b91-a50e-973d5baa04ae",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>on <code>pypi</code> via <code>pip install tdprepview</code> </p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Have a look here: <a href=\"https://pypi.org/project/tdprepview/\">https://pypi.org/project/tdprepview/</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b5ecc8-8846-436e-986f-afde0133c7c9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>Steps in the analysis:</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Initiate a connection to Vantage</li>\n",
    "    <li>Data Exploration</li>\n",
    "    <li>Quickstart: Automatic data preprocessing in less than a minute!</li>\n",
    "    <li>Refine auto-generated Pipeline</li>\n",
    "    <li>Appendix: Feature Overview - All Preprocessors in Action</li>\n",
    "    <li>Cleanup</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afcb4c4-dbd0-4e2a-91f4-797b2b4c0237",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Downloading and installing additional software needed</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18032022-e3ca-470f-9a12-87cf2328ef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install tdprepview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42823307-fdf4-4443-ac3e-153e2316b794",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Note: </b><i>Restart the kernel after executing the previous cell to bring the installed libraries into the session. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i></p>\n",
    "</div>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4554a930-d163-4f3c-84c1-099472e724f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "import pandas as pd\n",
    "from teradataml import *\n",
    "import tdprepview\n",
    "import json\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d68bfd-8bfc-4e0c-9e93-307eb9c56dfc",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>1. Initiate a connection to Vantage</b>\n",
    "\n",
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>1.1 Connect to Vantage</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>You will be prompted to provide the password. Enter your password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b1c03c-5b79-4209-8a08-164eda11d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce6ae13-a2d0-484e-8b77-52b49b61964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=Automatic_DataPreprocessing_tdprepview.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5b9f59-a5d3-4caa-b8f1-2d5c917cdb86",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917a5b6c-d7f6-45c0-9744-e3e4fb9e2612",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>1.2 Getting Data for This Demo</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have provided data for this demo on cloud storage. You can either run the demo using foreign tables to access the data without any storage on your environment or download the data to local storage, which may yield faster execution. Still, there could be considerations of available storage. Two statements are in the following cell, and one is commented out. You may switch which mode you choose by changing the comment string.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16973665-4402-466e-bd51-8b3e279bb866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i run_procedure.py \"call get_data('DEMO_BankChurn_cloud');\"        # Takes 30 seconds\n",
    "%run -i run_procedure.py \"call get_data('DEMO_BankChurn_local');\"        # Takes 1 minute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b93f7b-40b7-4feb-8feb-bb9c50bf62cd",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Next is an optional step – if you want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e6f604-ef55-4503-88ac-7dd584fbd601",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i run_procedure.py \"call space_report();\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450146f9-c2ce-4bb0-b96a-4e82a5579153",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>2. Data Exploration</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Create a \"Virtual DataFrame\" that points to the data set in Vantage. Check the shape of the dataframe as check the datatype of all the columns of the dataframe.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'><b><i>*Please scroll down to the end of the notebook for detailed column descriptions of the dataset.</i></b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ca4743-c0ca-4ebf-8122-9d68307c0b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = DataFrame(in_schema(\"DEMO_BankChurn\", \"customer_churn\"))\n",
    "print(\"Shape of the data: \", tdf.shape)\n",
    "tdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3640f8-f2d6-4727-a974-512a1ebf1a3c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>By looking at the datatypes and sample data, we classify the columns into ID column, target variable(y), numerical, categorical and binary. We skip using <i>RowNumber</i> and <i>Surname</i> columns as they are not helpful in the analysis.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2796a4-8b6d-4abc-9eb4-2278a710dc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = \"Exited\"\n",
    "numeric_columns = [\"Age\", \"Balance\", \"CreditScore\", \"EstimatedSalary\", \"Tenure\"]\n",
    "categorical_columns = [\"Gender\", \"Geography\", \"NumOfProducts\"]\n",
    "binary_columns = [\"HasCrCard\", \"IsActiveMember\"]\n",
    "id_column = [\"CustomerId\"]\n",
    "\n",
    "customer_data = tdf.select(\n",
    "    id_column + [target_variable] + numeric_columns + categorical_columns + binary_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91144ef8-fe0f-40a7-841e-d3e2665a472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17712575-cdf7-4e96-a83a-5c3150768d4f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" id=\"no-azure\">\n",
    "    <p style = 'font-size:16px;font-family:Arial'><i><b>Best Practice Tips: Raw Data: Distinguish Data for Training and for Scoring.</b></i></p>\n",
    "</div>\n",
    "     <ul style = 'font-size:16px;font-family:Arial'>\n",
    "        <li>Consider now the deployment phase of the model, specifically for making predictions. This includes batch processing, where scoring occurs at regular intervals (hourly, daily, weekly, or monthly), and event-based processing, where scoring is triggered by specific events.</li>\n",
    "        <li>Prepare the raw scoring dataset by creating a view on top of a source table to incorporate logic for scoring. Utilize a SQL WHERE statement for filtering, such as <code>WHERE ROW_DATE >= TRUNC(CURRENT_DATE, 'MONTH')</code>, to apply the correct Teradata SQL syntax.</li>\n",
    "        <li>If distinguishing between training and scoring data directly in a view definition (with a WHERE statement) is not feasible or desired, consider using the entire content of a table for scoring. Ensure that the data-to-be-scored table is managed by filling it through an external process and emptying it after scoring is completed.</li>\n",
    "        <li>When using stateful functions (e.g., Scaling), ensure to apply the parameters from the training dataset to the scoring dataset as well to prevent missing phenomena like feature drift. To do so, you can crystallize the scoring ADS as a view during data preparation with <code>CREATE VIEW your_view AS SELECT ...</code></li>\n",
    "    <li>One way to do this is using <code>tdprepview</code>. It is a package for fitting and transforming re-usable data preparation pipelines that are saved in view definitions. Hence, no other permanent database objects are required. By using views, you naturally levarage the superior performance of Teradata's Parsing Engine and its Optimizer.</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99776f4-beb1-417f-8758-9950dec1082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_raw_training = \"order_raw_training\"\n",
    "view_raw_scoring = \"order_raw_scoring\"\n",
    "Param = {'database':'demo_user'}\n",
    "\n",
    "key = \"CustomerId\"\n",
    "target = \"Exited\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64318580-1d1d-4d59-9d01-0ed4be567d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_sql(f\"\"\"\n",
    "REPLACE VIEW {Param[\"database\"]}.{view_raw_training} AS \n",
    "(\n",
    " {customer_data.loc[customer_data[key]>15690738].show_query()}\n",
    ")\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02d044f-3fb2-4a0d-9333-12247e08d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_sql(f\"\"\"\n",
    "REPLACE VIEW {Param[\"database\"]}.{view_raw_scoring} AS\n",
    "(\n",
    " {customer_data.drop(columns=[target]).loc[customer_data[key]<=15690738].show_query()}\n",
    ")\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8043dc95-a2da-4876-873a-c815f7340b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_train_raw = DataFrame(in_schema(Param[\"database\"], view_raw_training))\n",
    "print(DF_train_raw.shape)\n",
    "DF_train_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98f2eb0-fade-426f-b3ec-52fd004c2bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_score_raw = DataFrame(in_schema(Param[\"database\"], view_raw_scoring))\n",
    "print(DF_score_raw.shape)\n",
    "DF_score_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d987aa-73d7-48b0-bb99-eb1d131e8fb5",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>3. Quickstart: Automatic Data Preparation in less than a Minute with <code>tdprepview</code></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112cddb6-3c63-44da-9eac-48ca24b6359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. the raw data\n",
    "DF_train_raw # <- a teradataml.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0912dce-dad3-4c12-8c03-d457a7436c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tdprepview\n",
    "from tdprepview import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe69cc80-4ed6-4c37-b48f-87a9c9bd558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Generate and Fit the preprocessing Pipeline automagically!\n",
    "pl = Pipeline.from_DataFrame(\n",
    "                            DF_train_raw, # <- the raw input data\n",
    "                            non_feature_cols=[key,target,\"Surname\"], # <- columns we want to ignore\n",
    "                            fit_pipeline=True) # <- fit pipeline already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e90b819-b508-4c28-a298-c2426e56ac85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. inspect the transformed training dataset\n",
    "DF_train_transformed = pl.transform(DF_train_raw) # <- note the similarity to sklearn!\n",
    "DF_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c82a0c5-cc8a-4370-93f3-83caa0bf3fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Visualize the prepation pipeline. plotly and seaborn required\n",
    "fig = pl.plot_sankey()\n",
    "fig.update_layout(height=1000) # <- adjust the height if it doesnt all fit in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0608e036-538a-42f6-a42d-fded049f13df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. check output types. we want all features to be floats so we can create a single FloatTensorType for ONNX.\n",
    "DF_train_transformed.tdtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfb8781-0a70-4932-a8b0-b67540973bfb",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We take advantage of the fact that a view does not hold any actual data, but rather the computation logic. Therefore, there is no need to alter the computation logic if we wish to rerun the pipeline with new data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2995ba2d-3599-400e-a624-c8f6463f7d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Crystallize pipeline for training & scoring \n",
    "input_schema = Param[\"database\"]\n",
    "output_schema = Param[\"database\"]\n",
    "view_ADS_training = \"order_ADS_trainig\"\n",
    "view_ADS_scoring = \"order_ADS_scoring\"\n",
    "\n",
    "# training\n",
    "pl.transform(\n",
    "    create_replace_view=True, # <- this parameter is key. it will call a REPLACE VIEW statement.\n",
    "    \n",
    "    schema_name=input_schema,\n",
    "    table_name=view_raw_training,\n",
    "    return_type=None,   \n",
    "    output_schema_name=output_schema,\n",
    "    output_view_name=view_ADS_training)\n",
    "\n",
    "#note how we can take the pipeline fitted with the training data set for the scoring data set as well!\n",
    "#tdprepview will take *automatically* care of managing columns that were not present at training or at scoring (e.g the target column)\n",
    "pl.transform(\n",
    "    create_replace_view=True, # this parameter is key. it will call a REPLACE VIEW statement.\n",
    "    \n",
    "    schema_name=input_schema,\n",
    "    table_name=view_raw_scoring,\n",
    "    return_type=None,\n",
    "    output_schema_name=output_schema,\n",
    "    output_view_name=view_ADS_scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c51f5-1154-4f5d-abfd-f46469498909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's inspect the views\n",
    "DF_ADS_training = DataFrame(in_schema(output_schema,view_ADS_training))\n",
    "DF_ADS_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7983036b-ee57-4727-a517-b026b3093fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_ADS_scoring = DataFrame(in_schema(output_schema,view_ADS_scoring))\n",
    "DF_ADS_scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab6121d-1f13-4e05-aeda-509913dcd283",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;'>\n",
    "<b style = 'font-size:20px;font-family:Arial'>4. Refine autogenerated Pipeline</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcb7d61-7ea4-4198-8798-b65df9b49925",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Assume we want to make some adjustments to the auto-generated pipeline. This is what is done in the next chapter.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d911997-b5e7-47e5-af92-e3468eebfb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with suggested Pipeline: get suggested code as text, copy in cell, adjust as needed\n",
    "steps_str = tdprepview.auto_code(DF_train_raw, non_feature_cols=[key,target,\"Surname\"])\n",
    "print(steps_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260b4c0d-b8e4-4cf0-ae8d-e89f84ac4049",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" id=\"no-azure\">\n",
    "    <p style = 'font-size:16px;font-family:Arial'><i><b>Best Practice Tips</b></i></p>\n",
    "</div>\n",
    "\n",
    "<ul style=\"font-size:16px;font-family:Arial\">\n",
    "  <li>Ensure imputation is applied to all features; even if some or all columns currently do not contain NULL values, include imputation to prevent model failure in production.</li>\n",
    "  <li>Ensure that all features in the Analytical Data Set (ADS) are float values, which simplifies the creation of a working and robust model—you'll appreciate this later.</li>\n",
    "  <li>Perform all data preprocessing in Vantage for consistency; otherwise, you must verify whether the model conversion tools are compatible with your preprocessing functions.</li>\n",
    "  <li>Scale all your features to a range between 0 and 1, or use Z-score standardization. While this may not affect tree-based models, it ensures that features contribute equally to the performance of other model types.</li>\n",
    "  <li>Refine the data preprocessing pipeline iteratively: Employ data exploration to ascertain the efficacy of different transformations and selectively preserve those columns that demonstrably enhance your model's performance, as evidenced by measures like feature importance.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9def61-7560-456d-8661-e1def415cef9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial'><b>The first draft from <code>tdprepview.auto_code()</code> was good, but based on data exploration, we identified the need for some more data cleansing steps:</b></p>\n",
    "\n",
    "<ul style=\"font-size:16px;font-family:Arial\">\n",
    "  <li>Fill NULLs for all features (numeric/string) to ensure safety during deployment.</li>\n",
    "  <li>Extract academic title from surname and create one-hot encoded (OHE) features from it.</li>\n",
    "  <li>One-hot encode geography.</li>\n",
    "  <li>Label encode gender.</li>\n",
    "  <li>Limit age to the range of 10 to 100 to remove implausible values.</li>\n",
    "  <li>Log transform balance and estimatedsalary.</li>\n",
    "  <li>Split bank_products (a list of values) into indicator variables.</li>\n",
    "  <li>Scale all float/int features to the 0-1 range.</li>\n",
    "  <li>Ensure all feature columns are of type float with the Cast transformer.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c0c2d6-bcb2-4c06-ac9c-f5ea484eb426",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial'><b>To define the data preparation pipeline, you must specify the steps sequentially in a list. Each step is a tuple adheres to the following structure:</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a491219-0228-4189-b40f-9fcd60b308e0",
   "metadata": {},
   "source": [
    "<ul style=\"font-size:16px;font-family:Arial\">\n",
    "  <li><b>Input Column Names:</b> Specify the column name or a list of column names to be processed. You can also make a selection of columns based on regex patterns, data types or exclusion list.</li>\n",
    "  <li><b>Preprocessing Functions:</b> Apply one or more tdprepview preprocessing functions, along with their arguments, to the input columns.</li>\n",
    "  <li><b>Column Name Modification (Optional):</b> Define how the column names should be altered as a result of the preprocessing.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f56561-e250-4987-97e2-de67cf9005bb",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;font-family:Arial\"> This format ensures a clear and structured approach to setting up your data preparation pipeline in <code>tdprepview</code>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e124c2f6-c920-44b3-9033-f0e5781557a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of variables with same data type\n",
    "df_types = DF_train_raw.dtypes._column_names_and_types\n",
    "int_feats = [c[0] for c in df_types if c[1] == \"int\"]\n",
    "int_feats.remove(key)\n",
    "int_feats.remove(target)\n",
    "float_feats = [c[0] for c in df_types if c[1] == \"float\"]\n",
    "str_feats = [c[0] for c in df_types if c[1] == \"str\"]\n",
    "\n",
    "\n",
    "print(\"int_feats:\",  str(int_feats))\n",
    "print(\"float_feats:\",  str(float_feats))\n",
    "print(\"str_feats:\",  str(str_feats))\n",
    "print(\"key:\",  str([key]))\n",
    "print(\"target:\",  str([target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563c4233-cd34-4fea-b04c-c30710a2fca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdprepview import (Pipeline, # we will put all steps in a single pipeline. tdprepview will take care of creating a meaningful graph, calculating all necessary statistics\n",
    "                        SimpleImputer, # impute numeric values \n",
    "                        ImputeText, # impute text columns\n",
    "                        MultiLabelBinarizer, # to split up a list in a varchar column into multiple binary indicators, also used for Dr. and Prof. titles\n",
    "                        OneHotEncoder, #One Hot Encode Order types into mutliple binary indicators\n",
    "                        LabelEncoder, # encode gender\n",
    "                        CutOff, # cut offs for age\n",
    "                        CustomTransformer, # Log transform of balance and salary\n",
    "                        MultiLabelBinarizer, # to split up a list in a varchar column into multiple binary indicators\n",
    "                        MinMaxScaler, # min max scale all float features in to the range of 0-1\n",
    "                        Cast # all to float\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ca4421-55fb-4862-bc98-36313d62bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_train_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b34dbe9-e507-4039-b9e6-cdfba038dcaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "steps = [   \n",
    "    #1 fill NULLs\n",
    "    (int_feats, SimpleImputer(strategy=\"constant\",fill_value=0)),\n",
    "    (float_feats,SimpleImputer(strategy=\"mean\") ),\n",
    "    (\"Geography\", ImputeText(kind=\"custom\",value=\"France\") ),\n",
    "    \n",
    "\n",
    "    #2. get one hot encoding `geography`\n",
    "    (\"Geography\", OneHotEncoder()),  \n",
    "\n",
    "    #3. convert `gender` to numeric: \"Female\" --> 1, all other values including (\"Male\") --> 0 \n",
    "    (\"Gender\", LabelEncoder(elements=[\"Female\"])),\n",
    "\n",
    "    #4. cutoff implausible `age` value\n",
    "    (\"Age\", CutOff(cutoff_min=10, cutoff_max=100)),\n",
    "\n",
    "    #5. log transform `balance` and `estimatedsalary`, infuse custom SQL in pipeline, make sure its positive first\n",
    "    (['Balance', 'EstimatedSalary'], [CutOff(cutoff_min=1), CustomTransformer(\" LN(%%COL%%) \")]),\n",
    "\n",
    "    #6 min max scale all float features plus int features > 1.0 in to the range of 0-1\n",
    "    ([\"CreditScore\", \"Tenure\", \"NumOfProducts\"], Cast(new_type='FLOAT')), # needs to be done because those values are currently integer\n",
    "    (float_feats + [\"CreditScore\", \"Tenure\"], MinMaxScaler()),\n",
    "\n",
    "    #7 cast all features (but not the key and target column) to float\n",
    "    ({\"columns_exclude\":[key, target]}, Cast(new_type='FLOAT')),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68bd978-52a6-4ba6-9b09-b1a6c84dc46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise the pipeline\n",
    "pl2 = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9a12bf-1089-4dcf-a4bd-f562acedd97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl2.fit(DF_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6745a017-8166-4a7e-a8ea-ca70b32b6d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect the transformed training dataset\n",
    "DF_train_transformed2 = pl2.transform(DF_train_raw)\n",
    "DF_train_transformed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e68f98-4ce5-4cdd-b6bd-b277b9508ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect the transformed scoring dataset\n",
    "DF_score_transformed2 = pl2.transform(DF_train_raw)\n",
    "DF_score_transformed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f81f783-89a8-44d7-870d-aa98c6ae2323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise the prepation pipeline. plotly and seaborn required\n",
    "fig2 = pl2.plot_sankey()\n",
    "# adjust the height if it doesnt all fit in\n",
    "fig2.update_layout(height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abea7849-175d-4826-947f-ab76516a0ea9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 7. We can save the pipeline python object as json for later use\n",
    "pl2.to_json(\"mypipeline.json\")\n",
    "!head -n 10 mypipeline.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68051a57-e7fb-4bab-9f1f-5d6fe3e49135",
   "metadata": {},
   "source": [
    "Once the pipeline is completed, you can go ahead and build the actual ML model, may it be with in-DB function or with Python and Bring Your Own Model (BYOM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb92657-74e5-4279-8986-84093faa35e8",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>5. Appendix: Feature Overview - All Preprocessors in Action</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following is a list of all available preprocessors in tdprepview</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf152e8-cc43-44f2-9f72-1a60fed8cfdf",
   "metadata": {},
   "source": [
    "<img alt=\"tdprepview\" width=90% src=\"images/supportedpreprocessors_v131.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414534cb-ad80-4919-a6e1-b1a03ffea870",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.1 Impute</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial'>Impute, ImputeText, SimpleImputer.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c548e7-286a-4a18-ad20-4ccbdc2784ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdprepview import Impute, ImputeText, SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc1cda-0e9a-4800-a6e2-e49e1449b238",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    (\"CreditScore\", Impute(\"mean\")),\n",
    "    (\"HasCrCard\", Impute(\"min\")),\n",
    "    (\"IsActiveMember\", Impute(\"max\")),\n",
    "    (\"Age\", Impute(\"median\")),\n",
    "    (\"NumOfProducts\", SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    (\"Geography\", ImputeText(\"custom\",\"France\")),\n",
    "    (\"EstimatedSalary\", SimpleImputer(strategy='mean')),\n",
    "    (\"Balance\", SimpleImputer(strategy='median')),\n",
    "    (\"Tenure\", SimpleImputer(strategy='constant', fill_value=0))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21161185-0415-4730-a9ff-7c99aeac8073",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline(steps)\n",
    "pl.fit(DF_train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dfc723-e8a4-48ed-8082-4116f1f50b90",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.2 IterativeImputer</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial'>Impute missing values using an iterative approach.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7c532f-9e9e-4a72-b0fb-6b8845027a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdprepview import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a98152d-9dcf-4359-9076-0fea3f412916",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    ([\"Balance\",\"EstimatedSalary\",\"CreditScore\"], IterativeImputer()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca59d2-91ea-4bc9-9ec9-b17a4e6a0aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline(steps)\n",
    "pl.fit(DF_train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c5f848-8368-4ff1-ab91-05b1574ba97c",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.3 Transform</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Scales</b> numerical values using a chosen method (MinMax, Z-Score, RobustScaling) and parameters.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9af7d10-b7c6-4cf6-99a0-e7414ba23ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdprepview import Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7a4ee6-59a7-4ff6-90bb-a6ab4dbb7760",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_train_raw.tdtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7252c8a9-2dfb-49b4-ab70-40109ddf7621",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    (\"Age\", Scale(kind=\"custom\", numerator_subtr=\"mean\",denominator=\"max-P50\" )),\n",
    "    (\"Tenure\", Scale(kind=\"custom\", numerator_subtr=45,denominator=23 )),\n",
    "    (\"CreditScore\", Scale(kind=\"custom\", numerator_subtr=\"P10\",denominator=\"P90-P10\" )),\n",
    "    (\"EstimatedSalary\", Scale(kind=\"custom\", numerator_subtr=\"min\",denominator=\"max-P49\" )),\n",
    "    (\"Balance\", Scale(kind=\"custom\", numerator_subtr=\"mode\",denominator=\"std\" )),\n",
    "     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8513d8b-e745-4581-9329-0861f6eacd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline(steps)\n",
    "pl.fit(DF_train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409b776a-e287-4b87-86ef-4f38254b2310",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.4 Normalizer</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial'>A preprocessor that normalizes the input data. similar to sklearn's Normalizer</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47b3d43-ca5f-48a3-ad71-82d4c8d412ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdprepview import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9348dd1e-7a01-41ee-833d-0e70aadd5211",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    ([\"Balance\",\"EstimatedSalary\",\"CreditScore\"], Normalizer(\"l2\")),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b81cc5b-cdd6-4901-ae81-b50ba04f45d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline(steps)\n",
    "pl.fit(DF_train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92342f1a-88fe-4c18-8525-6d26d5104563",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.5 StandardScaler, MaxAbsScaler, MinMaxScaler, RobustScaler</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Standardize</b> Standardize features by removing the mean and scaling to unit variance.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>MaxAbsScaler</b> Scale each feature by its maximum absolute value.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>MinMaxScaler</b> Scale each feature by its maximum and minimum value.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>RobustScaler</b> Scale features using statistics that are robust to outliers.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e17b20e-4c99-4d47-a781-06ea44ca56e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdprepview import StandardScaler, MaxAbsScaler, MinMaxScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081aca04-e17d-40c5-80db-e4684677ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    (\"CreditScore\", StandardScaler()),\n",
    "    (\"Age\", MaxAbsScaler()),\n",
    "    (\"Tenure\", MinMaxScaler(feature_range=(0,10), clip = True)),\n",
    "    (\"Balance\", RobustScaler(quantile_range=(10,90))),\n",
    "     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d786083-a339-4302-8e21-dd665b292c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline(steps)\n",
    "pl.fit(DF_train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20af7be-e3e6-4161-b655-064d89874962",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.6 CutOff</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial'>Clips numeric values that fall outside a given range.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baea61c9-8525-4cfe-a9f7-01af55026c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdprepview import CutOff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e4e44c-4fac-4c4f-83ac-c1754bc28440",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    (\"CreditScore\", CutOff(\"min\",1000)),\n",
    "    (\"Tenure\", CutOff(cutoff_min=0)),\n",
    "    (\"Age\",  CutOff(cutoff_max=100)),\n",
    "    (\"Balance\", CutOff(0,\"P90\")),\n",
    "     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dfa1e6-08f2-4b5d-9348-999fed522553",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline(steps)\n",
    "pl.fit(DF_train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89406fa9-b2da-4430-aa4d-33fec39ebd0c",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.7 PowerTransformer</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial'>As PowerTransformer from sklearn: </p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Apply a power transform featurewise to make data more Gaussian-like.\n",
    "Power transforms are a family of parametric, monotonic transformations that are applied to make data more\n",
    "Gaussian-like. This is useful for modeling issues related to heteroscedasticity (non-constant variance), or other\n",
    "situations where normality is desired.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Currently, PowerTransformer supports the Box-Cox transform and the Yeo-Johnson transform. The optimal parameter\n",
    "for stabilizing variance and minimizing skewness is estimated through maximum likelihood.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Box-Cox requires input data to be strictly positive, while Yeo-Johnson supports both positive or negative data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b74cecf-69ec-4d12-9434-46ac8d8542e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdprepview import PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead561c0-1671-4084-847b-499073cda234",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    (\"CreditScore\", PowerTransformer(method='box-cox')),\n",
    "    (\"Balance\",  PowerTransformer(method='yeo-johnson')),\n",
    "     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c622ba4-9fba-4c64-883f-a5c0420ebb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline(steps)\n",
    "pl.fit(DF_train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee502c-5712-4949-adab-e5b10a5cb12f",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.8 CustomTransformer</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial'>A custom transformer that applies a custom SQL expression to a column.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91948981-9cb7-421c-b6d4-88e7942698c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdprepview import CustomTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08289a6-8588-4e6d-befd-4ce9234a7c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    (\"CreditScore\", CustomTransformer(\" 2 * POWER(%%COL%%, 2) + 3 * %%COL%% \")),\n",
    "    (\"Balance\", CustomTransformer(\" CASE WHEN %%COL%% < 0 THEN 'negative' ELSE 'positive' END\", \"VARCHAR()\")),\n",
    "     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe071099-4609-46c5-b51a-9e81254d3203",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline(steps)\n",
    "pl.fit(DF_train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42de8adc-3576-4f34-81fb-ab9db8ccd8ab",
   "metadata": {},
   "source": [
    "## \n",
    "\n",
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.9 Discretize</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial'><b>LabelEncoder:</b> Encodes a text column into numerical values using a label encoding scheme.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>SimpleHashEncoder:</b> Encodes a single text based column with td-built-in hashfunction to an INTEGER value.\n",
    "Stateless and hence very performant, but can lead to collisions.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864898a0-556b-4a97-99d4-3925a46e60dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdprepview import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efb0082-5dc0-4195-9240-cf52c490f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [(\"Geography\", LabelEncoder([\"Spain\",\"France\",\"Germany\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb696a0-1961-4b6a-9899-c2f1ec68e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline(steps)\n",
    "pl.fit(DF_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e716d0a-12ae-4a13-b95a-0c290aacd43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdprepview import SimpleHashEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60643939-4904-486d-b392-8060e3916b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    (\"Geography\", SimpleHashEncoder(10,\"salt\")),\n",
    "     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3108695a-abf7-443c-aacb-6f838fe14213",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline(steps)\n",
    "pl.fit(DF_train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9981e014-5fb7-4065-bd67-7582b56341d9",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.10 FixedWidthBinning, VariableWidthBinning, QuantileTransformer, DecisionTreeBinning</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial'><b>FixedWidthBinning:</b> Performs fixed-width binning on a numerical column. </p>\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>VariableWidthBinning:</b> Binning numerical data into variable-width bins. </p>\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>QuantileTransformer:</b> Transform features using quantiles information.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>DecisionTreeBinning:</b> Binning numerical data into variable-width bins, based on a decision tree.\n",
    "Trees are trained in sklearn.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84783d4-a726-4052-b5cc-a67c46f9b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdprepview import FixedWidthBinning, VariableWidthBinning, QuantileTransformer, DecisionTreeBinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bfbdaa-7e7e-4c0e-8046-1fe239d70a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    (\"CreditScore\", FixedWidthBinning(5)),\n",
    "    (\"Age\", FixedWidthBinning(5,0,100)),\n",
    "    (\"Tenure\", VariableWidthBinning(kind=\"custom\", boundaries=[-0.5,0.2,0.5])),\n",
    "    (\"Balance\", QuantileTransformer(n_quantiles=11)),\n",
    "    (\"EstimatedSalary\", DecisionTreeBinning(target_var=\"Exited\",no_bins=5))\n",
    "     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60bb694-27a9-4b5b-9157-e1d5279768ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline(steps)\n",
    "pl.fit(DF_train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cead98ef-e5d2-4753-a6f7-3b0bc64ec3ba",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.11 Binarizer, ListBinarizer, ThresholdBinarizer</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Binarizer:</b> Binarize data according to a threshold.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>ListBinarizer:</b> Preprocessor for text columns that outputs 1 if the value is in a given list or among the K most frequent values. </p>\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>ThresholdBinarizer:</b> Binarizes numeric data using a threshold value.</p></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d10160a-aacf-45b5-8ae4-de378b905dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdprepview import  ThresholdBinarizer, Binarizer, ListBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b783ac8-3485-4db9-8cbf-5de9ab8690b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_train_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec5cc40-5d3a-43c2-a1d2-a34e7fb7aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    (\"Geography\", ListBinarizer(['Spain',\"France\"])),\n",
    "    (\"Age\", ThresholdBinarizer(\"median\")),\n",
    "    (\"Balance\", Binarizer(threshold=0.0)),\n",
    "     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd2c87a-de86-43d8-b5c8-e3b82dc5f1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline(steps)\n",
    "pl.fit(DF_train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f58d59-cba8-4e2b-86dc-1d1cf162cac5",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.12 Feature Engineering</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial'><b>PolynomialFeatures:</b> Generate polynomial and interaction features from input data.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>OneHotEncoder:</b> One-hot encoder for categorical features.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>MultiLabelBinarizer:</b> MultiLabelBinarizer for categorical features. The input column is a delimiter separated list of values. The output is one indicator variable per unique value. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02de09b7-c110-471a-b117-d8442963eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdprepview import PolynomialFeatures, OneHotEncoder, MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e0e6b8-d126-4d9c-a905-1d25441b17d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_train_raw.to_pandas().Geography.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd42903-bc5a-4b7a-a59e-4f7946090091",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    ([\"HasCrCard\",\"IsActiveMember\",\"Tenure\" ], PolynomialFeatures(degree=2, interaction_only=True)),\n",
    "    (\"Geography\", OneHotEncoder()),\n",
    "    (\"Gender\", MultiLabelBinarizer(max_categories=2)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea7a366-8a3c-47d1-8157-1e0db25b2b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline(steps)\n",
    "pl.fit(DF_train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af46c44-0364-44fc-8313-462ba7402c02",
   "metadata": {},
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.13 Dimensionality Reduction & Miscellaneous</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial'><b>PCA:</b> Principal component analysis (PCA) is a technique used to reduce the dimensionality of a dataset while retaining\n",
    "most of its variance.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df552516-a399-42c1-9f26-d26794ce953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdprepview import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db559f14-815c-41dd-a7a2-a5393dacf6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    ([\"CreditScore\",\"Balance\", \"EstimatedSalary\"], PCA(n_components=2))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb68719-3454-4cd4-9209-b8ec4bc604f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline(steps)\n",
    "pl.fit(DF_train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358b0cb7-bca9-4dee-9840-df6e0d1a9a4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style='height:1px;border:none;'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.14 Cast, TryCast</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Cast:</b> A preprocessor that converts a column to a new data type using SQL CAST function. It will be mostly useful to transform all features into FLOAT as last preprocessing step. If the input columns are text based, it is safer to use TryCast.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>TryCast:</b> A preprocessor that attempts to convert a text column to a new data type using SQL TRYCAST function.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f02787b-88d0-4381-b62c-87bc84cb34bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdprepview import Cast, TryCast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5258cd8-d46f-4f3c-8cb0-4f360dace931",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    (\"Gender\", TryCast(\"INT\")),\n",
    "    (\"HasCrCard\", Cast(\"FLOAT\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c138ced1-2a21-4eb8-8cc8-f58cf23487ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline(steps)\n",
    "pl.fit(DF_train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c814fd-d049-4470-96f7-3e3e1554b685",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div id='section8'></div>\n",
    "<hr style='height:2px;border:none;'>\n",
    "<b style = 'font-size:20px;font-family:Arial'>6. Cleanup</b>\n",
    "<hr style='height:1px;border:none;'>\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>6.1 Work Tables</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea43226-03fb-4b2e-bd1c-e760a615db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in [view_raw_training, view_raw_scoring, view_ADS_training, view_ADS_scoring]:\n",
    "    try:\n",
    "        execute_sql(f\"DROP VIEW {v}\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788c1de1-8fa2-4f8c-8f85-83ba066c4cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i run_procedure.py \"call remove_data('DEMO_BankChurn');\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0c3110-0d7d-4e48-8814-a65b2f7a1cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60176c79-69ce-41af-8152-13d942e44c3d",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<b style = 'font-size:18px;font-family:Arial'>Dataset:</b>\n",
    "\n",
    "- `Surname`: Surname\n",
    "- `CreditScore`: Credit score\n",
    "- `Geography`: Country (Germany / France / Spain)\n",
    "- `Gender`: Gender (Female / Male)\n",
    "- `Age`: Age\n",
    "- `Tenure`: No of years the customer has been associated with the bank\n",
    "- `Balance`: Balance\n",
    "- `NumOfProducts`: No of bank products used\n",
    "- `HasCrCard`: Credit card status (0 = No, 1 = Yes)\n",
    "- `IsActiveMember`: Active membership status (0 = No, 1 = Yes)\n",
    "- `EstimatedSalary`: Estimated salary\n",
    "- `Exited`: Abandoned or not? (0 = No, 1 = Yes)\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Links:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Teradataml Python reference: <a href = 'https://docs.teradata.com/search/all?query=Python+Package+User+Guide&content-lang=en-US'>here</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53761f2e-c03d-4a80-b034-25c4cb6a5cb7",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; border-bottom:3px solid #91A0Ab\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2023. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
