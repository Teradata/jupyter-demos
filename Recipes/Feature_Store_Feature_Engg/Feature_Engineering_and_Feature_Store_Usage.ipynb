{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c679ab9-aae4-4418-ae86-59826af7ec1c",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Feature Store and Feature Engineering using tdfs4ds\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2552a4-7540-4633-b962-1efb3a33151e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial'><b>Introduction</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Successful AI/ML implementations face three main challenges:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial'><b>The Data Problem:</b> Quality data and feature engineering consume 80% of the implementation time. Even when different use cases share the same source data and features, organizations often handle data preparation separately.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'><b>The Scale Problem:</b> Real-world use cases often require multiple models. In production, these models require fresh features engineered in the same way as during training. Ensuring the auditability of these features behind model decisions is crucial.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'><b>The Deployment Problem:</b> Transitioning prototypes to production, especially operationalizing data prep pipelines, is often problematic.</li></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Addressing these challenges requires strategic planning, skilled talent, and integration with existing systems. Oraganizations with a history in Data Management recognize the benefits of reusable Data Products, making Enterprise Feature Stores a valuable investment.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>A Feature Store is a curated repository of pre-calculated features, simplifying the journey from data to actionable insights. An Enterprise Feature Store extends across domains/teams, incorporating a Governance Framework for predictable feature delivery. </p>\n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial'><b>While most features are reusable, some need model-specific calculations before integration into a unified dataset.</b></p>\n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial'>The key difference between Feature Store (FS) and Enterprise Feature Store (EFS) is the scope across multiple domains/teams along with the Governance Framework (that gives an assurance that features are delivered under predictable SLAs and it also defines the operating model how the EFS is used across different teams/domains and how features lifecycle is managed). Although most Features are considered as re-usable, there is still some minor part of Features that must be calculated as model-specific (e.g., scaled variables, principal components, etc.) and then combined with the rest of the pre-calculated Features into a single data set (ADS). The figure below describes this co-existence of model-specific ADS(es) and model-independent EFS.</p>\n",
    "\n",
    "<img src='images/EFS.png'>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Business Values</b></p>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial'>Rapid model creation and deployment through enterprise feature reuse.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Flexible creation and usage of new features without extensive engineering support.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Consistent definitions ensure accuracy and quick deployment.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Collaboration and sharing of features among teams.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Maintained feature lifecycle for compliance and auditability.</li>\n",
    "</p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>Why Vantage?</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>There are several reasons why EFS naturally fits to Teradata Vantage:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Utilizes Teradata Vantage with its powerful Analytical Library and SQL Engine.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Primary Index enables efficient single-row access for online feature use.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Single platform for both online and offline feature stores.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Macros reduce parsing overhead from API access.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>R and Python code execution within SQL Engine.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Bi-temporal querying capability.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Scalable MPP power for feature computation.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Industry-specific Logical Data Model as a feature source.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Connectivity to Object Storage via NOS for feature data sourcing.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Query Grid facilitates access to multiple data sources.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Close-to-real-time feature delivery using Query Services and Teradata Intelligent Memory.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Workload management prioritizes tasks effectively.</li></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The unique massively-parallel architecture of Teradata Vantage allows users to prepare data, train, evaluate, and deploy models at unprecedented scale.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e259bc-ca07-4933-bd29-f44da3664961",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>1. Connect to Vantage, Import python packages and explore the dataset</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ddde1b-c50c-45d9-a55c-a7961fa8cafd",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In the section, we import the required libraries and set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2628f9b-962b-4aff-becc-a06c6385bdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# # '%%capture' suppresses the display of installation steps of the following packages\n",
    "!pip install tdfs4ds --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d7a955-d34e-4c86-9b3a-66b78653d881",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Note: </b><i>Please execute the above pip install to get the latest version of the required library. Be sure to restart the kernel after executing those lines to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655981f7-a255-4eea-b576-6ba9a54d2a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from teradataml import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from getpass import getpass\n",
    "display.max_rows=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fd986f-33c4-457b-bb74-c1277af1ce93",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c17a3d-b03a-4ffb-a806-0c432287e9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../../UseCases/startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94ad83a-ec55-4e9a-bf13-d0ac3d142076",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=PP_Feature_Engineering_using_Feature_Store.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd70366-ecea-4056-b9f9-db54fb867bc0",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>1.1 Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have provided data for this demo on cloud storage. We will create tables using the below call to the procedure to get the data for this demo.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb4bd8e-2776-4b0d-8308-1842601bc6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../../UseCases/run_procedure.py \"call get_data('DEMO_FeatureEngg_local');\" \n",
    "# takes about 1 minute 30 seconds, estimated space: 4 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418d50f8-0a4d-4e6b-b7e8-b205e0511fb9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Optional step – We should execute the below step only if we want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4923f6-30fe-48eb-a6b7-83e72ed21436",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../../UseCases/run_procedure.py \"call space_report();\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e06ba4-5685-46eb-857d-6bf7b89b94f7",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>2. Setup a Feature Store</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47d3eae-79b5-41b2-b028-f2d9afcf4b25",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We can now set-up the feature store using the tdfs4dslibrary.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b31fe-f2a1-4f56-8976-45e44f739e2b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The first task is to deploy a feature store in the Data Lab. However, before proceeding with the deployment, we will perform a cleanup to ensure the environment is ready for a fresh start, especially if you wish to rerun the demo from scratch.\n",
    "</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Once the cleanup is complete, we will focus on the actual deployment of the feature store using the TDFS4DS package.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75621dc5-818a-4819-858a-49360765233f",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>2.1 Clean up</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Before deploying a fresh feature store with TDFS4DS, we do some cleanup. This will drop the objects creating by the demo in case you have already run it.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267d3ce7-2eed-4050-918d-8c5e044a0f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tables = db_list_tables()\n",
    "list_of_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac64e908-7923-4780-bc75-f550fb941069",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Drop Views</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eabb21-eb5a-416b-8de0-b1799819197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tables = db_list_tables()\n",
    "[execute_sql(f\"DROP VIEW DEMO_USER.{t}\") for t in list_of_tables.TableName if t.startswith('FS_V')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4135accf-02b7-4dc4-92c2-b74d6bce6b83",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Drop Tables</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edff59c9-2338-4de0-8e49-57cd4057e272",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tables = db_list_tables()\n",
    "[execute_sql(f\"DROP TABLE DEMO_USER.{t}\") for t in list_of_tables.TableName if t.startswith('FS_T')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d3f4a6-558c-42fd-8e4f-95860b385fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tables = db_list_tables()\n",
    "[execute_sql(f\"DROP TABLE DEMO_USER.{t}\") for t in list_of_tables.TableName if t.startswith('FS_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56d6c1c-e1e3-474f-a378-3643a77e4d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "[execute_sql(f\"DROP VIEW DEMO_USER.{t}\") for t in list_of_tables.TableName if t in ['FEAT_ENG_CAT','FEAT_ENG_CUST']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfe2f3e-0195-4e57-92b8-5623647268ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "[execute_sql(f\"DROP TABLE DEMO_USER.{t}\") for t in list_of_tables.TableName if t in ['temp','tdfs__fgjnojnsmdoignmosnig']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705fc4c1-18ad-4718-9a10-8a8ae6cf3279",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tables = db_list_tables()\n",
    "[execute_sql(f\"DROP VIEW DEMO_USER.{t}\") for t in list_of_tables.TableName if '_CAT' in t or '_CUST' in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37141db-c14c-43e8-8c4e-22a09e70c1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "[execute_sql(f\"DROP VIEW DEMO_USER.{t}\") for t in list_of_tables.TableName if t in ['BUSINESS_FILTER','BUSINESS_DATE_SEQ','BUSINESS_DATE','HYBRID_BUSINESS_FILTER']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b15927-f078-4ccb-a21a-fbd0d6d302bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "[execute_sql(f\"DROP TABLE DEMO_USER.{t}\") for t in list_of_tables.TableName if 'HIDDEN' in t ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93eb4a3-913c-4e30-921c-b143cdbf16e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tables = db_list_tables()\n",
    "list_of_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb326964-92eb-4104-abba-1141ed0d213e",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>2.2 Deploying a feature store in a datalab</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a474b905-998d-42bd-a394-821496b52580",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>It’s time to deploy a feature store! The process is straightforward. We will start by importing the <code>TFS4DS</code> package and checking its version. This step is informative as it provides details about the detected database and its working environment. Here are the steps we will follow:</p>\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><strong>Import the Package:</strong> Import the <code>TFS4DS</code> package.</li>\n",
    "    <li><strong>Check the Version:</strong> Verify the package version and observe the output for insights into the database configuration.</li>\n",
    "    <li><strong>Deploy the Feature Store:</strong> Use a single command to set up the feature store. Specify the database where it should be deployed. Note that the user must have the necessary permissions in the database to complete this operation.</li>\n",
    "</ol>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>During the deployment, several tables will be created as part of the feature store:</p>\n",
    "    <li style = 'font-size:16px;font-family:Arial'><strong>Feature Catalog:</strong> A table that organizes and manages the features.</li>\n",
    "    <li style = 'font-size:16px;font-family:Arial'><strong>Process Catalog:</strong> A table that tracks feature engineering workflows and processes.</li>\n",
    "    <li style = 'font-size:16px;font-family:Arial'><strong>Optional Tables:</strong> Additional tables for managing data distribution parameters, filter management, and other advanced capabilities (details on these will be explained in future notebooks).</li>\n",
    "</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Once the setup is complete, you can inspect the definitions of the created tables. Notably, the feature store relies on temporal table capabilities, enabling native <strong>time travel</strong> functionality for features. This powerful feature will be discussed in detail in the notebook.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e54043-cd18-4205-9f01-c9724bce4ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tdfs4ds\n",
    "tdfs4ds.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b567d43-25f2-4e2e-aaf3-8678b91c75c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfs4ds.setup(database='DEMO_USER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce935b-8155-4540-ab49-e8d90e6f5c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "FS_Objects = [t for t in db_list_tables().sort_values('TableName').TableName.values if t not in list_of_tables.TableName.values]\n",
    "FS_Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a360a1-19a8-422a-b7f6-40288f72f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in FS_Objects:\n",
    "    try:\n",
    "        print(tdfs4ds.utils.lineage.get_ddl(view_name=t,schema_name='DEMO_USER', object_type='table'))\n",
    "        print()\n",
    "    except:\n",
    "        ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534311f0-1a01-4272-a804-8dfd85f00561",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>3. Feature Engineering</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c08ae0-1c9b-445e-91ff-13676a55f2a9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Here, we will focus on the feature engineering process using the dataset available in the <strong>DEMO_USER</strong> database. For this, we will use the <code>teradataml</code> package, which enables Data Scientists to leverage the power of the Vantage system using Python.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>We will demonstrate two feature engineering processes:</p>\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>\n",
    "        A feature computed for each <strong>CustomerID</strong>, describing specific attributes of the customer.\n",
    "    </li>\n",
    "    <li>\n",
    "        A feature summarizing <strong>Category</strong> of transactions associated with the customer.\n",
    "    </li>\n",
    "</ol>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The dataset we will use is called <code>transactions</code>, which is a table with the following five columns:</p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><strong>Transaction Date:</strong> The date when the transaction occurred.</li>\n",
    "    <li><strong>Transaction Amount:</strong> The monetary value of the transaction.</li>\n",
    "    <li><strong>Customer ID:</strong> The identifier for the customer making the transaction.</li>\n",
    "    <li><strong>Merchant ID:</strong> The identifier for the merchant or retailer involved in the transaction.</li>\n",
    "    <li><strong>Category:</strong> A tag classifying the transaction into a specific category.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>We will do feature engineering without leveraging a feature store. It demonstrates how a Data Scientist might manually implement a feature engineering process using Vantage and the <code>teradataml</code> package. In the subsequent steps, we will revisit these processes and show how to integrate them with the feature store for a more streamlined and efficient workflow.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here, we define the source_database and create a teradataml dataframe using the <code>transactions</code> table in Vantage</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf078d92-83bf-4eeb-9a54-5d8bc8d78b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_df = pd.read_csv('sample_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306f16dc-6ad0-4ca1-b95e-d4db276bd5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_to_sql(pd_df, table_name='transactions', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d71997a-45a1-4cc2-a7e4-1bbc9b253519",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_database = 'Demo_FeatureEngg' #---'DB_SOURCE'\n",
    "df_transactions = DataFrame(in_schema(source_database,'transactions'))\n",
    "df_transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cdd2fa-a1c0-4e16-9405-f94f6ab54dac",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In this feature engineering process, we will use the <code>teradataml</code> package to create Teradata DataFrames that implement the required computations. The two main feature engineering tasks are:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>\n",
    "        <strong>Statistics on Customer:</strong> For each <code>customer ID</code>, we will compute:\n",
    "        <ul>\n",
    "            <li>The sum of all transaction amounts.</li>\n",
    "            <li>The average amount per transaction.</li>\n",
    "            <li>The total number of transactions.</li>\n",
    "            <li>The number of days since the last transaction.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        <strong>Spending Category Distribution:</strong> For each transaction category, we will compute:\n",
    "        <ul>\n",
    "            <li>The sum of transaction amounts.</li>\n",
    "            <li>The mean, standard deviation, maximum, and median of transaction amounts.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ol>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>These computations will result in two Teradata DataFrames:</p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><code>df_eng_feat_cust</code>: Features computed per customer.</li>\n",
    "    <li><code>df_eng_feat_cat</code>: Features computed for spending category distribution.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Note that these DataFrames only implement the processing logic and do not generate data until explicitly stored or exported. When displaying the content of these DataFrames, only a sample of the results will be shown. To generate the actual data, you would need to either:</p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Store the results in another table within the database.</li>\n",
    "    <li>Export the results to a <code>pandas</code> DataFrame, files, ...</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac9b03b-c26b-46b5-ae92-22bed4baeaa1",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>3.1 Statistics on customers</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19f308b-dec0-4935-8157-bf8434296c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import literal_column\n",
    "df_eng_feat_cust = df_transactions.groupby('CustomerID').agg({'Transaction_Amount' : ['sum','mean','count'], 'Date_transaction':['max']})\n",
    "df_eng_feat_cust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39f316d-d4af-42f7-9f87-f941be156d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_feat_cust.tdtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625891b0-6eac-4fa8-a2f3-0e116f9c054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_feat_cust = df_eng_feat_cust.assign(nb_days_since_last_transactions = literal_column('INTERVAL(PERIOD(max_Date_transaction, CURRENT_DATE)) DAY(4)',type_= INTEGER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888b42a4-48ec-4b14-a9d7-d81fa1425d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_feat_cust = df_eng_feat_cust[['CustomerID','sum_Transaction_Amount','mean_Transaction_Amount','count_Transaction_Amount','nb_days_since_last_transactions']]\n",
    "df_eng_feat_cust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccc0aa1-6a4d-4cc4-806e-100422d2acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c24abc6-36d6-43bd-ab6e-c5a0b536f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_feat_cust.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c16d00-6961-409a-b0d1-9db5cb271cd2",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>3.2 Spending Category Distribution</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec0e4f1-3e2e-40e8-9a4e-08c9e37f734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_feat_cat = df_transactions.groupby('Category').agg({'Transaction_Amount':['sum','mean','std','min','max','median']})\n",
    "df_eng_feat_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761e7bee-0944-49a8-9e33-a03028525643",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_feat_cat = df_eng_feat_cat.join(\n",
    "    df_transactions[['Category','Transaction_Amount']].groupby(\"Category\").percentile(0.25),\n",
    "    on = 'Category',\n",
    "    how = 'inner',\n",
    "    rprefix = 'r'\n",
    ")[df_eng_feat_cat.columns + ['percentile_Transaction_Amount']]\n",
    "df_eng_feat_cat = df_eng_feat_cat.assign(quartile_1_Transaction_Amount=df_eng_feat_cat.percentile_Transaction_Amount)\n",
    "df_eng_feat_cat = df_eng_feat_cat[[c for c in df_eng_feat_cat.columns if c not in ['percentile_Transaction_Amount']]]\n",
    "df_eng_feat_cat = df_eng_feat_cat.join(\n",
    "    df_transactions[['Category','Transaction_Amount']].groupby(\"Category\").percentile(0.25),\n",
    "    on = 'Category',\n",
    "    how = 'inner',\n",
    "    rprefix = 'r'\n",
    ")[df_eng_feat_cat.columns + ['percentile_Transaction_Amount']]\n",
    "df_eng_feat_cat = df_eng_feat_cat.assign(quartile_3_Transaction_Amount=df_eng_feat_cat.percentile_Transaction_Amount)\n",
    "df_eng_feat_cat = df_eng_feat_cat[[c for c in df_eng_feat_cat.columns if c not in ['percentile_Transaction_Amount']]]\n",
    "df_eng_feat_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc1294b-a1a8-4cc5-ba1d-c88e8ad47a84",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>4. Register your feature engineering in the feature store</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3855bf5c-41f8-452d-8f46-07922372694b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Here, we will demonstrate how the feature engineering tasks can be registered in a feature store. We will use the feature store deployed earlier in the series.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Steps for Feature Store Integration:</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><strong>Convert DataFrames to Views:</strong> The feature engineering logic will be stored as database views. These views persist beyond the session and allow for the computation of results whenever they are queried.</li>\n",
    "    <li><strong>Dynamic Updates:</strong> As the underlying tables are updated (via ingestion processes), rerunning the views will compute the updated results without requiring multiple file reprocessing.</li>\n",
    "    <li><strong>Register Processes in the Feature Store:</strong> Once the views are created, they can be registered in the feature store. This involves:\n",
    "        <ul style = 'font-size:16px;font-family:Arial'>\n",
    "            <li>Uploading features by specifying which columns represent entities (e.g., <code>customer ID</code>) and which columns represent features (e.g., transaction sums, averages, counts, etc.).</li>\n",
    "            <li>Adding metadata to describe the process, such as project details, authorship, and other relevant information.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ol>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Additional Concepts Introduced:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><strong>Data Domains:</strong> A namespace for features to prevent name collisions across projects or teams. This is a best practice to ensure clarity and manageability.</li>\n",
    "    <li><strong>Entity-Feature Mapping:</strong> Identifying entity columns (e.g., <code>customer ID</code>) and feature columns (e.g., transaction statistics) in the output to provide clear structure to the data.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here, we will see how to seamlessly integrate feature engineering processes with the feature store and ensure their usability across various projects and teams. This is achieved with a simple command, <code>upload_features</code>, where you define the process, specify entity and feature columns, and optionally include metadata for further documentation and organization.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d119a5-4b5c-4ea2-be75-52947dac9571",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>4.1 Process to compute \"Statistics on customers\"</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b43cd5c-6e15-43b8-a40e-6084b168c315",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The first step is to convert the feature engineering DataFrames into feature engineering processes by creating views. For this, we will use the <code>crystallize_view</code> function.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>About the <code>crystallize_view</code> Function:</p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><strong>Purpose:</strong> Converts a DataFrame into a view that persists the feature engineering logic in the database.</li>\n",
    "    <li><strong>Inputs:</strong>\n",
    "        <ul>\n",
    "            <li>The DataFrame to be crystallized.</li>\n",
    "            <li>The name of the view to be created.</li>\n",
    "            <li>The database where the view should be created.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><strong>Output:</strong> A Teradata DataFrame connected directly to the created view, allowing for seamless interaction with the crystallized process.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>This function provides an efficient way to store feature engineering processes in the database, ensuring they are reusable and persist across sessions.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44852777-0be1-44ae-9a64-6993466b2681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdfs4ds.utils.lineage import crystallize_view\n",
    "df_eng_feat_cust_proc = crystallize_view(df_eng_feat_cust, view_name='FEAT_ENG_CUST', schema_name='DEMO_USER')\n",
    "df_eng_feat_cust_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccacd801-9948-4832-a43f-ee59162c7228",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>4.2 Process to compute \"Spending Category Distribution\"</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af9e45c-a8ad-4470-93ce-36d2ab01364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_feat_cat_proc = crystallize_view(df_eng_feat_cat, view_name='FEAT_ENG_CAT', schema_name='DEMO_USER')\n",
    "df_eng_feat_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33c34ff-220a-4ae6-a409-0df4f6d77cd0",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>5 Connecting Feature Engineering Processes in the Feature Store</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e57486-f419-4852-92ca-73a11476e350",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Once the feature engineering processes have been created as permanent views, it’s time to bridge the gap and connect them to the feature store. Here’s the step-by-step process:</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Connecting to the Feature Store</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><strong>Import the TDFS4DS Package:</strong> Use the <code>import</code> statement to load the <code>TDFS4DS</code> package.</li>\n",
    "    <li><strong>Establish a Connection:</strong> Use the <code>connect</code> method to connect to the feature store.</li>\n",
    "    <li><strong>Define a Data Domain:</strong> A data domain acts as a namespace to organize features and processes. By default, the database name is used, but it is recommended to choose a more descriptive name, such as the project, team, or use case, for better clarity and organization.</li>\n",
    "</ol>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Registering a Feature Engineering Process</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Use the <code>upload_features</code> function to register the process in the feature store. Specify:\n",
    "        <ul style = 'font-size:16px;font-family:Arial'>\n",
    "            <li>Which columns represent the <strong>entity</strong> (e.g., <code>customer ID</code>).</li>\n",
    "            <li>Which columns represent the <strong>features</strong> (e.g., transaction statistics).</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Upon execution, the function:\n",
    "        <ul style = 'font-size:16px;font-family:Arial'>\n",
    "            <li>Analyzes the process and registers the features and entities in the <strong>Feature Catalog</strong>.</li>\n",
    "            <li>Registers the process in the <strong>Process Catalog</strong>, generating a unique <code>process ID</code>.</li>\n",
    "            <li>Computes the results of the process and ingests them into the feature store, timestamping them with the current time to support time travel queries later.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ol>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Rerunning and Scheduling Processes</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The generated <code>process_id</code> allows you to rerun or schedule the refresh of a specific process without needing to reference the original code. This simplifies maintenance and ensures reproducibility.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Processing Additional Features</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The same steps can be followed for other feature engineering processes. Each process can be registered and ingested into the feature store using the same workflow, ensuring consistency and efficiency.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e449e9-9b18-40b1-a915-48999340a779",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.1 Connecting to the feature store</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd7cdde-87a8-445e-b5af-15d1e165f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tdfs4ds\n",
    "tdfs4ds.connect(database='DEMO_USER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834acaa0-7411-4ac5-9089-79c352203804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a data domain for this use case\n",
    "tdfs4ds.DATA_DOMAIN = \"Customer Transaction Analytics\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd7b71e-aad6-45c6-a09f-4e84581b7a22",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.2 Registering the Statistics on customers process</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dc4d4f-84a6-4868-bb32-2258db18bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define the entity and the features in the outputs of the process\n",
    "entity   = 'CustomerID'\n",
    "features = ['sum_Transaction_Amount','mean_Transaction_Amount','count_Transaction_Amount','nb_days_since_last_transactions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25afe0e9-eeaf-4cdb-bab6-8c212d51cb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdfs4ds import upload_features\n",
    "tdfs4ds.DEBUG_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7c84f9-0231-4bf6-8e48-6f9abe13fe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_features(\n",
    "    df_eng_feat_cust_proc, # <-- the teradata dataframe pointing to the process view\n",
    "    entity_id     = entity,\n",
    "    feature_names = features,\n",
    "    metadata      = {'project' : 'customer transactions'} # <-- some informative metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51c2d16-ecd4-4fe3-bad2-4479eb4efa17",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>5.3 Registering the \"Spending Category Distribution\"</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b9ecf2-e753-4530-a203-dd4df84ad70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define the entity and the features in the outputs of the process\n",
    "entity   = 'Category'\n",
    "features = ['sum_Transaction_Amount','mean_Transaction_Amount','std_Transaction_Amount','min_Transaction_Amount','max_Transaction_Amount','median_Transaction_Amount','quartile_1_Transaction_Amount','quartile_3_Transaction_Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea8b697-bcf9-4791-ab86-9a8c3e6d5875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdfs4ds import upload_features\n",
    "tdfs4ds.DEBUG_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eb8962-082e-4543-a336-1500d789286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_features(\n",
    "    df_eng_feat_cat_proc, # <-- the teradata dataframe pointing to the process view\n",
    "    entity_id     = entity,\n",
    "    feature_names = features,\n",
    "    metadata      = {'project' : 'customer transactions'} # <-- some informative metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50867caa-80bc-4f5d-8a29-17997519fdfd",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>6  Inspecting the feature store</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff4794a-3966-4d88-a5df-59dbd762be1f",
   "metadata": {},
   "source": [
    "<p>After the first upload, you can inspect the contents of the feature store. The feature store maintains two catalogs: a feature catalog and a process catalog.</p>\n",
    "\n",
    "<p>This organization ensures that all features and processes are well-documented, accessible, and manageable within the feature store.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d1b3b9-0217-4a4b-a153-78096be0c092",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>6.1 Feature catalog </b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201ade6a-a4cc-4c57-8c98-e7ab4923dba3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><strong>Feature Catalog</strong></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Provides a list of features with unique <strong>Feature IDs</strong> assigned to each feature name.</li>\n",
    "    <li>Includes information about the location of each feature, specifying the feature table and the feature database where it is stored.</li>\n",
    "    <li>Offers views connected to the feature tables, simplifying multiple and concurrent access to the feature store.</li>\n",
    "    <li>Displays the <strong>entity name</strong> and the <strong>data domain</strong> the features belong to.</li>\n",
    "    <li>Includes temporal fields such as <strong>valid start</strong> and <strong>valid end</strong>, enabling native support for time travel functionality.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981bc3fa-6308-4404-be9a-5f73300daf3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tdfs4ds.feature_catalog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501ffa93-a45d-428a-b7f6-cdedbaab467f",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>6.2 - Process catalog</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645ac549-5fb2-4053-98a7-981a2af0cfb9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><strong>Process Catalog</strong></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Lists the names of the views created to describe the feature engineering processes.</li>\n",
    "    <li>Displays the <strong>Process IDs</strong> generated for each process.</li>\n",
    "    <li>Indicates the features and entities associated with each process (e.g., <strong>Feature ID</strong> and <strong>Entity ID</strong>).</li>\n",
    "    <li>Contains additional parameters related to the processes (details of these parameters will be explained in future notebooks).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d269632-336c-4cf7-8749-5fb24f87a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfs4ds.process_catalog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78da6590-7bfa-49ba-bb7b-24f92968b614",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>7 Building Datasets (snapshot) from the Feature Store</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69afe52e-e4ac-47f2-943c-35e651a9cffb",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Now we focus on building datasets from the feature store. As a Data Scientist, we will construct a dataset using features previously ingested into the feature store.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Steps to Build a Dataset</strong></p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><strong>Retrieve Entities:</strong> \n",
    "        <p>The first step is to list the available entities in the feature store. This is scoped to a specific <strong>data domain</strong> to avoid confusion between features with similar names but different meanings, as they may belong to different teams, departments, or use cases. Remember, the data domain serves as the namespace for features and entities.</p>\n",
    "    </li>\n",
    "    <li><strong>Select an Entity:</strong>\n",
    "        <p>For this demonstration, we will select <code>customer ID</code> as the entity.</p>\n",
    "    </li>\n",
    "    <li><strong>Retrieve Features for the Entity:</strong> \n",
    "        <p>Next, we will query the feature catalog to list features available for the selected entity. Since features may be computed by different processes, we will also retrieve and specify the <strong>process ID</strong> associated with each feature.</p>\n",
    "    </li>\n",
    "    <li><strong>Define the Dataset:</strong> \n",
    "        <p>We will create a dataset by mapping each feature to its corresponding <code>process ID</code>. This will be done using a dictionary, which acts as a structured representation of the features and processes.</p>\n",
    "    </li>\n",
    "    <li><strong>Build the Dataset:</strong> \n",
    "        <p>Using the <code>build_and_scale_dataset</code> function, we will generate a denormalized view of the feature store. This view will include:\n",
    "            <ul style = 'font-size:16px;font-family:Arial'>\n",
    "                <li>A list of <code>entity IDs</code> to include in the dataset. Columns for the entity (e.g., <code>customer ID</code>).</li>\n",
    "            <li>A dictionary where the keys are feature names, and the values are the corresponding feature versions (process IDs).</li>\n",
    "            <li>The name of the view to be created for the dataset.</li>\n",
    "            <li>The database where the view will be stored (optional).</li>\n",
    "            <li>An optional comment to document the dataset view, useful for database administrators or IT personnel.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ol>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Output of the <code>build_dataset</code> Function</strong></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Creates a view in the database that represents the dataset.</li>\n",
    "    <li>Returns a Teradata DataFrame connected directly to the created view.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The created dataset is efficient and fast to query as it leverages the indexing capabilities of Vantage (hash indexing, data partitioning, statistics collection). This makes it suitable for feeding machine learning models at high speed or add another layer of feature engineering. For example, you can aggregate the dataset and validate that each <code>entity ID</code> has a unique feature value, which is critical for consistency.</p>\n",
    "            \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Dataset Patterns</strong></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The <code>tdfs4ds</code> package supports two patterns for datasets:</p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><strong>Snapshot:</strong> Retrieves the current value of features at the present time. This is the focus of this notebook.</li>\n",
    "    <li><strong>Time Series:</strong> Allows retrieval of feature values over time, leveraging the temporal capabilities of Teradata Vantage. This pattern will be covered in a future demonstration.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Key Details</strong></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>The dataset created is a <strong>view</strong>, meaning no new data is generated. It provides a current view of the features based on the valid timestamp, ensuring up-to-date results.</li>\n",
    "    <li>If features are updated or refreshed through scheduled processes, querying the dataset will automatically retrieve the latest values without additional effort.</li>\n",
    "    <li>The temporal capabilities of Teradata Vantage ensure seamless management of feature versions over time.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Consuming the Dataset</strong></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The dataset view can be named and consumed in various tools, such as this Python notebook, BI tools, or any application that supports database connections and SQL queries. This makes it highly flexible for integration with other workflows and applications.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eba3d5-718d-4cc1-90eb-2d952d296a91",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>7.1 Get available entity </b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab17ac1-7efd-4b6d-bd06-a38f9215d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdfs4ds.feature_store.feature_query_retrieval import get_list_entity\n",
    "get_list_entity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a8f3fb-e547-464c-9dc3-24f7d57b5278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have two entities: CustomerID and Category that are described with features\n",
    "entity = 'CustomerID'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152f2ad5-37f0-470b-aaf7-a97fcf19987b",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>7.2 Get available features for the selected entity</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04722077-95e1-4f0c-980c-2fc7b76b5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdfs4ds.feature_store.feature_query_retrieval import get_available_features\n",
    "get_available_features(entity_id=entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee6da29-7507-4826-9389-003ced665cd1",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>7.3 Select the feature version</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Each feature may have more than one version, meaning they could be computed by different processes.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b92f68a-04a2-47a7-86e1-c7436d00de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdfs4ds.feature_store.feature_query_retrieval import get_feature_versions\n",
    "tdfs4ds.DEBUG_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20de99bb-19e2-4a85-a3db-f8368b114704",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection = get_feature_versions(\n",
    "    entity_name = entity,\n",
    "    features    = [\n",
    "        'count_Transaction_Amount',\n",
    "        'mean_Transaction_Amount',\n",
    "        'nb_days_since_last_transactions',\n",
    "        'sum_Transaction_Amount'\n",
    "    ]\n",
    ")\n",
    "feature_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5e0d89-8f3f-4d7a-8583-58cbcad00c55",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>7.4 Build the dataset (view)</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae03c20-8cf5-4db8-bf7f-2f328d73300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdfs4ds import build_dataset,build_dataset_opt\n",
    "tdfs4ds.DEBUG_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973590dc-6e92-4c8f-b6a0-cb74faa3ad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this build a view on the feature store data model with the entity and the selected features\n",
    "# (the features values are the up-to-date values of the features)\n",
    "dataset = build_dataset(\n",
    "    entity_id         = entity,\n",
    "    selected_features = feature_selection,\n",
    "    view_name         = 'DATASET_CUSTOMER',\n",
    "    comment           = 'my dataset for curve clustering'\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce525d3-3fd9-4605-b5b3-e599428e5b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.groupby('CustomerID').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402289db-f2c7-4dff-a87f-5f13db24d47b",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>8 Update the features and re-run the feature engineering processes</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576dc143-c23f-4dcb-b60d-0ddfacf91948",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In this notebook, we will explore how to refresh features in the feature store without requiring access to the original code that defined the feature engineering processes or created datasets. This approach leverages the metadata stored in the feature store to simplify and streamline the refresh process.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Steps to Refresh Features</strong>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><strong>Connect to the Feature Store:</strong> Establish a connection to the feature store.</li>\n",
    "    <li><strong>Inspect the Process Catalog:</strong> Review the <strong>Process Catalog</strong> to identify the processes associated with the features you want to refresh. \n",
    "        <ul>\n",
    "            <li>The catalog includes details such as <code>process ID</code>, <code>entity ID</code>, <code>data domain</code>, and the features involved.</li>\n",
    "            <li>Select the processes to refresh based on the updated source data.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><strong>Rerun the Process:</strong> Use the <code>run</code> method from the <code>TFS4DS</code> package. Provide the <code>process ID</code> as an argument to execute the process and refresh the feature content.</li>\n",
    "</ol>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>How It Works</strong></p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><strong>Source Table Updates:</strong> In real-world industrial scenarios, data ingestion processes continuously update source tables in a structured data model. These updates are seamlessly integrated into the feature store without requiring table schema changes.</li>\n",
    "    <li><strong>Incremental Processing:</strong> Ideally, processes are engineered to handle incremental updates rather than reprocessing entire tables. This minimizes computation time and optimizes efficiency.</li>\n",
    "    <li><strong>Temporal Features:</strong> The feature store uses temporal capabilities to manage feature validity:\n",
    "        <ul>\n",
    "            <li>If the feature value for an entity remains unchanged, the validity range of the feature is extended without adding new data.</li>\n",
    "            <li>If the feature value changes, a new row is added to record the update, closing the previous validity period and starting a new one with the current timestamp.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Benefits of Temporal Features</strong></p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Supports versioning of features over time, allowing reconstruction of changes as a time series or snapshots.</li>\n",
    "    <li>Enables time travel queries to analyze features at different points in time.</li>\n",
    "    <li>Optimizes storage by avoiding redundant data insertion for unchanged features.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa975870-b0f3-4344-a09b-7859ee618f20",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><strong>Automating the Refresh Process</strong></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The <code>run</code> method can be scheduled using any orchestrator that supports a Python runtime. This allows for automated feature refreshes as part of operational workflows. Note that feature refresh operations typically occur in production environments rather than in a data lab. By following this approach, operational teams can ensure that features remain up-to-date and reliable, enabling seamless integration into downstream applications and analytics workflows.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92cacbe-72d6-4009-9ca6-de22efd7dc45",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>8.1 Connect to the Feature Store</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27178a0f-c0ed-4e0d-b1e9-f841e5205524",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The first step after connecting to the Vantage system is to establish a connection to the deployed feature store. This is done using the <code>connect</code> method, which requires the following parameters:</p>\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><strong>Database:</strong> Specify the database where the feature store is hosted.</li>\n",
    "    <li><strong>Data Domain:</strong> Define the namespace to restrict the search for entities, features, and versions to the appropriate scope. This ensures clarity and prevents conflicts across different teams, projects, or use cases.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Establishing this connection is essential for working with the feature store and accessing its capabilities within the defined context.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb960719-9349-4ee4-b6b8-130e6bacf064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tdfs4ds\n",
    "tdfs4ds.connect(database='DEMO_USER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7879ae2b-c18b-49e9-8648-78e714488d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a data domain for this use case\n",
    "tdfs4ds.DATA_DOMAIN = \"Customer Transaction Analytics\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d030f28-ec8e-4247-8cb7-21260bd3901e",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>8.2 Get existing feature engineering processes (process catalog)</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d8b213-d6ac-4c33-bf8e-7377bea2b253",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>You can retrieve the <code>process ID</code> by inspecting the <strong>Process Catalog</strong>. The Process Catalog provides detailed information about all implemented processes, including their associated <code>process ID</code>, entities, features, and other metadata.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Refer to the catalog to identify the relevant <code>process ID</code> for the feature or process you wish to refresh.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18460b7e-79a9-4994-8f63-05dc35fc5332",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfs4ds.process_catalog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bb677a-5f89-4035-bdea-1bb1dc64adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_process_views = tdfs4ds.process_catalog()[['VIEW_NAME']].to_pandas().VIEW_NAME.values\n",
    "view_cat  = [c for c in list_process_views if 'CAT' in c][0]\n",
    "view_cust = [c for c in list_process_views if 'CUST' in c][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10abf176-1f28-4930-8d33-4a2a188a332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_id_cat  = tdfs4ds.process_store.process_query_administration.get_process_id(view_name=view_cat)\n",
    "process_id_cust = tdfs4ds.process_store.process_query_administration.get_process_id(view_name=view_cust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adce5afc-e024-4c89-8932-2ddfc212e3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('process_id_cat  : ',process_id_cat)\n",
    "print('process_id_cust : ',process_id_cust)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e22af6a-1fea-488a-a01c-d835b291f75b",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>8.3 Execute existing Feature Engineering processes</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a871c7d8-9c13-4536-8e3f-548ad6a052ba",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Once you have identified the relevant <code>process ID</code>, you can re-execute the process with the updated data and ingest the results into the feature store. This process leverages the temporal capabilities of Teradata Vantage.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>To re-execute a process, use the <code>run</code> function from the <code>TDFS4DS</code> package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35586f73-bd83-4a9f-8f25-faad0ba391dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will execute the corresponding processes and update the temporal tables of the feature store\n",
    "tdfs4ds.run(process_id=process_id_cat)\n",
    "tdfs4ds.run(process_id=process_id_cust)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b7c5f7-c436-4d4c-b0b6-71083e84eed7",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>9 Time management in feature store</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e75bba-e42e-40af-97cd-78f363499481",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Now that we have explored the basic usage of the feature store with <code>tdfs4ds</code>, this notebook addresses another common challenge. Customers starting feature store ingestion today may only capture a single version of the feature. However, users might desire a feature store that reflects data as if it had been refreshed over a historical period, such as the past two years, with updates occurring daily.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>This notebook demonstrates how to address this challenge by positioning the processes and the feature store at an earlier date and simulating feature ingestion over time. This capability is enabled by the temporal nature of the feature store and involves time management techniques.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Steps for Time Management</strong>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><strong>Setting an Earlier Date:</strong> Operate the feature store at a specific earlier date, such as two years ago, and simulate daily updates.</li>\n",
    "    <li><strong>Synchronizing Time:</strong>\n",
    "        <ul>\n",
    "            <li>Synchronize the <code>tdfs4ds</code> package with the Vantage platform.            </li>\n",
    "            <li>Ensure the client session, processes, and database data are aligned to the specified date.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><strong>Processing Data for Specific Dates:</strong> Write processes to handle only the data available at the selected date.</li>\n",
    "    <li><strong>Simulate Ingestion:</strong> Simulate the ingestion and upload of features at the earlier date, ensuring the feature store reflects the data for that time.</li>\n",
    "\n",
    "</ol>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Introducing the Time Manager</strong></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The concept of a <strong>Time Manager</strong> is introduced to facilitate this process. The Time Manager is an object represented by a table and a view that allows you to select a specific date from a list. It enables synchronization between:</p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>The feature store in the client session.</li>\n",
    "    <li>The processes to ensure they only operate on the data available for the selected date.</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Key Outcomes</strong></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>By using the Time Manager and aligning processes to specific dates:</p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Features are uploaded with their validity starting at the selected earlier date.</li>\n",
    "    <li>The feature store provides a time-accurate representation of features as they would have been at that time.</li>\n",
    "    <li>Users can simulate historical feature store operations and analyze features over time using temporal capabilities.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>This approach allows for a robust and flexible time management strategy in the feature store, enabling retrospective feature engineering and analysis.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e04a5-19ec-4d44-8c03-1a488f7ff17d",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>9.1 Simulating Daily Ingestion</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this notebook, we will compute the features on a daily basis, in order to simulate a daily run.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Hence the dataset is a single date. To make this easier, we will use a TimeManager, that is made of:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial'>a table that contains the list of days</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'> a view pointing on this table that output only one row of this table</li>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Then, in the next notebook, we will loop over the days in the table and synchronize with the tdfs4ds package.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c11321-5124-4993-aff0-8783d07c358e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>Creation of the time manager</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1382092d-7c4b-461a-8db1-9f457f496f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a data domain for this use case\n",
    "tdfs4ds.DATA_DOMAIN = \"Customer Transaction Analytics Time Management\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7961eb52-c9be-481c-bc9b-877f83dd288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdfs4ds.utils.time_management import TimeManager\n",
    "# this create the BUSINESS_DATE view pointing to the BUSINESS_DATE_HIDDEN table\n",
    "business_time = TimeManager(table_name = 'BUSINESS_DATE', schema_name = 'DEMO_USER')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb8450d-f045-46ee-99ce-decb8aad0823",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>Updating the list of date in the time manager</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af168b81-48c9-4ad6-8500-5c06b9b81a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we will fill the BUSINESS_DATE_HIDDEN table with all the dates available in our source table (transactions)\n",
    "source_data = DataFrame(in_schema(source_database, 'transactions'))\n",
    "business_time.load_time_steps(source_data.groupby('Date_transaction').count(), 'Date_transaction')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e853874f-20e0-463c-8ae0-e224bd532db5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The display() method displays the current time of the time manager object, the one that will be later used in the process definition. And the update() method that can position the cursor of the time manager to another date.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d188f71-2501-4b1d-b1e4-019e0a76feae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the current time of the time manager, here a date\n",
    "# it actually return the select of the BUSINESS_DATE view\n",
    "# by default, it points to the oldest time in BUSINESS_DATE_HIDDEN\n",
    "business_time.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1ea341-aa04-49ce-bf1c-8876821b00c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the current time of the time manager as the 10th value of the BUSINESS_DATE_HIDDEN table\n",
    "business_time.update(time_id=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9e1ada-a828-4588-904e-ddf7ec3766ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_time.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c70290-7e47-4e78-8bfa-b91bc6ca1c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set it back to the first date:\n",
    "business_time.update(time_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc1393-f709-4994-a293-5054b987d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_time.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b307512-6a25-403c-b256-2e8e22f2dd18",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>9.2 Synchronization with tdfs4ds</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e0ee3f-0225-4b8e-ba4f-4190d6825a66",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The feature store package includes a parameter called <code>FEATURE_STORE_TIME</code>, which defines the internal date and time of the feature store for data ingestion. This parameter determines the <strong>valid time</strong> recorded in the temporal table during the ingestion process.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Default Behavior</strong></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>By default, <code>FEATURE_STORE_TIME</code> is set to the system's current time when the package is imported.</li>\n",
    "    <li>If no changes are made, data ingested into the feature store will use the system's current time as the valid time.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Using a Specific Date and Time</strong></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>To set a specific earlier date and time for the feature store:</p>\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Provide a <code>timestamp</code> value to the <code>FEATURE_STORE_TIME</code> parameter.</li>\n",
    "    <li>Retrieve the desired timestamp value, such as the current time from the <strong>Time Manager</strong>, and assign it to <code>feature_store_time</code>.</li>\n",
    "</ol>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Impact on Feature Uploads</strong></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>When the <code>upload_feature</code> method is used, the <code>FEATURE_STORE_TIME</code> parameter ensures that the specified timestamp is recorded as the valid time for the ingested feature values. This allows for precise control of temporal data in the feature store.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>This functionality is particularly useful when simulating historical data ingestion or aligning feature validity with specific historical contexts, enabling robust time travel and retrospective analysis.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b872e-89ba-4d5f-9aa3-94279ca38fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the current time of the time manager in the format expected by tdfs4ds\n",
    "business_time.get_date_in_the_past()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3617c925-424f-4a8a-84d0-ce3f65d70f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synchronize the two\n",
    "tdfs4ds.FEATURE_STORE_TIME = business_time.get_date_in_the_past()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d66856-f58f-49bd-be77-b7641bd013b3",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>9.3 Use the time manager to filter out the source data</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad40d34-fa42-41a6-a1b0-f3fcc4e113e8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The time from the <strong>Time Manager</strong> is also accessible within the Vantage system, allowing it to be incorporated into process definitions. This enables the processes to work with data that aligns with the selected time, such as filtering transactions based on the current transaction date.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The <code>Time Manager</code> is used to define a filter that ensures only transactions matching the current date are processed. However, this part of the workflow cannot be fully automated due to the variability in use cases and process requirements.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Customization by the User</strong></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>The logic for incorporating the <code>Time Manager</code> depends on the specific use case and process being implemented.</li>\n",
    "    <li>Only the user fully understands the nature of their data and can determine how to position the filter to achieve the desired results.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Important Considerations</strong></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Positioning the filter at the end of the process is generally not effective. Filters should typically be applied to the source data or at appropriate stages earlier in the process.</li>\n",
    "    <li>This step is inherently a manual task, as it requires domain knowledge to ensure the filter is applied correctly and effectively.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Ultimately, the responsibility for positioning and defining these filters rests with the user to align the logic with their specific requirements and data characteristics.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a894b962-5130-4f7b-9557-d975481099a4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Here, we apply the time filtering using the = sign on the source data. Then our feature engineering process will use the filtered source instead of the original one.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff5a76e-52b5-4f67-9a62-2cda3fa5327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_source = DataFrame.from_query(\n",
    "f\"\"\"\n",
    "SELECT \n",
    "    CustomerID\n",
    ",   Transaction_Amount\n",
    ",   Date_transaction\n",
    ",   Category\n",
    ",   Merchant_Name\n",
    "FROM {source_database}.transactions A\n",
    "WHERE A.Date_transaction = (SEL BUSINESS_DATE FROM DEMO_USER.BUSINESS_DATE)\n",
    "\"\"\"\n",
    ")\n",
    "input_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bb59d4-44fd-45c6-95f4-9865c3926b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_source.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54d2d4c-9f80-4766-9b97-76629ca010fd",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In this feature engineering process, we will use two main feature engineering tasks are:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>\n",
    "        <strong>Statistics on Customer:</strong> For each <code>customer ID</code>, we will compute:\n",
    "        <ul>\n",
    "            <li>The sum of all transaction amounts.</li>\n",
    "            <li>The average amount per transaction.</li>\n",
    "            <li>The total number of transactions.</li>\n",
    "            <li>The number of days since the last transaction.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        <strong>Spending Category Distribution:</strong> For each transaction category, we will compute:\n",
    "        <ul>\n",
    "            <li>The sum of transaction amounts.</li>\n",
    "            <li>The mean, standard deviation, maximum, and median of transaction amounts.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ol>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>These computations will result in two Teradata DataFrames:</p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><code>df_eng_feat_cust</code>: Features computed per customer.</li>\n",
    "    <li><code>df_eng_feat_cat</code>: Features computed for spending category distribution.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Note that these DataFrames only implement the processing logic and do not generate data until explicitly stored or exported. When displaying the content of these DataFrames, only a sample of the results will be shown. To generate the actual data, you would need to either:</p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Store the results in another table within the database.</li>\n",
    "    <li>Export the results to a <code>pandas</code> DataFrame, files, ...</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8199c451-13e1-40dc-8cf9-e4d9eb796bbb",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Note that we use a input_source, the filtered source using the time of the time manager as input dataframe.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8491face-1c20-495e-bef3-421c8f5f78f5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Statistics on Customer</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9078cc-a585-43b0-bf5e-e6a34de24021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import literal_column\n",
    "df_eng_feat_cust = input_source.groupby('CustomerID').agg({'Transaction_Amount' : ['sum','mean','count'], 'Date_transaction':['max']})\n",
    "df_eng_feat_cust = df_eng_feat_cust.assign(nb_days_since_last_transactions = literal_column('INTERVAL(PERIOD(max_Date_transaction, CURRENT_DATE)) DAY(4)',type_= INTEGER))\n",
    "df_eng_feat_cust = df_eng_feat_cust[['CustomerID','sum_Transaction_Amount','mean_Transaction_Amount','count_Transaction_Amount','nb_days_since_last_transactions']]\n",
    "df_eng_feat_cust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182c05e3-165f-4de1-a757-6c0e14c28b86",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Spending Category Distribution</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3613a4-2cb1-4644-a4e8-e76aca2b2cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_feat_cat = input_source.groupby('Category').agg({'Transaction_Amount':['sum','mean','std','min','max','median']})\n",
    "df_eng_feat_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcb066d-bf87-4cb2-873d-c03c07876105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_eng_feat_cat = df_eng_feat_cat.join(\n",
    "    input_source[['Category','Transaction_Amount']].groupby(\"Category\").percentile(0.25),\n",
    "    on = 'Category',\n",
    "    how = 'inner',\n",
    "    rprefix = 'r'\n",
    ")[df_eng_feat_cat.columns + ['percentile_Transaction_Amount']]\n",
    "df_eng_feat_cat = df_eng_feat_cat.assign(quartile_1_Transaction_Amount=df_eng_feat_cat.percentile_Transaction_Amount)\n",
    "df_eng_feat_cat = df_eng_feat_cat[[c for c in df_eng_feat_cat.columns if c not in ['percentile_Transaction_Amount']]]\n",
    "df_eng_feat_cat = df_eng_feat_cat.join(\n",
    "    input_source[['Category','Transaction_Amount']].groupby(\"Category\").percentile(0.25),\n",
    "    on = 'Category',\n",
    "    how = 'inner',\n",
    "    rprefix = 'r'\n",
    ")[df_eng_feat_cat.columns + ['percentile_Transaction_Amount']]\n",
    "df_eng_feat_cat = df_eng_feat_cat.assign(quartile_3_Transaction_Amount=df_eng_feat_cat.percentile_Transaction_Amount)\n",
    "df_eng_feat_cat = df_eng_feat_cat[[c for c in df_eng_feat_cat.columns if c not in ['percentile_Transaction_Amount']]]\n",
    "df_eng_feat_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36de8e34-6fb9-4a8e-95bf-eac5fe8c4966",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Process to compute \"Statistics on customers\"</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f7412-caff-4180-8e20-4236f51ab7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdfs4ds.utils.lineage import crystallize_view\n",
    "df_eng_feat_cust_proc = crystallize_view(df_eng_feat_cust, view_name='FEAT_ENG_CUST_DAILY', schema_name='DEMO_USER')\n",
    "df_eng_feat_cust_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0449180-91c2-48b0-a417-cdccfa14e8f8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Process to compute \"Spending Category Distribution\"</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274fb9a6-47e2-4bf9-b69d-4e24de1d5b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_feat_cat_proc = crystallize_view(df_eng_feat_cat, view_name='FEAT_ENG_CAT_DAILY', schema_name='DEMO_USER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd21c3a-f2fe-47b7-a905-1ced836b37c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_feat_cat_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c866ab5-68dc-4689-9032-85ca495c4949",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Registering the Statistics on customers process</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17184355-4f4b-4bd4-9fd9-92fd9e31b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define the entity and the features in the outputs of the process\n",
    "entity   = 'CustomerID'\n",
    "features = ['sum_Transaction_Amount','mean_Transaction_Amount','count_Transaction_Amount','nb_days_since_last_transactions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1865a890-2076-406a-b76b-10099e8183ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdfs4ds import upload_features\n",
    "upload_features(\n",
    "    df_eng_feat_cust_proc, # <-- the teradata dataframe pointing to the process view\n",
    "    entity_id     = entity,\n",
    "    feature_names = features,\n",
    "    metadata      = {'project' : 'customer transactions'}, # <-- some informative metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e6ab46-cc42-42f8-a15d-302c85b46ca1",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Registering the \"Spending Category Distribution\"</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afde290a-e643-4e2c-b3bd-b9cf431d6caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define the entity and the features in the outputs of the process\n",
    "entity   = 'Category'\n",
    "features = ['sum_Transaction_Amount','mean_Transaction_Amount','std_Transaction_Amount','min_Transaction_Amount','max_Transaction_Amount','median_Transaction_Amount','quartile_1_Transaction_Amount','quartile_3_Transaction_Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd87601-b17d-4022-b466-dde930c43b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdfs4ds import upload_features\n",
    "upload_features(\n",
    "    df_eng_feat_cat_proc, # <-- the teradata dataframe pointing to the process view\n",
    "    entity_id     = entity,\n",
    "    feature_names = features,\n",
    "    metadata      = {'project' : 'customer transactions'} # <-- some informative metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1aafc6-8304-4f2e-befe-19417145dc7f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Inspecting the feature store</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99ac9f6-38b0-414b-8ca2-5054b41a3c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfs4ds.feature_catalog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37d3885-4c30-4e41-8a1c-b9e68002887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfs4ds.feature_catalog()[['DATA_DOMAIN','FEATURE_ID']].groupby('DATA_DOMAIN').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe11e634-5e74-47f3-b8c5-f5b578e6f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfs4ds.process_catalog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4c2aa6-845f-43c3-ae5e-1b484e04bb6c",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>10 Roll out Feature Engineering Processes over time</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95477813-3883-43f8-ab04-19e37ef10b5d",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Here, we will demonstrate how to update features iteratively from this earlier date to the current date. This is achieved by looping over all the dates available in the <strong>Time Manager</strong> and updating the features for each date.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Automating Feature Updates</strong></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Instead of manually managing the <code>FEATURE_STORE_TIME</code> of the package, a higher-level function called <code>roll_out</code> simplifies this process. The <code>roll_out</code> function automates the execution of processes over a range of dates specified in the Time Manager.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Key Features of <code>roll_out</code></strong></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><strong>Input:</strong> Takes a list of <code>process IDs</code> to execute.</li>\n",
    "    <li><strong>Time Manager:</strong> Utilizes the dates from the specified <strong>Time Manager</strong> to trigger these processes sequentially.</li>\n",
    "    <li><strong>Optional Parameters:</strong>\n",
    "        <ul>\n",
    "            <li><code>time_id_start:</code> Specifies the starting point in the Time Manager's list of dates (optional).</li>\n",
    "            <li><code>time_id_end:</code> Specifies the ending point in the Time Manager's list of dates (optional).</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Example Usage</strong></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here is an example call to the <code>roll_out</code> function:</p>\n",
    "\n",
    "<pre><code>roll_out(\n",
    "    process_list = [process_id_cat, process_id_cust],\n",
    "    time_manager = business_time,\n",
    "    time_id_start = 125, # optional\n",
    "    time_id_end   = 130  # optional\n",
    ")</code></pre>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>This example runs the processes <code>process_id_cat</code> and <code>process_id_cust</code> sequentially over the specified time range, leveraging the dates in the <code>business_time</code> Time Manager.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Practical Considerations</strong></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>In this notebook, the process will be restricted to a few iterations for demonstration purposes.</li>\n",
    "    <li>For a full historical data load, you can run the <code>roll_out</code> function over the entire date range in the Time Manager.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Using <code>roll_out</code>, you can efficiently update features over time, ensuring the feature store reflects the desired historical data timeline.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db643cf9-235b-422d-b178-f3381dfdc403",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>So far, our data are static. However, in practice, there is a continous ingestion of new data.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8035eda5-ff65-44d1-99eb-7951c898fcbb",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>10.1 Roll out existing processes over time</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc15878-cf14-41f5-8ad6-514217386031",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The first step is to retrieve the <strong>Time Manager</strong>. If a Time Manager already exists, the constructor will connect to it. If it does not exist, the constructor will create a new one.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Verifying the Starting Point</strong></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>To ensure the process starts from the first date in the Time Manager, use the <code>get_current_step</code> method.</li>\n",
    "    <li>If <code>get_current_step</code> returns <code>1</code>, the process will start at the first date.</li>\n",
    "    <li>If it does not return <code>1</code>, you can specify the starting <code>time_id</code> directly in the <code>roll_out</code> function.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Practical Usage</strong></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>By checking and setting the starting point, you can ensure the process begins from the correct date, whether performing a full run or focusing on a specific range of dates.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a41b70-a281-4bcf-a648-6ec59d5205d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdfs4ds.utils.time_management import TimeManager\n",
    "# this create the BUSINESS_DATE view pointing to the BUSINESS_DATE_HIDDEN table\n",
    "business_time = TimeManager(table_name = 'BUSINESS_DATE', schema_name = 'DEMO_USER')\n",
    "business_time.get_current_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe44a0a4-6bdf-4182-ad50-ee0d3cf2e075",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>10.2 Trigger the roll out</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8b3497-5958-477d-99ad-7c2ac05704cb",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Using <code>roll_out</code>, you can efficiently update features over time, ensuring the feature store reflects the desired historical data timeline.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab2a24b-eaee-4d0c-b545-f9421175c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdfs4ds import roll_out\n",
    "roll_out(\n",
    "    process_list = [process_id_cat, process_id_cust],\n",
    "    time_manager = business_time,\n",
    "    time_id_start= 125,\n",
    "    time_id_end  = 130\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0319f8c2-75db-4cbb-b597-33902810280d",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>11 Monitoring Process Execution with the Follow-Up Table</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db878e4-1545-4a5d-920d-cae4d00a40eb",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The <code>TDFS4DS</code> package provides a follow-up table to monitor the execution of processes in the feature store. This table contains detailed information about each process run, helping you track progress and troubleshoot issues.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Key Information in the Follow-Up Table </strong></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><strong>Run ID:</strong> Identifies each triggered run.</li>\n",
    "    <li><strong>Process Type:</strong> Indicates the type of process (e.g., upload).</li>\n",
    "    <li><strong>Process ID:</strong> The ID of the process being executed.</li>\n",
    "    <li><strong>Start and Completion Times:</strong> Timestamps indicating when the process started and finished.</li>\n",
    "    <li><strong>Valid Time:</strong> The time at which the data was inserted into the feature store.</li>\n",
    "    <li><strong>Status:</strong> Tracks the current state of the process (e.g., running, failed, or completed).</li>\n",
    "    <li><strong>Additional Metadata:</strong> Includes other relevant details to aid in monitoring and debugging.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here, we will examine the follow-up table to review the processes executed in previous notebooks. This provides insight into the operational framework of <code>TDFS4DS</code> and ensures that processes are functioning as expected.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The follow-up table is an essential tool for managing and monitoring feature store operations, enabling efficient tracking and resolution of any issues that may arise during process execution.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06b7ed8-498d-49e0-b10d-f6abefab73ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfs4ds.process_store.process_followup.follow_up_report().sort('START_DATETIME', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3753be8-09f1-42db-825b-010a1a4a6e9f",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>12 Processing Sequentially with Filter Manager</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b920367-5022-4c15-a2dc-dc234fc352c7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>This notebook introduces the <strong>Filter Manager</strong>, a tool for handling large data volumes during feature engineering and feature store processes. The Filter Manager addresses scenarios where processes handle data that may be too large for the system to process efficiently, potentially leading to spool issues or system constraints.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Key Concepts of the Filter Manager</strong></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><strong>Partitioning Data:</strong> The Filter Manager allows you to partition your data into smaller subsets (partitions) and process each partition sequentially. This reduces the data volume processed at any given time.</li>\n",
    "    <li><strong>Sequential Processing:</strong> While the overall process may take longer, partitioning ensures feasibility by dividing the workload into manageable portions.</li>\n",
    "    <li><strong>Granularity Control:</strong> Define the granularity of your processing and iterate over partitions during feature engineering, process execution, and result ingestion into the feature store.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Benefits of the Filter Manager</strong></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><strong>Progress Monitoring:</strong> Track the progression of your process, ensuring visibility into each partition’s execution.</li>\n",
    "    <li><strong>Error Recovery:</strong> If a partition fails, you do not need to rerun completed partitions. The follow-up table can help identify which partitions have been successfully processed.</li>\n",
    "    <li><strong>Operational Efficiency:</strong> Enables reliable and incremental execution of feature engineering processes in environments with large datasets.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Practical Impact</strong></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>When attaching a Filter Manager to a process definition, it impacts the way the <code>upload_features</code> method runs by:\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Splitting the processing and ingestion tasks based on the defined partitions.</li>\n",
    "    <li>Ensuring that results for each partition are ingested into the feature store sequentially and independently.</li>\n",
    "</ul>\n",
    "</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Usage in Operations</strong></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>By using the Filter Manager, you can:</p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Optimize processing for systems with limited capacity.</li>\n",
    "    <li>Prevent data loss by ensuring completed partitions are not rerun unnecessarily.</li>\n",
    "    <li>Monitor and manage partition execution through the follow-up table.</li>\n",
    "</ul>\n",
    "</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here, we will demonstrate how to define and use the Filter Manager in a process definition and explains its impact on feature store uploads and operations.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ec6dcd-f73f-44bb-b4a9-11dedf3a6c80",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We use a new DATA_DOMAIN for the sake of clarity.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055612b3-3f44-4bbd-b292-fd875e49e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a data domain for this use case\n",
    "tdfs4ds.DATA_DOMAIN = \"Customer Transaction Analytics Time and Category Management\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b92fda-24b3-451e-9cbf-66bd759c8e34",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Reuse of the time manager</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258a515a-c964-4018-8418-68c5b357c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdfs4ds.utils.time_management import TimeManager\n",
    "# this create the BUSINESS_DATE view pointing to the BUSINESS_DATE_HIDDEN table\n",
    "business_time = TimeManager(table_name = 'BUSINESS_DATE_SEQ', schema_name = 'DEMO_USER')\n",
    "# here we will fill the BUSINESS_DATE_HIDDEN table with all the dates available in our source table (transactions)\n",
    "business_time.load_time_steps(source_data.groupby('Date_transaction').count(), 'Date_transaction')\n",
    "# synchronize tdfs4ds with the time manager\n",
    "tdfs4ds.FEATURE_STORE_TIME = business_time.get_date_in_the_past()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97076ac2-41a6-42d3-9a03-30ded108cf3b",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>12.1 Creation of the filter manager</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Like for the time manager, TDFS4DS provide a filter manager to make the partitioning of the process easy.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642a24a0-44bc-4e03-806c-d27e8ce7c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdfs4ds.utils.filter_management import FilterManager\n",
    "# this create the BUSINESS_FILTER view pointing to the BUSINESS_FILTER_HIDDEN table\n",
    "filtermanager = FilterManager(table_name = 'BUSINESS_FILTER',schema_name='DEMO_USER')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb0fadd-3095-49f9-ade4-6f1e4186e958",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Here, we see how we define the granulatiry of the process partitioning. In this example, we want to split the processing by category. Note that the partitioning must be compliant with the business logic, meaning it should not have an unexpected impact on the result of the computations.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58866d-8ba6-4808-8011-c9b6debf0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we will fill the BUSINESS_FILTER_HIDDEN table with all the Categories available in our source table (Category)\n",
    "filtermanager.load_filter(source_data.groupby('Category').count()[['Category']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12a4cfe-3dc1-4ad1-b071-09232f84cc31",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Like with time manager, the fitler manager exhibit a display and update method to show the current value of the filter and position the cursor on a specific partition.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26f0007-18e5-434b-b56c-a059b989af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the current time of the filter manager, here a category\n",
    "# it actually return the select of the BUSINESS_FILTER view\n",
    "filtermanager.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c1c04-4f4d-4322-b1ef-fb3bc9c39f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the current filter of the filter manager as the 2nd value of the BUSINESS_FILTER_HIDDEN table\n",
    "filtermanager.update(filter_id=2)\n",
    "filtermanager.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19a2c96-0b46-4245-a331-75b4f41252a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set it back to the first filter:\n",
    "filtermanager.update(filter_id=1)\n",
    "filtermanager.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fb1a51-c85d-4c82-b790-53fc84ef8285",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>12.2 Use both the time and filter managers to filter out the source data</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa66091-35d2-4110-ba23-21c6889febe6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The <strong>Filter Manager</strong> is accessible within the Vantage system, allowing it to be incorporated into process definitions. It enables processes to work with data that is partitioned based on user-defined filters, ensuring efficient processing of large datasets by splitting the workload into manageable partitions.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Example Usage</strong></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this example, the Filter Manager is used to define partitions, ensuring that each partition of the data is processed sequentially. This approach reduces the volume of data processed at any given time, making it feasible to execute resource-intensive processes on large datasets.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Customization by the User</strong></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>The logic for incorporating the Filter Manager depends on the specific use case and process requirements.</li>\n",
    "    <li>Only the user fully understands the nature of their data and can determine how to define and position the filter to achieve the desired results.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Important Considerations</strong></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Positioning the filter at the end of the process is generally not effective. Filters should typically be applied at the source data or appropriate stages earlier in the process pipeline.</li>\n",
    "    <li>Defining the filter requires domain knowledge to ensure it is applied correctly and effectively for the specific dataset and process.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Ultimately, the responsibility for defining and positioning the filters rests with the user, ensuring alignment with the logic of their processes and the characteristics of their data. The Filter Manager is a powerful tool to optimize processing, but its proper application depends on user expertise.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fff241-8581-4d8d-8707-794d9400d190",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><strong>Registering a Feature Engineering Process with a Filter Manager</strong><p>\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Use the <code>upload_features</code> function to register the process in the feature store. Specify:\n",
    "        <ul>\n",
    "            <li>Which columns represent the <strong>entity</strong> (e.g., <code>customer ID</code>).</li>\n",
    "            <li>Which columns represent the <strong>features</strong> (e.g., transaction statistics).</li>\n",
    "            <li><strong>Attach a Filter Manager:</strong> Add the Filter Manager as an additional argument. This partitions the process into smaller subsets for sequential processing.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Upon execution, the function:\n",
    "        <ul>\n",
    "            <li>Analyzes the process and registers the features and entities in the <strong>Feature Catalog</strong>.</li>\n",
    "            <li>Registers the process in the <strong>Process Catalog</strong>, generating a unique <code>process ID</code>.</li>\n",
    "            <li>Computes the results of the process and ingests them into the feature store, timestamping them with the current time to support time travel queries later.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ol>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Executing Partitioned Processes</strong></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>When the process is run, it will iterate over the partitions defined by the Filter Manager. This sequential processing reduces the volume of data handled at any given time, enabling the execution of large-scale processes on systems with limited resources.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Rerunning and Scheduling Processes</strong></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The generated <code>process_id</code> allows you to rerun or schedule the refresh of a specific process without needing to reference the original code. If the Filter Manager is attached, the process will respect the defined partitions during execution, ensuring consistency and efficiency.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Processing Additional Features</strong></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The same steps can be followed for other feature engineering processes. Each process can be registered and ingested into the feature store using the same workflow, ensuring consistency and efficiency. Adding a Filter Manager further enhances flexibility by supporting partitioned processing where necessary.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ee15c2-589e-4364-b2c7-3b40a1907d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_source = DataFrame.from_query(\n",
    "f\"\"\"\n",
    "SELECT \n",
    "    A.CustomerID\n",
    ",   A.Transaction_Amount\n",
    ",   A.Date_transaction\n",
    ",   A.Category\n",
    ",   A.Merchant_Name\n",
    "FROM {source_database}.transactions A\n",
    ", {filtermanager.schema_name}.{filtermanager.view_name} F\n",
    ", {business_time.schema_name}.{business_time.view_name} T\n",
    "WHERE A.Date_transaction = T.BUSINESS_DATE\n",
    "AND A.Category = F.Category\n",
    "\"\"\"\n",
    ")\n",
    "input_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ec1f3b-a622-438a-9109-64f58046dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_feat_cat = input_source.groupby('Category').agg({'Transaction_Amount':['sum','mean','std','min','max','median']})\n",
    "df_eng_feat_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e0114d-60df-4edb-8f0b-09a145454704",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_feat_cat = df_eng_feat_cat.join(\n",
    "    input_source[['Category','Transaction_Amount']].groupby(\"Category\").percentile(0.25),\n",
    "    on = 'Category',\n",
    "    how = 'inner',\n",
    "    rprefix = 'r'\n",
    ")[df_eng_feat_cat.columns + ['percentile_Transaction_Amount']]\n",
    "df_eng_feat_cat = df_eng_feat_cat.assign(quartile_1_Transaction_Amount=df_eng_feat_cat.percentile_Transaction_Amount)\n",
    "df_eng_feat_cat = df_eng_feat_cat[[c for c in df_eng_feat_cat.columns if c not in ['percentile_Transaction_Amount']]]\n",
    "df_eng_feat_cat = df_eng_feat_cat.join(\n",
    "    input_source[['Category','Transaction_Amount']].groupby(\"Category\").percentile(0.25),\n",
    "    on = 'Category',\n",
    "    how = 'inner',\n",
    "    rprefix = 'r'\n",
    ")[df_eng_feat_cat.columns + ['percentile_Transaction_Amount']]\n",
    "df_eng_feat_cat = df_eng_feat_cat.assign(quartile_3_Transaction_Amount=df_eng_feat_cat.percentile_Transaction_Amount)\n",
    "df_eng_feat_cat = df_eng_feat_cat[[c for c in df_eng_feat_cat.columns if c not in ['percentile_Transaction_Amount']]]\n",
    "df_eng_feat_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8294bf-c1a9-46a5-9f6f-b897bf5d14b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdfs4ds.utils.lineage import crystallize_view\n",
    "df_eng_feat_cat_proc = crystallize_view(df_eng_feat_cat, view_name='FEAT_ENG_CAT_DAILY_FILTERED', schema_name='DEMO_USER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef52ba1-0b8b-45be-bdd7-d5cf720bbcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_feat_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d450bd74-1cd5-486e-98c4-c92e1a1291f3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Registering the \"Spending Category Distribution\"</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10192085-b936-4e83-b28c-95302eb6e501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define the entity and the features in the outputs of the process\n",
    "entity   = 'Category'\n",
    "features = ['sum_Transaction_Amount','mean_Transaction_Amount','std_Transaction_Amount','min_Transaction_Amount','max_Transaction_Amount','median_Transaction_Amount','quartile_1_Transaction_Amount','quartile_3_Transaction_Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d8fbef-066a-4f04-8720-e048c8b6e6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdfs4ds import upload_features\n",
    "upload_features(\n",
    "    df_eng_feat_cat_proc, # <-- the teradata dataframe pointing to the process view\n",
    "    entity_id     = entity,\n",
    "    feature_names = features,\n",
    "    metadata      = {'project' : 'customer transactions'}, # <-- some informative metadata\n",
    "    filtermanager = filtermanager #<-- now we have to tell the feature store there is a filter manager\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e289c99-eddf-4005-b56b-03b9088f1bed",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>After the first upload, we can inspect the contents of the feature store. The feature store maintains two catalogs: a feature catalog and a process catalog.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>This organization ensures that all features and processes are well-documented, accessible, and manageable within the feature store.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16ba8bd-9218-4173-ab96-9aab829c2583",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfs4ds.feature_catalog().show_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b664f0-d6d8-40c0-b046-6ba5f741cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfs4ds.feature_catalog()[['DATA_DOMAIN','FEATURE_ID']].groupby('DATA_DOMAIN').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9527e665-fa35-4a56-a708-a5ae37033c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfs4ds.process_catalog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f197379e-dada-47cb-baf8-2d7eac740533",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfs4ds.process_store.process_query_administration.remove_process('dc4fc42d-5388-4f88-b992-3700cb1e2ced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f006cbd-7e75-45bc-bdb3-6c93fb3916c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfs4ds.feature_catalog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afdf875-d1e9-4aa7-a85f-aed315f9c6b3",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>12.3 Get existing feature engineering processes (process catalog)</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137f66fd-e804-498f-acab-8712e2602469",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We can retrieve the <code>process ID</code> by inspecting the <strong>Process Catalog</strong>. The Process Catalog provides detailed information about all implemented processes, including their associated <code>process ID</code>, entities, features, and other metadata.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Refer to the catalog to identify the relevant <code>process ID</code> for the feature or process you wish to refresh.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a9ea0b-5538-45b2-84ec-8e29954f9e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a data domain for this use case\n",
    "tdfs4ds.DATA_DOMAIN = \"Customer Transaction Analytics Time and Category Management\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf7391f-0932-438c-8ae0-9f115f9c11e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfs4ds.process_catalog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38aad7a-2c18-4b96-9a0e-cfa294fa8281",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_process_views = tdfs4ds.process_catalog()[['VIEW_NAME']].to_pandas().VIEW_NAME.values\n",
    "view_cat  = [c for c in list_process_views if 'CAT_DAILY_FILTERED' in c][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b380ab8-ae6a-4310-87bd-fb2f51bfe88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_id_cat  = tdfs4ds.process_store.process_query_administration.get_process_id(view_name=view_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1017db04-a001-4f95-ab5d-19fdbac27c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('process_id_cat  : ',process_id_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a83e3-c8b5-4dbc-9ff1-31eb91f1b104",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<p style = 'font-size:20px;font-family:Arial'><b>13 Roll out existing processes over time</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b9d2f6-def6-478e-8b91-b8de7d859202",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The first step is to retrieve the <strong>Time Manager</strong>. If a Time Manager already exists, the constructor will connect to it. If it does not exist, the constructor will create a new one.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Verifying the Starting Point</strong></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>To ensure the process starts from the first date in the Time Manager, use the <code>get_current_step</code> method.</li>\n",
    "    <li>If <code>get_current_step</code> returns <code>1</code>, the process will start at the first date.</li>\n",
    "    <li>If it does not return <code>1</code>, you can specify the starting <code>time_id</code> directly in the <code>roll_out</code> function.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><strong>Practical Usage</strong></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>By checking and setting the starting point, you can ensure the process begins from the correct date, whether performing a full run or focusing on a specific range of dates.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba1154-3e7e-4184-99e8-cccb9be5782c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Get the time manager</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1b6a1a-6d9e-47a6-865f-7a838dbb63c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdfs4ds.utils.time_management import TimeManager\n",
    "# this create the BUSINESS_DATE view pointing to the BUSINESS_DATE_HIDDEN table\n",
    "business_time = TimeManager(table_name = 'BUSINESS_DATE_SEQ', schema_name = 'DEMO_USER')\n",
    "business_time.get_current_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7a6f4b-7aa9-451c-b49f-82ded5c973b8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'>Trigger the roll out</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26def3be-bf75-407f-80b5-92902d248ff0",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Using <code>roll_out</code>, you can efficiently update features over time, ensuring the feature store reflects the desired historical data timeline.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>As we can see, the <code>roll_out</code> does not require any filter manager specification, since the filter manager is part of the process definition itself.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648b1bfc-21b1-45c9-85f4-d3553ff78e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdfs4ds import roll_out\n",
    "roll_out(\n",
    "    process_list = [process_id_cat],\n",
    "    time_manager = business_time,\n",
    "    time_id_start= 136,\n",
    "    time_id_end  = 140\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e8b6e6-5769-4e8f-bbab-a312e6f95e41",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;\">\n",
    "<p style = 'font-size:18px;font-family:Arial'><b>13.1 the Follow-up Table</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a323d34c-887c-40b4-9203-4eb65173ea5a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><strong>Key Information in the Follow-Up Table </strong></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><strong>Run ID:</strong> Identifies each triggered run.</li>\n",
    "    <li><strong>Process Type:</strong> Indicates the type of process (e.g., upload).</li>\n",
    "    <li><strong>Process ID:</strong> The ID of the process being executed.</li>\n",
    "    <li><strong>Start and Completion Times:</strong> Timestamps indicating when the process started and finished.</li>\n",
    "    <li><strong>Valid Time:</strong> The time at which the data was inserted into the feature store.</li>\n",
    "    <li><strong>Status:</strong> Tracks the current state of the process (e.g., running, failed, or completed).</li>\n",
    "    <li><strong>Additional Metadata:</strong> Includes other relevant details to aid in monitoring and debugging.</li>\n",
    "</ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Note the <strong>APPLIED_FILTER</strong> column which identifies the filter manager state of a executed process</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf4bfa2-f41d-49dc-b3e9-23369fa72af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfs4ds.process_store.process_followup.follow_up_report().sort('START_DATETIME', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30914249-4a0d-4211-9e83-85a0513336a0",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;\">\n",
    "<b style = 'font-size:20px;font-family:Arial'>10. Cleanup</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial'> <b>Work Tables </b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1824918f-9cf3-441b-b69e-63a2495276d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tables = db_list_tables()\n",
    "list_of_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80807a3-a2d1-4a6b-ac9a-44fec31f1eee",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Drop Views</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31240a0d-55e2-404f-9488-9b66e857ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tables = db_list_tables()\n",
    "[execute_sql(f\"DROP VIEW DEMO_USER.{t}\") for t in list_of_tables.TableName if t.startswith('FS_V')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4588219f-39fd-4f98-87a5-fe8cdb72a65e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Drop Tables</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ee0081-8cac-416e-9658-19baf0437347",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tables = db_list_tables()\n",
    "[execute_sql(f\"DROP TABLE DEMO_USER.{t}\") for t in list_of_tables.TableName if t.startswith('FS_T')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a7e45b-1f7f-4fe9-ad27-3d8a9e678a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tables = db_list_tables()\n",
    "[execute_sql(f\"DROP TABLE DEMO_USER.{t}\") for t in list_of_tables.TableName if t.startswith('FS_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6000f037-96a1-4f70-ae29-2ed36a8bd430",
   "metadata": {},
   "outputs": [],
   "source": [
    "[execute_sql(f\"DROP VIEW DEMO_USER.{t}\") for t in list_of_tables.TableName if t in ['FEAT_ENG_CAT','FEAT_ENG_CUST']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b2d8cb-16c8-4378-8f0d-599479a3d619",
   "metadata": {},
   "outputs": [],
   "source": [
    "[execute_sql(f\"DROP TABLE DEMO_USER.{t}\") for t in list_of_tables.TableName if t in ['temp','tdfs__fgjnojnsmdoignmosnig']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8520d154-91af-414b-8715-21f1b518063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[execute_sql(f\"DROP VIEW DEMO_USER.{t}\") for t in list_of_tables.TableName if t in ['BUSINESS_FILTER','BUSINESS_DATE_SEQ','BUSINESS_DATE','HYBRID_BUSINESS_FILTER']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15e4ad7-2611-451c-81f1-01c2318eec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[execute_sql(f\"DROP TABLE DEMO_USER.{t}\") for t in list_of_tables.TableName if 'HIDDEN' in t ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64138a15-1864-4e2c-be66-83e76ff0cd2e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a24df3d-977e-4705-9708-7a5352a2609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../../UseCases/run_procedure.py \"call remove_data('DEMO_FeatureEngg');\" \n",
    "# #Takes 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17290d9c-71ef-4abd-abf5-01d99e33ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc82937c-c638-4e30-a285-876418b415fc",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; border-bottom:3px solid #91A0Ab\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2024. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
