{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2567a6ef-5562-4276-8df4-d8c3345dc4cc",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Vector Embeddings<br>\n",
    "   <span style=\"font-size: 20px;\">An introduction to generate vector embeddings using HuggingFace models in-Vantage</span>\n",
    "       \n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86b76b9-1dd0-444f-96ef-1baf0933a37f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Introduction</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "Hugging Face is a French-American company based in New York City that develops computation tools for building applications using machine learning. They are known for their <b>Transformers Library</b> which provides open-source implementations of transformer models for text, image, video, audio tasks including time-series. These models include well-known architectures like BERT and GPT. The library is compatible with PyTorch, TensorFlow, and JAX deep learning libraries. <br>\n",
    "    Deep Learning Models in HuggingFace are pre-trained by users/open source outfits/companies on various types of data – NLP, Audio, Images, Videos etc. Most popular tool of choice by users is PyTorch (open source python library) which helps create a Deep Learning model from scratch or take an existing model, retrain/fine-tune (Transfer Learning) on new set of data to be published in HF. Models can be inference with CPUs and GPUs with slight performance improvement for smaller models.<br>\n",
    "</p>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Why Vantage?</b></p>  \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>As many Hugging Face models are available in <b>ONNX Runtime</b>, we can load them using the <b>BYOM</b> feature of Vantage and run them in Vantage. Because of <b>Graph Optimizations</b> on ONNX Runtime, there are proven benchmarks that show that inference with <b>ONNX Runtime will be 20% faster than a native PyTorch model on a CPU</b>. </p>\n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Vantage Parallelism</b> on top of boosted ONNX Runtime inference can turn a Vantage system as effective as inference on GPUs. If we have a <b>Vantage box with 72 AMPs</b>, assuming the table is perfectly distributed, it will <b>closely match the performance of a dedicated GPU and data never moves across the network saving time and I/O operations</b>. As parallelism increases with number of AMPs, the model inference will complete faster in Teradata Vantage with the same amount of text data vs a GPU. We can of course quantize the model (change float8 weights to int8/int4) for inference on CPU to go even faster with some tradeoff with accuracy. However, If Model size goes up GPU advantage will widen – example LLM like LLama3 and costs will be disproportionate with GPU but for smaller models we can get comparable performance. \n",
    "</p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Overall flow:</b></p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bfa8e1-e77a-4b7a-b54f-536ee41e96f0",
   "metadata": {},
   "source": [
    "<center><img src=\"../../../UseCases/Language_Models_InVantage/images/pat1.png\" alt=\"Design pattern 1\" width=1200 height=900/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c281f40-3409-4a0b-b642-22d13d252a3e",
   "metadata": {},
   "source": [
    "<hr style='height:2px;border:none;background-color:#00233C;'>\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233c'>1. Configuring the environment</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86ce2fa-1722-425f-a325-4c7ac5e21968",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>1.1 Install the required libraries</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6405d1-ea63-42e6-a012-2aedb45f0228",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install tdstone2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d888ee6-aa18-402c-b277-7a84ee3620db",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note: </b><i>Please restart the kernel after executing these two lines. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b>\n",
    "</i>\n",
    "    <br>You can remove or comment the <b>%%capture</b> is you want to observe what <i>!pip install</i> is doing. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654a1960-257e-496d-a565-c3eee6bddec6",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233c'><b>1.2 Import the required libraries</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678dd728-e926-41c8-8c95-1f9a371ed873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from teradataml import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0ca04a-da4a-4b66-a548-13e95ee6f5ba",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>2. Connect to Vantage</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell. Begin running steps with Shift + Enter keys.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd4855-ac57-4241-9d12-024b0d2cbae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../../../UseCases/startup.ipynb\n",
    "eng = create_context(host='host.docker.internal', username='demo_user', password=password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ccda78-2923-49ed-873d-58183d725c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql(\"SET query_band='DEMO=PP_Vectore_Embedding_iVSM.ipynb;' UPDATE FOR SESSION;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a5750-87e5-4d72-8f00-5c9f96a9d009",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Optional step – We should execute the below step only if we want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49645f4-2888-41f9-a03b-6a9628d1a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cc673b-3790-4652-8107-fc46781519f9",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>3. Getting data for this demo</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2108b8-0533-4e8b-8f09-6476dc0274c7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will generate the required data. The data we are creating is categorized by typical software issues and some questions that are typically asked. To simplify the process we will insert the data into a python dictionary, load it into pandas dataframe, and than copy the dataframeinto a table in Vantage.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0635eb-0bf6-44b3-8b49-942d34f66470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the three types of software problems and corresponding questions\n",
    "problems_data = {\n",
    "    \"Problem_Type\": [\"Installation Issue\", \"Performance Issue\", \"Functionality Issue\"],\n",
    "    \"User_Question\": [\n",
    "        [\n",
    "            \"Why can't I install the software on my machine?\",\n",
    "            \"What do I do if the installer keeps crashing?\",\n",
    "            \"How do I resolve dependency errors during installation?\",\n",
    "            \"Why is my antivirus blocking the software installation?\"\n",
    "        ],\n",
    "        [\n",
    "            \"Why is the software running so slowly?\",\n",
    "            \"How do I fix memory issues causing the software to crash?\",\n",
    "            \"What can I do if the software takes too long to load?\",\n",
    "            \"Why is the CPU usage so high when using the software?\"\n",
    "        ],\n",
    "        [\n",
    "            \"Why is the 'Save' button not working?\",\n",
    "            \"How do I troubleshoot errors when trying to export data?\",\n",
    "            \"Why does the software keep freezing when I try to open certain files?\",\n",
    "            \"What should I do if features are missing after an update?\"\n",
    "        ]\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a pandas DataFrame\n",
    "df = pd.DataFrame(problems_data)\n",
    "\n",
    "# Expanding the dataframe so each row corresponds to one question\n",
    "expanded_rows = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    problem_type = row[\"Problem_Type\"]\n",
    "    questions = row[\"User_Question\"]\n",
    "    for question in questions:\n",
    "        expanded_rows.append({\"Problem_Type\": problem_type, \"User_Question\": question})\n",
    "\n",
    "# Create a new DataFrame with the expanded rows\n",
    "df = pd.DataFrame(expanded_rows)\n",
    "df['id'] = df.index\n",
    "df = df[['id','Problem_Type','User_Question']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a044bd7e-7166-4045-96af-a6d8bc82d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(df, table_name = 'questions', if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0964b5-b1a0-4685-89e7-5d1215e3e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataFrame('questions')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c3a1db-49ac-4343-a5e1-586d835d997c",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>4. Data Distribution</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae9a817-acb1-4abe-8823-c5dacb3830db",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will check the number of AMPs available on our system and than based on that we will distribute the data equally on all amps to utilize the complete power of the sytem available to us.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33315afa-c443-4a31-804c-2e2a8dfa22f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_amps = execute_sql('SEL HASHAMP()').fetchall()[0][0]+1\n",
    "nb_amps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ae7bc-2516-47e8-aff9-5078ad569ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdstone2.data_distribution import InverseHash, EquallyDistribute\n",
    "from tdstone2.dataset_generation import gen_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a649f16-7dff-4866-9c21-91443232384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gen_query(dataset[['User_Question']],n=1)[['User_Question']] # Generate a single partition\n",
    "df = gen_query(df, n=nb_amps, replication_column = 'Partition_ID')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1bbc0c-893d-4098-8d1e-1cfb3ae29898",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = EquallyDistribute(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593c9eec-cb0a-4920-a594-1d6d17eb534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(Problem_Type = df.Partition_ID)\n",
    "df = FillRowId(data=df,\n",
    "                    row_id_column='Id'\n",
    "                   ).result\n",
    "df[['Id','Problem_Type','User_Question']].to_sql(\n",
    "    table_name='questions_large',\n",
    "    primary_index = 'Id',\n",
    "    if_exists = 'replace'\n",
    ")\n",
    "dataset_large = DataFrame('questions_large')\n",
    "dataset_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b51e3c-5dcf-43ad-952c-bc8b358c28a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tdstone2.data_distribution import PlotDistribution\n",
    "PlotDistribution('demo_user', 'questions_large', partition = 'Problem_Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df91781-0292-4dca-84af-c0ffa5a11079",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>5. Installing the files in Vantage</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Below command will create the database and functions required for text summarization and embedding models using Huggingface PyTorch models in Vantage.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bb24b9-eb86-4fa1-bc12-ff2a030cbfcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../../../UseCases/Language_Models_InVantage/commands.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for item in data[\"queries\"]:\n",
    "    try:\n",
    "        print('Executing query: ', item[\"query\"])\n",
    "        execute_sql(item[\"query\"])\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"The initialization steps have already been executed for this environment!\"\n",
    "        )\n",
    "        # print(f\"Error: {e}\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b0d807-94d1-4e26-b766-4d05cf1a3be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdstone2.tdsgenai import install_model_in_vantage_from_name_for_byom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c55208a-a30a-4b09-bdb4-9df1ea4392b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "install_model_in_vantage_from_name_for_byom(\n",
    "    sequence_length=256,\n",
    "    model_name = 'BAAI/bge-small-en-v1.5',\n",
    "    model_task = 'feature-extraction',\n",
    "    replace = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d8e2a2-ecaa-48ef-9555-fbb2a10de6db",
   "metadata": {},
   "source": [
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>Check installed files</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bac667-5806-457e-bd47-6bb052e3d46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdstone2.tdsgenai import list_installed_files_byom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8952af0e-6a99-4297-9028-0d2e26f30158",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_installed_files_byom()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf93089b-70ff-441f-b493-2c37526164c7",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>6. Compute Vector Embeddings</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6974f0-3426-4a15-82b0-68cfef75ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataFrame('questions')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30da0e8a-f346-4d5c-b8e4-5051ebc92200",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'tdstone2_emb_256_BAAI_bge-small-en-v1.5'\n",
    "get_model_dimension(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43722399-835a-4941-bf48-768712594328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdstone2.tdsgenai import compute_vector_embedding_byom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289b4063-08bb-4c7c-8879-07e87f10639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = compute_vector_embedding_byom(\n",
    "    # choose your language model\n",
    "    model              = 'tdstone2_emb_256_BAAI_bge-small-en-v1.5',\n",
    "    # the description of the dataset\n",
    "    dataset            = dataset,           # the teradata dataframeS\n",
    "    text_column        = 'User_Question',   # the column containing the text\n",
    "    accumulate_columns = ['id','User_Question'],  # the columns we want to keep in the output results\n",
    "    # the output table\n",
    "    schema_name        = 'demo_user', # the database \n",
    "    table_name         = 'embeddings_ivsm', # the output table name\n",
    "    primary_index      = ['id'],            # the primary index columns\n",
    "    # choose ivsm instead of onnxembeddins\n",
    "    mldb_function      = 'iVSM'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b95340-aea4-445f-8ed4-62b220d018db",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d7e7e-0bd0-4265-a9cb-b44d5138ab8a",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>7. Cleanup</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:##00233C'><b>Work Tables</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1802873-7f52-4e66-b4e0-084998667053",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['questions', 'questions_large','embeddings>ivsm']\n",
    "\n",
    "# Loop through the list of tables and execute the drop table command for each table\n",
    "for table in tables:\n",
    "    try:\n",
    "        db_drop_table(table_name=table)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c34a7b-5769-4eca-a5ac-e85bacd6f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed47344-fe8f-4dc3-a8b3-6452d482ab92",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2025. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
