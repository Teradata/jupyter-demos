{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2736aaae-046a-4c71-a97c-26d63c39e5c9",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Huggingface model using Script Table Operator(STO)\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcc73f6-de05-4c0e-9d8a-5739f8a810c1",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Introduction:</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "Hugging Face is a French-American company based in New York City that develops computation tools for building applications using machine learning. They are known for their <b>Transformers Library</b> which provides open-source implementations of transformer models for text, image, video, audio tasks including time-series. These models include well-known architectures like BERT and GPT. The library is compatible with PyTorch, TensorFlow, and JAX deep learning libraries. <br>\n",
    "    Deep Learning Models in HuggingFace are pretrained by users/open source outfits/companies on various types of data – NLP, Audio, Images, Videos etc. Most popular tool of choice by users is PyTorch (open source python library) which helps create a Deep Learning model from scratch or take an existing model, retrain/fine-tune (Transfer Learning) on new set of data to be published in HF. Models can be inferenced with CPUs and GPUs with slight performance improvement for smaller models.<br>\n",
    "</p>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Why Vantage?</b></p>  \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>As many Hugging Face models are availble in ONNX Runtime, we can load them using the BYOM feature of Vantage and run them in Vantage. Because of Graph Optimizations on ONNX Runtime, there are proven benchmarks that show that inference with ONNX Runtime will be 20% faster than a native PyTorch model on a CPU. Vantage Parallelism on top of boosted ONNX Runtime inference can turn a Vantage system as effective as inference on GPUs. If we have a Vantage box with 72 AMPs, assuming the table is perfectly distributed, it will closely match the performance of a dedicated GPU and data never moves across the network saving time and I/O operations. As parallelism increases with number of AMPs, the model inference will complete faster in Teradata Vantage with the same amount of text data vs a GPU. We can of course quantize the model (change float8 weights to int8/int4) for inference on CPU to go even faster with some tradeoff with accuracy. However, If Model size goes up GPU advantage will widen – example LLM like LLama2 and costs will be disproportionate with GPU but for smaller models we can get comparable performance. \n",
    "</p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    This notebook demonstrates the ability to use Huggingface model in Vantage Script table operator(STO) for an On Prem Enterprise edition of Vantage.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc5bd91-74af-4de9-983e-769561857a45",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>1. Connect to Vantage</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06a0041-c447-4506-87fe-fae4d48fc1cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tdstone2==0.1.3.13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac596eaf-6801-4e66-9007-870d88906a8e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note: </b><i>The above statements may need to be uncommented if you run the notebooks on a platform other than ClearScape Analytics Experience that does not have the libraries installed. If you uncomment those installs, be sure to restart the kernel after executing those lines to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa92dce1-ee7c-42cb-8a3f-a995d41f51c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from teradataml import (create_context,execute_sql, copy_to_sql, DataFrame,remove_context)\n",
    "import tdstone2\n",
    "\n",
    "# Modify the following to match the specific client environment settings\n",
    "display.max_rows = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de7f1e2-be50-4ba8-a174-ae516dc59556",
   "metadata": {},
   "source": [
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>You will be prompted to provide the password. Enter your password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4973a39d-8e67-4c94-85c8-36a876a68c5c",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "teradata sql"
    }
   },
   "outputs": [],
   "source": [
    "%run -i ../UseCases/startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e737b384-6e0f-48e1-baee-d0882435d173",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Setup for execution of notebook. Begin running steps with Shift + Enter keys.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da0e5de-c583-461e-a701-6b0512fc6413",
   "metadata": {
    "vscode": {
     "languageId": "teradata sql"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=PP_HuggingFace_model_STO_Python.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116ecab4-14ac-4245-97e7-a0935eea88fe",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>2. Getting Data for This Demo</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef45f47-9bdb-4a01-b01b-3626e869d1ad",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will generate the required data. The data we are generating is related to software issues and the questions related to these issues that can be asked. To simplify the process we will generate the data load it into pandas daraframe and than copy the data inot Vantage.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013a8b6d-1998-4d6a-9fd1-70687660ddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the three types of software problems and corresponding questions\n",
    "problems_data = {\n",
    "    \"Problem_Type\": [\"Installation Issue\", \"Performance Issue\", \"Functionality Issue\"],\n",
    "    \"User_Question\": [\n",
    "        [\n",
    "            \"Why can't I install the software on my machine?\",\n",
    "            \"What do I do if the installer keeps crashing?\",\n",
    "            \"How do I resolve dependency errors during installation?\",\n",
    "            \"Why is my antivirus blocking the software installation?\"\n",
    "        ],\n",
    "        [\n",
    "            \"Why is the software running so slowly?\",\n",
    "            \"How do I fix memory issues causing the software to crash?\",\n",
    "            \"What can I do if the software takes too long to load?\",\n",
    "            \"Why is the CPU usage so high when using the software?\"\n",
    "        ],\n",
    "        [\n",
    "            \"Why is the 'Save' button not working?\",\n",
    "            \"How do I troubleshoot errors when trying to export data?\",\n",
    "            \"Why does the software keep freezing when I try to open certain files?\",\n",
    "            \"What should I do if features are missing after an update?\"\n",
    "        ]\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a pandas DataFrame\n",
    "df = pd.DataFrame(problems_data)\n",
    "\n",
    "# Expanding the dataframe so each row corresponds to one question\n",
    "expanded_rows = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    problem_type = row[\"Problem_Type\"]\n",
    "    questions = row[\"User_Question\"]\n",
    "    for question in questions:\n",
    "        expanded_rows.append({\"Problem_Type\": problem_type, \"User_Question\": question})\n",
    "\n",
    "# Create a new DataFrame with the expanded rows\n",
    "df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332fd417-0f60-4970-a1c8-a1baa5cdb015",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(df,table_name = 'questions', if_exists = 'replace')\n",
    "dataset = DataFrame('questions')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eba780-c37a-48d9-b456-8e42e47108bd",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>3. Huggingface model usage with Vantage STO</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the tdstone2 package to install the generic python files that enables ml training, scoring, feature engineering and vector embedding computations. These files are installed once, and enable user friendly interactions with the platform, like vector embedding as you will see in the following.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b660daf7-20a4-4457-86e0-2798d91ade62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdstone2.tdstone import TDStone\n",
    "sto = TDStone(schema_name = 'demo_user', SEARCHUIFDBPATH = 'demo_user')\n",
    "sto.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14650d53-581d-4703-98c1-c06f8d32fbde",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will install the necessary libraries into the sto environment of Vantage. PushFile installs the py file, including the py file that implements the vector embedding.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8118f00-76e3-479a-8870-741cc96c8653",
   "metadata": {},
   "outputs": [],
   "source": [
    "sto.PushFile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7be20d-ad99-48f8-90f6-257ac72912c4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will than install the required models into Vantage. Here, we are using the <code>sentence-transformers/paraphrase-MiniLM-L6-v2</code> and <code>prajjwal1/bert-mini</code> models</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea21695-2b9b-40dc-997c-27913ab49de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdstone2.tdsgenai import install_model_in_vantage_from_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ab45fc-d941-42df-ae4f-ee2fcc1b17d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "install_model_in_vantage_from_name(model_name = 'sentence-transformers/paraphrase-MiniLM-L6-v2', model_task = 'sentence-similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9236e0ee-aaed-4711-8dbc-87525dcc6357",
   "metadata": {},
   "outputs": [],
   "source": [
    "install_model_in_vantage_from_name(model_name = 'prajjwal1/bert-mini')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43cff60-2a14-4b14-b65b-5ed3201a91f4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will check the install models using the list function and as we can see the 2 models we installed above are now available in the Vantage environment.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa62148d-a449-4a87-a830-6469b6ccdf67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tdstone2.tdsgenai import list_installed_files\n",
    "list_installed_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b1218c-55ec-4476-88a8-818ce6e453ec",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will specify the model and the dataset to be used for computing the vector embeddings.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b804f8bf-aabe-468f-ac6c-17f2660f9cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'tdstone2_emb_512_sentence-transformers_paraphrase-MiniLM-L6-v2.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b654c-a565-4b9d-bafb-d62a95807097",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataFrame('questions')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfac3a8-72c7-41e0-937d-2c06d1b53a21",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will specify the details of the dataset. Like, the text column to be used, the hash column that is the primary index so that it helps us in the parallel processing based on the PI column and than the columns that need to be retained.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687035bc-9ede-4434-a9f4-8ca6e738cf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdstone2.tdsgenai import compute_vector_embedding\n",
    "schema_name        = 'demo_user'\n",
    "table_name         = 'embeddings'\n",
    "\n",
    "text_column        = 'User_Question'\n",
    "hash_columns       = ['Problem_Type']\n",
    "accumulate_columns = ['Problem_Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eb6457-f48a-4cf2-bc24-2e8548eaf989",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will than compute the embeddings using the compute function which will use the model and the dataset and than generate the embeddings. The steps involved in the process will be displayed as a part of the output.  compute_vector_embedding function sets up and executes a script for the given model and dataset, ensuring that the text column is VARCHAR\n",
    "and the model exists. Finally, create a pivot view of the results.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284be5d7-5c9b-4f48-8613-35da8dc9b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = compute_vector_embedding(model, dataset, schema_name, table_name, text_column, hash_columns, accumulate_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa3ddb6-be65-4874-b4a3-07df949dc638",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a4a5f8-d7d3-43a4-8753-87cb74ae64b0",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will than execute the run_tds_vector_embedding_script_locally function. It runs the 'tds_vector_embedding.py' script in the data module of the 'tdstone2' package by passing a dataframe via stdin and the required arguments.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853cbb79-a28c-4345-824b-e3c87e76af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdstone2.tdsgenai import run_tds_vector_embedding_script_locally \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f8cd2c-5f30-40ec-a42d-d46334bae7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the three types of software problems and corresponding questions\n",
    "problems_data = {\n",
    "    \"Problem_Type\": [\"Installation Issue\", \"Performance Issue\", \"Functionality Issue\"],\n",
    "    \"User_Question\": [\n",
    "        [\n",
    "            \"Why can't I install the software on my machine?\",\n",
    "            \"What do I do if the installer keeps crashing?\",\n",
    "            \"How do I resolve dependency errors during installation?\",\n",
    "            \"Why is my antivirus blocking the software installation?\"\n",
    "        ],\n",
    "        [\n",
    "            \"Why is the software running so slowly?\",\n",
    "            \"How do I fix memory issues causing the software to crash?\",\n",
    "            \"What can I do if the software takes too long to load?\",\n",
    "            \"Why is the CPU usage so high when using the software?\"\n",
    "        ],\n",
    "        [\n",
    "            \"Why is the 'Save' button not working?\",\n",
    "            \"How do I troubleshoot errors when trying to export data?\",\n",
    "            \"Why does the software keep freezing when I try to open certain files?\",\n",
    "            \"What should I do if features are missing after an update?\"\n",
    "        ]\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a pandas DataFrame\n",
    "df = pd.DataFrame(problems_data)\n",
    "\n",
    "# Expanding the dataframe so each row corresponds to one question\n",
    "expanded_rows = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    problem_type = row[\"Problem_Type\"]\n",
    "    questions = row[\"User_Question\"]\n",
    "    for question in questions:\n",
    "        expanded_rows.append({\"Problem_Type\": problem_type, \"User_Question\": question})\n",
    "\n",
    "# Create a new DataFrame with the expanded rows\n",
    "df = pd.DataFrame(expanded_rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d03d882-2a24-4067-aa77-4457091beede",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will execute the function for both models. </p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The inputs to the function are as below:</p> \n",
    "    <li style = 'font-size:16px;font-family:Arial;color:#00233C'>df (pd.DataFrame): The dataframe to process.</li>\n",
    "        <li style = 'font-size:16px;font-family:Arial;color:#00233C'>zip_file_path (str): The path to the zip file.</li>\n",
    "        <li style = 'font-size:16px;font-family:Arial;color:#00233C'>text_column (int): The index of the text column in the dataframe.</li>\n",
    "        <li style = 'font-size:16px;font-family:Arial;color:#00233C'>accumulate_columns (list): The list of column indexes to accumulate and print.</li></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe5d491-96e1-4ee7-8a3e-ab3e1c0224f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the arguments\n",
    "zip_file_path      = \"models/sentence-transformers_paraphrase-MiniLM-L6-v2/\"  # Replace with actual path\n",
    "text_column        = 'User_Question'  # Assuming 'text' column is at index 0\n",
    "accumulate_columns = ['Problem_Type']  # Indices of other columns to accumulate\n",
    "\n",
    "# Run the script\n",
    "output = run_tds_vector_embedding_script_locally(df, zip_file_path, text_column, accumulate_columns)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db067c3f-23cd-4e9c-af61-5eb6f3a85331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the arguments\n",
    "zip_file_path      = \"models/prajjwal1_bert-mini/\"  # Replace with actual path\n",
    "text_column        = 'User_Question'  # Assuming 'text' column is at index 0\n",
    "accumulate_columns = ['Problem_Type']  # Indices of other columns to accumulate\n",
    "\n",
    "# Run the script\n",
    "output = run_tds_vector_embedding_script_locally(df, zip_file_path, text_column, accumulate_columns)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbc7a5f-e28b-4dfe-96ca-4c1be88c242a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will than compute the embeddings using the SentenceTranformer to verify the embeddings.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cc1b3e-1826-4880-a809-75f70296b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('prajjwal1/bert-mini')\n",
    "model.encode(output.index[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3e5edc-5697-4c5c-b378-59c964bdee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/paraphrase-MiniLM-L6-v2')\n",
    "model.encode(output.index[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb859e90-6861-46bc-91c6-292a106b01fb",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We can use these functions and process for business use cases like finding similarity, clustering or topic modelling etc.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb076ff-297e-47fb-97d9-7d52a0068c7b",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>4. Cleanup</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:##00233C'><b>Work Tables</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d5b0dd-bf5c-44a9-9d45-c4479b67eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['questions', 'T_embeddings','TDS_MODEL_REPOSITORY','TDS_MAPPER_REPOSITORY','TDS_HYPER_MODEL_REPOSITORY',\n",
    "          'TDS_FEATURE_ENGINEERING_PROCESS_REPOSITORY','TDS_CODE_REPOSITORY']\n",
    "\n",
    "# Loop through the list of tables and execute the drop table command for each table\n",
    "for table in tables:\n",
    "    try:\n",
    "        db_drop_table(table_name=table)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "try:\n",
    "    db_drop_view('embeddings')\n",
    "except:\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e35e86c-e3e8-4ef7-a68f-f1ca5126b8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79524f61-15a5-4a01-bd10-94577e4b3aab",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2024. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
